{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AIModel.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U15L-7kEOFy6",
        "outputId": "3c842f70-708f-4989-a3b3-45bf5813992d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.12.1+cu113)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (4.1.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from collections import Counter\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torch.optim as torch_optim\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import models\n",
        "from datetime import datetime\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NSeLEDL_S5fk",
        "outputId": "56673789-645c-48d2-c14d-9285b0b8932d"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ComplexityDataset(Dataset):\n",
        "    def __init__(self, csv_file):\n",
        "\n",
        "        df = pd.read_csv(csv_file)\n",
        "        df = df.drop(labels = \"id\", axis=1)\n",
        "        self.X = df.drop(labels = \"heat\", axis=1)\n",
        "        self.y = df[\"heat\"]\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        # Convert idx from tensor to list due to pandas bug (that arises when using pytorch's random_split)\n",
        "        if isinstance(idx, torch.Tensor):\n",
        "            idx = idx.tolist()\n",
        "\n",
        "        return [self.X.iloc[idx].values, self.y[idx]]\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GMDqHBMHUvTi"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_default_device():\n",
        "    \"\"\"Pick GPU if available, else CPU\"\"\"\n",
        "    if torch.cuda.is_available():\n",
        "        return torch.device('cuda')\n",
        "    else:\n",
        "        return torch.device('cpu')\n",
        "def to_device(data, device):\n",
        "    \"\"\"Move tensor(s) to chosen device\"\"\"\n",
        "    if isinstance(data, (list,tuple)):\n",
        "        return [to_device(x, device) for x in data]\n",
        "    return data.to(device, non_blocking=True)\n",
        "class DeviceDataLoader():\n",
        "    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n",
        "    def __init__(self, dl, device):\n",
        "        self.dl = dl\n",
        "        self.device = device\n",
        "        \n",
        "    def __iter__(self):\n",
        "        \"\"\"Yield a batch of data after moving it to device\"\"\"\n",
        "        for b in self.dl: \n",
        "            yield to_device(b, self.device)\n",
        "\n",
        "    def __len__(self):\n",
        "        \"\"\"Number of batches\"\"\"\n",
        "        return len(self.dl)\n",
        "device = get_default_device()\n",
        "print(device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lQIDVQQXqAkm",
        "outputId": "4df314d5-7387-4ab1-c5b9-b06f77a52bfd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ComplexityNN(nn.Module):\n",
        "\n",
        "    def __init__(self, D_in, D_out=1):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(D_in, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, D_out)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        return x.squeeze()\n"
      ],
      "metadata": {
        "id": "adz8gZgYqkSz"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ComplexityNN(1)\n",
        "print(to_device(model, device))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iqgv966grXGM",
        "outputId": "4ad75b2a-c4f9-46c7-9f98-bb9c21408a95"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ComplexityNN(\n",
            "  (fc1): Linear(in_features=1, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=1, bias=True)\n",
            "  (relu): ReLU()\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def get_optimizer(model, lr = 0.001, wd = 0.0):\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optim = torch_optim.Adam(parameters, lr=lr, weight_decay=wd)\n",
        "    return optim"
      ],
      "metadata": {
        "id": "K7NcdkPzrnsV"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(csv_file, n_epochs=100):\n",
        "    \"\"\"Trains the model.\n",
        "    Args:\n",
        "        csv_file (str): Absolute path of the dataset used for training.\n",
        "        n_epochs (int): Number of epochs to train.\n",
        "    \"\"\"\n",
        "    # Load dataset\n",
        "    # Split into training and test\n",
        "    dataset = ComplexityDataset(csv_file)\n",
        "    train_size = int(0.8 * len(dataset))\n",
        "    test_size = len(dataset) - train_size\n",
        "    trainset, testset = random_split(dataset, [train_size, test_size])\n",
        "\n",
        "    # Dataloaders\n",
        "    trainloader = DataLoader(trainset, batch_size=500, shuffle=True)\n",
        "    testloader = DataLoader(testset, batch_size=500, shuffle=False)\n",
        "\n",
        "    # Use gpu if available\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    # Define the model\n",
        "    D_in = 63\n",
        "    net = ComplexityNN(D_in).to(device)\n",
        "\n",
        "    # Loss function\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Optimizer\n",
        "    optimizer = torch.optim.Adam(net.parameters(), weight_decay=0.0001)\n",
        "\n",
        "    # Train the net\n",
        "    loss_per_iter = []\n",
        "    loss_per_batch = []\n",
        "    for epoch in range(n_epochs):\n",
        "\n",
        "        running_loss = 0.0\n",
        "        for i, (inputs, labels) in enumerate(trainloader):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # Zero the parameter gradients\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward + backward + optimize\n",
        "            outputs = net(inputs.float())\n",
        "            loss = criterion(outputs, labels.float())\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # Save loss to plot\n",
        "            running_loss += loss.item()\n",
        "            loss_per_iter.append(loss.item())\n",
        "\n",
        "        loss_per_batch.append(running_loss / (i + 1))\n",
        "        running_loss = 0.0\n",
        "\n",
        "    # Comparing training to test\n",
        "    dataiter = iter(testloader)\n",
        "    inputs, labels = dataiter.next()\n",
        "    inputs = inputs.to(device)\n",
        "    labels = labels.to(device)\n",
        "    outputs = net(inputs.float())\n",
        "    torch.save(model, '/content/drive/My Drive/model.pt') # Save\n",
        "    print(\"Root mean squared error\")\n",
        "    print(\"Training:\", np.sqrt(loss_per_batch[-1]))\n",
        "    print(\"Test\", np.sqrt(criterion(labels.float(), outputs).detach().cpu().numpy()))\n",
        "\n"
      ],
      "metadata": {
        "id": "wWd-75hmrppC"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "\n",
        "    # By default, read csv file in the same directory as this script\n",
        "    csv_file = ('/content/drive/My Drive/dataset.csv')\n",
        "    train(csv_file, n_epochs=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I01G9rlRuGYB",
        "outputId": "310211a9-80f9-4879-8360-9074a688331f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Root mean squared error\n",
            "Training: 0.1816222325108915\n",
            "Test 0.2130938\n"
          ]
        }
      ]
    }
  ]
}