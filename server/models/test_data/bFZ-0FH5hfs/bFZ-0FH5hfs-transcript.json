[{"text": "The following content is\nprovided under a Creative", "start": 0.12, "duration": 2.34}, {"text": "Commons license.", "start": 2.46, "duration": 1.42}, {"text": "Your support will help\nMIT OpenCourseWare", "start": 3.88, "duration": 2.21}, {"text": "continue to offer high quality\neducational resources for free.", "start": 6.09, "duration": 4.09}, {"text": "To make a donation or to\nview additional materials", "start": 10.18, "duration": 2.54}, {"text": "from hundreds of\nMIT courses, visit", "start": 12.72, "duration": 2.49}, {"text": "MITOpenCourseWare@OCW.MIT.edu", "start": 15.21, "duration": 6.26}, {"text": "PHILIPPE RIGOLLET: So today\nWE'LL actually just do a brief", "start": 21.47, "duration": 5.2}, {"text": "chapter on Bayesian statistics.", "start": 26.67, "duration": 1.92}, {"text": "And there's entire courses\non Bayesian statistics,", "start": 28.59, "duration": 2.79}, {"text": "there's entire books\non Bayesian statistics,", "start": 31.38, "duration": 2.1}, {"text": "there's entire careers\nin Bayesian statistics.", "start": 33.48, "duration": 2.65}, {"text": "So admittedly, I'm\nnot going to be", "start": 36.13, "duration": 3.14}, {"text": "able to do it\njustice and tell you", "start": 39.27, "duration": 1.65}, {"text": "all the interesting\nthings that are happening", "start": 40.92, "duration": 1.93}, {"text": "in Bayesian statistics.", "start": 42.85, "duration": 1.19}, {"text": "But I think it's important\nas a statistician", "start": 44.04, "duration": 3.27}, {"text": "to know what it\nis, how it works,", "start": 47.31, "duration": 2.01}, {"text": "because it's actually\na weapon of choice", "start": 49.32, "duration": 3.18}, {"text": "for many practitioners.", "start": 52.5, "duration": 2.76}, {"text": "And because it allows them to\nincorporate their knowledge", "start": 55.26, "duration": 2.82}, {"text": "about a problem in a\nfairly systematic manner.", "start": 58.08, "duration": 2.71}, {"text": "So if you look at like, say the\nBayesian statistics literature,", "start": 60.79, "duration": 3.309}, {"text": "it's huge.", "start": 64.099, "duration": 1.39}, {"text": "And so here I give\nyou sort of a range", "start": 65.489, "duration": 4.081}, {"text": "of what you can expect to\nsee in Bayesian statistics", "start": 69.57, "duration": 3.27}, {"text": "from your second edition of\na traditional book, something", "start": 72.84, "duration": 5.46}, {"text": "that involves computation,\nsome things that", "start": 78.3, "duration": 2.28}, {"text": "involve risk thinking.", "start": 80.58, "duration": 1.62}, {"text": "And there's a lot of\nBayesian thinking.", "start": 82.2, "duration": 2.55}, {"text": "There's a lot of\nthings that you know", "start": 84.75, "duration": 1.89}, {"text": "talking about sort of like\nphilosophy of thinking", "start": 86.64, "duration": 2.37}, {"text": "Bayesian.", "start": 89.01, "duration": 1.17}, {"text": "This book, for example,\nseems to be one of them.", "start": 90.18, "duration": 2.2}, {"text": "This book is\ndefinitely one of them.", "start": 92.38, "duration": 2.33}, {"text": "This one represents sort of\na wide, a broad literature", "start": 94.71, "duration": 4.17}, {"text": "on Bayesian statistics, for\napplications for example,", "start": 98.88, "duration": 3.49}, {"text": "in social sciences.", "start": 102.37, "duration": 1.25}, {"text": "But even in large\nscale machine learning,", "start": 103.62, "duration": 1.76}, {"text": "there's a lot of Bayesian\nstatistics happening,", "start": 105.38, "duration": 1.96}, {"text": "particular using something\ncalled Bayesian parametrics,", "start": 107.34, "duration": 2.94}, {"text": "or hierarchical\nBayesian modeling.", "start": 110.28, "duration": 3.21}, {"text": "So we do have some experts\nat MIT in the c-cell.", "start": 113.49, "duration": 5.98}, {"text": "Tamara Broderick for\nexample, is a person", "start": 119.47, "duration": 2.6}, {"text": "who does quite a bit\nof interesting work", "start": 122.07, "duration": 2.49}, {"text": "on Bayesian parametrics.", "start": 124.56, "duration": 1.533}, {"text": "And if that's something you\nwant to know more about,", "start": 126.093, "duration": 2.166}, {"text": "I urge you to go\nand talk to her.", "start": 128.259, "duration": 2.63}, {"text": "So before we go into\nmore advanced things,", "start": 130.889, "duration": 3.181}, {"text": "we need to start with what\nis the Bayesian approach.", "start": 134.07, "duration": 3.15}, {"text": "What do Bayesians\ndo, and how is it", "start": 137.22, "duration": 2.07}, {"text": "different from what\nwe've been doing so far?", "start": 139.29, "duration": 3.43}, {"text": "So to understand the\ndifference between Bayesians", "start": 142.72, "duration": 3.62}, {"text": "and what we've been\ndoing so far is,", "start": 146.34, "duration": 2.46}, {"text": "we need to first put a name on\nwhat we've been doing so far.", "start": 148.8, "duration": 2.55}, {"text": "It's called\nfrequentist statistics.", "start": 151.35, "duration": 1.59}, {"text": "Which usually Bayesian versus\nfrequentist statistics,", "start": 152.94, "duration": 3.78}, {"text": "by versus I don't mean\nthat there is naturally", "start": 156.72, "duration": 2.04}, {"text": "in opposition to them.", "start": 158.76, "duration": 1.62}, {"text": "Actually, often you will\nsee the same method that", "start": 160.38, "duration": 2.97}, {"text": "comes out of both approaches.", "start": 163.35, "duration": 2.07}, {"text": "So let's see how\nwe did it, right.", "start": 165.42, "duration": 1.44}, {"text": "The first thing, we had data.", "start": 166.86, "duration": 2.07}, {"text": "We observed some data.", "start": 168.93, "duration": 1.77}, {"text": "And we assumed that this\ndata was generated randomly.", "start": 170.7, "duration": 2.28}, {"text": "The reason we did\nthat is because this", "start": 172.98, "duration": 1.86}, {"text": "would allow us to leverage\ntools from probability.", "start": 174.84, "duration": 3.0}, {"text": "So let's say by nature,\nmeasurements, you do a survey,", "start": 177.84, "duration": 3.18}, {"text": "you get some data.", "start": 181.02, "duration": 2.07}, {"text": "Then we made some assumptions\non the data generating process.", "start": 183.09, "duration": 2.94}, {"text": "For example, we\nassumed they were iid.", "start": 186.03, "duration": 1.909}, {"text": "That was one of the\nrecurring things.", "start": 187.939, "duration": 1.541}, {"text": "Sometimes we assume\nit was Gaussian.", "start": 189.48, "duration": 2.05}, {"text": "If you wanted to\nuse say, T-test.", "start": 191.53, "duration": 1.94}, {"text": "Maybe we did some\nnonparametric statistics.", "start": 193.47, "duration": 1.86}, {"text": "We assume it was a\nsmooth function or maybe", "start": 195.33, "duration": 2.91}, {"text": "linear regression function.", "start": 198.24, "duration": 2.11}, {"text": "So those are our modeling.", "start": 200.35, "duration": 1.19}, {"text": "And this was basically\na way to say, well,", "start": 201.54, "duration": 3.31}, {"text": "we're not going to allow for\nany distributions for the data", "start": 204.85, "duration": 3.59}, {"text": "that we have.", "start": 208.44, "duration": 0.72}, {"text": "But maybe a small\nset of distributions", "start": 209.16, "duration": 2.48}, {"text": "that indexed by some small\nparameters, for example.", "start": 211.64, "duration": 3.13}, {"text": "Or at least remove some\nof the possibilities.", "start": 214.77, "duration": 3.63}, {"text": "Otherwise, there's\nnothing we can learn.", "start": 218.4, "duration": 3.26}, {"text": "And so for example,\nthis was associated", "start": 221.66, "duration": 3.61}, {"text": "to some parameter of\ninterest, say data or beta", "start": 225.27, "duration": 3.71}, {"text": "in the regression model.", "start": 228.98, "duration": 2.29}, {"text": "Then we had this unknown\nproblem and this unknown thing,", "start": 231.27, "duration": 4.59}, {"text": "a known parameter.", "start": 235.86, "duration": 0.75}, {"text": "And we wanted to find it.", "start": 236.61, "duration": 1.041}, {"text": "We wanted to either\nestimate it or test it,", "start": 237.651, "duration": 1.959}, {"text": "or maybe find a confidence\ninterval for the subject.", "start": 239.61, "duration": 2.85}, {"text": "So, so far I should not have\nsaid anything that's new.", "start": 242.46, "duration": 3.57}, {"text": "But this last\nsentence is actually", "start": 246.03, "duration": 2.18}, {"text": "what's going to be different\nfrom the Bayesian part.", "start": 248.21, "duration": 2.38}, {"text": "And particular, this\nunknown but fixed things", "start": 250.59, "duration": 2.399}, {"text": "is what's going to be changing.", "start": 252.989, "duration": 1.291}, {"text": "In the Bayesian\napproach, we still", "start": 256.965, "duration": 1.775}, {"text": "assume that we observe\nsome random data.", "start": 258.74, "duration": 3.31}, {"text": "But the generating process\nis slightly different.", "start": 262.05, "duration": 2.13}, {"text": "It's sort of a\ntwo later process.", "start": 264.18, "duration": 1.557}, {"text": "And there's one\nprocess that generates", "start": 265.737, "duration": 1.583}, {"text": "the parameter and\nthen one process", "start": 267.32, "duration": 1.42}, {"text": "that, given this parameter\ngenerates the data.", "start": 268.74, "duration": 2.73}, {"text": "So what the first layer\ndoes, nobody really", "start": 271.47, "duration": 4.52}, {"text": "believes that there's\nsome random process that's", "start": 275.99, "duration": 2.04}, {"text": "happening, about\ngenerating what is going", "start": 278.03, "duration": 2.97}, {"text": "to be the true expected\nnumber of people", "start": 281.0, "duration": 3.82}, {"text": "who turn their head to\nthe right when they kiss.", "start": 284.82, "duration": 2.24}, {"text": "But this is actually going to\nbe something that brings us", "start": 287.06, "duration": 2.375}, {"text": "some easiness for\nus to incorporate", "start": 289.435, "duration": 3.835}, {"text": "what we call prior belief.", "start": 293.27, "duration": 3.96}, {"text": "We'll see an\nexample in a second.", "start": 297.23, "duration": 1.41}, {"text": "But often, you actually\nhave prior belief", "start": 298.64, "duration": 2.79}, {"text": "of what this\nparameter should be.", "start": 301.43, "duration": 1.53}, {"text": "When we, say least\nsquares, we looked", "start": 302.96, "duration": 2.55}, {"text": "over all of the vectors\nin all of R to the p,", "start": 305.51, "duration": 3.84}, {"text": "including the ones that\nhave coefficients equal", "start": 309.35, "duration": 2.49}, {"text": "to 50 million.", "start": 311.84, "duration": 3.24}, {"text": "Those are things that we\nmight be able to rule out.", "start": 315.08, "duration": 2.97}, {"text": "We might be able to rule out\nthat on a much smaller scale.", "start": 318.05, "duration": 3.75}, {"text": "For example, well\nI'm not an expert", "start": 321.8, "duration": 2.85}, {"text": "on turning your head to\nthe right or to the left.", "start": 324.65, "duration": 4.53}, {"text": "But maybe you can\nrule out the fact", "start": 329.18, "duration": 1.77}, {"text": "that almost everybody\nis turning their head", "start": 330.95, "duration": 2.25}, {"text": "in the same direction, or almost\neverybody is turning their head", "start": 333.2, "duration": 2.79}, {"text": "to another direction.", "start": 335.99, "duration": 2.1}, {"text": "So we have this prior belief.", "start": 338.09, "duration": 1.89}, {"text": "And this belief is going\nto play say, hopefully", "start": 339.98, "duration": 3.77}, {"text": "less and less important role as\nwe collect more and more data.", "start": 343.75, "duration": 3.784}, {"text": "But if we have a\nsmaller amount of data,", "start": 347.534, "duration": 1.666}, {"text": "we might want to be able\nto use this information,", "start": 349.2, "duration": 3.31}, {"text": "rather than just\nshooting in the dark.", "start": 352.51, "duration": 2.19}, {"text": "And so the idea is to\nhave this prior belief.", "start": 354.7, "duration": 3.45}, {"text": "And then, we want to\nupdate this prior belief", "start": 358.15, "duration": 2.28}, {"text": "into what's called the\nposterior belief after we've", "start": 360.43, "duration": 3.12}, {"text": "seen some data.", "start": 363.55, "duration": 1.32}, {"text": "Maybe I believe that\nthere's something", "start": 364.87, "duration": 3.18}, {"text": "that should be in some range.", "start": 368.05, "duration": 1.59}, {"text": "But maybe after I see data, it's\ncomforting me in my beliefs.", "start": 369.64, "duration": 2.94}, {"text": "So I'm actually having\nmaybe a belief that's more.", "start": 372.58, "duration": 2.75}, {"text": "So belief encompasses\nbasically what you think", "start": 375.33, "duration": 3.13}, {"text": "and how strongly\nyou think about it.", "start": 378.46, "duration": 1.54}, {"text": "That's what I call belief.", "start": 380.0, "duration": 1.37}, {"text": "So for example, if I have a\nbelief about some parameter", "start": 381.37, "duration": 2.7}, {"text": "theta, maybe my\nbelief is telling me", "start": 384.07, "duration": 1.98}, {"text": "where theta should\nbe and how strongly I", "start": 386.05, "duration": 2.92}, {"text": "believe in it, in the sense\nthat I have a very narrow region", "start": 388.97, "duration": 3.95}, {"text": "where theta could be.", "start": 392.92, "duration": 2.55}, {"text": "The posterior beliefs, as\nwell, you see some data.", "start": 395.47, "duration": 2.34}, {"text": "And maybe you're more confident\nor less confident about what", "start": 397.81, "duration": 2.19}, {"text": "you've seen.", "start": 400.0, "duration": 0.499}, {"text": "Maybe you've shifted\nyour belief a little bit.", "start": 400.499, "duration": 2.297}, {"text": "And so that's what we're\ngoing to try to see,", "start": 402.796, "duration": 1.874}, {"text": "and how to do this in\na principal manner.", "start": 404.67, "duration": 3.96}, {"text": "To understand this\nbetter, there's", "start": 408.63, "duration": 1.56}, {"text": "nothing better than an example.", "start": 410.19, "duration": 1.96}, {"text": "So let's talk about another\nstupid statistical question.", "start": 412.15, "duration": 4.07}, {"text": "Which is, let's try\nto understand p.", "start": 416.22, "duration": 2.4}, {"text": "Of course, I'm not going to\ntalk about politics from now on.", "start": 418.62, "duration": 2.81}, {"text": "So let's talk about p,\nthe proportion of women", "start": 421.43, "duration": 2.5}, {"text": "in the population.", "start": 423.93, "duration": 1.02}, {"text": "And so what I could do is\nto collect some data, X1, Xn", "start": 435.33, "duration": 6.52}, {"text": "and assume that\nthey're Bernoulli", "start": 441.85, "duration": 2.1}, {"text": "with some parameter, p unknown.", "start": 443.95, "duration": 1.95}, {"text": "So p is in 0, 1.", "start": 445.9, "duration": 4.91}, {"text": "OK, let's assume that\nthose guys are iid.", "start": 450.81, "duration": 2.46}, {"text": "So this is just an indicator\nfor each of my collected data,", "start": 453.27, "duration": 4.92}, {"text": "whether the person I randomly\nsample is a woman, I get a one.", "start": 458.19, "duration": 3.94}, {"text": "If it's a man, I get a zero.", "start": 462.13, "duration": 1.22}, {"text": "Now the question is, I\nsample these people randomly.", "start": 466.2, "duration": 3.27}, {"text": "I do you know their gender.", "start": 469.47, "duration": 2.09}, {"text": "And the frequentist\napproach was just saying,", "start": 471.56, "duration": 3.04}, {"text": "OK, let's just estimate\np hat being Xn bar.", "start": 474.6, "duration": 3.65}, {"text": "And then we could do some tests.", "start": 478.25, "duration": 2.86}, {"text": "So here, there's a test.", "start": 481.11, "duration": 1.13}, {"text": "I want to test maybe if\np is equal to 0.5 or not.", "start": 482.24, "duration": 3.09}, {"text": "That sounds like a pretty\nreasonable thing to test.", "start": 485.33, "duration": 4.38}, {"text": "But we want to also\nmaybe estimate p.", "start": 489.71, "duration": 3.39}, {"text": "But here, this is a case where\nwe definitely prior belief", "start": 493.1, "duration": 3.06}, {"text": "of what p should be.", "start": 496.16, "duration": 1.56}, {"text": "We are pretty confident that\np is not going to be 0.7.", "start": 497.72, "duration": 4.32}, {"text": "We actually believe\nthat we should", "start": 502.04, "duration": 1.53}, {"text": "be extremely close to one\nhalf, but maybe not exactly.", "start": 503.57, "duration": 5.76}, {"text": "Maybe this population is not\nthe population in the world.", "start": 509.33, "duration": 3.349}, {"text": "But maybe this is the\npopulation of, say some college", "start": 512.679, "duration": 2.98}, {"text": "and we want to understand if\nthis college has half women", "start": 515.659, "duration": 3.061}, {"text": "or not.", "start": 518.72, "duration": 1.349}, {"text": "Maybe we know it's going\nto be close to one half,", "start": 520.069, "duration": 2.041}, {"text": "but maybe we're not quite sure.", "start": 522.11, "duration": 1.35}, {"text": "We're going to want to\nintegrate that knowledge.", "start": 526.84, "duration": 3.12}, {"text": "So I could integrate it in\na blunt manner by saying,", "start": 529.96, "duration": 2.7}, {"text": "discard the data and say\nthat p is equal to one half.", "start": 532.66, "duration": 2.76}, {"text": "But maybe that's just\na little too much.", "start": 535.42, "duration": 2.23}, {"text": "So how do I do this trade\noff between adding the data", "start": 537.65, "duration": 3.71}, {"text": "and combining it with\nthis prior knowledge?", "start": 541.36, "duration": 5.4}, {"text": "In many instances, essentially\nwhat's going to happen", "start": 546.76, "duration": 2.85}, {"text": "is this one half is going to\nact like one new observation.", "start": 549.61, "duration": 4.72}, {"text": "So if you have\nfive observations,", "start": 554.33, "duration": 2.732}, {"text": "this is just the\nsixth observation,", "start": 557.062, "duration": 1.458}, {"text": "which will play a role.", "start": 558.52, "duration": 1.72}, {"text": "If you have a\nmillion observations,", "start": 560.24, "duration": 1.55}, {"text": "you're going to have\na million and one.", "start": 561.79, "duration": 1.07}, {"text": "It's not going to play\nso much of a role.", "start": 562.86, "duration": 1.708}, {"text": "That's basically how it goes.", "start": 564.568, "duration": 1.332}, {"text": "But, definitely not\nalways because we'll", "start": 568.76, "duration": 4.71}, {"text": "see that if I take my prior to\nbe a point minus one half here,", "start": 573.47, "duration": 3.23}, {"text": "it's basically as if I\nwas discarding my data.", "start": 576.7, "duration": 2.59}, {"text": "So essentially, there's\nalso your ability", "start": 579.29, "duration": 2.45}, {"text": "to encompass how strongly\nyou believe in this prior.", "start": 581.74, "duration": 3.78}, {"text": "And if you believe\ninfinitely more in the prior", "start": 585.52, "duration": 2.289}, {"text": "than you believe in\nthe data you collected,", "start": 587.809, "duration": 1.791}, {"text": "then it's not going to act\nlike one more observation.", "start": 589.6, "duration": 5.0}, {"text": "The Bayesian approach\nis a tool to one,", "start": 594.6, "duration": 2.22}, {"text": "include mathematically\nour prior.", "start": 596.82, "duration": 2.19}, {"text": "And our prior belief into\nstatistical procedures.", "start": 599.01, "duration": 3.57}, {"text": "Maybe I have this\nprior knowledge.", "start": 602.58, "duration": 1.45}, {"text": "But if I'm a medical\ndoctor, it's not clear to me", "start": 604.03, "duration": 2.06}, {"text": "how I'm going to turn this into\nsome principal way of building", "start": 606.09, "duration": 3.78}, {"text": "estimators.", "start": 609.87, "duration": 0.54}, {"text": "And the second\ngoal is going to be", "start": 610.41, "duration": 1.92}, {"text": "to update this prior belief\ninto a posterior belief", "start": 612.33, "duration": 3.93}, {"text": "by using the data.", "start": 616.26, "duration": 1.01}, {"text": "How do I do this?", "start": 622.2, "duration": 1.717}, {"text": "And at some point,\nI sort of suggested", "start": 623.917, "duration": 1.583}, {"text": "that there's two layers.", "start": 625.5, "duration": 3.11}, {"text": "One is where you draw\nthe parameter at random.", "start": 628.61, "duration": 3.05}, {"text": "And two, once you\nhave the parameter,", "start": 631.66, "duration": 3.63}, {"text": "conditionless parameter,\nyou draw your data.", "start": 635.29, "duration": 4.03}, {"text": "Nobody believed this actually is\nhappening, that nature is just", "start": 639.32, "duration": 2.76}, {"text": "rolling dice for us and\nchoosing parameters at random.", "start": 642.08, "duration": 3.43}, {"text": "But what's happening\nis that, this idea", "start": 645.51, "duration": 2.75}, {"text": "that the parameter comes\nfrom some random distribution", "start": 648.26, "duration": 3.15}, {"text": "actually captures, very\nwell, this idea that how", "start": 651.41, "duration": 3.45}, {"text": "you would encompass your prior.", "start": 654.86, "duration": 2.1}, {"text": "How would you say, my\nbelief is as follows?", "start": 656.96, "duration": 2.13}, {"text": "Well here's an example about p.", "start": 659.09, "duration": 2.78}, {"text": "I'm 90% sure that p is\nbetween 0.4 and 0.6.", "start": 661.87, "duration": 5.986}, {"text": "And I'm 95% sure that p\nis between 0.3 and 0.8.", "start": 667.856, "duration": 6.374}, {"text": "So essentially, I have\nthis possible value of p.", "start": 674.23, "duration": 4.26}, {"text": "And what I know is that, there's\n90% here between 0.4 and 0.6.", "start": 678.49, "duration": 16.94}, {"text": "And then I have 0.3 and 0.8.", "start": 695.43, "duration": 3.91}, {"text": "And I know that I'm 95%\nsure that I'm in here.", "start": 699.34, "duration": 4.86}, {"text": "If you remember, this sort of\nlooks like the kind of pictures", "start": 704.2, "duration": 2.85}, {"text": "that I made when I had\nsome Gaussian, for example.", "start": 707.05, "duration": 3.06}, {"text": "And I said, oh here we have\n90% of the observations.", "start": 710.11, "duration": 4.11}, {"text": "And here, we have 95%\nof the observations.", "start": 714.22, "duration": 2.885}, {"text": "So in a way, if I\nwere able to tell you", "start": 720.5, "duration": 4.07}, {"text": "all those ranges for\nall possible values,", "start": 724.57, "duration": 3.04}, {"text": "then I would essentially\ndescribe a probability", "start": 727.61, "duration": 2.9}, {"text": "distribution for p.", "start": 730.51, "duration": 2.89}, {"text": "And what I'm saying\nis that, p is going", "start": 733.4, "duration": 2.01}, {"text": "to have this kind of shape.", "start": 735.41, "duration": 1.172}, {"text": "So of course, if I tell you\nonly two twice this information", "start": 736.582, "duration": 2.458}, {"text": "that there's 90% I'm here,\nand I'm between here and here.", "start": 739.04, "duration": 3.24}, {"text": "And 95%, I'm between here\nand here, then there's", "start": 742.28, "duration": 2.7}, {"text": "many ways I can\naccomplish that, right.", "start": 744.98, "duration": 1.865}, {"text": "I could have something that\nlooks like this, maybe.", "start": 746.845, "duration": 2.125}, {"text": "It could be like this.", "start": 753.19, "duration": 2.64}, {"text": "There's many ways\nI can have this.", "start": 755.83, "duration": 1.775}, {"text": "Some of them are\ndefinitely going", "start": 757.605, "duration": 1.375}, {"text": "to be mathematically more\nconvenient than others.", "start": 758.98, "duration": 3.3}, {"text": "And hopefully, we're\ngoing to have things", "start": 762.28, "duration": 2.04}, {"text": "that I can\nparameterize very well.", "start": 764.32, "duration": 2.91}, {"text": "Because if I tell\nyou this is this guy,", "start": 767.23, "duration": 2.67}, {"text": "then there's basically one,\ntwo three, four, five, six,", "start": 769.9, "duration": 4.44}, {"text": "seven parameters.", "start": 774.34, "duration": 2.214}, {"text": "So I probably don't\nwant something", "start": 776.554, "duration": 1.416}, {"text": "that has seven parameters.", "start": 777.97, "duration": 1.083}, {"text": "But maybe I can say, oh,\nit's a Gaussian and I all", "start": 779.053, "duration": 2.529}, {"text": "I have to do is to tell\nyou where it's centered", "start": 781.582, "duration": 1.958}, {"text": "and what the standard\ndeviation is.", "start": 783.54, "duration": 1.458}, {"text": "So the idea of using\nthis two layer thing,", "start": 787.25, "duration": 3.78}, {"text": "where we think of\nthe parameter p", "start": 791.03, "duration": 1.77}, {"text": "as being drawn from\nsome distribution,", "start": 792.8, "duration": 1.65}, {"text": "is really just a way for us\nto capture this information.", "start": 794.45, "duration": 3.21}, {"text": "Our prior belief\nbeing, well there's", "start": 797.66, "duration": 2.76}, {"text": "this percentage of\nchances that it's there.", "start": 800.42, "duration": 2.374}, {"text": "But the percentage of\nthis chance, I'm not I'm", "start": 802.794, "duration": 1.916}, {"text": "deliberately not using\nprobability here.", "start": 804.71, "duration": 4.02}, {"text": "So it's really a way\nto get close to this.", "start": 808.73, "duration": 2.25}, {"text": "That's why I say, the true\nparameter is not random.", "start": 813.62, "duration": 2.55}, {"text": "But the Bayesian approach\ndoes as if it was random.", "start": 816.17, "duration": 4.25}, {"text": "And then, just spits\nout a procedure", "start": 820.42, "duration": 2.01}, {"text": "out of this thought process,\nthis thought experiment.", "start": 822.43, "duration": 6.68}, {"text": "So when you practice\nBayesian statistics a lot,", "start": 829.11, "duration": 4.95}, {"text": "you start getting automatisms.", "start": 834.06, "duration": 3.78}, {"text": "You start getting some things\nthat you do without really", "start": 837.84, "duration": 3.065}, {"text": "thinking about\nit. just like when", "start": 840.905, "duration": 1.375}, {"text": "you you're a statistician,\nthe first thing you do is,", "start": 842.28, "duration": 2.58}, {"text": "can I think of this data as\nbeing Gaussian for example?", "start": 844.86, "duration": 2.559}, {"text": "When you're Bayesian\nyou're thinking about,", "start": 847.419, "duration": 1.791}, {"text": "OK I have a set of parameters.", "start": 849.21, "duration": 2.19}, {"text": "So here, I can\ndescribe my parameter", "start": 851.4, "duration": 2.85}, {"text": "as being theta in\ngeneral, in some big space", "start": 854.25, "duration": 5.94}, {"text": "parameter of theta.", "start": 860.19, "duration": 1.35}, {"text": "But what spaces\ndid we encounter?", "start": 861.54, "duration": 3.19}, {"text": "Well, we encountered\nthe real line.", "start": 864.73, "duration": 2.36}, {"text": "We encountered the interval\n0, 1 for Bernoulli's And we", "start": 867.09, "duration": 4.23}, {"text": "encountered some of\nthe positive real line", "start": 871.32, "duration": 5.0}, {"text": "for exponential\ndistributions, etc.", "start": 876.32, "duration": 3.0}, {"text": "And so what I'm\ngoing to need to do,", "start": 879.32, "duration": 2.7}, {"text": "if I want to put some\nprior on those spaces,", "start": 882.02, "duration": 2.55}, {"text": "I'm going to have to\nhave a usual set of tools", "start": 884.57, "duration": 3.124}, {"text": "for this guy, usual set\nof tools for this guy,", "start": 887.694, "duration": 1.916}, {"text": "usual sort of\ntools for this guy.", "start": 889.61, "duration": 1.566}, {"text": "And by usual set\nof tools, I mean", "start": 891.176, "duration": 1.374}, {"text": "I'm going to have to have a\nfamily of distributions that's", "start": 892.55, "duration": 2.416}, {"text": "supported on this.", "start": 894.966, "duration": 1.724}, {"text": "So in particular,\nthis is the speed", "start": 896.69, "duration": 2.32}, {"text": "in which my parameter\nthat I usually denote", "start": 899.01, "duration": 2.6}, {"text": "by p for Bernoulli lives.", "start": 901.61, "duration": 2.29}, {"text": "And so what I need is to find a\ndistribution on the interval 0,", "start": 903.9, "duration": 3.94}, {"text": "1 just like this guy.", "start": 907.84, "duration": 5.7}, {"text": "The problem with the\nGaussian is that it's", "start": 913.54, "duration": 1.77}, {"text": "not on the interval 0, 1.", "start": 915.31, "duration": 2.58}, {"text": "It's going to spill\nout in the end.", "start": 917.89, "duration": 2.34}, {"text": "And it's not going to be\nsomething that works for me.", "start": 920.23, "duration": 2.62}, {"text": "And so the question is, I need\nto think about distributions", "start": 922.85, "duration": 2.952}, {"text": "that are probably continuous.", "start": 925.802, "duration": 1.208}, {"text": "Why would I restrict myself\nto discrete distributions that", "start": 927.01, "duration": 3.06}, {"text": "are actually convenient and for\nBernoulli, one that's actually", "start": 930.07, "duration": 3.99}, {"text": "basically the main tool\nthat everybody is using", "start": 934.06, "duration": 2.67}, {"text": "is the so-called\nbeta distribution.", "start": 936.73, "duration": 2.94}, {"text": "So the beta distribution\nhas two parameters.", "start": 939.67, "duration": 2.52}, {"text": "So x follows a beta\nwith parameters", "start": 950.68, "duration": 6.23}, {"text": "a and b if it has\na density, f of x", "start": 956.91, "duration": 8.16}, {"text": "is equal to x to the a minus 1.", "start": 965.07, "duration": 3.98}, {"text": "1 minus x to the b minus 1,\nif x is in the interval 0,", "start": 969.05, "duration": 6.75}, {"text": "1 and 0 for all other x's.", "start": 975.8, "duration": 6.93}, {"text": "OK?", "start": 982.73, "duration": 0.5}, {"text": "Why is that a good thing?", "start": 987.59, "duration": 2.88}, {"text": "Well, it's a density that's\non the interval 0, 1 for sure.", "start": 990.47, "duration": 3.4}, {"text": "But now I have these two\nparameters and a set of shapes", "start": 993.87, "duration": 3.26}, {"text": "that I can get by tweaking those\ntwo parameters is incredible.", "start": 997.13, "duration": 4.395}, {"text": "It's going to be a\nunimodal distribution.", "start": 1004.26, "duration": 1.93}, {"text": "It's still fairly nice.", "start": 1006.19, "duration": 1.07}, {"text": "It's not going to be something\nthat goes like this and this.", "start": 1007.26, "duration": 2.5}, {"text": "Because if you think\nabout this, what", "start": 1009.76, "duration": 3.03}, {"text": "would it mean if your prior\ndistribution of the interval 0,", "start": 1012.79, "duration": 2.76}, {"text": "1 had this shape?", "start": 1015.55, "duration": 1.57}, {"text": "It would mean that, maybe\nyou think that p is here", "start": 1019.63, "duration": 2.304}, {"text": "or maybe you think\nthat p is here,", "start": 1021.934, "duration": 1.416}, {"text": "or maybe you think\nthat p is here.", "start": 1023.35, "duration": 1.777}, {"text": "Which essentially\nmeans that you think", "start": 1025.127, "duration": 1.583}, {"text": "that p can come from\nthree different phenomena.", "start": 1026.71, "duration": 3.951}, {"text": "And there's other models\nthat are called mixers", "start": 1030.661, "duration": 1.958}, {"text": "for that, that directly\naccount for the fact", "start": 1032.619, "duration": 2.46}, {"text": "that maybe there are several\nphenomena that are aggregated", "start": 1035.079, "duration": 4.471}, {"text": "in your data set.", "start": 1039.55, "duration": 1.5}, {"text": "But if you think that your\ndata set is sort of pure,", "start": 1041.05, "duration": 2.34}, {"text": "and that everything comes\nfrom the same phenomenon,", "start": 1043.39, "duration": 2.26}, {"text": "you want something\nthat looks like this,", "start": 1045.65, "duration": 3.2}, {"text": "or maybe looks like this, or\nmaybe is sort of symmetric.", "start": 1048.85, "duration": 4.0}, {"text": "You want to get all this stuff.", "start": 1052.85, "duration": 1.56}, {"text": "Maybe you want something\nthat says, well", "start": 1054.41, "duration": 2.49}, {"text": "if I'm talking about p being the\nprobability of the proportion", "start": 1056.9, "duration": 5.43}, {"text": "of women in the whole world, you\nwant something that's probably", "start": 1062.33, "duration": 3.51}, {"text": "really spiked around one half.", "start": 1065.84, "duration": 2.76}, {"text": "Almost the point\nmath, because you know", "start": 1068.6, "duration": 2.25}, {"text": "let's agree that 0.5\nis the actual number.", "start": 1070.85, "duration": 4.14}, {"text": "So you want something that\nsays, OK maybe I'm wrong.", "start": 1074.99, "duration": 3.96}, {"text": "But I'm sure I'm not going\nto be really that way off.", "start": 1078.95, "duration": 2.35}, {"text": "So you want something\nthat's really pointy.", "start": 1081.3, "duration": 2.0}, {"text": "But if it's something\nyou've never checked,", "start": 1083.3, "duration": 3.36}, {"text": "and again I can not make\nreferences at this point,", "start": 1086.66, "duration": 3.12}, {"text": "but something where you might\nhave some uncertainty that", "start": 1089.78, "duration": 3.417}, {"text": "should be around one half.", "start": 1093.197, "duration": 1.083}, {"text": "Maybe you want something\nthat a little more allows", "start": 1094.28, "duration": 2.79}, {"text": "you to say, well, I think\nthere's more around one half.", "start": 1097.07, "duration": 2.34}, {"text": "But there's still some\nfluctuations that are possible.", "start": 1099.41, "duration": 3.54}, {"text": "And in particular\nhere, I talk about p,", "start": 1102.95, "duration": 2.16}, {"text": "where the two parameters a\nand b are actually the same.", "start": 1105.11, "duration": 4.2}, {"text": "I call them a.", "start": 1109.31, "duration": 1.19}, {"text": "One is called scale.", "start": 1110.5, "duration": 1.21}, {"text": "The other one is called shape.", "start": 1111.71, "duration": 1.72}, {"text": "Oh sorry, this is not a density.", "start": 1113.43, "duration": 2.07}, {"text": "So it actually has\nto be normalized.", "start": 1115.5, "duration": 3.146}, {"text": "When you integrate\nthis guy, it's", "start": 1118.646, "duration": 1.374}, {"text": "going to be some function\nthat depends on a", "start": 1120.02, "duration": 1.47}, {"text": "and b, actually depends\non this function", "start": 1121.49, "duration": 1.92}, {"text": "through the beta function.", "start": 1123.41, "duration": 2.017}, {"text": "Which is this combination\nof gamma function,", "start": 1125.427, "duration": 1.833}, {"text": "so that's why it's\ncalled beta distribution.", "start": 1127.26, "duration": 4.255}, {"text": "That's the definition of\nthe beta function when you", "start": 1131.515, "duration": 2.125}, {"text": "integrate this thing anyway.", "start": 1133.64, "duration": 2.081}, {"text": "You just have to normalize it.", "start": 1135.721, "duration": 1.249}, {"text": "That's just a number that\ndepends on the a and b.", "start": 1136.97, "duration": 2.76}, {"text": "So here, if you\ntake a equal to b,", "start": 1139.73, "duration": 1.812}, {"text": "you have something\nthat essentially", "start": 1141.542, "duration": 1.458}, {"text": "is symmetric around one half.", "start": 1143.0, "duration": 2.34}, {"text": "Because what does it look like?", "start": 1145.34, "duration": 1.78}, {"text": "Well, so my density f of\nx, is going to be what?", "start": 1147.12, "duration": 3.86}, {"text": "It's going to be my constant\ntimes x, times one minus x", "start": 1150.98, "duration": 8.22}, {"text": "to a minus one.", "start": 1159.2, "duration": 2.47}, {"text": "And this function, x times\n1 minus x looks like this.", "start": 1161.67, "duration": 4.41}, {"text": "We've drawn it before.", "start": 1166.08, "duration": 1.65}, {"text": "That was something\nthat showed up", "start": 1167.73, "duration": 1.65}, {"text": "as being the variance\nof my Bernoulli.", "start": 1169.38, "duration": 7.11}, {"text": "So we know it's something that\ntakes its maximum at one half.", "start": 1176.49, "duration": 5.75}, {"text": "And now I'm just taking\na power of this guy.", "start": 1182.24, "duration": 1.95}, {"text": "So I'm really just\ndistorting this thing", "start": 1184.19, "duration": 1.83}, {"text": "into some fairly\nsymmetric manner.", "start": 1186.02, "duration": 5.32}, {"text": "This distribution that\nwe actually take for p.", "start": 1196.4, "duration": 4.23}, {"text": "I assume that p, the\nparameter, notice", "start": 1200.63, "duration": 2.4}, {"text": "that this is kind of weird.", "start": 1203.03, "duration": 1.44}, {"text": "First of all, this is\nprobably the first time", "start": 1204.47, "duration": 1.874}, {"text": "in this entire\ncourse that something", "start": 1206.344, "duration": 3.226}, {"text": "has a distribution when it's\nactually a lower case letter.", "start": 1209.57, "duration": 2.515}, {"text": "That's something you\nhave to deal with,", "start": 1212.085, "duration": 1.625}, {"text": "because we've been using lower\ncase letters for parameters.", "start": 1213.71, "duration": 3.117}, {"text": "And now we want them\nto have a distribution.", "start": 1216.827, "duration": 1.833}, {"text": "So that's what's\ngoing to happen.", "start": 1218.66, "duration": 1.89}, {"text": "This is called the\nprior distribution.", "start": 1220.55, "duration": 3.3}, {"text": "So really, I should write\nsomething like f of p", "start": 1223.85, "duration": 3.9}, {"text": "is equal to a constant times\np, 1 minus p, to the n minus 1.", "start": 1227.75, "duration": 7.54}, {"text": "Well no, actually I should not\nbecause then it's confusing.", "start": 1235.29, "duration": 4.695}, {"text": "One thing in terms\nof notation that I'm", "start": 1239.985, "duration": 1.625}, {"text": "going to write, when\nI have a constant here", "start": 1241.61, "duration": 2.029}, {"text": "and I don't want to\nmake it explicit.", "start": 1243.639, "duration": 1.541}, {"text": "And we'll see in a second why I\ndon't need to make it explicit.", "start": 1245.18, "duration": 3.3}, {"text": "I'm going to write\nthis as f of x", "start": 1248.48, "duration": 4.77}, {"text": "is proportional to x 1\nminus x to the n minus 1.", "start": 1253.25, "duration": 10.81}, {"text": "That's just to say, equal to\nsome constant that does not", "start": 1264.06, "duration": 4.68}, {"text": "depend on x times this thing.", "start": 1268.74, "duration": 2.52}, {"text": "So if we continue\nwith our experiment", "start": 1276.32, "duration": 5.61}, {"text": "where I'm drawing\nthis data, X1 to Xn,", "start": 1281.93, "duration": 3.48}, {"text": "which is Bernoulli p, if\np has some distribution", "start": 1285.41, "duration": 3.64}, {"text": "it's not clear what it\nmeans to have a Bernoulli", "start": 1289.05, "duration": 2.0}, {"text": "with some random parameter.", "start": 1291.05, "duration": 1.377}, {"text": "So what I'm going to do is, then\nI'm going to first draw my p.", "start": 1292.427, "duration": 2.583}, {"text": "Let's say I get a number, 0.52.", "start": 1295.01, "duration": 3.3}, {"text": "And then, I'm going to draw\nmy data conditionally on p.", "start": 1298.31, "duration": 2.79}, {"text": "So here comes the first and\nlast flowchart of this class.", "start": 1301.1, "duration": 4.05}, {"text": "So nature first draws p.", "start": 1309.5, "duration": 1.69}, {"text": "p follows some data on a, a.", "start": 1313.93, "duration": 4.43}, {"text": "Then I condition on p.", "start": 1318.36, "duration": 1.31}, {"text": "And then I draw X1, Xn\nthat are iid, Bernoulli p.", "start": 1322.46, "duration": 8.3}, {"text": "Everybody understand the\nprocess of generating this data?", "start": 1330.76, "duration": 3.49}, {"text": "So you first draw a\nparameter, and then you just", "start": 1334.25, "duration": 2.0}, {"text": "flip those independent biased\ncoins with this particular p.", "start": 1336.25, "duration": 4.79}, {"text": "There's this layered thing.", "start": 1341.04, "duration": 2.19}, {"text": "Now conditionally p, right so\nhere I have this prior about p", "start": 1346.57, "duration": 4.44}, {"text": "which was the thing.", "start": 1351.01, "duration": 1.06}, {"text": "So this is just the\nthought process again,", "start": 1352.07, "duration": 2.02}, {"text": "it's not anything that\nactually happens in practice.", "start": 1354.09, "duration": 2.39}, {"text": "This is my way of thinking about\nhow the data was generated.", "start": 1356.48, "duration": 3.44}, {"text": "And from this, I'm going to try\nto come up with some procedure.", "start": 1359.92, "duration": 3.39}, {"text": "Just like, if your estimator\nis the average of the data,", "start": 1363.31, "duration": 4.57}, {"text": "you don't have to\nunderstand probability", "start": 1367.88, "duration": 1.82}, {"text": "to say that my estimator\nis the average of the data.", "start": 1369.7, "duration": 2.97}, {"text": "Anyone outside this\nroom understands", "start": 1372.67, "duration": 1.53}, {"text": "that the average\nis a good estimator", "start": 1374.2, "duration": 1.77}, {"text": "for some average behavior.", "start": 1375.97, "duration": 2.58}, {"text": "And they don't need\nto think of the data", "start": 1378.55, "duration": 2.52}, {"text": "as being a random\nvariable, et cetera.", "start": 1381.07, "duration": 1.89}, {"text": "So same thing, basically.", "start": 1382.96, "duration": 1.61}, {"text": "In this case, you can see that\nthe posterior distribution", "start": 1390.76, "duration": 3.03}, {"text": "is still a beta.", "start": 1393.79, "duration": 0.93}, {"text": "What it means is that,\nI had this thing.", "start": 1398.32, "duration": 1.77}, {"text": "Then, I observed my data.", "start": 1400.09, "duration": 1.56}, {"text": "And then, I continue\nand here I'm", "start": 1401.65, "duration": 1.92}, {"text": "going to update my prior\ninto some posterior", "start": 1403.57, "duration": 9.23}, {"text": "distribution, pi.", "start": 1412.8, "duration": 3.88}, {"text": "And here, this guy is\nactually also a beta.", "start": 1416.68, "duration": 2.53}, {"text": "My posterior\ndistribution, p, is also", "start": 1423.37, "duration": 2.58}, {"text": "a beta distribution\nwith the parameters", "start": 1425.95, "duration": 2.052}, {"text": "that are on this slide.", "start": 1428.002, "duration": 0.958}, {"text": "And I'll have the space\nto reproduce them.", "start": 1428.96, "duration": 2.71}, {"text": "So I start the beginning\nof this flowchart", "start": 1431.67, "duration": 2.51}, {"text": "as having p, which is a prior.", "start": 1434.18, "duration": 2.95}, {"text": "I'm going to get\nsome observations", "start": 1437.13, "duration": 1.68}, {"text": "and then, I'm going to\nupdate what my posterior is.", "start": 1438.81, "duration": 2.31}, {"text": "This posterior is\nbasically something", "start": 1444.53, "duration": 2.37}, {"text": "that's, in business\nstatistics was", "start": 1446.9, "duration": 2.79}, {"text": "beautiful is as soon as\nyou have this distribution,", "start": 1449.69, "duration": 4.03}, {"text": "it's essentially capturing all\nthe information about the data", "start": 1453.72, "duration": 3.31}, {"text": "that you want for p.", "start": 1457.03, "duration": 1.98}, {"text": "And it's not just the point.", "start": 1459.01, "duration": 1.419}, {"text": "It's not just an average.", "start": 1460.429, "duration": 1.041}, {"text": "It's actually an\nentire distribution", "start": 1461.47, "duration": 2.19}, {"text": "for the possible\nvalues of theta.", "start": 1463.66, "duration": 3.39}, {"text": "And it's not the same\nthing as saying, well", "start": 1467.05, "duration": 3.69}, {"text": "if theta hat is equal to Xn\nbar, in the Gaussian case I know", "start": 1470.74, "duration": 4.29}, {"text": "that this is some mean, mu.", "start": 1475.03, "duration": 2.1}, {"text": "And then maybe it has\nvarying sigma squared over n.", "start": 1477.13, "duration": 2.55}, {"text": "That's not what I mean by, this\nis my posterior distribution.", "start": 1479.68, "duration": 3.87}, {"text": "This is not what I mean.", "start": 1483.55, "duration": 3.09}, {"text": "This is going to come from\nthis guy, the Gaussian thing", "start": 1486.64, "duration": 3.15}, {"text": "and the central limit theorem.", "start": 1489.79, "duration": 1.56}, {"text": "But what I mean is this guy.", "start": 1491.35, "duration": 1.62}, {"text": "And this came exclusively\nfrom the prior distribution.", "start": 1492.97, "duration": 5.16}, {"text": "If I had another prior,\nI would not necessarily", "start": 1498.13, "duration": 2.7}, {"text": "have a beta distribution\non the output.", "start": 1500.83, "duration": 3.01}, {"text": "So when I have the same\nfamily of distributions", "start": 1503.84, "duration": 3.74}, {"text": "at the beginning and at\nthe end of this flowchart,", "start": 1507.58, "duration": 3.51}, {"text": "I say that beta is\na conjugate prior.", "start": 1511.09, "duration": 5.43}, {"text": "Meaning I put in beta as a prior\nand I get beta as [INAUDIBLE]", "start": 1521.2, "duration": 6.19}, {"text": "And that's why betas\nare so popular.", "start": 1527.39, "duration": 3.46}, {"text": "Conjugate priors\nare really nice,", "start": 1530.85, "duration": 1.43}, {"text": "because you know that whatever\nyou put in, what you're going", "start": 1532.28, "duration": 3.45}, {"text": "to get in the end is a beta.", "start": 1535.73, "duration": 1.44}, {"text": "So all you have to think\nabout is the parameters.", "start": 1537.17, "duration": 1.62}, {"text": "You don't have to check\nagain what the posterior is", "start": 1538.79, "duration": 2.25}, {"text": "going to look like, what the\nPDF of this guy is going to be.", "start": 1541.04, "duration": 2.25}, {"text": "You don't have to\nthink about it.", "start": 1543.29, "duration": 1.374}, {"text": "You just have to check\nwhat the parameters are.", "start": 1544.664, "duration": 1.986}, {"text": "And there's families\nof conjugate priors.", "start": 1546.65, "duration": 1.708}, {"text": "Gaussian gives\nGaussian, for example.", "start": 1548.358, "duration": 2.792}, {"text": "There's a bunch of them.", "start": 1551.15, "duration": 1.02}, {"text": "And this is what drives people\ninto using specific priors as", "start": 1552.17, "duration": 5.04}, {"text": "opposed to others.", "start": 1557.21, "duration": 0.99}, {"text": "It has nice\nmathematical properties.", "start": 1558.2, "duration": 2.46}, {"text": "Nobody believes that p is really\ndistributed according to beta.", "start": 1560.66, "duration": 5.25}, {"text": "But it's flexible enough\nand super convenient", "start": 1565.91, "duration": 2.73}, {"text": "mathematically.", "start": 1568.64, "duration": 1.06}, {"text": "Now let's see for one\nsecond, before we actually", "start": 1572.45, "duration": 2.19}, {"text": "go any further.", "start": 1574.64, "duration": 2.44}, {"text": "I didn't mention A and\nB are both in here,", "start": 1577.08, "duration": 2.71}, {"text": "A and B are both\npositive numbers.", "start": 1579.79, "duration": 1.75}, {"text": "They can be anything positive.", "start": 1584.32, "duration": 3.29}, {"text": "So here what I did\nis that, I updated A", "start": 1587.61, "duration": 1.85}, {"text": "into a plus the sum\nof my data, and b", "start": 1589.46, "duration": 5.19}, {"text": "into b plus n minus\nthe sum of my data.", "start": 1594.65, "duration": 3.85}, {"text": "So that's essentially, a becomes\na plus the number of ones.", "start": 1598.5, "duration": 3.41}, {"text": "Well, that's only\nwhen I have a and a.", "start": 1605.04, "duration": 2.31}, {"text": "So the first parameters become\nitself plus the number of ones.", "start": 1607.35, "duration": 2.766}, {"text": "And the second\none becomes itself", "start": 1610.116, "duration": 1.374}, {"text": "plus the number of zeros.", "start": 1611.49, "duration": 1.041}, {"text": "And so just as a sanity\ncheck, what does this mean?", "start": 1615.44, "duration": 3.72}, {"text": "If a it goes to zero, what\nis the beta when a goes to 0?", "start": 1619.16, "duration": 9.75}, {"text": "We can actually\nread this from here.", "start": 1628.91, "duration": 1.5}, {"text": "Actually, let's take a goes to--", "start": 1636.92, "duration": 2.25}, {"text": "no.", "start": 1645.37, "duration": 0.74}, {"text": "Sorry, let's just do this.", "start": 1646.11, "duration": 1.2}, {"text": "I'll do it when we talk\nabout non-informative prior,", "start": 1658.67, "duration": 2.17}, {"text": "because it's a little too messy.", "start": 1660.84, "duration": 2.0}, {"text": "How do we do this?", "start": 1667.22, "duration": 0.75}, {"text": "How did I get this posterior\ndistribution, given the prior?", "start": 1667.97, "duration": 3.42}, {"text": "How do I update This well this\nis called Bayesian statistics.", "start": 1671.39, "duration": 4.68}, {"text": "And you've heard this\nword, Bayes before.", "start": 1676.07, "duration": 2.73}, {"text": "And the way you've heard\nit is in the Bayes formula.", "start": 1678.8, "duration": 3.21}, {"text": "What was the Bayes formula?", "start": 1682.01, "duration": 1.67}, {"text": "The Bayes formula\nwas telling you", "start": 1683.68, "duration": 1.51}, {"text": "that the probability of A, given\nB was equal to something that", "start": 1685.19, "duration": 6.2}, {"text": "depended on the probability of\nB, given A. That's what it was.", "start": 1691.39, "duration": 3.04}, {"text": "You can actually either\nremember the formula", "start": 1696.787, "duration": 1.833}, {"text": "or you can remember\nthe definition.", "start": 1698.62, "duration": 1.63}, {"text": "And this is what p of A\nand B divided by p of B.", "start": 1700.25, "duration": 5.75}, {"text": "So this is p of B, given A\ntimes p of A divided by p of B.", "start": 1706.0, "duration": 9.48}, {"text": "That's what Bayes\nformula is telling you.", "start": 1715.48, "duration": 2.11}, {"text": "Agree?", "start": 1717.59, "duration": 2.46}, {"text": "So now what I want is to have\nsomething that's telling me", "start": 1720.05, "duration": 6.15}, {"text": "how this is going to work.", "start": 1726.2, "duration": 3.53}, {"text": "What is going to play the\nrole of those events, A and B?", "start": 1729.73, "duration": 4.68}, {"text": "Well one is going\nto be, this is going", "start": 1734.41, "duration": 4.87}, {"text": "to be the distribution\nof my parameter of theta,", "start": 1739.28, "duration": 2.7}, {"text": "given that I see the data.", "start": 1741.98, "duration": 1.914}, {"text": "And this is going\nto tell me, what", "start": 1743.894, "duration": 1.416}, {"text": "is the distribution of the\ndata, given that I know what", "start": 1745.31, "duration": 2.291}, {"text": "my parameter if theta is.", "start": 1747.601, "duration": 1.669}, {"text": "But that part, if\nthis is theta and this", "start": 1749.27, "duration": 2.186}, {"text": "is the parameter of\ntheta, this is what", "start": 1751.456, "duration": 1.624}, {"text": "we've been doing all along.", "start": 1753.08, "duration": 2.64}, {"text": "The distribution of the data,\ngiven the parameter here", "start": 1755.72, "duration": 3.0}, {"text": "was n iid Bernoulli p.", "start": 1758.72, "duration": 3.63}, {"text": "I knew exactly what their joint\nprobability mass function is.", "start": 1762.35, "duration": 5.61}, {"text": "Then, that was what?", "start": 1767.96, "duration": 1.33}, {"text": "So we said that this\nis going to be my data", "start": 1769.29, "duration": 3.41}, {"text": "and this is going\nto be my parameter.", "start": 1772.7, "duration": 2.03}, {"text": "So that means that, this is\nthe probability of my data,", "start": 1777.27, "duration": 2.94}, {"text": "given the parameter.", "start": 1780.21, "duration": 2.79}, {"text": "This is the probability\nof the parameter.", "start": 1783.0, "duration": 2.729}, {"text": "What is this?", "start": 1785.729, "duration": 0.541}, {"text": "What did we call this?", "start": 1786.27, "duration": 2.825}, {"text": "This is the prior.", "start": 1789.095, "duration": 1.185}, {"text": "It's just the distribution\nof my parameter.", "start": 1790.28, "duration": 3.41}, {"text": "Now what is this?", "start": 1793.69, "duration": 2.34}, {"text": "Well, this is just\nthe distribution", "start": 1796.03, "duration": 1.46}, {"text": "of the data, itself.", "start": 1797.49, "duration": 2.85}, {"text": "This is essentially the\ndistribution of this,", "start": 1800.34, "duration": 6.46}, {"text": "if this was indeed\nnot conditioned on p.", "start": 1806.8, "duration": 8.28}, {"text": "So if I don't condition\non p, this data", "start": 1815.08, "duration": 3.63}, {"text": "is going to be a bunch of iid,\nBernoulli with some parameter.", "start": 1818.71, "duration": 5.272}, {"text": "But the perimeter\nis random, right.", "start": 1823.982, "duration": 1.458}, {"text": "So for different realization\nof this data set,", "start": 1825.44, "duration": 2.397}, {"text": "I'm going to get different\nparameters for the Bernoulli.", "start": 1827.837, "duration": 2.333}, {"text": "And so that leads to\nsome sort of convolution.", "start": 1830.17, "duration": 4.209}, {"text": "It's not really a\nconvolution in this case,", "start": 1834.379, "duration": 1.791}, {"text": "but it's like some sort of\ncomposition of distributions.", "start": 1836.17, "duration": 2.49}, {"text": "I have the randomness that\ncomes from here and then,", "start": 1838.66, "duration": 2.94}, {"text": "the randomness that comes\nfrom realizing the Bernoulli.", "start": 1841.6, "duration": 3.157}, {"text": "That's just the\nmarginal distribution.", "start": 1844.757, "duration": 1.583}, {"text": "It actually might be painful to\nunderstand what this is, right.", "start": 1846.34, "duration": 3.48}, {"text": "In a way, it's sort of a\nmixture and it's not super nice.", "start": 1849.82, "duration": 3.15}, {"text": "But we'll see that this\nactually won't matter for us.", "start": 1852.97, "duration": 2.91}, {"text": "This is going to be some number.", "start": 1855.88, "duration": 1.36}, {"text": "It's going to be there.", "start": 1857.24, "duration": 0.98}, {"text": "But it will matter\nfor us, what it is.", "start": 1858.22, "duration": 2.04}, {"text": "Because it actually does\nnot depend on the parameter.", "start": 1860.26, "duration": 2.25}, {"text": "And that's all\nthat matters to us.", "start": 1862.51, "duration": 1.83}, {"text": "Let's put some names\non those things.", "start": 1869.1, "duration": 2.07}, {"text": "This was very informal.", "start": 1871.17, "duration": 1.69}, {"text": "So let's put some actual\nnames on what we call prior.", "start": 1872.86, "duration": 6.85}, {"text": "So what is the formal\ndefinition of a prior,", "start": 1879.71, "duration": 2.61}, {"text": "what is the formal\ndefinition of a posterior,", "start": 1882.32, "duration": 2.64}, {"text": "and what are the\nrules to update it?", "start": 1884.96, "duration": 2.49}, {"text": "So I'm going to have my data,\nwhich is going to be X1, Xn.", "start": 1887.45, "duration": 2.65}, {"text": "Let's say they are iid, but\nthey don't actually have to.", "start": 1895.71, "duration": 2.81}, {"text": "And so I'm going to\nhave given, theta.", "start": 1898.52, "duration": 2.74}, {"text": "And when I say\ngiven, it's either", "start": 1907.45, "duration": 1.44}, {"text": "given like I did in the\nfirst part of this course", "start": 1908.89, "duration": 3.0}, {"text": "in all previous chapters,\nor conditionally on.", "start": 1911.89, "duration": 4.05}, {"text": "If you're thinking like a\nBayesian, what I really mean", "start": 1915.94, "duration": 2.4}, {"text": "is conditionally on\nthis random parameter.", "start": 1918.34, "duration": 3.91}, {"text": "It's as if it was\na fixed number.", "start": 1922.25, "duration": 4.1}, {"text": "They're going to\nhave a distribution,", "start": 1926.35, "duration": 2.06}, {"text": "X1, Xn is going to\nhave some distribution.", "start": 1928.41, "duration": 3.94}, {"text": "Let's assume for now\nit's a PDF, pn of X1, Xn.", "start": 1932.35, "duration": 6.91}, {"text": "I'm going to write\ntheta like this.", "start": 1939.26, "duration": 2.88}, {"text": "So for example, what is this?", "start": 1942.14, "duration": 2.76}, {"text": "Let's say this is a PDF.", "start": 1944.9, "duration": 2.24}, {"text": "It could be a PMF.", "start": 1947.14, "duration": 0.97}, {"text": "Everything I say, I'm going to\nthink of them as being PDF's.", "start": 1948.11, "duration": 3.087}, {"text": "I'm going to combine\nPDF's with PDF's, but I", "start": 1951.197, "duration": 1.833}, {"text": "could combine PDF it PMF, PMF\nwith PDF's or PMF with PMF.", "start": 1953.03, "duration": 4.41}, {"text": "So everywhere you see\na D could be an M.", "start": 1957.44, "duration": 4.15}, {"text": "Now I have those things.", "start": 1961.59, "duration": 1.0}, {"text": "So what does it mean?", "start": 1962.59, "duration": 0.875}, {"text": "So here is an example.", "start": 1963.465, "duration": 2.965}, {"text": "X1, Xn or iid, and theta 1.", "start": 1966.43, "duration": 7.54}, {"text": "Now I know exactly what the\njoint PDF of this thing is.", "start": 1973.97, "duration": 3.56}, {"text": "It means that pn of X1, Xn\ngiven theta is equal to what?", "start": 1977.53, "duration": 6.26}, {"text": "Well it's 1 over\n2pi to the power n", "start": 1983.79, "duration": 6.77}, {"text": "e, to the minus sum\nfrom i equal 1 to n", "start": 1990.56, "duration": 4.44}, {"text": "of xi minus theta\nsquared divided by 2.", "start": 1995.0, "duration": 3.45}, {"text": "So that's just the joint\ndistribution of n iid", "start": 1998.45, "duration": 2.77}, {"text": "and theta 1, random variables.", "start": 2001.22, "duration": 3.9}, {"text": "That's my pn given theta.", "start": 2005.12, "duration": 2.17}, {"text": "Now this is what we denoted\nby f sub theta before.", "start": 2007.29, "duration": 6.02}, {"text": "We had the subscript before, but\nnow we just put a bar in theta", "start": 2013.31, "duration": 3.48}, {"text": "because we want to remember\nthat this is actually", "start": 2016.79, "duration": 2.07}, {"text": "conditioned on theta.", "start": 2018.86, "duration": 1.8}, {"text": "But this is just notation.", "start": 2020.66, "duration": 1.47}, {"text": "You should just think of this\nas being, just the usual thing", "start": 2022.13, "duration": 3.93}, {"text": "that you get from some\nstatistical model.", "start": 2026.06, "duration": 4.85}, {"text": "Now, that's going to be pn.", "start": 2030.91, "duration": 3.0}, {"text": "Theta has prior\ndistribution, pi.", "start": 2051.02, "duration": 8.48}, {"text": "For example, so think of it\nas either PDF or PMF again.", "start": 2062.4, "duration": 6.73}, {"text": "For example, pi\nof theta was what?", "start": 2069.13, "duration": 4.79}, {"text": "Well it was some constant\ntimes theta to the a minus 1,", "start": 2073.92, "duration": 6.239}, {"text": "1 minus theta to a minus 1.", "start": 2080.159, "duration": 3.58}, {"text": "So it has some\nprior distribution,", "start": 2083.739, "duration": 2.161}, {"text": "and that's another PMF.", "start": 2085.9, "duration": 3.15}, {"text": "So now I'm given the\ndistribution of my,", "start": 2089.05, "duration": 2.04}, {"text": "x is given theta and given\nthe distribution of my theta.", "start": 2091.09, "duration": 2.91}, {"text": "I'm given this guy.", "start": 2094.0, "duration": 3.41}, {"text": "That's this guy.", "start": 2097.41, "duration": 2.69}, {"text": "I'm given that guy,\nwhich is my pi.", "start": 2100.1, "duration": 5.24}, {"text": "So that's my pn of\nX1, Xn given theta.", "start": 2105.34, "duration": 6.36}, {"text": "That's my pi of theta.", "start": 2111.7, "duration": 1.363}, {"text": "Well, this is just\nthe integral of pn", "start": 2117.39, "duration": 3.74}, {"text": "of X1, Xn times pi\nof theta, d theta,", "start": 2121.13, "duration": 7.15}, {"text": "over all possible sets of theta.", "start": 2128.28, "duration": 1.44}, {"text": "That's just when I\nintegrate out my theta,", "start": 2129.72, "duration": 3.64}, {"text": "or I compute the\nmarginal distribution,", "start": 2133.36, "duration": 2.43}, {"text": "I did this by integrating.", "start": 2135.79, "duration": 1.5}, {"text": "That's just basic probability,\nconditional probabilities.", "start": 2137.29, "duration": 3.72}, {"text": "Then if I had the\nPMF, I would just", "start": 2141.01, "duration": 1.6}, {"text": "sum over the values of thetas.", "start": 2142.61, "duration": 1.36}, {"text": "Now what I want is to\nfind what's called,", "start": 2149.02, "duration": 6.19}, {"text": "so that's the\nprior distribution,", "start": 2155.21, "duration": 3.66}, {"text": "and I want to find the\nposterior distribution.", "start": 2158.87, "duration": 2.357}, {"text": "It's pi of theta, given X1, Xn.", "start": 2175.11, "duration": 3.58}, {"text": "If I use Bayes' rule\nI know that this", "start": 2181.78, "duration": 2.19}, {"text": "is pn of X1, Xn, given\ntheta times pi of theta.", "start": 2183.97, "duration": 10.68}, {"text": "And then it's divided\nby the distribution", "start": 2194.65, "duration": 2.88}, {"text": "of those guys, which I will\nwrite as integral over theta", "start": 2197.53, "duration": 3.54}, {"text": "of pn, X1, Xn, given theta\ntimes pi of theta, d theta.", "start": 2201.07, "duration": 7.76}, {"text": "Everybody's with me, still?", "start": 2215.36, "duration": 2.34}, {"text": "If you're not\ncomfortable with this,", "start": 2217.7, "duration": 1.5}, {"text": "it means that you probably need\nto go read your couple of pages", "start": 2219.2, "duration": 3.81}, {"text": "on conditional densities\nand conditional", "start": 2223.01, "duration": 1.92}, {"text": "PMF's from your probably class.", "start": 2224.93, "duration": 2.49}, {"text": "There's really not much there.", "start": 2227.42, "duration": 1.45}, {"text": "It's just a matter of being able\nto define those quantities, f", "start": 2228.87, "duration": 4.79}, {"text": "density of x, given y.", "start": 2233.66, "duration": 1.629}, {"text": "This is just what's called\na conditional density.", "start": 2235.289, "duration": 2.041}, {"text": "You need to understand\nwhat this object is", "start": 2237.33, "duration": 1.749}, {"text": "and how it relates to the\njoint distribution of x and y,", "start": 2239.079, "duration": 2.841}, {"text": "or maybe the distribution of\nx or the distribution of y.", "start": 2241.92, "duration": 2.382}, {"text": "But it's the same rules.", "start": 2247.4, "duration": 2.52}, {"text": "One way to actually\nremember this", "start": 2249.92, "duration": 1.545}, {"text": "is, this is exactly\nthe same rules as this.", "start": 2251.465, "duration": 2.265}, {"text": "When you see a bar, it's the\nsame thing as the probability", "start": 2253.73, "duration": 2.88}, {"text": "of this and this guy.", "start": 2256.61, "duration": 1.18}, {"text": "So for densities,\nit's just a comma", "start": 2257.79, "duration": 2.27}, {"text": "divided by the second the\nprobably the second guy.", "start": 2260.06, "duration": 3.18}, {"text": "That's it.", "start": 2263.24, "duration": 1.88}, {"text": "So if you remember this, you can\njust do some pattern matching", "start": 2265.12, "duration": 3.24}, {"text": "and see what I just wrote here.", "start": 2268.36, "duration": 1.62}, {"text": "Now, I can compute every\nsingle one of these guys.", "start": 2273.22, "duration": 3.79}, {"text": "This something I get\nfrom my modeling.", "start": 2277.01, "duration": 7.02}, {"text": "So I did not write this.", "start": 2284.03, "duration": 1.26}, {"text": "It's not written in the slides.", "start": 2285.29, "duration": 3.84}, {"text": "But I give a name to this guy\nthat was my prior distribution.", "start": 2289.13, "duration": 5.69}, {"text": "And that was my\nposterior distribution.", "start": 2294.82, "duration": 1.73}, {"text": "In chapter three, maybe\nwhat did we call this guy?", "start": 2302.55, "duration": 4.43}, {"text": "The one that does not have a\nname and that's in the box.", "start": 2312.12, "duration": 3.06}, {"text": "What did we call it?", "start": 2319.347, "duration": 0.833}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 2323.498, "duration": 2.837}, {"text": "PHILLIPE RIGOLLET: It is the\njoint distribution of the Xi's.", "start": 2326.335, "duration": 2.5}, {"text": "And we gave it a name.", "start": 2331.95, "duration": 1.285}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 2333.235, "duration": 0.979}, {"text": "PHILLIPE RIGOLLET: It's\nthe likelihood, right?", "start": 2334.214, "duration": 1.916}, {"text": "This is exactly the likelihood.", "start": 2336.13, "duration": 1.5}, {"text": "This was the\nlikelihood of theta.", "start": 2337.63, "duration": 1.47}, {"text": "And this is something that's\nvery important to remember,", "start": 2343.92, "duration": 2.43}, {"text": "and that really reminds you\nthat these things are really not", "start": 2346.35, "duration": 4.17}, {"text": "that different.", "start": 2350.52, "duration": 1.02}, {"text": "Maximum likelihood estimation\nand Bayesian estimation,", "start": 2351.54, "duration": 2.43}, {"text": "because your posterior is really\njust your likelihood times", "start": 2353.97, "duration": 4.89}, {"text": "something that's just putting\nsome weights on the thetas,", "start": 2358.86, "duration": 4.71}, {"text": "depending on where you\nthink theta should be.", "start": 2363.57, "duration": 2.82}, {"text": "If I had, say a maximum\nlikelihood estimate,", "start": 2366.39, "duration": 2.03}, {"text": "and my likelihood and\ntheta looked like this,", "start": 2368.42, "duration": 2.71}, {"text": "but my prior and theta\nlooked like this.", "start": 2371.13, "duration": 2.28}, {"text": "I said, oh I really want\nthetas that are like this.", "start": 2373.41, "duration": 3.63}, {"text": "So what's going to\nhappen is that, I'm", "start": 2377.04, "duration": 1.67}, {"text": "going to turn this into some\nposterior that looks like this.", "start": 2378.71, "duration": 2.61}, {"text": "So I'm just really\nwaiting, this posterior,", "start": 2384.4, "duration": 3.21}, {"text": "this is a constant that does\nnot depend on theta right?", "start": 2387.61, "duration": 2.361}, {"text": "Agreed?", "start": 2389.971, "duration": 0.499}, {"text": "I integrated over\ntheta, so theta is gone.", "start": 2390.47, "duration": 2.99}, {"text": "So forget about this guy.", "start": 2393.46, "duration": 2.76}, {"text": "I have basically, that the\nposterior distribution up", "start": 2396.22, "duration": 3.027}, {"text": "to scaling, because it has to\nbe a probability density and not", "start": 2399.247, "duration": 2.583}, {"text": "just anything any\nfunction that's positive,", "start": 2401.83, "duration": 1.98}, {"text": "is the product of this guy.", "start": 2403.81, "duration": 1.26}, {"text": "It's a weighted version\nof my likelihood.", "start": 2405.07, "duration": 1.85}, {"text": "That's all it is.", "start": 2406.92, "duration": 0.97}, {"text": "I'm just weighing\nthe likelihood,", "start": 2407.89, "duration": 2.1}, {"text": "using my prior belief on theta.", "start": 2409.99, "duration": 3.16}, {"text": "And so given this guy\na natural estimator,", "start": 2413.15, "duration": 3.72}, {"text": "if you follow the maximum\nlikelihood principle,", "start": 2416.87, "duration": 2.61}, {"text": "would be the maximum\nof this posterior.", "start": 2419.48, "duration": 3.67}, {"text": "Agreed?", "start": 2423.15, "duration": 1.47}, {"text": "That would basically be doing\nexactly what maximum likelihood", "start": 2424.62, "duration": 4.21}, {"text": "estimation is telling you.", "start": 2428.83, "duration": 2.91}, {"text": "So it turns out that you can.", "start": 2431.74, "duration": 1.82}, {"text": "It's called Maximum\nA Posteriori,", "start": 2433.56, "duration": 1.77}, {"text": "and I won't talk much\nabout this, or MAP.", "start": 2435.33, "duration": 4.04}, {"text": "That's Maximum a Posteriori.", "start": 2439.37, "duration": 5.13}, {"text": "So it's just the\ntheta hat is the arc", "start": 2444.5, "duration": 2.7}, {"text": "max of pi theta, given X1, Xn.", "start": 2447.2, "duration": 3.59}, {"text": "And it sounds like it's OK.", "start": 2454.99, "duration": 1.2}, {"text": "I'll give you a\ndensity and you say, OK", "start": 2456.19, "duration": 2.47}, {"text": "I have a density for all\nvalues of my parameters.", "start": 2458.66, "duration": 2.31}, {"text": "You're asking me to\nsummarize it into one number.", "start": 2460.97, "duration": 2.47}, {"text": "I'm just going to take the most\nlikely number of those guys.", "start": 2463.44, "duration": 3.13}, {"text": "But you could summarize\nit, otherwise.", "start": 2466.57, "duration": 1.74}, {"text": "You could take the average.", "start": 2468.31, "duration": 2.46}, {"text": "You could take the median.", "start": 2470.77, "duration": 1.65}, {"text": "You could take a\nbunch of numbers.", "start": 2472.42, "duration": 1.95}, {"text": "And the beauty of\nBayesian statistics", "start": 2474.37, "duration": 1.71}, {"text": "is that, you don't have to\ntake any number in particular.", "start": 2476.08, "duration": 3.15}, {"text": "You have an entire\nposterior distribution.", "start": 2479.23, "duration": 2.25}, {"text": "This is not only telling\nyou where theta is,", "start": 2481.48, "duration": 3.6}, {"text": "but it's actually telling\nyou the difference", "start": 2485.08, "duration": 4.08}, {"text": "if you actually\ngive as something", "start": 2489.16, "duration": 2.76}, {"text": "that gives you the posterior.", "start": 2491.92, "duration": 1.26}, {"text": "Now, let's say the theta\nis p between 0 and 1.", "start": 2493.18, "duration": 3.09}, {"text": "If my posterior distribution\nlooks like this,", "start": 2496.27, "duration": 3.72}, {"text": "or my posterior distribution\nlooks like this,", "start": 2499.99, "duration": 3.42}, {"text": "then those two guys\nhave one, the same mode.", "start": 2503.41, "duration": 4.2}, {"text": "This is the same value.", "start": 2507.61, "duration": 1.59}, {"text": "And their symmetric, so they'll\nalso have the same mean.", "start": 2509.2, "duration": 2.43}, {"text": "So these two posterior\ndistributions", "start": 2511.63, "duration": 1.5}, {"text": "give me the same\nsummary into one number.", "start": 2513.13, "duration": 2.37}, {"text": "However clearly, one\nis much more confident", "start": 2515.5, "duration": 2.729}, {"text": "than the other one.", "start": 2518.229, "duration": 0.791}, {"text": "So I might as well just\nspit it out as a solution.", "start": 2519.02, "duration": 4.99}, {"text": "You can do even better.", "start": 2524.01, "duration": 1.17}, {"text": "People actually do things,\nsuch as drawing a random number", "start": 2525.18, "duration": 4.38}, {"text": "from this distribution.", "start": 2529.56, "duration": 1.04}, {"text": "Say, this is my number.", "start": 2530.6, "duration": 2.34}, {"text": "That's kind of\ndangerous, but you", "start": 2532.94, "duration": 1.5}, {"text": "can imagine you could do this.", "start": 2534.44, "duration": 1.25}, {"text": "This is what works.", "start": 2540.73, "duration": 1.41}, {"text": "That's what we went through.", "start": 2542.14, "duration": 1.54}, {"text": "So here, as you notice I don't\ncare so much about this part", "start": 2543.68, "duration": 4.97}, {"text": "here.", "start": 2548.65, "duration": 1.59}, {"text": "Because it does not\ndepend on theta.", "start": 2550.24, "duration": 2.0}, {"text": "So I know that given the\nproduct of those two things,", "start": 2552.24, "duration": 2.95}, {"text": "this thing is only the\nconstant that I need to divide", "start": 2555.19, "duration": 2.46}, {"text": "so that when I integrate\nthis thing over theta,", "start": 2557.65, "duration": 2.4}, {"text": "it integrates to one.", "start": 2560.05, "duration": 1.41}, {"text": "Because this has to be a\nprobability density on theta.", "start": 2561.46, "duration": 4.08}, {"text": "I can write this and just\nforget about that part.", "start": 2565.54, "duration": 2.37}, {"text": "And that's what's written\non the top of this slide.", "start": 2567.91, "duration": 4.37}, {"text": "This notation, this sort of\nweird alpha, or I don't know.", "start": 2572.28, "duration": 5.64}, {"text": "Infinity sign\npropped to the right.", "start": 2577.92, "duration": 1.86}, {"text": "Whatever you want\nto call this thing", "start": 2579.78, "duration": 2.55}, {"text": "is actually just really\nemphasizing the fact", "start": 2582.33, "duration": 2.37}, {"text": "that I don't care.", "start": 2584.7, "duration": 1.61}, {"text": "I write it because I can,\nbut you know what it is.", "start": 2586.31, "duration": 6.18}, {"text": "In some instances, you have\nto compute the integral.", "start": 2597.314, "duration": 2.166}, {"text": "In some instances, you don't\nhave to compute the integral.", "start": 2599.48, "duration": 2.16}, {"text": "And a lot of\nBayesian computation", "start": 2601.64, "duration": 1.56}, {"text": "is about saying,\nOK it's actually", "start": 2603.2, "duration": 2.4}, {"text": "really hard to\ncompute this integral,", "start": 2605.6, "duration": 1.546}, {"text": "so I'd rather not doing it.", "start": 2607.146, "duration": 1.124}, {"text": "So let me try to find some\nmethods that will allow me", "start": 2608.27, "duration": 3.18}, {"text": "to sample from the\nposterior distribution,", "start": 2611.45, "duration": 2.339}, {"text": "without having to compute this.", "start": 2613.789, "duration": 1.291}, {"text": "And that's what's called\nMonte-Carlo Markov", "start": 2615.08, "duration": 2.64}, {"text": "chains, or MCMC, and that's\nexactly what they're doing.", "start": 2617.72, "duration": 2.86}, {"text": "They're just using\nonly ratios of things,", "start": 2620.58, "duration": 1.79}, {"text": "like that for different thetas.", "start": 2622.37, "duration": 1.76}, {"text": "And which means that\nif you take ratios,", "start": 2624.13, "duration": 1.76}, {"text": "the normalizing constant\nis gone and you don't", "start": 2625.89, "duration": 1.97}, {"text": "need to find this integral.", "start": 2627.86, "duration": 2.95}, {"text": "So we won't go into\nthose details at all.", "start": 2630.81, "duration": 2.205}, {"text": "That would be the purpose\nof an entire course", "start": 2633.015, "duration": 1.875}, {"text": "on Bayesian inference.", "start": 2634.89, "duration": 1.74}, {"text": "Actually, even\nBayesian computations", "start": 2636.63, "duration": 2.94}, {"text": "would be an entire\ncourse on its own.", "start": 2639.57, "duration": 2.584}, {"text": "And there's some very\ninteresting things", "start": 2642.154, "duration": 1.666}, {"text": "that are going on there,\nthe interface of stats", "start": 2643.82, "duration": 1.958}, {"text": "and computation.", "start": 2645.778, "duration": 1.112}, {"text": "So let's go back to our example\nand see if we can actually", "start": 2650.054, "duration": 2.416}, {"text": "compute any of those things.", "start": 2652.47, "duration": 1.166}, {"text": "Because it's very nice to give\nyou some data, some formulas.", "start": 2653.636, "duration": 3.784}, {"text": "Let's see if we\ncan actually do it.", "start": 2657.42, "duration": 2.57}, {"text": "In particular, can I\nactually recover this claim", "start": 2659.99, "duration": 3.82}, {"text": "that the posterior associated\nto a beta prior with a Bernoulli", "start": 2663.81, "duration": 7.44}, {"text": "likelihood is actually\ngiving me a beta again?", "start": 2671.25, "duration": 4.53}, {"text": "What was my prior?", "start": 2675.78, "duration": 0.93}, {"text": "So p was following\na beta AA, which", "start": 2682.67, "duration": 3.3}, {"text": "means that p, the density.", "start": 2685.97, "duration": 2.35}, {"text": "That was pi of theta.", "start": 2693.62, "duration": 2.99}, {"text": "Well I'm going to\nwrite this as pi of p--", "start": 2696.61, "duration": 2.97}, {"text": "was proportional to p to the\nA minus 1 times 1 minus p", "start": 2699.58, "duration": 6.22}, {"text": "to the A minus 1.", "start": 2705.8, "duration": 3.006}, {"text": "So that's the first ingredient\nI need to complete my posterior.", "start": 2708.806, "duration": 2.624}, {"text": "I really need only two, if I\nwanted to bound up to constant.", "start": 2711.43, "duration": 2.94}, {"text": "The second one was p hat.", "start": 2714.37, "duration": 1.864}, {"text": "We've computed that many times.", "start": 2720.71, "duration": 1.91}, {"text": "And we had even a nice\ncompact way of writing it,", "start": 2722.62, "duration": 2.99}, {"text": "which was that pn of X1,\nXn, given the parameter p.", "start": 2725.61, "duration": 6.96}, {"text": "So the joint density of my data,\ngiven p, that's my likelihood.", "start": 2732.57, "duration": 4.28}, {"text": "The likelihood of p was what?", "start": 2736.85, "duration": 1.88}, {"text": "Well it was p to\nthe sum of Xi's.", "start": 2738.73, "duration": 2.5}, {"text": "1 minus p to the n\nminus some of the Xi's.", "start": 2744.03, "duration": 2.27}, {"text": "Anybody wants me\nto parse this more?", "start": 2750.99, "duration": 2.76}, {"text": "Or do you remember seeing\nthat from maximum likelihood", "start": 2753.75, "duration": 2.31}, {"text": "estimation?", "start": 2756.06, "duration": 1.0}, {"text": "Yeah?", "start": 2757.06, "duration": 0.637}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 2757.697, "duration": 5.232}, {"text": "PHILLIPE RIGOLLET: That's\nwhat conditioning does.", "start": 2762.929, "duration": 2.041}, {"text": "AUDIENCE: [INAUDIBLE]\nprevious slide.", "start": 2770.838, "duration": 4.401}, {"text": "[INAUDIBLE] bottom\nthere, it says D pi of t.", "start": 2775.239, "duration": 3.912}, {"text": "Shouldn't it be dt pi of t?", "start": 2779.151, "duration": 4.419}, {"text": "PHILLIPE RIGOLLET:\nSo D pi of T is", "start": 2783.57, "duration": 1.73}, {"text": "a measure theoretic notation,\nwhich I used without thinking.", "start": 2785.3, "duration": 3.81}, {"text": "And I should not because\nI can see it upsets you.", "start": 2789.11, "duration": 3.27}, {"text": "D pi of T is just a\nnatural way to say", "start": 2792.38, "duration": 2.67}, {"text": "that I integrate\nagainst whatever I'm", "start": 2795.05, "duration": 3.12}, {"text": "given for the prior of theta.", "start": 2798.17, "duration": 5.76}, {"text": "In particular, if theta is just\nthe mix of a PDF and a point", "start": 2803.93, "duration": 4.89}, {"text": "mass, maybe I say\nthat my p takes", "start": 2808.82, "duration": 2.61}, {"text": "value 0.5 with probability 0.5.", "start": 2811.43, "duration": 2.97}, {"text": "And then is uniform on the\ninterval with probability 0.5.", "start": 2814.4, "duration": 4.5}, {"text": "For this, I neither\nhave a PDF nor a PMF.", "start": 2818.9, "duration": 3.03}, {"text": "But I can still talk about\nintegrating with respect", "start": 2821.93, "duration": 2.22}, {"text": "to this, right?", "start": 2824.15, "duration": 0.78}, {"text": "It's going to look like, if\nI take a function f of T,", "start": 2824.93, "duration": 3.6}, {"text": "D pi of T is going to be\none half of f of one half.", "start": 2828.53, "duration": 5.95}, {"text": "That's the point mass\nwith probability one half,", "start": 2834.48, "duration": 2.0}, {"text": "at one half.", "start": 2836.48, "duration": 1.08}, {"text": "Plus one half of the integral\nbetween 0 and 1, of f of TDT.", "start": 2837.56, "duration": 5.67}, {"text": "This is just the notation, which\nis actually funnily enough,", "start": 2843.23, "duration": 3.75}, {"text": "interchangeable with pi of DT.", "start": 2846.98, "duration": 2.38}, {"text": "But if you have a\ndensity, it's really", "start": 2852.46, "duration": 2.43}, {"text": "just the density pi of TDT.", "start": 2854.89, "duration": 4.911}, {"text": "If pi is really a\ndensity, but that's", "start": 2859.801, "duration": 2.139}, {"text": "when it's when pi is and\nmeasure and not a density.", "start": 2861.94, "duration": 2.18}, {"text": "Everybody else,\nforget about this.", "start": 2866.82, "duration": 2.88}, {"text": "This is not something\nyou should really", "start": 2869.7, "duration": 1.927}, {"text": "worry about at this point.", "start": 2871.627, "duration": 1.083}, {"text": "This is more graduate\nlevel probability classes.", "start": 2872.71, "duration": 3.009}, {"text": "But yeah, it's called\nmeasure theory.", "start": 2875.719, "duration": 1.541}, {"text": "And that's when you think\nof pi as being a measure", "start": 2877.26, "duration": 1.9}, {"text": "in an abstract fashion.", "start": 2879.16, "duration": 0.82}, {"text": "You don't have to worry\nwhether it's a density", "start": 2879.98, "duration": 1.916}, {"text": "or not, or whether\nit has a density.", "start": 2881.896, "duration": 2.104}, {"text": "So everybody is OK with this?", "start": 2888.35, "duration": 1.9}, {"text": "Now I need to\ncompute my posterior.", "start": 2895.53, "duration": 1.86}, {"text": "And as I said, my\nposterior is really", "start": 2897.39, "duration": 5.73}, {"text": "just the product of\nthe likelihood weighted", "start": 2903.12, "duration": 2.43}, {"text": "by the prior.", "start": 2905.55, "duration": 3.42}, {"text": "Hopefully, at this stage\nof your application,", "start": 2908.97, "duration": 4.06}, {"text": "you can multiply two functions.", "start": 2913.03, "duration": 2.36}, {"text": "So what's happening is,\nif I multiply this guy", "start": 2915.39, "duration": 2.19}, {"text": "with this guy, p gets\nthis guy to the power", "start": 2917.58, "duration": 3.72}, {"text": "this guy plus this guy.", "start": 2921.3, "duration": 1.56}, {"text": "And then 1 minus p gets the\npower n minus some of Xi's.", "start": 2933.81, "duration": 6.21}, {"text": "So this is always\nfrom I equal 1 to n.", "start": 2940.02, "duration": 2.88}, {"text": "And then plus A minus 1 as well.", "start": 2942.9, "duration": 1.49}, {"text": "This is up to constant, because\nI still need to solve this.", "start": 2950.01, "duration": 5.55}, {"text": "And I could try to do it.", "start": 2955.56, "duration": 1.699}, {"text": "But I really don't\nhave to, because I", "start": 2957.259, "duration": 1.541}, {"text": "know that if my density\nhas this form, then", "start": 2958.8, "duration": 5.58}, {"text": "it's a beta distribution.", "start": 2964.38, "duration": 1.152}, {"text": "And then I can just\ngo on Wikipedia", "start": 2965.532, "duration": 1.458}, {"text": "and see what should be\nthe normalization factor.", "start": 2966.99, "duration": 2.031}, {"text": "But I know it's going to\nbe a beta distribution.", "start": 2969.021, "duration": 1.999}, {"text": "It's actually the\nbeta with parameter.", "start": 2971.02, "duration": 3.0}, {"text": "So this is really my beta\nwith parameter, sum of Xi,", "start": 2974.02, "duration": 5.19}, {"text": "i equal 1 to n plus A minus 1.", "start": 2979.21, "duration": 4.37}, {"text": "And then the second\nparameter is n minus sum", "start": 2983.58, "duration": 2.55}, {"text": "of the Xi's plus A minus 1.", "start": 2986.13, "duration": 3.676}, {"text": "I just wrote what was here.", "start": 2994.98, "duration": 4.05}, {"text": "What happened to my one?", "start": 2999.03, "duration": 2.55}, {"text": "Oh no, sorry.", "start": 3001.58, "duration": 1.34}, {"text": "Beta has the power minus 1.", "start": 3002.92, "duration": 2.72}, {"text": "So that's the\nparameter of the beta.", "start": 3005.64, "duration": 3.207}, {"text": "And this is the\nparameter of the beta.", "start": 3008.847, "duration": 1.583}, {"text": "Beta is over there, right?", "start": 3015.127, "duration": 1.083}, {"text": "So I just replace\nA by what I see.", "start": 3016.21, "duration": 3.642}, {"text": "A is just becoming\nthis guy plus this guy", "start": 3019.852, "duration": 2.438}, {"text": "and this guy plus this guy.", "start": 3022.29, "duration": 4.11}, {"text": "Everybody is comfortable\nwith this computation?", "start": 3026.4, "duration": 2.262}, {"text": "We just agreed that beta priors\nfor Bernoulli observations", "start": 3034.17, "duration": 4.68}, {"text": "are certainly convenient.", "start": 3038.85, "duration": 3.69}, {"text": "Because they are just\nconjugate, and we know", "start": 3042.54, "duration": 1.917}, {"text": "that's what is going\nto come out in the end.", "start": 3044.457, "duration": 1.833}, {"text": "That's going to\nbe a beta as well.", "start": 3046.29, "duration": 2.609}, {"text": "I just claim it was convenient.", "start": 3048.899, "duration": 1.291}, {"text": "It was certainly convenient\nto compute this, right?", "start": 3050.19, "duration": 2.7}, {"text": "There was certainly\nsome compatibility", "start": 3052.89, "duration": 2.851}, {"text": "when I had to multiply this\nfunction by that function.", "start": 3055.741, "duration": 2.249}, {"text": "And you can imagine that things\ncould go much more wrong,", "start": 3057.99, "duration": 2.926}, {"text": "than just having p to some power\nand p to some power, 1 minus p", "start": 3060.916, "duration": 2.624}, {"text": "to some power, when it might\njust be some other power.", "start": 3063.54, "duration": 2.85}, {"text": "Things were nice.", "start": 3066.39, "duration": 2.89}, {"text": "Now this is nice, but I can also\nquestion the following things.", "start": 3069.28, "duration": 3.13}, {"text": "Why beta, for one?", "start": 3072.41, "duration": 1.92}, {"text": "The beta tells me something.", "start": 3074.33, "duration": 3.51}, {"text": "That's convenient, but\nthen how do I pick A?", "start": 3077.84, "duration": 2.796}, {"text": "I know that A should definitely\ncapture the fact that where", "start": 3080.636, "duration": 6.864}, {"text": "I want to have my p\nmost likely located.", "start": 3087.5, "duration": 2.7}, {"text": "But it also actually\nalso captures", "start": 3090.2, "duration": 2.19}, {"text": "the variance of my beta.", "start": 3092.39, "duration": 2.19}, {"text": "And so choosing\ndifferent As is going", "start": 3094.58, "duration": 2.16}, {"text": "to have different functions.", "start": 3096.74, "duration": 1.21}, {"text": "If I have A and B, If I started\nwith the beta with parameter.", "start": 3097.95, "duration": 5.1}, {"text": "If I started with a B here, I\nwould just pick up the B here.", "start": 3103.05, "duration": 5.06}, {"text": "Agreed?", "start": 3108.11, "duration": 1.752}, {"text": "And that would just\nbe a symmetric.", "start": 3109.862, "duration": 1.458}, {"text": "But they're going to\ncapture mean and variance", "start": 3111.32, "duration": 1.95}, {"text": "of this thing.", "start": 3113.27, "duration": 0.583}, {"text": "And so how do I pick those guys?", "start": 3113.853, "duration": 2.177}, {"text": "If I'm a doctor and\nyou're asking me,", "start": 3116.03, "duration": 3.407}, {"text": "what do you think the\nchances of this drug working", "start": 3119.437, "duration": 2.083}, {"text": "in this kind of patients is?", "start": 3121.52, "duration": 1.71}, {"text": "And I have to spit out the\nparameters of a beta for you,", "start": 3123.23, "duration": 2.85}, {"text": "it might be a bit of a\ncomplicated thing to do.", "start": 3126.08, "duration": 2.55}, {"text": "So how do you do this,\nespecially for problems?", "start": 3128.63, "duration": 2.09}, {"text": "So by now, people\nhave actually mastered", "start": 3130.72, "duration": 4.03}, {"text": "the art of coming up with how\nto formulate those numbers.", "start": 3134.75, "duration": 4.54}, {"text": "But in new problems that\ncome up, how do you do this?", "start": 3139.29, "duration": 2.37}, {"text": "What happens if you want\nto use Bayesian methods,", "start": 3141.66, "duration": 2.18}, {"text": "but you actually do not\nknow what you expect to see?", "start": 3143.84, "duration": 6.3}, {"text": "To be fair, before we started\nthis class, I hope all of you", "start": 3150.14, "duration": 3.12}, {"text": "had no idea whether people tend\nto bend their head to the right", "start": 3153.26, "duration": 3.61}, {"text": "or to the left before kissing.", "start": 3156.87, "duration": 1.302}, {"text": "Because if you did, well\nyou have too much time", "start": 3158.172, "duration": 1.958}, {"text": "on your hands and I should\ndouble your homework.", "start": 3160.13, "duration": 2.0}, {"text": "So in this case,\nmaybe you still want", "start": 3164.39, "duration": 2.58}, {"text": "to use the Bayesian machinery.", "start": 3166.97, "duration": 1.86}, {"text": "Maybe you just want\nto do something nice.", "start": 3168.83, "duration": 2.15}, {"text": "It's nice right, I mean\nit worked out pretty well.", "start": 3170.98, "duration": 2.532}, {"text": "What if you want to do?", "start": 3173.512, "duration": 0.958}, {"text": "Well you actually want\nto use some priors that", "start": 3174.47, "duration": 2.4}, {"text": "carry no information, that\nbasically do not prefer", "start": 3176.87, "duration": 3.3}, {"text": "any theta to another theta.", "start": 3180.17, "duration": 2.58}, {"text": "Now, you could read\nthis slide or you", "start": 3182.75, "duration": 2.685}, {"text": "could look at this formula.", "start": 3185.435, "duration": 1.125}, {"text": "We just said that this\npi here was just here", "start": 3190.01, "duration": 4.91}, {"text": "to weigh some thetas more\nthan others, depending", "start": 3194.92, "duration": 3.3}, {"text": "on their prior belief.", "start": 3198.22, "duration": 1.65}, {"text": "If our prior belief\ndoes not want", "start": 3199.87, "duration": 1.53}, {"text": "to put any preference towards\nsome thetas than to others,", "start": 3201.4, "duration": 3.48}, {"text": "what do I do?", "start": 3204.88, "duration": 1.452}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 3206.332, "duration": 1.323}, {"text": "PHILLIPE RIGOLLET:\nYeah, I remove it.", "start": 3207.655, "duration": 1.807}, {"text": "And the way to remove\nsomething we multiply by,", "start": 3209.462, "duration": 1.958}, {"text": "is just replace it by one.", "start": 3211.42, "duration": 1.23}, {"text": "That's really what we're doing.", "start": 3212.65, "duration": 2.45}, {"text": "If this was a constant\nnot depending on theta,", "start": 3215.1, "duration": 3.46}, {"text": "then that would mean that\nwe're not preferring any theta.", "start": 3218.56, "duration": 2.84}, {"text": "And we're looking\nat the likelihood.", "start": 3221.4, "duration": 2.97}, {"text": "But not as a function that\nwe're trying to maximize,", "start": 3224.37, "duration": 2.19}, {"text": "but it is a function that\nwe normalize in such a way", "start": 3226.56, "duration": 3.66}, {"text": "that it's actually\na distribution.", "start": 3230.22, "duration": 2.35}, {"text": "So if I have pi,\nwhich is not here,", "start": 3232.57, "duration": 2.212}, {"text": "this is really just taking\nthe like likelihood,", "start": 3234.782, "duration": 1.958}, {"text": "which is a positive function.", "start": 3236.74, "duration": 1.25}, {"text": "It may not integrate\nto 1, so I normalize it", "start": 3237.99, "duration": 1.98}, {"text": "so that it integrates to 1.", "start": 3239.97, "duration": 2.36}, {"text": "And then I just say, well this\nis my posterior distribution.", "start": 3242.33, "duration": 2.79}, {"text": "Now I could just\nmaximize this thing", "start": 3245.12, "duration": 1.65}, {"text": "and spit out my maximum\nlikelihood estimator.", "start": 3246.77, "duration": 2.41}, {"text": "But I can also\nintegrate and find", "start": 3249.18, "duration": 1.67}, {"text": "what the expectation\nof this guy is.", "start": 3250.85, "duration": 1.5}, {"text": "I can find what the\nmedian of this guy is.", "start": 3252.35, "duration": 1.86}, {"text": "I can sample data from this guy.", "start": 3254.21, "duration": 2.16}, {"text": "I can build, understand what\nthe variance of this guy is.", "start": 3256.37, "duration": 3.06}, {"text": "Which is something we did\nnot do when we just did", "start": 3259.43, "duration": 2.4}, {"text": "maximum likelihood estimation\nbecause given a function, all", "start": 3261.83, "duration": 2.97}, {"text": "we cared about was the\narc max of this function.", "start": 3264.8, "duration": 3.198}, {"text": "These priors are\ncalled uninformative.", "start": 3271.68, "duration": 4.44}, {"text": "This is just replacing this\nnumber by one or by a constant.", "start": 3276.12, "duration": 7.32}, {"text": "Because it still\nhas to be a density.", "start": 3283.44, "duration": 1.58}, {"text": "If I have a bounded\nset, I'm just", "start": 3289.236, "duration": 1.374}, {"text": "looking for the\nuniform distribution", "start": 3290.61, "duration": 2.34}, {"text": "on this bounded set, the\none that puts constant one", "start": 3292.95, "duration": 3.63}, {"text": "over the size of this thing.", "start": 3296.58, "duration": 2.62}, {"text": "But if I have an\ninvalid set, what", "start": 3299.2, "duration": 2.39}, {"text": "is the density that\ntakes a constant value", "start": 3301.59, "duration": 2.28}, {"text": "on the entire real\nline, for example?", "start": 3303.87, "duration": 3.685}, {"text": "What is this density?", "start": 3307.555, "duration": 0.875}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 3313.2, "duration": 3.35}, {"text": "PHILLIPE RIGOLLET:\nDoesn't exist, right?", "start": 3316.55, "duration": 1.98}, {"text": "It just doesn't exist.", "start": 3318.53, "duration": 2.46}, {"text": "The way you can think\nof it is a Gaussian", "start": 3320.99, "duration": 1.78}, {"text": "with the variance going\nto infinity, maybe,", "start": 3322.77, "duration": 2.09}, {"text": "or something like this.", "start": 3324.86, "duration": 1.429}, {"text": "But you can think\nof it in many ways.", "start": 3326.289, "duration": 1.541}, {"text": "You can think of the limit of\nthe uniform between minus T", "start": 3327.83, "duration": 4.5}, {"text": "and T, with T going to infinity.", "start": 3332.33, "duration": 1.92}, {"text": "But this thing is actually zero.", "start": 3334.25, "duration": 2.23}, {"text": "There's nothing there.", "start": 3336.48, "duration": 3.05}, {"text": "You can actually\nstill talk about this.", "start": 3339.53, "duration": 2.46}, {"text": "You could always talk\nabout this thing, where", "start": 3341.99, "duration": 2.4}, {"text": "you think of this guy\nas being a constant,", "start": 3344.39, "duration": 2.16}, {"text": "remove this thing from this\nequation, and just say,", "start": 3346.55, "duration": 2.53}, {"text": "well my posterior is\njust the likelihood", "start": 3349.08, "duration": 2.24}, {"text": "divided by the integral of\nthe likelihood over theta.", "start": 3351.32, "duration": 3.36}, {"text": "And if theta is the entire\nreal line, so be it.", "start": 3354.68, "duration": 3.97}, {"text": "As long as this\nintegral converges,", "start": 3358.65, "duration": 1.74}, {"text": "you can still talk\nabout this stuff.", "start": 3360.39, "duration": 1.5}, {"text": "This is what's called\nan improper prior.", "start": 3364.46, "duration": 1.84}, {"text": "An improper prior is just a\nnon-negative function defined", "start": 3369.14, "duration": 2.85}, {"text": "in theta, but it does not have\nto integrate neither to one,", "start": 3371.99, "duration": 5.4}, {"text": "nor to anything.", "start": 3377.39, "duration": 0.78}, {"text": "If I integrate the\nfunction equal to 1", "start": 3380.9, "duration": 1.8}, {"text": "on the entire real\nline, what do I get?", "start": 3382.7, "duration": 1.63}, {"text": "Infinity.", "start": 3387.8, "duration": 0.72}, {"text": "It's not a proper prior, and\nit's called and improper prior.", "start": 3392.39, "duration": 3.57}, {"text": "And those improper\npriors are usually", "start": 3395.96, "duration": 3.42}, {"text": "what you see when you start\nto want non-informative priors", "start": 3399.38, "duration": 3.45}, {"text": "on infinite sets of datas.", "start": 3402.83, "duration": 1.53}, {"text": "That's just the nature of it.", "start": 3404.36, "duration": 2.52}, {"text": "You should think of them as\nbeing the uniform distribution", "start": 3406.88, "duration": 3.14}, {"text": "of some infinite set, if\nthat thing were to exist.", "start": 3410.02, "duration": 2.53}, {"text": "Let's see some examples\nabout non-informative priors.", "start": 3416.36, "duration": 4.71}, {"text": "If I'm in the interval 0,\n1 this is a finite set.", "start": 3421.07, "duration": 3.34}, {"text": "So I can talk about\nthe uniform prior", "start": 3424.41, "duration": 3.32}, {"text": "on the interval 0, 1 for a\nparameter, p of a Bernoulli.", "start": 3427.73, "duration": 2.87}, {"text": "If I want to talk\nabout this, then it", "start": 3446.38, "duration": 1.62}, {"text": "means that my prior is p follows\nsome uniform on the interval", "start": 3448.0, "duration": 7.91}, {"text": "0, 1.", "start": 3455.91, "duration": 1.66}, {"text": "So that means that f of\nx is 1 if x is in 0, 1.", "start": 3457.57, "duration": 11.37}, {"text": "Otherwise, there is actually\nnot even a normalization.", "start": 3468.94, "duration": 3.06}, {"text": "This thing integrates to 1.", "start": 3472.0, "duration": 1.86}, {"text": "And so now if I look\nat my likelihood,", "start": 3473.86, "duration": 2.277}, {"text": "it's still the same thing.", "start": 3476.137, "duration": 1.083}, {"text": "So my posterior\nbecomes theta X1, Xn.", "start": 3477.22, "duration": 7.29}, {"text": "That's my posterior.", "start": 3484.51, "duration": 2.512}, {"text": "I don't write the\nlikelihood again,", "start": 3487.022, "duration": 1.458}, {"text": "because we still have it--", "start": 3488.48, "duration": 1.35}, {"text": "well we don't have\nit here anymore.", "start": 3489.83, "duration": 1.753}, {"text": "The likelihood is given here.", "start": 3495.44, "duration": 2.5}, {"text": "Copy, paste over there.", "start": 3497.94, "duration": 2.99}, {"text": "The posterior is just\nthis thing times 1.", "start": 3500.93, "duration": 2.139}, {"text": "So you will see it in a second.", "start": 3503.069, "duration": 1.291}, {"text": "So it's p to the power sum\nof the Xi's, one minus p", "start": 3504.36, "duration": 4.21}, {"text": "to the power, n minus\nsum of the Xi's.", "start": 3508.57, "duration": 3.4}, {"text": "And then it's multiplied by\n1, and then divided by this", "start": 3511.97, "duration": 4.41}, {"text": "integral between 0 and\n1 of p, sum of the Xi's.", "start": 3516.38, "duration": 5.87}, {"text": "1 minus p, n minus\nsum of the Xi's.", "start": 3522.25, "duration": 5.62}, {"text": "Dp, which does not depend on p.", "start": 3527.87, "duration": 3.996}, {"text": "And I really don't care\nwhat the thing actually is.", "start": 3531.866, "duration": 2.124}, {"text": "That's posterior of p.", "start": 3538.9, "duration": 4.65}, {"text": "And now I can see,\nwell what is this?", "start": 3543.55, "duration": 2.73}, {"text": "It's actually just the\nbeta with parameters.", "start": 3546.28, "duration": 6.59}, {"text": "This guy plus 1.", "start": 3552.87, "duration": 1.25}, {"text": "And this guy plus 1.", "start": 3559.67, "duration": 2.01}, {"text": "I didn't tell you what the\nexpectation of a beta was.", "start": 3574.43, "duration": 3.627}, {"text": "We don't know what the\nexpectation of a beta", "start": 3578.057, "duration": 1.833}, {"text": "is, agreed?", "start": 3579.89, "duration": 2.31}, {"text": "If I wanted to find say, the\nexpectation of this thing that", "start": 3582.2, "duration": 3.78}, {"text": "would be some good\nestimator, we know", "start": 3585.98, "duration": 2.01}, {"text": "that the maximum\nof this guy-- what", "start": 3587.99, "duration": 1.912}, {"text": "is the maximum of this thing?", "start": 3589.902, "duration": 1.208}, {"text": "Well, it's just this thing,\nit's the average of the Xi's.", "start": 3594.88, "duration": 3.057}, {"text": "That's just the maximum\nlikelihood estimator", "start": 3597.937, "duration": 1.833}, {"text": "for Bernoulli.", "start": 3599.77, "duration": 0.583}, {"text": "We know it's the average.", "start": 3600.353, "duration": 1.349}, {"text": "Do you think if I take the\nexpectation of this thing,", "start": 3601.702, "duration": 2.208}, {"text": "I'm going to get the average?", "start": 3603.91, "duration": 1.385}, {"text": "So actually, I'm not\ngoing to get the average.", "start": 3613.864, "duration": 1.916}, {"text": "I'm going to get this guy plus\nthis guy, divided by n plus 1.", "start": 3615.78, "duration": 4.01}, {"text": "Let's look at what\nthis thing is doing.", "start": 3627.246, "duration": 1.624}, {"text": "It's looking at the number\nof ones and it's adding one.", "start": 3628.87, "duration": 5.494}, {"text": "And this guy is looking\nat the number of zeros", "start": 3634.364, "duration": 1.916}, {"text": "and it's adding one.", "start": 3636.28, "duration": 2.91}, {"text": "Why is it adding this one?", "start": 3639.19, "duration": 2.72}, {"text": "What's going on here?", "start": 3641.91, "duration": 0.93}, {"text": "This is going to matter\nmostly when the number of ones", "start": 3647.51, "duration": 4.53}, {"text": "is actually zero, or the\nnumber of zeros is zero.", "start": 3652.04, "duration": 4.02}, {"text": "Because what it does is just\npushes the zero from non-zero.", "start": 3656.06, "duration": 3.94}, {"text": "And why is that something that\nthis Bayesian method actually", "start": 3660.0, "duration": 3.02}, {"text": "does for you automatically?", "start": 3663.02, "duration": 1.58}, {"text": "It's because when we\nput this non-informative", "start": 3664.6, "duration": 1.93}, {"text": "prior on p, which was\nuniform on the interval 0, 1.", "start": 3666.53, "duration": 4.639}, {"text": "In particular, we know\nthat the probability", "start": 3671.169, "duration": 1.791}, {"text": "that p is equal to 0 is zero.", "start": 3672.96, "duration": 3.73}, {"text": "And the probability p\nis equal to 1 is zero.", "start": 3676.69, "duration": 2.49}, {"text": "And so the problem\nis that if I did not", "start": 3679.18, "duration": 2.7}, {"text": "add this 1 with some\npositive probability,", "start": 3681.88, "duration": 2.64}, {"text": "I wouldn't be allowed to spit\nout something that actually had", "start": 3684.52, "duration": 3.6}, {"text": "p hat, which was equal to 0.", "start": 3688.12, "duration": 2.52}, {"text": "If by chance, let's say\nI have n is equal to 3,", "start": 3690.64, "duration": 2.64}, {"text": "and I get only 0, 0, 0, that\ncould happen with probability.", "start": 3693.28, "duration": 4.47}, {"text": "1 over pq, one over 1 minus pq.", "start": 3697.75, "duration": 3.72}, {"text": "That's not something\nthat I want.", "start": 3706.36, "duration": 1.52}, {"text": "And I'm using my priors.", "start": 3707.88, "duration": 1.479}, {"text": "My prior is not informative,\nbut somehow it captures the fact", "start": 3709.359, "duration": 2.541}, {"text": "that I don't want to\nbelieve p is going", "start": 3711.9, "duration": 1.65}, {"text": "to be either equal to 0 or 1.", "start": 3713.55, "duration": 2.56}, {"text": "So that's sort of\ntaken care of here.", "start": 3716.11, "duration": 3.68}, {"text": "So let's move away a little\nbit from the Bernoulli example,", "start": 3719.79, "duration": 5.85}, {"text": "shall we?", "start": 3725.64, "duration": 0.67}, {"text": "I think we've seen enough of it.", "start": 3726.31, "duration": 1.81}, {"text": "And so let's talk about\nthe Gaussian model.", "start": 3728.12, "duration": 2.74}, {"text": "Let's say I want to\ndo Gaussian inference.", "start": 3730.86, "duration": 1.83}, {"text": "I want to do inference\nin a Gaussian model,", "start": 3737.859, "duration": 1.791}, {"text": "using Bayesian methods.", "start": 3739.65, "duration": 1.08}, {"text": "What I want is that Xi,\nX1, Xn, or say 0, 1 iid.", "start": 3750.6, "duration": 9.24}, {"text": "Sorry, theta 1, iid\nconditionally on theta.", "start": 3764.72, "duration": 3.05}, {"text": "That means that pn of\nX1, Xn, given theta", "start": 3770.63, "duration": 5.67}, {"text": "is equal to exactly\nwhat I wrote before.", "start": 3776.3, "duration": 2.37}, {"text": "So 1 square root to pi, to the\nn exponential minus one half", "start": 3778.67, "duration": 6.09}, {"text": "sum of Xi minus theta squared.", "start": 3784.76, "duration": 4.819}, {"text": "So that's just the\njoint distribution", "start": 3789.579, "duration": 1.541}, {"text": "of my Gaussian with mean data.", "start": 3791.12, "duration": 2.29}, {"text": "And the another\nquestion is, what", "start": 3793.41, "duration": 1.4}, {"text": "is the posterior distribution?", "start": 3794.81, "duration": 2.73}, {"text": "Well here I said, let's use\nthe uninformative prior,", "start": 3797.54, "duration": 4.96}, {"text": "which is an improper prior.", "start": 3802.5, "duration": 1.34}, {"text": "It puts weight on everyone.", "start": 3803.84, "duration": 1.65}, {"text": "That's the so-called uniform\non the entire real line.", "start": 3805.49, "duration": 3.82}, {"text": "So that's certainly\nnot a density.", "start": 3809.31, "duration": 1.88}, {"text": "But it can still just use this.", "start": 3811.19, "duration": 3.17}, {"text": "So all I need to do\nis get this divided", "start": 3814.36, "duration": 6.07}, {"text": "by normalizing this thing.", "start": 3820.43, "duration": 4.26}, {"text": "But if you look at\nthis, essentially I", "start": 3824.69, "duration": 3.21}, {"text": "want to understand.", "start": 3827.9, "duration": 1.63}, {"text": "So this is proportional\nto the exponential", "start": 3829.53, "duration": 2.94}, {"text": "minus one half\nsum from I equal 1", "start": 3832.47, "duration": 2.57}, {"text": "to n of Xi minus theta squared.", "start": 3835.04, "duration": 3.91}, {"text": "And now I want to see\nthis thing as a density,", "start": 3838.95, "duration": 2.42}, {"text": "not on the Xi's but on theta.", "start": 3841.37, "duration": 2.19}, {"text": "What I want is a\ndensity on theta.", "start": 3846.42, "duration": 3.7}, {"text": "So it looks like I have\nchances of getting something", "start": 3850.12, "duration": 3.53}, {"text": "that looks like a Gaussian.", "start": 3853.65, "duration": 3.15}, {"text": "To have a Gaussian, I would\nneed to see minus one half.", "start": 3856.8, "duration": 2.7}, {"text": "And then I would need to\nsee theta minus something", "start": 3859.5, "duration": 2.16}, {"text": "here, not just the sum of\nsomething minus thetas.", "start": 3861.66, "duration": 3.57}, {"text": "So I need to work\na little bit more,", "start": 3865.23, "duration": 4.59}, {"text": "to expand the square here.", "start": 3869.82, "duration": 1.655}, {"text": "So this thing here\nis going to be", "start": 3871.475, "duration": 1.375}, {"text": "equal to exponential minus\none half sum from I equal 1", "start": 3872.85, "duration": 4.48}, {"text": "to n of Xi squared minus 2Xi\ntheta plus theta squared.", "start": 3877.33, "duration": 7.95}, {"text": "Now what I'm going to do\nis, everything remember", "start": 3910.59, "duration": 3.0}, {"text": "is up to this little sign.", "start": 3913.59, "duration": 2.28}, {"text": "So every time I see a term\nthat does not depend on theta,", "start": 3915.87, "duration": 3.84}, {"text": "I can just push it in there\nand just make it disappear.", "start": 3919.71, "duration": 2.54}, {"text": "Agreed?", "start": 3922.25, "duration": 2.3}, {"text": "This term here, exponential\nminus one half sum of Xi", "start": 3924.55, "duration": 3.87}, {"text": "squared, does it\ndepend on theta?", "start": 3928.42, "duration": 3.241}, {"text": "No.", "start": 3931.661, "duration": 0.499}, {"text": "So I'm just pushing it here.", "start": 3932.16, "duration": 1.26}, {"text": "This guy, yes.", "start": 3933.42, "duration": 1.11}, {"text": "And the other one, yes.", "start": 3934.53, "duration": 1.44}, {"text": "So this is proportional to\nexponential sum of the Xi.", "start": 3935.97, "duration": 9.05}, {"text": "And then I'm going to pull out\nmy theta, the minus one half", "start": 3945.02, "duration": 2.76}, {"text": "canceled with the minus 2.", "start": 3947.78, "duration": 2.37}, {"text": "And then I have minus\none half sum from I", "start": 3950.15, "duration": 6.31}, {"text": "equal 1 to n of theta squared.", "start": 3956.46, "duration": 1.72}, {"text": "Agreed?", "start": 3961.48, "duration": 1.98}, {"text": "So now what this\nthing looks like,", "start": 3963.46, "duration": 1.89}, {"text": "this looks very much like some\ntheta minus something squared.", "start": 3965.35, "duration": 4.22}, {"text": "This thing here is really\njust n over 2 times theta.", "start": 3969.57, "duration": 5.54}, {"text": "Sorry, times theta squared.", "start": 3978.52, "duration": 3.22}, {"text": "So now what I need to do is to\nwrite this of the form, theta", "start": 3981.74, "duration": 3.38}, {"text": "minus something.", "start": 3985.12, "duration": 1.11}, {"text": "Let's call it mu, squared,\ndivided by 2 sigma squared.", "start": 3986.23, "duration": 5.59}, {"text": "I want to turn this into\nthat, maybe up to terms", "start": 3991.82, "duration": 2.34}, {"text": "that do not depend on theta.", "start": 3994.16, "duration": 2.35}, {"text": "That's what I'm\ngoing to try to do.", "start": 3996.51, "duration": 2.552}, {"text": "So that's called\ncompleting the squaring.", "start": 3999.062, "duration": 1.708}, {"text": "That's some exercises you do.", "start": 4000.77, "duration": 1.24}, {"text": "You've done it probably,\nalready in the homework.", "start": 4002.01, "duration": 2.25}, {"text": "And that's something\nyou do a lot when", "start": 4004.26, "duration": 2.3}, {"text": "you do Bayesian\nstatistics, in particular.", "start": 4006.56, "duration": 2.19}, {"text": "So let's do this.", "start": 4008.75, "duration": 1.26}, {"text": "What is it going to\nbe the leading term?", "start": 4010.01, "duration": 1.9}, {"text": "Theta squared is going to\nbe multiplied by this thing.", "start": 4011.91, "duration": 2.25}, {"text": "So I'm going to pull\nout my n over 2.", "start": 4014.16, "duration": 2.97}, {"text": "And then I'm going to write\nthis as minus theta over 2.", "start": 4017.13, "duration": 5.94}, {"text": "And then I'm going to write\ntheta minus something squared.", "start": 4023.07, "duration": 3.15}, {"text": "And this something is going\nto be one half of what", "start": 4026.22, "duration": 2.67}, {"text": "I see in the cross-product.", "start": 4028.89, "duration": 1.27}, {"text": "I need to actually\npull this thing out.", "start": 4032.966, "duration": 1.624}, {"text": "So let me write it\nlike that first.", "start": 4034.59, "duration": 3.75}, {"text": "So that's theta squared.", "start": 4038.34, "duration": 3.52}, {"text": "And then I'm going to write it\nas minus 2 times 1 over n sum", "start": 4041.86, "duration": 8.82}, {"text": "from I equal 1 to n\nof Xi's times theta.", "start": 4050.68, "duration": 6.3}, {"text": "That's exactly just a rewriting\nof what we had before.", "start": 4056.98, "duration": 2.894}, {"text": "And that should look\nmuch more familiar.", "start": 4059.874, "duration": 1.666}, {"text": "A squared minus 2 blap A,\nand then I missed something.", "start": 4064.99, "duration": 4.71}, {"text": "So this thing, I'm going\nto be able to rewrite", "start": 4069.7, "duration": 2.16}, {"text": "as theta minus Xn bar squared.", "start": 4071.86, "duration": 6.07}, {"text": "But then I need to remove\nthe square of Xn bar.", "start": 4077.93, "duration": 2.79}, {"text": "Because it's not here.", "start": 4080.72, "duration": 1.02}, {"text": "So I just complete the square.", "start": 4089.21, "duration": 2.087}, {"text": "And then I actually really don't\ncare with this thing actually", "start": 4091.297, "duration": 2.583}, {"text": "was, because it's going to go\nagain in the little Alpha's", "start": 4093.88, "duration": 3.019}, {"text": "sign over there.", "start": 4096.899, "duration": 1.517}, {"text": "So this thing\neventually is going", "start": 4098.416, "duration": 1.374}, {"text": "to be proportional\nto exponential", "start": 4099.79, "duration": 4.83}, {"text": "of minus n over 2 times theta\nof minus Xn bar squared.", "start": 4104.62, "duration": 6.47}, {"text": "And so we know that if\nthis is a density that's", "start": 4111.09, "duration": 2.28}, {"text": "proportional to this guy, it has\nto be some n with mean, Xn bar.", "start": 4113.37, "duration": 10.73}, {"text": "And variance, this is supposed\nto be 1 over sigma squared.", "start": 4124.1, "duration": 3.42}, {"text": "This guy over here, this n.", "start": 4127.52, "duration": 1.798}, {"text": "So that's really just 1 over n.", "start": 4129.318, "duration": 1.291}, {"text": "So the posterior\ndistribution is a Gaussian", "start": 4133.87, "duration": 7.87}, {"text": "centered at the average\nof my observations.", "start": 4141.74, "duration": 4.079}, {"text": "And with variance, 1 over n.", "start": 4145.819, "duration": 2.611}, {"text": "Everybody's with me?", "start": 4153.307, "duration": 0.833}, {"text": "Why I'm saying this, this was\nthe output of some computation.", "start": 4156.74, "duration": 3.039}, {"text": "But it sort of\nmakes sense, right?", "start": 4159.779, "duration": 1.671}, {"text": "It's really telling me that\nthe more observations I have,", "start": 4161.45, "duration": 2.76}, {"text": "the more concentrated\nthis posterior is.", "start": 4164.21, "duration": 2.04}, {"text": "Concentrated around what?", "start": 4166.25, "duration": 1.569}, {"text": "Well around this Xn bar.", "start": 4167.819, "duration": 2.71}, {"text": "That looks like something\nwe've sort of seen before.", "start": 4170.529, "duration": 2.611}, {"text": "But it does not have the\nsame meaning, somehow.", "start": 4173.14, "duration": 2.28}, {"text": "This is really just the\nposterior distribution.", "start": 4175.42, "duration": 2.16}, {"text": "It's sort of a sanity check,\nthat I have this 1 over n", "start": 4180.49, "duration": 2.67}, {"text": "when I have Xn bar.", "start": 4183.16, "duration": 0.979}, {"text": "But it's not the\nsame thing as saying", "start": 4184.139, "duration": 1.541}, {"text": "that the variance of Xn bar was\n1 over n, like we had before.", "start": 4185.68, "duration": 2.749}, {"text": "As an exercise,\nI would recommend", "start": 4195.67, "duration": 3.72}, {"text": "if you don't get it,\njust try pi of theta", "start": 4199.39, "duration": 10.75}, {"text": "to be equal to some n mu 1.", "start": 4210.14, "duration": 5.15}, {"text": "Here, the prior that we used\nwas completely non-informative.", "start": 4218.12, "duration": 4.23}, {"text": "What happens if I take my prior\nto be some Gaussian, which", "start": 4222.35, "duration": 3.244}, {"text": "is centered at mu and\nit has the same variance", "start": 4225.594, "duration": 1.916}, {"text": "as the other guys?", "start": 4227.51, "duration": 2.61}, {"text": "So what's going to\nhappen here is that we're", "start": 4230.12, "duration": 2.084}, {"text": "going to put a weight.", "start": 4232.204, "duration": 0.916}, {"text": "And everything\nthat's away from mu", "start": 4233.12, "duration": 1.416}, {"text": "is going to actually\nget less weight.", "start": 4234.536, "duration": 3.933}, {"text": "I want to know how I'm\ngoing to be updating", "start": 4238.469, "duration": 1.791}, {"text": "this prior into a posterior.", "start": 4240.26, "duration": 1.59}, {"text": "Everybody sees what\nI'm saying here?", "start": 4244.52, "duration": 2.52}, {"text": "So that means that pi of theta\nhas the density proportional", "start": 4247.04, "duration": 3.0}, {"text": "to exponential minus one\nhalf theta minus mu squared.", "start": 4250.04, "duration": 5.64}, {"text": "So I need to multiply\nmy posterior with this,", "start": 4255.68, "duration": 4.86}, {"text": "and then see.", "start": 4260.54, "duration": 1.309}, {"text": "It's actually going\nto be a Gaussian.", "start": 4261.849, "duration": 1.541}, {"text": "This is also a conjugate prior.", "start": 4263.39, "duration": 1.384}, {"text": "It's going to spit\nout another Gaussian.", "start": 4264.774, "duration": 1.666}, {"text": "You're going to have to complete\na square again, and just check", "start": 4266.44, "duration": 2.95}, {"text": "what it's actually giving you.", "start": 4269.39, "duration": 1.424}, {"text": "And so spoiler alert,\nit's going to look", "start": 4270.814, "duration": 1.666}, {"text": "like you get an extra\nobservation, which is actually", "start": 4272.48, "duration": 2.31}, {"text": "equal to mu.", "start": 4274.79, "duration": 0.57}, {"text": "It's going to be the average\nof n plus 1 observations.", "start": 4278.8, "duration": 3.64}, {"text": "The first n1's being X1 to Xn.", "start": 4282.44, "duration": 1.67}, {"text": "And then, the last one being mu.", "start": 4284.11, "duration": 3.42}, {"text": "And it sort of makes sense.", "start": 4287.53, "duration": 3.33}, {"text": "That's actually a\nfairly simple exercise.", "start": 4290.86, "duration": 3.84}, {"text": "Rather than going\ninto more computation,", "start": 4294.7, "duration": 1.741}, {"text": "this is something\nyou can definitely", "start": 4296.441, "duration": 1.499}, {"text": "do when you're in the\ncomfort of your room.", "start": 4297.94, "duration": 3.57}, {"text": "I want to talk about\nother types of priors.", "start": 4301.51, "duration": 2.4}, {"text": "The first thing I said is,\nthere's this beta prior", "start": 4303.91, "duration": 3.42}, {"text": "that I just pulled out of my hat\nand that was just convenient.", "start": 4307.33, "duration": 3.06}, {"text": "Then there was this\nnon-informative prior.", "start": 4310.39, "duration": 2.47}, {"text": "It was convenient.", "start": 4312.86, "duration": 0.86}, {"text": "It was non-informative, so\nif you don't know anything", "start": 4313.72, "duration": 2.58}, {"text": "else maybe that's\nwhat you want to do.", "start": 4316.3, "duration": 2.65}, {"text": "The question is, are there\nany other priors that", "start": 4318.95, "duration": 2.99}, {"text": "are sort of principled\nand generic, in the sense", "start": 4321.94, "duration": 2.55}, {"text": "that the uninformative\nprior was generic, right?", "start": 4324.49, "duration": 4.11}, {"text": "It was equal to 1, that's\nas generic as it gets.", "start": 4328.6, "duration": 2.8}, {"text": "So is there anything\nthat's generic as well?", "start": 4331.4, "duration": 2.79}, {"text": "Well, there's this priors that\nare called Jeffrey's priors.", "start": 4334.19, "duration": 2.99}, {"text": "And Jeffrey's prior, which is\nproportional to square root", "start": 4337.18, "duration": 3.36}, {"text": "of the determinant of the\nFisher information of theta.", "start": 4340.54, "duration": 2.75}, {"text": "This is actually a\nweird thing to do.", "start": 4346.36, "duration": 2.24}, {"text": "It says, look at your model.", "start": 4348.6, "duration": 2.78}, {"text": "Your model is going to\nhave a Fisher information.", "start": 4351.38, "duration": 2.772}, {"text": "Let's say it exists.", "start": 4354.152, "duration": 0.833}, {"text": "Because we know it\ndoes not always exist.", "start": 4358.15, "duration": 1.807}, {"text": "For example, in the\nmultinomial model,", "start": 4359.957, "duration": 1.583}, {"text": "we didn't have a\nFisher information.", "start": 4361.54, "duration": 3.12}, {"text": "The determinant of\na matrix is somehow", "start": 4364.66, "duration": 2.01}, {"text": "measuring the size of a matrix.", "start": 4366.67, "duration": 2.13}, {"text": "If you don't trust\nme, just think", "start": 4368.8, "duration": 1.74}, {"text": "about the matrix being\nof size one by one,", "start": 4370.54, "duration": 3.33}, {"text": "then the determinant is just\nthe number that you have there.", "start": 4373.87, "duration": 3.04}, {"text": "And so this is really something\nthat looks like the Fisher", "start": 4376.91, "duration": 3.86}, {"text": "information.", "start": 4380.77, "duration": 0.9}, {"text": "It's proportional to the\namount of information", "start": 4384.374, "duration": 1.916}, {"text": "that you have at\na certain point.", "start": 4386.29, "duration": 3.33}, {"text": "And so what my prior\nis saying well,", "start": 4389.62, "duration": 2.69}, {"text": "I want to put more weights\non those thetas that", "start": 4392.31, "duration": 1.97}, {"text": "are going to just extract more\ninformation from the data.", "start": 4394.28, "duration": 2.77}, {"text": "You can actually\ncompute those things.", "start": 4400.51, "duration": 2.25}, {"text": "In the first example,\nJeffrey's prior", "start": 4402.76, "duration": 3.455}, {"text": "is something that\nlooks like this.", "start": 4406.215, "duration": 2.145}, {"text": "In one dimension,\nFisher information", "start": 4408.36, "duration": 1.87}, {"text": "is essentially one\nthe word variance.", "start": 4410.23, "duration": 3.246}, {"text": "That's just 1 over the\nsquare root of the variance,", "start": 4413.476, "duration": 2.124}, {"text": "because I have the square root.", "start": 4415.6, "duration": 1.95}, {"text": "And when I have the Jeffrey's\nprior, when I have the Gaussian", "start": 4417.55, "duration": 8.22}, {"text": "case, this is the\nidentity matrix", "start": 4425.77, "duration": 3.0}, {"text": "that I would have in\nthe Gaussian case.", "start": 4428.77, "duration": 2.07}, {"text": "The determinant of\nthe identities is 1.", "start": 4430.84, "duration": 1.74}, {"text": "So square root of 1 is 1, and\nso I would basically get 1.", "start": 4432.58, "duration": 3.6}, {"text": "And that gives me my improper\nprior, my uninformative prior", "start": 4436.18, "duration": 2.99}, {"text": "that I had.", "start": 4439.17, "duration": 1.85}, {"text": "So the uninformative\nprior 1 is fine.", "start": 4441.02, "duration": 2.67}, {"text": "Clearly, all the thetas\ncarry the same information", "start": 4443.69, "duration": 3.09}, {"text": "in the Gaussian model.", "start": 4446.78, "duration": 1.38}, {"text": "Whether I translate\nit here or here,", "start": 4448.16, "duration": 2.04}, {"text": "it's pretty clear none\nof them is actually", "start": 4450.2, "duration": 1.92}, {"text": "better than the other.", "start": 4452.12, "duration": 1.02}, {"text": "But clearly for\nthe Bernoulli case,", "start": 4453.14, "duration": 3.39}, {"text": "the p's that are closer\nto the boundary carry", "start": 4456.53, "duration": 6.03}, {"text": "more information.", "start": 4462.56, "duration": 1.38}, {"text": "I sort of like those\nguys, because they just", "start": 4463.94, "duration": 2.31}, {"text": "carry more information.", "start": 4466.25, "duration": 1.507}, {"text": "So what I do is, I\ntake this function.", "start": 4467.757, "duration": 1.583}, {"text": "So p1 minus p.", "start": 4469.34, "duration": 0.96}, {"text": "Remember, it's something\nthat looks like this.", "start": 4470.3, "duration": 3.87}, {"text": "On the interval 0, 1.", "start": 4474.17, "duration": 1.22}, {"text": "This guy, 1 over square\nroot of p1 minus p", "start": 4478.71, "duration": 2.269}, {"text": "is something that\nlooks like this.", "start": 4480.979, "duration": 1.416}, {"text": "Agreed", "start": 4485.78, "duration": 1.84}, {"text": "What it's doing is\nsort of wants to push", "start": 4487.62, "duration": 2.16}, {"text": "towards the piece that actually\ncarry more information.", "start": 4489.78, "duration": 4.806}, {"text": "Whether you want to\nbias your data that", "start": 4494.586, "duration": 1.624}, {"text": "way or not, is something\nyou need to think about.", "start": 4496.21, "duration": 2.91}, {"text": "When you put a prior on your\ndata, on your parameter,", "start": 4499.12, "duration": 2.43}, {"text": "you're sort of biasing\ntowards this idea your data.", "start": 4501.55, "duration": 4.59}, {"text": "That's maybe not\nsuch a good idea,", "start": 4506.14, "duration": 1.56}, {"text": "when you have some p that's\nactually close to one half,", "start": 4507.7, "duration": 5.46}, {"text": "for example.", "start": 4513.16, "duration": 0.66}, {"text": "You're actually\nsaying, no I don't", "start": 4513.82, "duration": 1.14}, {"text": "want to see a p that's\nclose to one half.", "start": 4514.96, "duration": 1.65}, {"text": "Just make a decision,\none way or another.", "start": 4516.61, "duration": 1.74}, {"text": "But just make a decision.", "start": 4518.35, "duration": 1.349}, {"text": "So it's forcing you to do that.", "start": 4519.699, "duration": 1.291}, {"text": "Jeffrey's prior, I'm\nrunning out of time", "start": 4523.69, "duration": 2.4}, {"text": "so I don't want to go\ninto too much detail.", "start": 4526.09, "duration": 3.76}, {"text": "We'll probably stop\nhere, actually.", "start": 4529.85, "duration": 1.82}, {"text": "So Jeffrey's priors have\nthis very nice property.", "start": 4544.57, "duration": 3.24}, {"text": "It's that they actually do not\ncare about the parameterization", "start": 4547.81, "duration": 3.93}, {"text": "of your space.", "start": 4551.74, "duration": 1.41}, {"text": "If you actually have\np and you suddenly", "start": 4553.15, "duration": 3.21}, {"text": "decide that p is not the\nright parameter for Bernoulli,", "start": 4556.36, "duration": 2.49}, {"text": "but it's p squared.", "start": 4558.85, "duration": 1.89}, {"text": "You could decide to\nparameterize this by p squared.", "start": 4560.74, "duration": 2.46}, {"text": "Maybe your doctor is\nactually much more able", "start": 4563.2, "duration": 2.64}, {"text": "to formulate some prior\nassumption on p squared,", "start": 4565.84, "duration": 3.0}, {"text": "rather than p.", "start": 4568.84, "duration": 0.96}, {"text": "You never know.", "start": 4569.8, "duration": 1.3}, {"text": "And so what happens is\nthat Jeffrey's priors", "start": 4571.1, "duration": 3.29}, {"text": "are an invariant in this.", "start": 4574.39, "duration": 1.6}, {"text": "And the reason is because\nthe information carried by p", "start": 4575.99, "duration": 2.57}, {"text": "is the same as the information\ncarried by p squared, somehow.", "start": 4578.56, "duration": 2.57}, {"text": "They're essentially\nthe same thing.", "start": 4588.822, "duration": 1.458}, {"text": "You need to have one to one map.", "start": 4592.95, "duration": 1.68}, {"text": "Where you basically for\neach parameter, before", "start": 4594.63, "duration": 3.266}, {"text": "you have another parameter.", "start": 4597.896, "duration": 1.124}, {"text": "Let's call Eta the\nnew parameters.", "start": 4599.02, "duration": 1.79}, {"text": "The PDF of the new prior\nindexed by Eta this time", "start": 4605.79, "duration": 4.59}, {"text": "is actually also\nJeffrey's prior.", "start": 4610.38, "duration": 2.61}, {"text": "But this time, the\nnew Fisher information", "start": 4612.99, "duration": 2.184}, {"text": "is not the Fisher information\nwith respect to theta.", "start": 4615.174, "duration": 2.166}, {"text": "But it's this Fisher\ninformation associated", "start": 4617.34, "duration": 2.67}, {"text": "to this statistical\nmodel indexed by Eta.", "start": 4620.01, "duration": 3.12}, {"text": "So essentially, when you\nchange the parameterization", "start": 4623.13, "duration": 4.98}, {"text": "of your model, you still\nget Jeffrey's prior", "start": 4628.11, "duration": 2.49}, {"text": "for the new parameterization.", "start": 4630.6, "duration": 2.22}, {"text": "Which is, in a way,\na desirable property.", "start": 4632.82, "duration": 2.2}, {"text": "Jeffrey's prior is just\nan uninformative priors,", "start": 4639.41, "duration": 2.51}, {"text": "or priors you want\nto use when you", "start": 4641.92, "duration": 2.22}, {"text": "want a systematic way without\nreally thinking about what", "start": 4644.14, "duration": 2.34}, {"text": "to pick for your mile.", "start": 4646.48, "duration": 0.916}, {"text": "I'll finish this next time.", "start": 4655.44, "duration": 1.62}, {"text": "And we'll talk about\nBayesian confidence regions.", "start": 4657.06, "duration": 2.85}, {"text": "We'll talk about\nBayesian estimation.", "start": 4659.91, "duration": 1.71}, {"text": "Once I have a posterior,\nwhat do I get?", "start": 4661.62, "duration": 2.454}, {"text": "And basically, the\nonly message is", "start": 4664.074, "duration": 1.416}, {"text": "going to be that you\nmight want to integrate", "start": 4665.49, "duration": 2.37}, {"text": "against the posterior.", "start": 4667.86, "duration": 1.05}, {"text": "Find the posterior, the\nexpectation of your posterior", "start": 4668.91, "duration": 2.58}, {"text": "distribution.", "start": 4671.49, "duration": 0.64}, {"text": "That's a good point\nestimator for theta.", "start": 4672.13, "duration": 1.88}, {"text": "We'll just do a\ncouple of computation.", "start": 4676.86, "duration": 4.16}]