[{"text": "The following content is\nprovided under a Creative", "start": 0.12, "duration": 2.34}, {"text": "Commons license.", "start": 2.46, "duration": 1.42}, {"text": "Your support will help\nMIT OpenCourseWare", "start": 3.88, "duration": 2.21}, {"text": "continue to offer high quality\neducational resources for free.", "start": 6.09, "duration": 4.09}, {"text": "To make a donation or to\nview additional materials", "start": 10.18, "duration": 2.54}, {"text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare", "start": 12.72, "duration": 3.48}, {"text": "at ocw.mit.edu.", "start": 16.2, "duration": 1.425}, {"text": "PHILIPPE RIGOLLET: --of\nour limiting distribution,", "start": 20.507, "duration": 2.083}, {"text": "which happen to be Gaussian.", "start": 22.59, "duration": 1.669}, {"text": "But if the central\nlimit theorem told", "start": 24.259, "duration": 1.541}, {"text": "us that the limiting\ndistribution of some average", "start": 25.8, "duration": 2.76}, {"text": "was something that\nlooked like a Poisson", "start": 28.56, "duration": 1.989}, {"text": "or an [? exponential, ?]\nthen we would just", "start": 30.549, "duration": 1.791}, {"text": "have in the same way\ntaken the quintiles", "start": 32.34, "duration": 2.43}, {"text": "of the exponential distribution.", "start": 34.77, "duration": 1.93}, {"text": "So let's go back to what we had.", "start": 36.7, "duration": 2.74}, {"text": "So generically if you have a\nset of observations X1 to Xn.", "start": 39.44, "duration": 7.55}, {"text": "So remember for the kiss example\nthey were denoted by R1 to Rn,", "start": 46.99, "duration": 5.19}, {"text": "because they were turning\nthe head to the right,", "start": 52.18, "duration": 3.06}, {"text": "but let's just go back.", "start": 55.24, "duration": 1.61}, {"text": "We say X1 to Xn,\nand in this case", "start": 56.85, "duration": 2.95}, {"text": "I'm going to assume\nthey're IID, and I'm", "start": 59.8, "duration": 2.91}, {"text": "going to make them Bernoulli\nwith [INAUDIBLE] p,", "start": 62.71, "duration": 2.99}, {"text": "and p is unknown, right?", "start": 65.7, "duration": 1.01}, {"text": "So what did we do from here?", "start": 70.15, "duration": 1.45}, {"text": "Well, we said p is\nthe expectation of Xi,", "start": 71.6, "duration": 4.224}, {"text": "and actually we didn't even\nthink about it too much.", "start": 75.824, "duration": 2.166}, {"text": "We said, well, if\nI need to estimate", "start": 77.99, "duration": 1.1}, {"text": "the proportion of people who\nturn their head to the right", "start": 79.09, "duration": 2.37}, {"text": "when they kiss, I\njust basically I'm", "start": 81.46, "duration": 1.5}, {"text": "going to compute the average.", "start": 82.96, "duration": 1.44}, {"text": "So our p hat was just\nXn bar, which was just 1", "start": 84.4, "duration": 4.26}, {"text": "over n sum from i\nover 1 2n of the Xi.", "start": 88.66, "duration": 3.51}, {"text": "The average of the observations\nwas their estimate.", "start": 92.17, "duration": 2.82}, {"text": "And then we wanted to build\nsome confidence intervals", "start": 94.99, "duration": 2.7}, {"text": "around this.", "start": 97.69, "duration": 0.53}, {"text": "So what we wanted to understand\nis, how much that this p hat", "start": 98.22, "duration": 3.14}, {"text": "fluctuates.", "start": 101.36, "duration": 1.61}, {"text": "This is a random variable.", "start": 102.97, "duration": 1.09}, {"text": "It's an average of\nrandom variables.", "start": 104.06, "duration": 1.04}, {"text": "It's a random\nvariable, so we want", "start": 105.1, "duration": 1.47}, {"text": "to know what the\ndistribution is.", "start": 106.57, "duration": 1.17}, {"text": "And if we know what\nthe distribution is,", "start": 107.74, "duration": 1.666}, {"text": "then we actually know,\nwell, where it fluctuates.", "start": 109.406, "duration": 2.264}, {"text": "What the expectation is.", "start": 111.67, "duration": 1.14}, {"text": "Around which value it tends\nto fluctuate et cetera.", "start": 112.81, "duration": 2.839}, {"text": "And so what the\ncentral limit theorem", "start": 115.649, "duration": 1.541}, {"text": "told us was if I take square\nroot of n times Xn bar minus p,", "start": 117.19, "duration": 6.12}, {"text": "which is its average.", "start": 123.31, "duration": 1.68}, {"text": "And then I divide it by\nthe standard deviation.", "start": 124.99, "duration": 2.455}, {"text": "Then this thing here converges\nas n goes to infinity,", "start": 130.84, "duration": 4.83}, {"text": "and we will say\na little bit more", "start": 135.67, "duration": 1.71}, {"text": "about what it means\nin distribution", "start": 137.38, "duration": 1.98}, {"text": "to some standard\nnormal random variable.", "start": 139.36, "duration": 3.797}, {"text": "So that was the\ncentral limit theorem.", "start": 143.157, "duration": 1.583}, {"text": "So what it means is\nthat when I think", "start": 147.069, "duration": 1.541}, {"text": "of this as a random variable,\nwhen n is large enough", "start": 148.61, "duration": 6.8}, {"text": "it's going to look like this.", "start": 155.41, "duration": 2.22}, {"text": "And so I understand\nperfectly its fluctuations.", "start": 157.63, "duration": 2.4}, {"text": "I know that this\nthing here has--", "start": 160.03, "duration": 3.42}, {"text": "I know the probability\nof being in this zone.", "start": 163.45, "duration": 2.07}, {"text": "I know that this\nnumber here is 0.", "start": 165.52, "duration": 2.37}, {"text": "I know a bunch of things.", "start": 167.89, "duration": 1.71}, {"text": "And then, in\nparticular, what I was", "start": 169.6, "duration": 2.31}, {"text": "interested in was that\nthe probability, that's", "start": 171.91, "duration": 4.08}, {"text": "the absolute value of a\nGaussian random variable,", "start": 175.99, "duration": 3.12}, {"text": "exceeds q alpha over\n2, q alpha over 2.", "start": 179.11, "duration": 6.001}, {"text": "We said that this\nwas equal to what?", "start": 185.111, "duration": 1.499}, {"text": "Anybody?", "start": 193.61, "duration": 1.917}, {"text": "What was that?", "start": 195.527, "duration": 0.583}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 196.11, "duration": 2.027}, {"text": "PHILIPPE RIGOLLET: Alpha, right?", "start": 198.137, "duration": 1.333}, {"text": "So that's the probability.", "start": 199.47, "duration": 1.74}, {"text": "That's my random variable.", "start": 201.21, "duration": 1.85}, {"text": "So this is by definition q\nalpha over 2 is the number.", "start": 203.06, "duration": 3.99}, {"text": "So that to the right\nof it is alpha over 2.", "start": 207.05, "duration": 2.91}, {"text": "And this is a negative q\nalpha over 2 by symmetry.", "start": 209.96, "duration": 4.14}, {"text": "And so the probability\nthat i exceeds-- well,", "start": 214.1, "duration": 2.02}, {"text": "it's not very symmetric,\nbut the probability", "start": 216.12, "duration": 2.03}, {"text": "that i exceeds this\nvalue, q alpha over 2,", "start": 218.15, "duration": 2.87}, {"text": "is just the sum of\nthe two gray areas.", "start": 221.02, "duration": 5.23}, {"text": "All right?", "start": 226.25, "duration": 1.11}, {"text": "So now I said that this thing\nwas approximately equal,", "start": 227.36, "duration": 3.245}, {"text": "due to the central\nlimit theorem,", "start": 230.605, "duration": 1.375}, {"text": "to the probability,\nthat square root of n.", "start": 231.98, "duration": 3.34}, {"text": "Xn bar minus p divided by\nsquare root p 1 minus p.", "start": 235.32, "duration": 3.743}, {"text": "Well, absolute value was\nlarger than q alpha over 2.", "start": 244.97, "duration": 5.21}, {"text": "Well, then this thing by default\nis actually approximately equal", "start": 250.18, "duration": 2.69}, {"text": "to alpha, just because of virtue\nof the central limit theorem.", "start": 252.87, "duration": 4.0}, {"text": "And then we just said,\nwell, I'll solve for p.", "start": 256.87, "duration": 6.9}, {"text": "Has anyone attempted to solve\nthe degree two equation for p", "start": 263.77, "duration": 4.65}, {"text": "in the homework?", "start": 268.42, "duration": 0.992}, {"text": "Everybody has tried it?", "start": 269.412, "duration": 0.958}, {"text": "So essentially, this is\ngoing to be an equation in p.", "start": 275.4, "duration": 2.34}, {"text": "Sometimes we don't\nwant to solve it.", "start": 277.74, "duration": 1.5}, {"text": "Some of the p's we will replace\nby their worst possible value.", "start": 279.24, "duration": 2.583}, {"text": "For example, we said one\nof the tricks we had was", "start": 281.823, "duration": 2.607}, {"text": "that this value here,\nsquare root of p 1 minus p,", "start": 284.43, "duration": 4.4}, {"text": "was always less than one half.", "start": 288.83, "duration": 2.387}, {"text": "Until we could actually get\nthe confidence interval that", "start": 291.217, "duration": 2.333}, {"text": "was larger than all\npossible confidence", "start": 293.55, "duration": 1.624}, {"text": "intervals for all\npossible values of p,", "start": 295.174, "duration": 1.996}, {"text": "but we could solve for p.", "start": 297.17, "duration": 2.22}, {"text": "Do we all agree on the\nprinciple of what we did?", "start": 299.39, "duration": 2.18}, {"text": "So that's how you build\nconfidence intervals.", "start": 301.57, "duration": 2.27}, {"text": "Now let's step\nback for a second,", "start": 303.84, "duration": 1.52}, {"text": "and see what was important in\nthe building of this confidence", "start": 305.36, "duration": 2.71}, {"text": "interval.", "start": 308.07, "duration": 1.4}, {"text": "The really key thing is\nthat I didn't tell you", "start": 309.47, "duration": 2.4}, {"text": "why I formed this thing, right?", "start": 311.87, "duration": 3.48}, {"text": "We started from\nx bar, and then I", "start": 315.35, "duration": 1.77}, {"text": "took some weird function of x\nbar that depended on p and n.", "start": 317.12, "duration": 3.88}, {"text": "And the reason is, because\nwhen I take this function,", "start": 321.0, "duration": 2.824}, {"text": "the central limit\ntheorem tells me", "start": 323.824, "duration": 1.416}, {"text": "that it converges to\nsomething that I know.", "start": 325.24, "duration": 2.769}, {"text": "But this very important thing\nabout the something that I know", "start": 328.009, "duration": 2.541}, {"text": "is that it does not depend on\nanything that I don't know.", "start": 330.55, "duration": 4.48}, {"text": "For example, if I\nforgot to divide", "start": 335.03, "duration": 1.77}, {"text": "by square root of p 1 minus\np, then this thing would have", "start": 336.8, "duration": 3.42}, {"text": "had a variance, which\nis the p 1 minus p.", "start": 340.22, "duration": 3.76}, {"text": "If I didn't remove this\np here, the mean here", "start": 343.98, "duration": 3.64}, {"text": "would have been affected by p.", "start": 347.62, "duration": 2.24}, {"text": "And there's no table\nfor normal p 1.", "start": 349.86, "duration": 3.181}, {"text": "Yes?", "start": 353.041, "duration": 0.499}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 353.54, "duration": 2.294}, {"text": "PHILIPPE RIGOLLET: Oh, so\nthe square root of n terms", "start": 355.834, "duration": 2.166}, {"text": "come from.", "start": 358.0, "duration": 0.5}, {"text": "So really you should view this.", "start": 358.5, "duration": 2.33}, {"text": "So there's a rule and sort\nof a quiet rule in math", "start": 360.83, "duration": 3.95}, {"text": "that you don't write a\ndivided by b over c, right?", "start": 364.78, "duration": 4.21}, {"text": "You write c times a divided\nby b, because it looks nicer.", "start": 368.99, "duration": 3.724}, {"text": "But the way you want\nto think about this", "start": 372.714, "duration": 1.666}, {"text": "is that this is x bar minus p\ndivided by the square root of p", "start": 374.38, "duration": 6.22}, {"text": "1 minus p divided by n.", "start": 380.6, "duration": 3.239}, {"text": "And the reason is,\nbecause this is actually", "start": 383.839, "duration": 1.791}, {"text": "the standard deviation of this--", "start": 385.63, "duration": 1.37}, {"text": "oh sorry, x bar n.", "start": 387.0, "duration": 1.72}, {"text": "This is actually the standard\ndeviation of this guy,", "start": 388.72, "duration": 2.79}, {"text": "and the square root of n comes\nfrom the [INAUDIBLE] average.", "start": 391.51, "duration": 5.03}, {"text": "So the key thing\nwas that this thing,", "start": 396.54, "duration": 3.382}, {"text": "this limiting distribution\ndid not depend on anything", "start": 399.922, "duration": 2.208}, {"text": "I don't know.", "start": 402.13, "duration": 1.21}, {"text": "And this is actually called\na pivotal distribution.", "start": 403.34, "duration": 2.295}, {"text": "It's pivotal.", "start": 405.635, "duration": 2.055}, {"text": "I don't need anything.", "start": 407.69, "duration": 1.33}, {"text": "I don't need to know anything,\nand I can read it in a table.", "start": 409.02, "duration": 2.73}, {"text": "Sometimes there's going\nto be complicated things,", "start": 411.75, "duration": 2.57}, {"text": "but now we have computers.", "start": 414.32, "duration": 1.11}, {"text": "The beauty about Gaussian is\nthat people have studied them", "start": 415.43, "duration": 2.416}, {"text": "to death, and you can\nopen any stats textbook,", "start": 417.846, "duration": 2.203}, {"text": "and you will see a table\nagain that will tell you", "start": 420.049, "duration": 2.041}, {"text": "for each value of alpha\nyou're interested in,", "start": 422.09, "duration": 2.05}, {"text": "it will tell you what\nq alpha over 2 is.", "start": 424.14, "duration": 3.08}, {"text": "But there might be some\ncrazy distributions,", "start": 427.22, "duration": 3.346}, {"text": "but as long as they\ndon't depend on anything,", "start": 430.566, "duration": 1.874}, {"text": "we might actually\nbe able to simulate", "start": 432.44, "duration": 1.541}, {"text": "from them, and in particular\ncompute what q alpha over 2", "start": 433.981, "duration": 2.559}, {"text": "is for any possible\nvalue [INAUDIBLE]..", "start": 436.54, "duration": 2.617}, {"text": "And so that's what we're\ngoing to be trying to do.", "start": 439.157, "duration": 2.083}, {"text": "Finding pivotal distributions.", "start": 441.24, "duration": 1.56}, {"text": "How do we take this Xn bar,\nwhich is a good estimate,", "start": 442.8, "duration": 3.26}, {"text": "and turn it into something\nwhich may be exactly", "start": 446.06, "duration": 2.88}, {"text": "or asymptotically\ndoes not depend", "start": 448.94, "duration": 2.16}, {"text": "on any unknown parameter.", "start": 451.1, "duration": 2.31}, {"text": "So here is one way\nwe can actually--", "start": 453.41, "duration": 2.19}, {"text": "so that's what we did for\nthe kiss example, right?", "start": 455.6, "duration": 2.484}, {"text": "And here I mentioned,\nfor example,", "start": 458.084, "duration": 1.416}, {"text": "in the extreme case,\nwhen n was equal to 3", "start": 459.5, "duration": 2.28}, {"text": "we would get a different\nthing, but here the CLT", "start": 461.78, "duration": 2.46}, {"text": "would not be valid.", "start": 464.24, "duration": 1.62}, {"text": "And what that means is that\nmy pivotal distribution", "start": 465.86, "duration": 3.66}, {"text": "is actually not the\nnormal distribution,", "start": 469.52, "duration": 3.35}, {"text": "but it might be something else.", "start": 472.87, "duration": 1.75}, {"text": "And I said we can make\ntake exact computations.", "start": 474.62, "duration": 2.3}, {"text": "Well, let's see\nwhat it is, right?", "start": 476.92, "duration": 1.59}, {"text": "If I have three observations,\nso I'm going to have X1, X2, X3.", "start": 478.51, "duration": 8.1}, {"text": "So now I take the\naverage of those guys.", "start": 486.61, "duration": 2.2}, {"text": "OK, so that's my estimate.", "start": 493.26, "duration": 2.144}, {"text": "How many values\ncan this guy take?", "start": 495.404, "duration": 1.416}, {"text": "It's a little bit of counting.", "start": 503.125, "duration": 1.94}, {"text": "Four values.", "start": 507.98, "duration": 0.549}, {"text": "How did you get to that number?", "start": 508.529, "duration": 1.291}, {"text": "OK, so each of these guys\ncan take value 0, 1, right?", "start": 517.59, "duration": 4.329}, {"text": "So the number of values\nthat it can take,", "start": 521.919, "duration": 1.75}, {"text": "I mean, it's a little\nannoying, because then I", "start": 523.669, "duration": 2.061}, {"text": "have to sum them, right?", "start": 525.73, "duration": 1.38}, {"text": "So basically, I have to\ncount the number of 1's.", "start": 527.11, "duration": 4.51}, {"text": "So how many 1's\ncan I get, right?", "start": 531.62, "duration": 3.169}, {"text": "Sorry I have to-- yeah, so this\nis the number of 1's that I--", "start": 534.789, "duration": 2.541}, {"text": "OK, so let's look at that.", "start": 537.33, "duration": 1.17}, {"text": "So we get 0, 0, 0.", "start": 538.5, "duration": 1.682}, {"text": "0, 0, 1.", "start": 540.182, "duration": 1.508}, {"text": "And then I get\nbasically three of them", "start": 541.69, "duration": 1.66}, {"text": "that have just the\none in there, right?", "start": 543.35, "duration": 1.625}, {"text": "So there's three of them.", "start": 547.66, "duration": 1.26}, {"text": "How many of them\nhave exactly two 1's?", "start": 548.92, "duration": 3.79}, {"text": "2.", "start": 552.71, "duration": 0.64}, {"text": "Sorry, 3, right?", "start": 553.35, "duration": 1.92}, {"text": "So it's just this guy where\nI replaced the 0's and the 1.", "start": 555.27, "duration": 2.96}, {"text": "OK, so now I get--", "start": 558.23, "duration": 3.16}, {"text": "so here I get three\nthat take the value 1,", "start": 561.39, "duration": 2.36}, {"text": "and one that gets the value 0.", "start": 563.75, "duration": 1.93}, {"text": "And then I get three\nthat take the value 2,", "start": 565.68, "duration": 2.43}, {"text": "and then one that\ntakes the value 1.", "start": 568.11, "duration": 2.86}, {"text": "The value [? 0 ?] 1's, right?", "start": 570.97, "duration": 2.13}, {"text": "OK, so everybody knows what I'm\nmissing here is just the ones", "start": 573.1, "duration": 2.77}, {"text": "here where I replaced\nthe 0's by 1's.", "start": 575.87, "duration": 2.57}, {"text": "So the number of values\nthat this thing can take", "start": 578.44, "duration": 2.04}, {"text": "is 1, 2, 3, 4.", "start": 580.48, "duration": 2.6}, {"text": "So someone is counting\nmuch faster than me.", "start": 583.08, "duration": 2.669}, {"text": "And so those numbers, you've\nprobably seen them before,", "start": 585.749, "duration": 2.291}, {"text": "right?", "start": 588.04, "duration": 0.499}, {"text": "1, 3, 3, 1, remember?", "start": 588.539, "duration": 1.991}, {"text": "And so essentially\nthose guys, it", "start": 590.53, "duration": 2.4}, {"text": "takes only three values,\nwhich are either 1/3, 1.", "start": 592.93, "duration": 5.83}, {"text": "Sorry, 1/3.", "start": 598.76, "duration": 3.572}, {"text": "Oh OK, so it's 0, sorry.", "start": 602.332, "duration": 4.068}, {"text": "1/3, 2/3, and 1.", "start": 606.4, "duration": 3.7}, {"text": "Those are the four possible\nvalues you can take.", "start": 610.1, "duration": 2.69}, {"text": "And so now-- which is\nprobably much easier", "start": 612.79, "duration": 2.08}, {"text": "to count like that--\nand so now all", "start": 614.87, "duration": 1.844}, {"text": "I have to tell you\nif I want to describe", "start": 616.714, "duration": 1.666}, {"text": "the distribution\nof this probability", "start": 618.38, "duration": 1.86}, {"text": "of this random variable,\nis just the probability", "start": 620.24, "duration": 2.85}, {"text": "that it takes each\nof these values.", "start": 623.09, "duration": 1.9}, {"text": "So X bar 3 takes the\nvalue 0 probability", "start": 624.99, "duration": 5.18}, {"text": "that X bar 3 takes the\nvalue 1/3, et cetera.", "start": 630.17, "duration": 3.99}, {"text": "If I give you each of\nthese possible values,", "start": 634.16, "duration": 2.102}, {"text": "then you will be able to know\nexactly what the distribution", "start": 636.262, "duration": 2.458}, {"text": "is, and hopefully maybe\nto turn it into something", "start": 638.72, "duration": 3.0}, {"text": "you can compute.", "start": 641.72, "duration": 0.971}, {"text": "Now the thing is that\nthose values will actually", "start": 642.691, "duration": 1.999}, {"text": "depend on the unknown p.", "start": 644.69, "duration": 2.6}, {"text": "What is the unknown p here?", "start": 647.29, "duration": 1.15}, {"text": "What is the\nprobability that X bar", "start": 648.44, "duration": 1.416}, {"text": "3 is equal to 0 for example?", "start": 649.856, "duration": 2.358}, {"text": "I'm sorry?", "start": 652.214, "duration": 0.952}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 653.166, "duration": 1.428}, {"text": "PHILIPPE RIGOLLET: Yeah, OK.", "start": 654.594, "duration": 1.166}, {"text": "So let's write it without\nmaking the computation So 1/8 is", "start": 655.76, "duration": 4.17}, {"text": "probably not the\nright answer, right?", "start": 659.93, "duration": 3.936}, {"text": "For example, if p is equal to\n0, what is this probability?", "start": 663.866, "duration": 5.401}, {"text": "1.", "start": 669.267, "duration": 1.473}, {"text": "If p is 1, what is\nthis probability?", "start": 670.74, "duration": 3.24}, {"text": "0.", "start": 673.98, "duration": 0.5}, {"text": "So it will depend on p.", "start": 674.48, "duration": 1.77}, {"text": "So the probability that\nthis thing is equal to 0,", "start": 676.25, "duration": 2.064}, {"text": "is just the probability\nthat all three of those guys", "start": 678.314, "duration": 2.166}, {"text": "are equal to 0.", "start": 680.48, "duration": 1.126}, {"text": "The probability that X1 is equal\nto 0, and X2 is equal to 0,", "start": 681.606, "duration": 2.499}, {"text": "and X3 is equal to 0.", "start": 684.105, "duration": 1.427}, {"text": "Now my things are\nindependent, so I", "start": 685.532, "duration": 1.458}, {"text": "do what I actually\nwant to do, which", "start": 686.99, "duration": 1.35}, {"text": "say the probability\nof the intersection", "start": 688.34, "duration": 1.624}, {"text": "is the product of the\nprobabilities, right?", "start": 689.964, "duration": 2.366}, {"text": "So it's just the probability\nthat each of them is equal to 0", "start": 692.33, "duration": 2.61}, {"text": "to the power of 3.", "start": 694.94, "duration": 1.375}, {"text": "And the probability that each\nof them, or say one of them", "start": 696.315, "duration": 2.375}, {"text": "is equal to 0, is\njust 1 minus p.", "start": 698.69, "duration": 2.895}, {"text": "And then for this guy I just\nget the probability-- well,", "start": 705.96, "duration": 2.94}, {"text": "it's more complicated, because I\nhave to decide which one it is.", "start": 708.9, "duration": 2.79}, {"text": "But those things are\njust the probability", "start": 711.69, "duration": 1.89}, {"text": "of some binomial random\nvariables, right?", "start": 713.58, "duration": 2.71}, {"text": "This is just a\nbinomial, X bar 3.", "start": 716.29, "duration": 4.03}, {"text": "So if I look at X bar 3,\nand then I multiply it by 3,", "start": 720.32, "duration": 3.666}, {"text": "it's just this sum of\nindependent Bernoulli's", "start": 723.986, "duration": 1.874}, {"text": "with parameter p.", "start": 725.86, "duration": 1.26}, {"text": "So this is actually a binomial\nwith parameter 3 and p.", "start": 727.12, "duration": 4.576}, {"text": "And there's tables\nfor binomials,", "start": 731.696, "duration": 1.374}, {"text": "and they tell you all this.", "start": 733.07, "duration": 3.497}, {"text": "Now the thing is I want\nto invert this guy, right?", "start": 736.567, "duration": 2.083}, {"text": "Somehow.", "start": 738.65, "duration": 1.22}, {"text": "This thing depends on p.", "start": 739.87, "duration": 1.185}, {"text": "I don't like it, so\nI'm going to have", "start": 741.055, "duration": 1.935}, {"text": "to find ways to get this\nthings depending on p,", "start": 742.99, "duration": 2.884}, {"text": "and I could make all\nthese nasty computations,", "start": 745.874, "duration": 1.916}, {"text": "and spend hours doing this.", "start": 747.79, "duration": 1.92}, {"text": "But there's tricks\nto go around this.", "start": 749.71, "duration": 1.62}, {"text": "There's upper bounds.", "start": 751.33, "duration": 1.08}, {"text": "Just like we just\nsaid, well, maybe I", "start": 752.41, "duration": 1.98}, {"text": "don't want to solve the\nsecond degree equation in p,", "start": 754.39, "duration": 2.45}, {"text": "because it's just going to\ncapture maybe smaller order", "start": 756.84, "duration": 3.52}, {"text": "terms, right?", "start": 760.36, "duration": 0.67}, {"text": "Things that maybe won't make\na huge difference numerically.", "start": 761.03, "duration": 2.9}, {"text": "You can check that in\nyour problem set one.", "start": 763.93, "duration": 2.97}, {"text": "Does it make a huge\ndifference numerically", "start": 766.9, "duration": 2.01}, {"text": "to solve the second\ndegree equation,", "start": 768.91, "duration": 1.68}, {"text": "or to just use the\n[INAUDIBLE] p 1", "start": 770.59, "duration": 2.37}, {"text": "minus p or even to plug\nin p hat instead of p.", "start": 772.96, "duration": 3.09}, {"text": "Those are going to\nbe the-- problem", "start": 776.05, "duration": 1.67}, {"text": "set one is to make sure that you\nsee what magnitude of changes", "start": 777.72, "duration": 3.82}, {"text": "you get by changing from\none method to the other.", "start": 781.54, "duration": 3.81}, {"text": "So what I wanted to\ngo to is something", "start": 785.35, "duration": 8.07}, {"text": "where we can use\nsomething, which is just", "start": 793.42, "duration": 2.73}, {"text": "a little more brute force.", "start": 796.15, "duration": 1.75}, {"text": "So the probability\nthat-- so here", "start": 797.9, "duration": 1.7}, {"text": "is this Hoeffding's inequality.", "start": 799.6, "duration": 1.331}, {"text": "We saw that.", "start": 800.931, "duration": 0.499}, {"text": "That's what we've\nfinished on last time.", "start": 801.43, "duration": 1.89}, {"text": "So Hoeffding's\ninequality is actually", "start": 803.32, "duration": 1.8}, {"text": "one of the most\nuseful inequalities.", "start": 805.12, "duration": 2.44}, {"text": "If any one of you is doing\nanything really to algorithms,", "start": 807.56, "duration": 2.57}, {"text": "you've seen that\ninequality before.", "start": 810.13, "duration": 1.959}, {"text": "It's extremely convenient\nthat it tells you", "start": 812.089, "duration": 1.791}, {"text": "something about bounded\nrandom variables,", "start": 813.88, "duration": 1.77}, {"text": "and if you do algorithms\ntypically with things bounded.", "start": 815.65, "duration": 2.334}, {"text": "And that's the case of\nBernoulli's random variables,", "start": 817.984, "duration": 2.166}, {"text": "right?", "start": 820.15, "duration": 0.499}, {"text": "They're bounded between 0 and 1.", "start": 820.649, "duration": 2.116}, {"text": "And so when I do\nthis thing, when", "start": 822.765, "duration": 1.375}, {"text": "I do Hoeffding's inequality,\nwhat this thing is telling", "start": 824.14, "duration": 2.67}, {"text": "me is for any given epsilon\nhere, for any given epsilon,", "start": 826.81, "duration": 6.31}, {"text": "what is the probability\nthat Xn bar goes away", "start": 833.12, "duration": 2.67}, {"text": "from its expectation?", "start": 835.79, "duration": 2.58}, {"text": "All right, then we saw that it\ndecreases somewhat similarly", "start": 838.37, "duration": 3.66}, {"text": "to the way a Gaussian\nwould look like.", "start": 842.03, "duration": 2.53}, {"text": "So essentially what Hoeffding's\ninequality is telling me, is", "start": 844.56, "duration": 3.56}, {"text": "that I have this picture, when\nI have a Gaussian with mean u,", "start": 848.12, "duration": 10.0}, {"text": "I know it looks\nlike this, right?", "start": 858.12, "duration": 2.627}, {"text": "What Hoeffding's\ninequality is telling", "start": 860.747, "duration": 1.583}, {"text": "me is that if I actually\ntake the average", "start": 862.33, "duration": 2.45}, {"text": "of some bounded\nrandom variables,", "start": 864.78, "duration": 2.96}, {"text": "then their probability\ndistribution function or maybe", "start": 867.74, "duration": 2.754}, {"text": "math function-- this thing\nmight not even have [INAUDIBLE]", "start": 870.494, "duration": 2.416}, {"text": "the density, but let's think\nof it as being a density just", "start": 872.91, "duration": 2.63}, {"text": "for simplicity-- it's\ngoing to be something", "start": 875.54, "duration": 3.09}, {"text": "that's going to look like this.", "start": 878.63, "duration": 2.265}, {"text": "It's going to be\nsomewhat-- well,", "start": 880.895, "duration": 1.375}, {"text": "sometimes it's going\nto have to escape just", "start": 882.27, "duration": 1.791}, {"text": "for the sake of\nhaving integral 1.", "start": 884.061, "duration": 2.479}, {"text": "But it's essentially\ntelling me that those guys", "start": 886.54, "duration": 2.822}, {"text": "stay below those guys.", "start": 889.362, "duration": 3.318}, {"text": "The probability that\nXn bar exceeds mu", "start": 892.68, "duration": 3.93}, {"text": "is bounded by\nsomething that decays", "start": 896.61, "duration": 2.33}, {"text": "like to tail of Gaussian.", "start": 898.94, "duration": 1.862}, {"text": "So really that's the picture\nyou should have in mind.", "start": 900.802, "duration": 2.208}, {"text": "When I average bounded\nrandom variables,", "start": 903.01, "duration": 2.73}, {"text": "I actually have something\nthat might be really rugged.", "start": 905.74, "duration": 2.5}, {"text": "It might not be smooth\nlike a Gaussian,", "start": 908.24, "duration": 2.27}, {"text": "but I know that it's always\nbounded by a Gaussian.", "start": 910.51, "duration": 2.11}, {"text": "And what's nice about it\nis that when I actually", "start": 912.62, "duration": 2.0}, {"text": "start computing probability\nthat exceeds some number,", "start": 914.62, "duration": 3.18}, {"text": "say alpha over 2, then I\nknow that this I can actually", "start": 917.8, "duration": 6.54}, {"text": "get a number, which is just--", "start": 924.34, "duration": 5.12}, {"text": "sorry, the probability\nthat it exceeds, yeah.", "start": 929.46, "duration": 2.37}, {"text": "So this number that I\nget here is actually", "start": 931.83, "duration": 1.75}, {"text": "going to be somewhat\nsmaller, right?", "start": 933.58, "duration": 1.844}, {"text": "So that's going to be the q\nalpha over 2 for the Gaussian,", "start": 935.424, "duration": 2.416}, {"text": "and that's going to be the--", "start": 937.84, "duration": 1.55}, {"text": "I don't know, r alpha over\n2 for this [? Bernoulli ?]", "start": 939.39, "duration": 2.208}, {"text": "random variable.", "start": 941.598, "duration": 1.952}, {"text": "Like q prime or different q.", "start": 943.55, "duration": 2.928}, {"text": "So I can actually do\nthis without actually", "start": 946.478, "duration": 3.671}, {"text": "taking any limits, right?", "start": 950.149, "duration": 1.041}, {"text": "This is valid for any n.", "start": 951.19, "duration": 2.01}, {"text": "I don't need to\nactually go to infinity.", "start": 953.2, "duration": 1.71}, {"text": "Now this seems a\nbit magical, right?", "start": 954.91, "duration": 2.46}, {"text": "I mean, I just said\nwe need n to be,", "start": 957.37, "duration": 2.451}, {"text": "we discussed that we\nwanted n to be larger", "start": 959.821, "duration": 1.749}, {"text": "than 30 last time for\nthe central limit theorem", "start": 961.57, "duration": 2.09}, {"text": "to kick in, and this\none seems to tell me", "start": 963.66, "duration": 2.29}, {"text": "I can do it for any n.", "start": 965.95, "duration": 1.99}, {"text": "Now there will be a price to pay\nis that I pick up this 2 over b", "start": 967.94, "duration": 5.03}, {"text": "minus alpha squared.", "start": 972.97, "duration": 0.96}, {"text": "So that's the variance of the\nGaussian that I have, right?", "start": 973.93, "duration": 6.491}, {"text": "Sort of.", "start": 980.421, "duration": 0.499}, {"text": "That's telling me what\nthe variance should be,", "start": 980.92, "duration": 2.53}, {"text": "and this is actually\nnot as nice.", "start": 983.45, "duration": 1.5}, {"text": "I pick factor 4\ncompared to the Gaussian", "start": 984.95, "duration": 2.58}, {"text": "that I would get for that.", "start": 987.53, "duration": 1.76}, {"text": "So let's try to solve\nit for our case.", "start": 989.29, "duration": 2.94}, {"text": "So I just told you try it.", "start": 992.23, "duration": 1.57}, {"text": "Did anybody try to do it?", "start": 993.8, "duration": 1.238}, {"text": "So we started from\nthis last time, right?", "start": 997.362, "duration": 1.708}, {"text": "And the reason was\nthat we could say", "start": 1001.98, "duration": 1.75}, {"text": "that the probability that this\nthing exceeds q alpha over 2", "start": 1003.73, "duration": 2.76}, {"text": "is alpha.", "start": 1006.49, "duration": 1.2}, {"text": "So that was using CLT, so let's\njust keep it here, and see", "start": 1007.69, "duration": 4.31}, {"text": "what we would do differently.", "start": 1012.0, "duration": 1.484}, {"text": "What Hoeffding tells me is\nthat the probability that Xn", "start": 1016.23, "duration": 2.3}, {"text": "bar minus--", "start": 1018.53, "duration": 1.54}, {"text": "well, what is mu in this case?", "start": 1020.07, "duration": 4.195}, {"text": "It's p, right?", "start": 1024.265, "duration": 1.955}, {"text": "It's just notation here.", "start": 1026.22, "duration": 1.44}, {"text": "Mu was the average,\nbut we call it", "start": 1027.66, "duration": 1.62}, {"text": "p in the case of\nBernoulli's, exceeds--", "start": 1029.28, "duration": 3.69}, {"text": "let's just call it\nepsilon for a second.", "start": 1032.97, "duration": 4.25}, {"text": "So we said that this\nwas bounded by what?", "start": 1037.22, "duration": 2.051}, {"text": "So Hoeffding tells me\nthat this is bounded", "start": 1039.271, "duration": 1.749}, {"text": "by 2 times exponential minus 2.", "start": 1041.02, "duration": 5.039}, {"text": "Now the nice thing is that\nI pick up a factor n here,", "start": 1046.059, "duration": 3.091}, {"text": "epsilon squared.", "start": 1049.15, "duration": 1.0}, {"text": "And what is b minus a\nsquared for the Bernoulli's?", "start": 1050.15, "duration": 2.98}, {"text": "1.", "start": 1053.13, "duration": 0.71}, {"text": "So I don't have a\ndenominator here.", "start": 1053.84, "duration": 2.677}, {"text": "And I'm going to do\nexactly what I did here.", "start": 1056.517, "duration": 1.833}, {"text": "I'm going to set this\nguy to be equal to alpha.", "start": 1058.35, "duration": 2.37}, {"text": "So that if I get\nalpha here, then that", "start": 1063.24, "duration": 3.4}, {"text": "means that just\nsolving for epsilon,", "start": 1066.64, "duration": 3.46}, {"text": "I'm going to have some number,\nwhich will play the role of q", "start": 1070.1, "duration": 2.5}, {"text": "alpha over 2, and\nthen I'm going to be", "start": 1072.6, "duration": 1.6}, {"text": "able to just say that p\nis between X bar and minus", "start": 1074.2, "duration": 4.2}, {"text": "epsilon, and X bar\nn plus epsilon.", "start": 1078.4, "duration": 2.434}, {"text": "OK, so let's do it.", "start": 1080.834, "duration": 1.434}, {"text": "So we have to\nsolve the equation.", "start": 1085.14, "duration": 1.64}, {"text": "2 exponential minus 2n\nepsilon squared equals alpha,", "start": 1094.572, "duration": 6.198}, {"text": "which means that--", "start": 1100.77, "duration": 2.076}, {"text": "so here I'm going to get,\nthere's a 2 right here.", "start": 1102.846, "duration": 3.696}, {"text": "So that means that I\nget alpha over 2 here.", "start": 1106.542, "duration": 2.658}, {"text": "Then I take the\nlogs on both sides,", "start": 1109.2, "duration": 1.65}, {"text": "and now let me just write it.", "start": 1110.85, "duration": 1.208}, {"text": "And then I want to\nsolve for epsilon.", "start": 1116.65, "duration": 2.78}, {"text": "So that means that epsilon\nis equal to square root log", "start": 1119.43, "duration": 3.92}, {"text": "q over alpha divided by 2n.", "start": 1123.35, "duration": 2.51}, {"text": "Yes?", "start": 1130.618, "duration": 0.5}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 1131.118, "duration": 1.912}, {"text": "PHILIPPE RIGOLLET:\nWhy is b minus a 1?", "start": 1133.03, "duration": 2.38}, {"text": "Well, let's just look, right?", "start": 1135.41, "duration": 2.43}, {"text": "X lives in the\ninterval b minus a.", "start": 1137.84, "duration": 3.02}, {"text": "So I can take b to be 25,\nand a to be my negative 42.", "start": 1140.86, "duration": 5.25}, {"text": "But I'm going to try to\nbe as sharp as I can.", "start": 1146.11, "duration": 3.024}, {"text": "All right, so what\nis the smallest value", "start": 1149.134, "duration": 1.666}, {"text": "you can think of such that\na Bernoulli random variable", "start": 1150.8, "duration": 2.54}, {"text": "is larger than or\nequal to this value?", "start": 1153.34, "duration": 1.95}, {"text": "What values does a Bernoulli\nrandom variable take?", "start": 1159.51, "duration": 4.23}, {"text": "0 and 1.", "start": 1163.74, "duration": 0.79}, {"text": "So it takes values\nbetween 0 and 1.", "start": 1164.53, "duration": 4.71}, {"text": "It just maxes the value.", "start": 1169.24, "duration": 2.04}, {"text": "Actually, this is the\nworst possible case", "start": 1171.28, "duration": 2.58}, {"text": "for the Hoeffding inequality.", "start": 1173.86, "duration": 4.27}, {"text": "So now I just get this\none, and so now you", "start": 1178.13, "duration": 2.12}, {"text": "tell me that I have this thing.", "start": 1180.25, "duration": 1.5}, {"text": "So when I solve\nthis guy over there.", "start": 1181.75, "duration": 1.51}, {"text": "So combining this\nthing and this thing", "start": 1183.26, "duration": 2.81}, {"text": "implies that the probability\nthat p lives between Xn", "start": 1186.07, "duration": 7.23}, {"text": "bar minus square root log 2\nover alpha divided by 2n and X", "start": 1193.3, "duration": 8.36}, {"text": "bar plus the square root log\n2 over alpha divided by 2n", "start": 1201.66, "duration": 9.31}, {"text": "is equal to?", "start": 1210.97, "duration": 1.05}, {"text": "I mean, is at least.", "start": 1215.17, "duration": 1.712}, {"text": "What is it at least equal to?", "start": 1216.882, "duration": 1.208}, {"text": "Here this controls the\nprobability of them outside", "start": 1222.93, "duration": 2.94}, {"text": "of this interval, right?", "start": 1225.87, "duration": 1.31}, {"text": "It tells me the probability\nthat Xn bar is far from p", "start": 1227.18, "duration": 4.55}, {"text": "by more than epsilon.", "start": 1231.73, "duration": 0.875}, {"text": "So there's a probability\nthat they're actually", "start": 1232.605, "duration": 1.916}, {"text": "outside of the interval\nthat I just wrote.", "start": 1234.521, "duration": 2.119}, {"text": "So it's 1 minus the probability\nof being in the interval.", "start": 1236.64, "duration": 3.01}, {"text": "So this is at least\n1 minus alpha.", "start": 1239.65, "duration": 4.232}, {"text": "So I just use the fact that a\nprobability of the complement", "start": 1243.882, "duration": 2.458}, {"text": "is 1 minus the\nprobability of the set.", "start": 1246.34, "duration": 3.76}, {"text": "And since I have an upper bound\non the probability of the set,", "start": 1250.1, "duration": 3.36}, {"text": "I have a lower bound on the\nprobability of the complement.", "start": 1253.46, "duration": 5.64}, {"text": "So now it's a bit different.", "start": 1259.1, "duration": 4.07}, {"text": "Before, we actually wrote\nsomething that was--", "start": 1263.17, "duration": 3.47}, {"text": "so let me get it back.", "start": 1266.64, "duration": 1.37}, {"text": "So if we go back to the example\nwhere we took the [INAUDIBLE]", "start": 1268.01, "duration": 3.98}, {"text": "over p, we got this guy.", "start": 1271.99, "duration": 4.85}, {"text": "q alpha over square root of--", "start": 1276.84, "duration": 3.15}, {"text": "over 2 square root n.", "start": 1279.99, "duration": 1.71}, {"text": "So we had Xn bar plus minus\nq alpha over 2 square root n.", "start": 1281.7, "duration": 3.266}, {"text": "Actually, that was q alpha\nover 2n, I'm sorry about that.", "start": 1284.966, "duration": 2.374}, {"text": "And so now we have something\nthat replaces this q alpha,", "start": 1290.73, "duration": 3.81}, {"text": "and it's essentially square\nroot of 2 log 2 over alpha.", "start": 1294.54, "duration": 6.34}, {"text": "Because if I replace\nq alpha by square root", "start": 1300.88, "duration": 2.7}, {"text": "of 2 log 2 over\nalpha, I actually", "start": 1303.58, "duration": 3.66}, {"text": "get exactly this thing here.", "start": 1307.24, "duration": 2.098}, {"text": "And so the question is,\nwhat would you guess?", "start": 1312.03, "duration": 3.94}, {"text": "Is this number, this margin,\nsquare root of log 2 over alpha", "start": 1315.97, "duration": 5.82}, {"text": "divided by 2n, is it smaller\nor larger than this guy?", "start": 1321.79, "duration": 4.14}, {"text": "q alpha all over 2/3n.", "start": 1325.93, "duration": 2.985}, {"text": "Yes?", "start": 1328.915, "duration": 0.895}, {"text": "Larger.", "start": 1329.81, "duration": 0.83}, {"text": "Everybody agrees with this?", "start": 1330.64, "duration": 1.54}, {"text": "Just qualitatively?", "start": 1332.18, "duration": 2.51}, {"text": "Right, because we just made a\nvery conservative statement.", "start": 1334.69, "duration": 2.74}, {"text": "We do not use anything.", "start": 1337.43, "duration": 1.08}, {"text": "This is true always.", "start": 1338.51, "duration": 1.59}, {"text": "So it can only be better.", "start": 1340.1, "duration": 1.98}, {"text": "The reason in statistics where\nyou use those assumptions", "start": 1342.08, "duration": 2.76}, {"text": "that n is large enough, that you\nhave this independence that you", "start": 1344.84, "duration": 2.75}, {"text": "like so much, and so you can\nactually have the central limit", "start": 1347.59, "duration": 2.5}, {"text": "theorem kick in,\nall these things", "start": 1350.09, "duration": 2.2}, {"text": "are for you to have\nenough assumptions", "start": 1352.29, "duration": 3.21}, {"text": "so that you can actually make\nsharper and sharper decisions.", "start": 1355.5, "duration": 2.69}, {"text": "More and more\nconfident statement.", "start": 1358.19, "duration": 2.059}, {"text": "And that's why there's all\nthis junk science out there,", "start": 1360.249, "duration": 2.291}, {"text": "because people make too much\nassumptions for their own good.", "start": 1362.54, "duration": 3.0}, {"text": "They're saying,\nwell, let's assume", "start": 1365.54, "duration": 1.416}, {"text": "that everything is the way I\nlove it, so that I can for sure", "start": 1366.956, "duration": 3.764}, {"text": "any minor change, I\nwill be able to say", "start": 1370.72, "duration": 2.819}, {"text": "that's because I made an\nimportant scientific discovery", "start": 1373.539, "duration": 2.291}, {"text": "rather than, well, that\nwas just [INAUDIBLE] OK?", "start": 1375.83, "duration": 6.22}, {"text": "So now here's the fun moment.", "start": 1382.05, "duration": 2.3}, {"text": "And actually let me tell you\nwhy we look at this thing.", "start": 1384.35, "duration": 4.76}, {"text": "So there's actually--\nwho has seen", "start": 1389.11, "duration": 2.49}, {"text": "different types of convergence\nin the probability statistic", "start": 1391.6, "duration": 2.728}, {"text": "class?", "start": 1394.328, "duration": 0.5}, {"text": "[INAUDIBLE] students.", "start": 1397.9, "duration": 2.53}, {"text": "And so there's\ndifferent types of--", "start": 1400.43, "duration": 1.91}, {"text": "in the real numbers\nthere's very simple.", "start": 1402.34, "duration": 3.27}, {"text": "There's one\nconvergence, Xn turns", "start": 1405.61, "duration": 1.55}, {"text": "to X. To start thinking\nabout functions,", "start": 1407.16, "duration": 2.52}, {"text": "well, maybe you have\nuniform convergence,", "start": 1409.68, "duration": 2.55}, {"text": "you have pointwise convergence.", "start": 1412.23, "duration": 1.38}, {"text": "So if you've done\nsome real analysis,", "start": 1413.61, "duration": 1.38}, {"text": "you know there's different\ntypes of convergence", "start": 1414.99, "duration": 1.958}, {"text": "you can think of.", "start": 1416.948, "duration": 0.842}, {"text": "And in the convergence\nof random variables,", "start": 1417.79, "duration": 2.647}, {"text": "there's also different types,\nbut for different reasons.", "start": 1420.437, "duration": 2.333}, {"text": "It's just because the\nquestion is, what do you", "start": 1422.77, "duration": 2.032}, {"text": "do with the randomness?", "start": 1424.802, "duration": 0.958}, {"text": "When you see that something\nconverges to something,", "start": 1425.76, "duration": 2.125}, {"text": "it probably means that\nyou're willing to tolerate", "start": 1427.885, "duration": 2.735}, {"text": "low probability things happening\nor where it doesn't happen,", "start": 1430.62, "duration": 3.57}, {"text": "and on how you\nhandle those, creates", "start": 1434.19, "duration": 2.16}, {"text": "different types of convergence.", "start": 1436.35, "duration": 2.32}, {"text": "So to be fair, in statistics the\nonly convergence we care about", "start": 1438.67, "duration": 4.67}, {"text": "is the convergence\nin distribution.", "start": 1443.34, "duration": 2.26}, {"text": "That's this one.", "start": 1445.6, "duration": 2.257}, {"text": "The one that comes from\nthe central limit theorem.", "start": 1447.857, "duration": 2.083}, {"text": "That's actually the weakest\npossible you could make.", "start": 1449.94, "duration": 2.677}, {"text": "Which is good, because\nthat means it's", "start": 1452.617, "duration": 1.583}, {"text": "going to happen more often.", "start": 1454.2, "duration": 1.95}, {"text": "And so why do we\nneed this thing?", "start": 1456.15, "duration": 1.69}, {"text": "Because the only\nthing we really need", "start": 1457.84, "duration": 1.56}, {"text": "to do is to say that\nwhen I start computing", "start": 1459.4, "duration": 2.18}, {"text": "probabilities on\nthis random variable,", "start": 1461.58, "duration": 2.274}, {"text": "they're going to look\nlike probabilities", "start": 1463.854, "duration": 1.666}, {"text": "on that random variable.", "start": 1465.52, "duration": 2.32}, {"text": "All right, so for example,\nthink of the following", "start": 1467.84, "duration": 2.16}, {"text": "two random variables,\nx and minus x.", "start": 1470.0, "duration": 11.07}, {"text": "So this is the same\nrandom variable,", "start": 1481.07, "duration": 1.5}, {"text": "and this one is negative.", "start": 1482.57, "duration": 2.4}, {"text": "When I look at those\ntwo random variables,", "start": 1484.97, "duration": 3.08}, {"text": "think of them as a sequence,\na constant sequence.", "start": 1488.05, "duration": 3.26}, {"text": "These two constant sequences\ndo not go to the same number,", "start": 1491.31, "duration": 2.66}, {"text": "right?", "start": 1493.97, "duration": 0.5}, {"text": "One is plus-- one is x,\nthe other one is minus x.", "start": 1494.47, "duration": 3.44}, {"text": "So unless x is the random\nvariable always equal to 0,", "start": 1497.91, "duration": 3.33}, {"text": "those two things are different.", "start": 1501.24, "duration": 2.05}, {"text": "However, when I compute\nprobabilities on this guy,", "start": 1503.29, "duration": 2.63}, {"text": "and when I compute probabilities\non that guy, they're the same.", "start": 1505.92, "duration": 3.09}, {"text": "Because x and minus x\nhave the same distribution", "start": 1509.01, "duration": 3.24}, {"text": "just by symmetry of the\ngaps in random variables.", "start": 1512.25, "duration": 3.18}, {"text": "And so you can see\nthis is very weak.", "start": 1515.43, "duration": 1.61}, {"text": "I'm not saying anything about\nthe two random variables being", "start": 1517.04, "duration": 2.11}, {"text": "close to each other\nevery time I'm", "start": 1519.15, "duration": 1.416}, {"text": "going to flip my coin, right?", "start": 1520.566, "duration": 1.534}, {"text": "Maybe I'm going to press my\ncomputer and say, what is x?", "start": 1522.1, "duration": 3.585}, {"text": "Well, it's 1.2.", "start": 1525.685, "duration": 0.875}, {"text": "Negative x is going\nto be negative 1.2.", "start": 1526.56, "duration": 2.55}, {"text": "Those things are\nfar apart, and it", "start": 1529.11, "duration": 1.56}, {"text": "doesn't matter, because\nin average those things", "start": 1530.67, "duration": 1.56}, {"text": "are going to have the same\nprobabilities that's happening.", "start": 1532.23, "duration": 2.1}, {"text": "And that's all we care\nabout in statistics.", "start": 1534.33, "duration": 1.71}, {"text": "You need to realize that\nthis is what's important,", "start": 1536.04, "duration": 1.77}, {"text": "and why you need to know.", "start": 1537.81, "duration": 1.32}, {"text": "Because you have it really good.", "start": 1539.13, "duration": 1.47}, {"text": "If your problem is you really\ncare more about convergence", "start": 1540.6, "duration": 2.52}, {"text": "almost surely, which is probably\nthe strongest you can think of.", "start": 1543.12, "duration": 2.836}, {"text": "So what we're going to do is\ntalk about different types", "start": 1545.956, "duration": 2.634}, {"text": "of convergence not to\njust reflect on the fact", "start": 1548.59, "duration": 2.61}, {"text": "on how our life is good.", "start": 1551.2, "duration": 1.92}, {"text": "It's just that the problem\nis that when the convergence", "start": 1553.12, "duration": 3.3}, {"text": "in distribution is so weak that\nit cannot do anything I want", "start": 1556.42, "duration": 3.69}, {"text": "with it.", "start": 1560.11, "duration": 0.63}, {"text": "In particular, I cannot\nsay that if X converges,", "start": 1560.74, "duration": 3.66}, {"text": "Xn converges in distribution,\nand Yn converges", "start": 1564.4, "duration": 2.83}, {"text": "in distribution, then Xn plus\nYn converge in distribution", "start": 1567.23, "duration": 3.56}, {"text": "to the sum of their limits.", "start": 1570.79, "duration": 1.29}, {"text": "I cannot do that.", "start": 1572.08, "duration": 0.81}, {"text": "It's just too weak.", "start": 1572.89, "duration": 1.965}, {"text": "Think of this example\nand it's preventing you", "start": 1574.855, "duration": 1.875}, {"text": "to do quite a lot of things.", "start": 1576.73, "duration": 1.166}, {"text": "So this is converge in\ndistribution to sum n 0, 1.", "start": 1580.82, "duration": 5.21}, {"text": "This is converge in\ndistribution to sum n 0, 1.", "start": 1586.03, "duration": 2.91}, {"text": "But their sum is 0, and\nit's certainly not--", "start": 1588.94, "duration": 2.55}, {"text": "it doesn't look\nlike the sum of two", "start": 1591.49, "duration": 2.34}, {"text": "independent Gaussian\nrandom variables, right?", "start": 1593.83, "duration": 2.61}, {"text": "And so what we need is to\nhave stronger conditions here", "start": 1596.44, "duration": 3.78}, {"text": "and there, so that we can\nactually put things together.", "start": 1600.22, "duration": 2.73}, {"text": "And we're going to have\nmore complicated formulas.", "start": 1602.95, "duration": 2.226}, {"text": "One of the formulas,\nfor example,", "start": 1605.176, "duration": 1.374}, {"text": "is if I replace p by p\nhat in this denominator.", "start": 1606.55, "duration": 3.88}, {"text": "We mentioned doing\nthis at some point.", "start": 1610.43, "duration": 3.04}, {"text": "So I would need that\np hat goes to p,", "start": 1613.47, "duration": 4.08}, {"text": "but I need stronger\nthan n distributions", "start": 1617.55, "duration": 1.77}, {"text": "so that this happens.", "start": 1619.32, "duration": 1.1}, {"text": "I actually need this to\nhappen in a stronger sense.", "start": 1620.42, "duration": 3.85}, {"text": "So here are the first two\nstrongest sense in which", "start": 1624.27, "duration": 3.42}, {"text": "random variables can converge.", "start": 1627.69, "duration": 1.98}, {"text": "The first one is almost surely.", "start": 1629.67, "duration": 3.47}, {"text": "And who has already seen\nthis notation little omega", "start": 1633.14, "duration": 3.43}, {"text": "when they're talking\nabout random variables?", "start": 1636.57, "duration": 2.92}, {"text": "All right, so very few.", "start": 1639.49, "duration": 1.02}, {"text": "So this little omega is-- so\nwhat is a random variable?", "start": 1640.51, "duration": 3.502}, {"text": "A random variable is\nsomething that you measure", "start": 1644.012, "duration": 1.958}, {"text": "on something that's random.", "start": 1645.97, "duration": 1.655}, {"text": "So the example I\nlike to think of", "start": 1647.625, "duration": 1.375}, {"text": "is, if you take a ball\nof snow, and put it", "start": 1649.0, "duration": 5.91}, {"text": "in the sun for some time.", "start": 1654.91, "duration": 2.16}, {"text": "You come back.", "start": 1657.07, "duration": 1.142}, {"text": "It's going to have a\nrandom shape, right?", "start": 1658.212, "duration": 1.708}, {"text": "It's going to be a random\nblurb of something.", "start": 1659.92, "duration": 2.684}, {"text": "But there's still a bunch of\nthings you can measure on it.", "start": 1662.604, "duration": 2.416}, {"text": "You can measure its volume.", "start": 1665.02, "duration": 1.39}, {"text": "You can measure its\ninner temperature.", "start": 1666.41, "duration": 1.79}, {"text": "You can measure\nits surface area.", "start": 1668.2, "duration": 2.01}, {"text": "All these things are\nrandom variables,", "start": 1670.21, "duration": 2.04}, {"text": "but the ball itself is omega.", "start": 1672.25, "duration": 2.34}, {"text": "That's the thing on which\nyou make your measurement.", "start": 1674.59, "duration": 2.31}, {"text": "And so a random variable is\njust a function of those omegas.", "start": 1676.9, "duration": 3.97}, {"text": "Now why do we make all\nthese things fancy?", "start": 1680.87, "duration": 2.34}, {"text": "Because you cannot\ntake any function.", "start": 1683.21, "duration": 1.59}, {"text": "This function has to be\nwhat's called measurable,", "start": 1684.8, "duration": 2.041}, {"text": "and there's entire\ncourses on measure theory,", "start": 1686.841, "duration": 2.229}, {"text": "and not everything\nis measurable.", "start": 1689.07, "duration": 1.96}, {"text": "And so that's why you have\nto be a little careful", "start": 1691.03, "duration": 2.145}, {"text": "why not everything\nis measurable,", "start": 1693.175, "duration": 1.375}, {"text": "because you need some\nsort of nice property.", "start": 1694.55, "duration": 3.04}, {"text": "So that the measure\nof something,", "start": 1697.59, "duration": 2.207}, {"text": "the union of two things, is less\nthan the sum of the measures,", "start": 1699.797, "duration": 2.583}, {"text": "things like that.", "start": 1702.38, "duration": 1.45}, {"text": "And so almost surely is telling\nyou that for most of the balls,", "start": 1703.83, "duration": 7.11}, {"text": "for most of the omegas,\nthat's the right-hand side.", "start": 1710.94, "duration": 3.6}, {"text": "The probability of omega is\nsuch that those things converge", "start": 1714.54, "duration": 2.61}, {"text": "to each other is\nactually equal to 1.", "start": 1717.15, "duration": 4.25}, {"text": "So it tells me that for almost\nall omegas, all the omegas,", "start": 1721.4, "duration": 4.22}, {"text": "if I put them together,\nI get something", "start": 1725.62, "duration": 1.626}, {"text": "that has probability of 1.", "start": 1727.246, "duration": 1.082}, {"text": "It might be that there are other\nones that have probability 0,", "start": 1728.328, "duration": 2.642}, {"text": "but what it's telling\nis that this thing", "start": 1730.97, "duration": 1.71}, {"text": "happens for all possible\nrealization of the underlying", "start": 1732.68, "duration": 3.161}, {"text": "thing.", "start": 1735.841, "duration": 0.499}, {"text": "That's very strong.", "start": 1736.34, "duration": 1.38}, {"text": "It essentially says\nrandomness does not matter,", "start": 1737.72, "duration": 2.421}, {"text": "because it's happening always.", "start": 1740.141, "duration": 1.249}, {"text": "Now convergence in\nprobability allows", "start": 1744.31, "duration": 2.03}, {"text": "you to squeeze a little bit\nof probability under the rock.", "start": 1746.34, "duration": 2.84}, {"text": "It tells you I want the\nconvergence to hold,", "start": 1749.18, "duration": 2.95}, {"text": "but I'm willing to let go\nof some little epsilon.", "start": 1752.13, "duration": 4.99}, {"text": "So I'm willing to allow Tn\nto be less than epsilon.", "start": 1757.12, "duration": 6.38}, {"text": "Tn minus T to be-- sorry,\nto be larger than epsilon.", "start": 1763.5, "duration": 3.88}, {"text": "But the problem is they\nwant this to go to 0", "start": 1767.38, "duration": 1.98}, {"text": "as well as n goes to\ninfinity, but for each", "start": 1769.36, "duration": 2.07}, {"text": "n this thing does not\nhave to be 0, which", "start": 1771.43, "duration": 2.661}, {"text": "is different from here, right?", "start": 1774.091, "duration": 2.159}, {"text": "So this probability\nhere is fine.", "start": 1776.25, "duration": 3.89}, {"text": "So it's a little weaker, but\nit's a slightly different one.", "start": 1780.14, "duration": 4.32}, {"text": "I'm not going to ask you\nto learn and show that one", "start": 1784.46, "duration": 2.4}, {"text": "is weaker than the other one.", "start": 1786.86, "duration": 1.65}, {"text": "But just know that these\nare two different types.", "start": 1788.51, "duration": 2.5}, {"text": "This one is actually much\neasier to check than this one.", "start": 1791.01, "duration": 2.795}, {"text": "Then there's something\ncalled convergence in Lp.", "start": 1802.55, "duration": 4.0}, {"text": "So this one is the fact that\nit embodies the following fact.", "start": 1806.55, "duration": 2.65}, {"text": "If I give you a random\nvariable with mean 0,", "start": 1809.2, "duration": 2.54}, {"text": "and I tell you that its\nvariance is going to 0, right?", "start": 1811.74, "duration": 2.37}, {"text": "You have a sequence of random\nvariables, their mean is 0,", "start": 1814.11, "duration": 2.685}, {"text": "their expectation is 0, but\ntheir variance is going to 0.", "start": 1816.795, "duration": 3.595}, {"text": "So think of Gaussian random\nvariables with mean 0,", "start": 1820.39, "duration": 3.11}, {"text": "and a variance\nthat shrinks to 0.", "start": 1823.5, "duration": 2.8}, {"text": "And this random variable\nconverges to a spike at 0,", "start": 1826.3, "duration": 2.96}, {"text": "so it converges to 0, right?", "start": 1829.26, "duration": 2.31}, {"text": "And so what I mean by that is\nthat to have this convergence,", "start": 1831.57, "duration": 4.09}, {"text": "all I had to tell you was that\nthe variance was going to 0.", "start": 1835.66, "duration": 3.14}, {"text": "And so in L2 this is really\nwhat it's telling you.", "start": 1838.8, "duration": 2.9}, {"text": "It's telling you, well, if\nthe variance is going to 0--", "start": 1841.7, "duration": 3.02}, {"text": "well, it's for any\nrandom variable T,", "start": 1844.72, "duration": 2.15}, {"text": "so here what I describe\nwas for a deterministic.", "start": 1846.87, "duration": 3.37}, {"text": "So Tn goes to a random variable\nT. If you look at the square--", "start": 1850.24, "duration": 5.1}, {"text": "the expectation of the square\ndistance, and it goes to 0.", "start": 1855.34, "duration": 3.075}, {"text": "But you don't have to limit\nyourself to the square.", "start": 1858.415, "duration": 2.125}, {"text": "You can take power of three.", "start": 1860.54, "duration": 1.37}, {"text": "You can take power\n67.6, power of 9 pi.", "start": 1861.91, "duration": 4.87}, {"text": "You take whatever power you\nwant, it can be fractional.", "start": 1866.78, "duration": 3.0}, {"text": "It has to be lower than 1, and\nthat's the convergence in Lp.", "start": 1869.78, "duration": 4.14}, {"text": "But we mostly care\nabout integer p.", "start": 1873.92, "duration": 3.6}, {"text": "And then here's our star, the\nconvergence in distribution,", "start": 1877.52, "duration": 2.587}, {"text": "and that's just the\none that tells you", "start": 1880.107, "duration": 1.583}, {"text": "that when I start computing\nprobabilities on the Tn,", "start": 1881.69, "duration": 5.6}, {"text": "they're going to look very close\nto the probabilities on the T.", "start": 1887.29, "duration": 4.33}, {"text": "So that was our Tn with\nthis guy, for example,", "start": 1891.62, "duration": 2.79}, {"text": "and T was this standard\nGaussian distribution.", "start": 1894.41, "duration": 2.7}, {"text": "Now here, this is\nnot any probability.", "start": 1897.11, "duration": 1.85}, {"text": "This is just the probability\nthen less than or equal to x.", "start": 1898.96, "duration": 3.48}, {"text": "But if you remember\nyour probability class,", "start": 1902.44, "duration": 1.95}, {"text": "if you can compute\nthose probabilities,", "start": 1904.39, "duration": 1.44}, {"text": "you can compute\nany probabilities", "start": 1905.83, "duration": 1.374}, {"text": "just by subtracting and just\nbuilding things together.", "start": 1907.204, "duration": 2.83}, {"text": "Well, I need this for all x's,\nso I want this for each x,", "start": 1915.23, "duration": 3.42}, {"text": "So you fix x, and then you\nmake the limit go to infinity.", "start": 1918.65, "duration": 2.87}, {"text": "You make n go to\ninfinity, and I want", "start": 1921.52, "duration": 1.66}, {"text": "this for the point x's at which\nthe cumulative distribution", "start": 1923.18, "duration": 3.3}, {"text": "function of T is continuous.", "start": 1926.48, "duration": 1.75}, {"text": "There might be jumps, and that\nI don't actually care for those.", "start": 1928.23, "duration": 7.12}, {"text": "All right, so here I mentioned\nit for random variables.", "start": 1935.35, "duration": 2.427}, {"text": "If you're interested,\nthere's also random vectors.", "start": 1937.777, "duration": 2.083}, {"text": "A random vector is just a\ntable of random variables.", "start": 1939.86, "duration": 3.57}, {"text": "You can talk about\nrandom matrices.", "start": 1943.43, "duration": 1.921}, {"text": "And you can talk about\nrandom whatever you want.", "start": 1945.351, "duration": 1.999}, {"text": "Every time you have\nan object that's", "start": 1947.35, "duration": 1.57}, {"text": "just collecting real\nnumbers, you can just", "start": 1948.92, "duration": 2.22}, {"text": "plug random variables in there.", "start": 1951.14, "duration": 2.23}, {"text": "And so there's all these\ndefinitions that [? extend. ?]", "start": 1953.37, "duration": 3.68}, {"text": "So where I see you\nsee an absolute value,", "start": 1957.05, "duration": 2.03}, {"text": "we'll see a norm.", "start": 1959.08, "duration": 1.086}, {"text": "Things like this.", "start": 1960.166, "duration": 2.874}, {"text": "So I'm sure this might\nlook scary a little bit,", "start": 1963.04, "duration": 3.03}, {"text": "but really what we are going to\nuse is only the last one, which", "start": 1966.07, "duration": 2.94}, {"text": "as you can see is\njust telling you", "start": 1969.01, "duration": 1.416}, {"text": "that the probabilities\nconverge to the probabilities.", "start": 1970.426, "duration": 2.464}, {"text": "But I'm going to need the other\nones every once in a while.", "start": 1972.89, "duration": 2.94}, {"text": "And the reason is,\nwell, OK, so here I'm", "start": 1975.83, "duration": 3.84}, {"text": "actually going to the\nimportant characterizations", "start": 1979.67, "duration": 3.3}, {"text": "of the convergence\nin distribution,", "start": 1982.97, "duration": 2.37}, {"text": "which is R convergence style.", "start": 1985.34, "duration": 2.77}, {"text": "So i converge in\ndistribution if and only", "start": 1988.11, "duration": 2.09}, {"text": "if for any function that's\ncontinuous and bounded,", "start": 1990.2, "duration": 3.87}, {"text": "when I look at the\nexpectation of f of Tn,", "start": 1994.07, "duration": 2.1}, {"text": "this converges to the\nexpectation of f of T. OK,", "start": 1996.17, "duration": 3.7}, {"text": "so this is just those two\nthings are actually equivalent.", "start": 1999.87, "duration": 5.257}, {"text": "Sometimes it's easier to check\none, easier to check the other,", "start": 2005.127, "duration": 2.583}, {"text": "but in this class you won't\nhave to prove that something", "start": 2007.71, "duration": 2.333}, {"text": "converges in distribution\nother than just combining", "start": 2010.043, "duration": 3.337}, {"text": "our existing\nconvergence results.", "start": 2013.38, "duration": 3.86}, {"text": "And then the last one which\nis equivalent to the above two", "start": 2017.24, "duration": 2.78}, {"text": "is, anybody knows what the\nname of this quantity is?", "start": 2020.02, "duration": 2.97}, {"text": "This expectation here?", "start": 2022.99, "duration": 2.13}, {"text": "What is it called?", "start": 2025.12, "duration": 2.04}, {"text": "The characteristic\nfunction, right?", "start": 2027.16, "duration": 1.92}, {"text": "And so this i is the complex\ni, and is the complex number.", "start": 2029.08, "duration": 3.6}, {"text": "And so it's\nessentially telling me", "start": 2032.68, "duration": 1.44}, {"text": "that, well, rather\nthan actually looking", "start": 2034.12, "duration": 1.95}, {"text": "at all bounded and continuous\nbut real functions,", "start": 2036.07, "duration": 2.55}, {"text": "I can actually look\nat one specific family", "start": 2038.62, "duration": 5.01}, {"text": "of complex functions, which\nare the functions that maps", "start": 2043.63, "duration": 4.66}, {"text": "T to E to the ixT\nfor x and R. That's", "start": 2048.29, "duration": 4.69}, {"text": "a much smaller\nfamily of functions.", "start": 2052.98, "duration": 1.9}, {"text": "All possible continuous\nembedded functions", "start": 2054.88, "duration": 2.4}, {"text": "has many more elements\nthan just the real element.", "start": 2057.28, "duration": 4.31}, {"text": "And so now I can show that\nif I limit myself to do it,", "start": 2061.59, "duration": 2.72}, {"text": "it's actually sufficient.", "start": 2064.31, "duration": 1.182}, {"text": "So those three things are used\nall over the literature just", "start": 2068.139, "duration": 4.381}, {"text": "to show things.", "start": 2072.52, "duration": 0.84}, {"text": "In particular, if you're\ninterested in deep digging", "start": 2073.36, "duration": 3.859}, {"text": "a little more mathematically,\nthe central limit theorem", "start": 2077.219, "duration": 2.291}, {"text": "is going to be so important.", "start": 2079.51, "duration": 1.0}, {"text": "Maybe you want to read\nabout how to prove it.", "start": 2080.51, "duration": 1.61}, {"text": "We're not going to\nprove it in this class.", "start": 2082.12, "duration": 1.829}, {"text": "There's probably at least five\ndifferent ways of proving it,", "start": 2083.949, "duration": 5.851}, {"text": "but the most canonical one, the\none that you find in textbooks,", "start": 2089.8, "duration": 2.64}, {"text": "is the one that actually\nuses the third element.", "start": 2092.44, "duration": 3.54}, {"text": "So you just look at the\ncharacteristic function", "start": 2095.98, "duration": 3.12}, {"text": "of the square root of\nn Xn bar minus say mu,", "start": 2099.1, "duration": 5.3}, {"text": "and you just expand the thing,\nand this is what you get.", "start": 2104.4, "duration": 3.45}, {"text": "And you will see\nthat in the end,", "start": 2107.85, "duration": 1.38}, {"text": "you will get the characteristic\nfunction of a Gaussian.", "start": 2109.23, "duration": 4.59}, {"text": "Why a Gaussian?", "start": 2113.82, "duration": 0.75}, {"text": "Why does it kick in?", "start": 2114.57, "duration": 1.23}, {"text": "Well, because what is the\ncharacteristic function", "start": 2115.8, "duration": 1.62}, {"text": "of a Gaussian?", "start": 2117.42, "duration": 0.48}, {"text": "Does anybody remember the\ncharacteristic function", "start": 2117.9, "duration": 1.86}, {"text": "of a standard Gaussian?", "start": 2119.76, "duration": 0.958}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 2120.718, "duration": 1.211}, {"text": "PHILIPPE RIGOLLET:\nYeah, well, I mean", "start": 2121.929, "duration": 1.541}, {"text": "there's two pi's and stuff\nthat goes away, right?", "start": 2123.47, "duration": 4.29}, {"text": "A Gaussian is a random variable.", "start": 2127.76, "duration": 1.57}, {"text": "A characteristic\nfunction is a function,", "start": 2129.33, "duration": 1.81}, {"text": "and so it's not really itself.", "start": 2131.14, "duration": 1.9}, {"text": "It looks like itself.", "start": 2133.04, "duration": 1.76}, {"text": "Anybody knows what\nthe actual formula is?", "start": 2134.8, "duration": 2.462}, {"text": "Yeah.", "start": 2137.262, "duration": 0.499}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 2137.761, "duration": 1.823}, {"text": "PHILIPPE RIGOLLET:\nE to the minus?", "start": 2139.584, "duration": 1.416}, {"text": "AUDIENCE: E to the\nminus x squared over 2.", "start": 2141.0, "duration": 1.23}, {"text": "PHILIPPE RIGOLLET: Exactly.", "start": 2142.23, "duration": 1.125}, {"text": "E to the minus x squared over 2.", "start": 2143.355, "duration": 1.605}, {"text": "But this x squared\nover 2 is actually", "start": 2144.96, "duration": 1.71}, {"text": "just the second order expansion\nin the Taylor expansion.", "start": 2146.67, "duration": 3.031}, {"text": "And that's why the\nGaussian is so important.", "start": 2149.701, "duration": 1.833}, {"text": "It's just the second\norder Taylor expansion.", "start": 2151.534, "duration": 3.286}, {"text": "And so you can check it out.", "start": 2154.82, "duration": 1.37}, {"text": "I think Terry Tao has\nsome stuff on his blog,", "start": 2156.19, "duration": 2.16}, {"text": "and there's a bunch\nof different proofs.", "start": 2158.35, "duration": 2.01}, {"text": "But if you want to prove\nconvergence in distribution,", "start": 2160.36, "duration": 2.43}, {"text": "you very likely are going to\nuse one this three right here.", "start": 2162.79, "duration": 5.11}, {"text": "So let's move on.", "start": 2167.9, "duration": 1.11}, {"text": "This is when I said\nthat this convergence is", "start": 2173.05, "duration": 2.46}, {"text": "weaker than that convergence.", "start": 2175.51, "duration": 1.68}, {"text": "This is what I meant.", "start": 2177.19, "duration": 1.68}, {"text": "If you have convergence\nin one style,", "start": 2178.87, "duration": 1.83}, {"text": "it implies convergence\nin the other stuff.", "start": 2180.7, "duration": 2.5}, {"text": "So the first [INAUDIBLE] is that\nif Tn converges almost surely,", "start": 2183.2, "duration": 3.305}, {"text": "this a dot s dot\nmeans almost surely,", "start": 2186.505, "duration": 2.445}, {"text": "then it also converges\nin probability", "start": 2188.95, "duration": 2.25}, {"text": "and actually the\ntwo limits, which", "start": 2191.2, "duration": 1.7}, {"text": "are this random variable\nT, are equal almost surely.", "start": 2192.9, "duration": 4.51}, {"text": "Basically what it means is\nthat whatever you measure one", "start": 2197.41, "duration": 2.34}, {"text": "is going to be the same that\nyou measure on the other one.", "start": 2199.75, "duration": 2.416}, {"text": "So that's very strong.", "start": 2202.166, "duration": 2.134}, {"text": "So that means that\nconvergence almost surely", "start": 2204.3, "duration": 3.66}, {"text": "is stronger than\nconvergence in probability.", "start": 2207.96, "duration": 3.03}, {"text": "If you're converge in Lp\nthen you also converge", "start": 2210.99, "duration": 2.58}, {"text": "in Lq for sum q less than p.", "start": 2213.57, "duration": 2.82}, {"text": "So if you converge in L2,\nyou'll also converge in L1.", "start": 2216.39, "duration": 3.09}, {"text": "If you converge in L67,\nyou converge in L2.", "start": 2219.48, "duration": 3.57}, {"text": "If you're converge\nin L infinity,", "start": 2223.05, "duration": 1.87}, {"text": "you converge in Lp for anything.", "start": 2224.92, "duration": 4.47}, {"text": "And so, again, limits are equal.", "start": 2229.39, "duration": 3.0}, {"text": "And then when you\nconverge in distribution,", "start": 2232.39, "duration": 2.006}, {"text": "when you converge\nin probability,", "start": 2234.396, "duration": 1.374}, {"text": "you also converge\nin distribution.", "start": 2235.77, "duration": 3.09}, {"text": "OK, so almost surely\nimplies probability.", "start": 2238.86, "duration": 3.92}, {"text": "Lp implies probability.", "start": 2242.78, "duration": 1.62}, {"text": "Probability implies\ndistribution.", "start": 2244.4, "duration": 2.12}, {"text": "And here note that\nI did not write,", "start": 2246.52, "duration": 2.22}, {"text": "and the limits are\nequal almost surely.", "start": 2248.74, "duration": 2.15}, {"text": "Why?", "start": 2250.89, "duration": 0.5}, {"text": "Because the convergence\nin distribution", "start": 2255.446, "duration": 1.624}, {"text": "is actually not telling you\nthat your random variable", "start": 2257.07, "duration": 1.86}, {"text": "is converging to\nanother random variable.", "start": 2258.93, "duration": 1.92}, {"text": "It's telling you\nthat the distribution", "start": 2260.85, "duration": 1.583}, {"text": "of your random variable is\nconverging to a distribution.", "start": 2262.433, "duration": 2.757}, {"text": "And think of this, guys.", "start": 2265.19, "duration": 1.99}, {"text": "x and minus x.", "start": 2267.18, "duration": 1.884}, {"text": "The central limit\ntheorem tells me", "start": 2269.064, "duration": 1.416}, {"text": "that I'm converging to some\nstandard Gaussian distribution,", "start": 2270.48, "duration": 2.98}, {"text": "but am I converging to x or\nam I converging to minus x?", "start": 2273.46, "duration": 3.874}, {"text": "It's not well identified.", "start": 2277.334, "duration": 1.041}, {"text": "It's any random variable\nthat has this distribution.", "start": 2278.375, "duration": 3.095}, {"text": "So there's no way\nthe limits are equal.", "start": 2281.47, "duration": 2.64}, {"text": "Their distributions are\ngoing to be the same,", "start": 2284.11, "duration": 1.96}, {"text": "but they're not the same limit.", "start": 2286.07, "duration": 1.84}, {"text": "Is that clear for everyone?", "start": 2287.91, "duration": 2.06}, {"text": "So in a way, convergence\nin distribution", "start": 2289.97, "duration": 2.73}, {"text": "is really not a convergence\nof a random variable", "start": 2292.7, "duration": 2.477}, {"text": "towards another random variable.", "start": 2295.177, "duration": 1.333}, {"text": "It's just telling you\nthe limiting distribution", "start": 2296.51, "duration": 2.01}, {"text": "of your random\nvariable [INAUDIBLE]", "start": 2298.52, "duration": 1.87}, {"text": "which is enough for us.", "start": 2300.39, "duration": 2.432}, {"text": "And one thing that's\nactually really nice", "start": 2302.822, "duration": 1.708}, {"text": "is this continuous\nmapping theorem, which", "start": 2304.53, "duration": 4.26}, {"text": "essentially tells you that--", "start": 2308.79, "duration": 1.557}, {"text": "so this is one of the\ntheorems that we like,", "start": 2310.347, "duration": 1.833}, {"text": "because they tell\nus you can do what", "start": 2312.18, "duration": 1.77}, {"text": "you feel like you want to do.", "start": 2313.95, "duration": 1.71}, {"text": "So if I have Tn that goes to\nT, f of Tn goes to f of T,", "start": 2315.66, "duration": 4.17}, {"text": "and this is true for\nany of those convergence", "start": 2319.83, "duration": 2.97}, {"text": "except for Lp.", "start": 2322.8, "duration": 2.85}, {"text": "But they have to have f,\nwhich is continuous, otherwise", "start": 2328.17, "duration": 3.32}, {"text": "weird stuff can happen.", "start": 2331.49, "duration": 3.46}, {"text": "So this is going to be\nconvenient, because here I", "start": 2334.95, "duration": 3.2}, {"text": "don't have X to n minus p.", "start": 2338.15, "duration": 1.862}, {"text": "I have a continuous function.", "start": 2340.012, "duration": 1.208}, {"text": "It's between a linear\nfunction of Xn minus p,", "start": 2341.22, "duration": 1.874}, {"text": "but I could think of like\neven crazier stuff to do,", "start": 2343.094, "duration": 2.706}, {"text": "and it would still be true.", "start": 2345.8, "duration": 2.076}, {"text": "If I took the square, it would\nconverge to something that", "start": 2347.876, "duration": 2.374}, {"text": "looks like its distribution.", "start": 2350.25, "duration": 1.35}, {"text": "It's the same as\nthe distribution", "start": 2351.6, "duration": 1.375}, {"text": "of a square Gaussian.", "start": 2352.975, "duration": 3.125}, {"text": "So this is a mouthful,\nthese two slides--", "start": 2356.1, "duration": 2.335}, {"text": "actually this particular\nslide is a mouthful.", "start": 2358.435, "duration": 1.875}, {"text": "What I have in my head since\nI was pretty much where you're", "start": 2360.31, "duration": 4.31}, {"text": "sitting, is this diagram.", "start": 2364.62, "duration": 3.27}, {"text": "So what it tells me-- so it's\nactually voluntarily cropped,", "start": 2367.89, "duration": 4.21}, {"text": "so you can start from\nany Lq you want large.", "start": 2372.1, "duration": 3.33}, {"text": "And then as you\ndecrease the index,", "start": 2375.43, "duration": 2.6}, {"text": "you are actually\nimplying, implying,", "start": 2378.03, "duration": 1.72}, {"text": "implying until you imply\nconvergence in probability.", "start": 2379.75, "duration": 2.94}, {"text": "Convergence almost surely\nimplies convergence", "start": 2382.69, "duration": 2.16}, {"text": "in probability, and everything\ngoes to the [? sync, ?]", "start": 2384.85, "duration": 4.8}, {"text": "that is convergence\nin distribution.", "start": 2389.65, "duration": 2.94}, {"text": "So everything implies\nconvergence in distribution.", "start": 2392.59, "duration": 2.64}, {"text": "So that's basically rather than\nremembering those formulas,", "start": 2395.23, "duration": 2.57}, {"text": "this is really the diagram\nyou want to remember.", "start": 2397.8, "duration": 2.04}, {"text": "All right, so why do we bother\nlearning about those things.", "start": 2402.69, "duration": 3.9}, {"text": "That's because of this\nlimits and operations.", "start": 2406.59, "duration": 2.79}, {"text": "Operations and limits.", "start": 2409.38, "duration": 1.2}, {"text": "If I have a sequence\nof real numbers,", "start": 2410.58, "duration": 3.13}, {"text": "and I know that Xn converges\nto X and Yn converges to Y,", "start": 2413.71, "duration": 4.06}, {"text": "then I can start doing all\nmy manipulations and things", "start": 2417.77, "duration": 2.281}, {"text": "are happy.", "start": 2420.051, "duration": 0.499}, {"text": "I can add stuff.", "start": 2420.55, "duration": 1.01}, {"text": "I can multiply stuff.", "start": 2421.56, "duration": 1.68}, {"text": "But it's not true always for\nconvergence in distribution.", "start": 2423.24, "duration": 4.809}, {"text": "But it is, what's\nnice, it's actually", "start": 2428.049, "duration": 1.541}, {"text": "true for convergence\nalmost surely.", "start": 2429.59, "duration": 2.9}, {"text": "Convergence almost surely\neverything is true.", "start": 2432.49, "duration": 2.76}, {"text": "It's just impossible\nto make it fail.", "start": 2435.25, "duration": 2.86}, {"text": "But convergence in probability\nis not always everything,", "start": 2438.11, "duration": 2.97}, {"text": "but at least you can actually\nadd stuff and multiply stuff.", "start": 2441.08, "duration": 2.79}, {"text": "And it will still give\nyou the sum of the n,", "start": 2443.87, "duration": 2.73}, {"text": "and the product of the n.", "start": 2446.6, "duration": 2.48}, {"text": "You can even take the ratio\nif V is not 0 of course.", "start": 2449.08, "duration": 6.51}, {"text": "If the limit is not\n0, then actually", "start": 2455.59, "duration": 1.5}, {"text": "you need Vn to be not 0 as well.", "start": 2457.09, "duration": 1.43}, {"text": "You can actually prove\nthis last statement, right?", "start": 2461.44, "duration": 4.09}, {"text": "Because it's a combination\nof the first statement", "start": 2465.53, "duration": 3.09}, {"text": "of the second one, and the\ncontinuous mapping theorem.", "start": 2468.62, "duration": 3.12}, {"text": "Because the function\nthat maps x to 1", "start": 2471.74, "duration": 3.03}, {"text": "over x on everything\nbut 0, is continuous.", "start": 2474.77, "duration": 4.41}, {"text": "And so 1 over Vn\nconverges to 1 over V,", "start": 2479.18, "duration": 5.38}, {"text": "and then I can multiply\nthose two things.", "start": 2484.56, "duration": 2.26}, {"text": "So you actually knew that one.", "start": 2486.82, "duration": 2.05}, {"text": "But really this is\nnot what matters,", "start": 2488.87, "duration": 1.89}, {"text": "because this is something that\nyou will do whatever happens.", "start": 2490.76, "duration": 4.35}, {"text": "If I don't tell you you cannot\ndo it, well, you will do it.", "start": 2495.11, "duration": 2.676}, {"text": "But in general\nthose things don't", "start": 2497.786, "duration": 1.374}, {"text": "apply to convergence\nin distribution", "start": 2499.16, "duration": 1.5}, {"text": "unless the pair itself is known\nto converge in distribution.", "start": 2500.66, "duration": 3.73}, {"text": "Remember when I said that\nthese things apply to vectors,", "start": 2504.39, "duration": 3.83}, {"text": "then you need to actually\nsay that the vector converges", "start": 2508.22, "duration": 2.93}, {"text": "in distributions to\nthe limiting factor.", "start": 2511.15, "duration": 2.37}, {"text": "Now this tells\nyou in particular,", "start": 2513.52, "duration": 1.779}, {"text": "since the cumulative\ndistribution function is not", "start": 2515.299, "duration": 2.041}, {"text": "defined for vectors,\nI would have", "start": 2517.34, "duration": 2.48}, {"text": "to actually use one of the\nother distributions, one", "start": 2519.82, "duration": 2.79}, {"text": "of the other criteria,\nwhich is convergence", "start": 2522.61, "duration": 1.8}, {"text": "of characteristic\nfunctions or convergence", "start": 2524.41, "duration": 3.0}, {"text": "of a function of bounded\ncontinuous function", "start": 2527.41, "duration": 3.69}, {"text": "of the random variable.", "start": 2531.1, "duration": 1.37}, {"text": "0.2 or 0.3, but 0.1 is not\ngoing get you anywhere.", "start": 2532.47, "duration": 4.684}, {"text": "But this is something\nthat's going", "start": 2537.154, "duration": 1.416}, {"text": "to be too hard for us to\ndeal with, so we're actually", "start": 2538.57, "duration": 2.28}, {"text": "going to rely on the\nfact that we have", "start": 2540.85, "duration": 2.892}, {"text": "something that's even better.", "start": 2543.742, "duration": 1.208}, {"text": "There's something\nthat is waiting for us", "start": 2544.95, "duration": 1.63}, {"text": "at the end of his lecture, which\nis called Slutsky's that says", "start": 2546.58, "duration": 2.583}, {"text": "that if V, in this case,\nconverges in probability", "start": 2549.163, "duration": 4.327}, {"text": "but U converge in distribution,\nI can actually still do that.", "start": 2553.49, "duration": 2.55}, {"text": "I actually don't\nneed both of them", "start": 2556.04, "duration": 1.416}, {"text": "to converge in probability.", "start": 2557.456, "duration": 1.29}, {"text": "I actually need only one of\nthem to converge in probability", "start": 2558.746, "duration": 2.458}, {"text": "to make this statement.", "start": 2561.204, "duration": 0.958}, {"text": "But two sum.", "start": 2562.162, "duration": 2.908}, {"text": "So let's go to another example.", "start": 2565.07, "duration": 1.99}, {"text": "So I just want to make sure that\nwe keep on doing statistics.", "start": 2567.06, "duration": 2.69}, {"text": "And every time we're going\nto just do a little bit", "start": 2569.75, "duration": 2.203}, {"text": "too much probability, I'm\ngoing to reset the pressure,", "start": 2571.953, "duration": 2.249}, {"text": "and start doing\nstatistics again.", "start": 2574.202, "duration": 1.888}, {"text": "All right, so assume\nyou observe the times", "start": 2576.09, "duration": 3.37}, {"text": "the inter-arrival time\nof the T at Kendall.", "start": 2579.46, "duration": 5.13}, {"text": "So this is not the arrival time.", "start": 2584.59, "duration": 1.44}, {"text": "It's not like 7:56, 8:15.", "start": 2586.03, "duration": 3.95}, {"text": "No, it's really the\ninter-arrival time, right?", "start": 2589.98, "duration": 2.94}, {"text": "So say the next T is\narriving in six minutes.", "start": 2592.92, "duration": 4.38}, {"text": "So let's say [INAUDIBLE] bound.", "start": 2597.3, "duration": 3.65}, {"text": "And so you have this\ninter-arrival time.", "start": 2600.95, "duration": 2.3}, {"text": "So those are numbers say,\n3, 4, 5, 4, 3, et cetera.", "start": 2603.25, "duration": 4.01}, {"text": "So I have this\nsequence of numbers.", "start": 2607.26, "duration": 2.23}, {"text": "So I'm going to\nobserve this, and I'm", "start": 2609.49, "duration": 1.61}, {"text": "going to try to infer what\nis the rate of T's going out", "start": 2611.1, "duration": 4.95}, {"text": "of the station from this.", "start": 2616.05, "duration": 2.907}, {"text": "So I'm going to assume\nthat these things are", "start": 2618.957, "duration": 1.833}, {"text": "mutually independent.", "start": 2620.79, "duration": 2.37}, {"text": "That's probably not\ncompletely true.", "start": 2623.16, "duration": 1.73}, {"text": "Again, it just means\nthat what it would mean", "start": 2624.89, "duration": 1.96}, {"text": "is that two consecutive\ninter-arrival times are", "start": 2626.85, "duration": 2.25}, {"text": "independent.", "start": 2629.1, "duration": 0.921}, {"text": "I mean, you can make it\nindependent if you want,", "start": 2630.021, "duration": 1.999}, {"text": "but again, this\nindependent assumption", "start": 2632.02, "duration": 1.583}, {"text": "is for us to be happy and safe.", "start": 2633.603, "duration": 2.577}, {"text": "Unless someone comes\nwith overwhelming proof", "start": 2636.18, "duration": 1.98}, {"text": "that it's not independent and\nfar from being independent,", "start": 2638.16, "duration": 3.306}, {"text": "then yes, you have a problem.", "start": 2641.466, "duration": 2.484}, {"text": "But it might be the fact\nthat it's actually-- if you", "start": 2643.95, "duration": 2.25}, {"text": "have a T that's one hour late.", "start": 2646.2, "duration": 3.04}, {"text": "If an inter-arrival time is\none hour, then the other T,", "start": 2649.24, "duration": 3.09}, {"text": "either they fixed\nit, and it's going", "start": 2652.33, "duration": 1.97}, {"text": "to be just 30 seconds behind,\nor they haven't fixed it,", "start": 2654.3, "duration": 2.85}, {"text": "then it's going to be\nanother hour behind.", "start": 2657.15, "duration": 1.84}, {"text": "So they're not\nexactly independent,", "start": 2658.99, "duration": 1.79}, {"text": "but they are when things\nwork well and approximate.", "start": 2660.78, "duration": 3.65}, {"text": "And so now I need to model\na random variable that's", "start": 2664.43, "duration": 3.15}, {"text": "positive, maybe\nnot upper bounded.", "start": 2667.58, "duration": 1.984}, {"text": "I mean, people complain\nenough that this thing", "start": 2669.564, "duration": 1.916}, {"text": "can be really large.", "start": 2671.48, "duration": 0.955}, {"text": "And so one thing that people\nlike for inter-arrival times", "start": 2672.435, "duration": 2.375}, {"text": "is exponential distribution.", "start": 2674.81, "duration": 2.029}, {"text": "So that's a positive\nrandom variable.", "start": 2676.839, "duration": 1.541}, {"text": "Looks like an exponential\non the right-hand slide,", "start": 2678.38, "duration": 2.083}, {"text": "on the positive line.", "start": 2680.463, "duration": 1.187}, {"text": "And so it decays\nvery fast towards 0.", "start": 2681.65, "duration": 1.95}, {"text": "The probability that\nyou have very large", "start": 2683.6, "duration": 1.8}, {"text": "values exponentially small, and\nthere's a [INAUDIBLE] lambda", "start": 2685.4, "duration": 3.68}, {"text": "that controls how\nexponential is defined.", "start": 2689.08, "duration": 1.82}, {"text": "It's exponential minus\nlambda times something.", "start": 2690.9, "duration": 2.7}, {"text": "And so we're going\nto assume that they", "start": 2693.6, "duration": 2.67}, {"text": "have the same distribution,\nthe same random variable.", "start": 2696.27, "duration": 2.34}, {"text": "So they're IID, because\nthey are independent,", "start": 2698.61, "duration": 1.92}, {"text": "and they're identically\ndistributed.", "start": 2700.53, "duration": 1.28}, {"text": "They all have this exponential\nwith parameter lambda,", "start": 2701.81, "duration": 2.208}, {"text": "and I'm going to try to\nlearn something about lambda.", "start": 2704.018, "duration": 2.312}, {"text": "What is the estimated\nvalue of lambda,", "start": 2706.33, "duration": 2.46}, {"text": "and can I build a confidence\ninterval for lambda.", "start": 2708.79, "duration": 3.42}, {"text": "So we observe n arrival times.", "start": 2712.21, "duration": 4.26}, {"text": "So as I said, the\nmutual independence", "start": 2716.47, "duration": 3.95}, {"text": "is plausible, but not\ncompletely justified.", "start": 2720.42, "duration": 3.635}, {"text": "The fact that\nthey're exponential", "start": 2724.055, "duration": 1.375}, {"text": "is actually something that\npeople like in all this what's", "start": 2725.43, "duration": 2.374}, {"text": "called queuing theory.", "start": 2727.804, "duration": 1.226}, {"text": "So exponentials\narise a lot when you", "start": 2729.03, "duration": 2.01}, {"text": "talk about inter-arrival times.", "start": 2731.04, "duration": 1.41}, {"text": "It's not about\nthe bus, but where", "start": 2732.45, "duration": 1.56}, {"text": "it's very important is call\ncenters, service, servers where", "start": 2734.01, "duration": 7.77}, {"text": "tasks come, and people\nwant to know how long it's", "start": 2741.78, "duration": 3.48}, {"text": "going to take to serve a task.", "start": 2745.26, "duration": 2.19}, {"text": "So when I call at\na center, nobody", "start": 2747.45, "duration": 2.61}, {"text": "knows how long I'm going to stay\non the phone with this person.", "start": 2750.06, "duration": 2.65}, {"text": "But it turns out that\nempirically exponential", "start": 2752.71, "duration": 1.88}, {"text": "distributions have been\nvery good at modeling this.", "start": 2754.59, "duration": 2.207}, {"text": "And what it means is\nthat they're actually--", "start": 2756.797, "duration": 1.833}, {"text": "you have this\nmemoryless property.", "start": 2758.63, "duration": 3.23}, {"text": "It's kind of crazy if\nyou think about it.", "start": 2761.86, "duration": 1.71}, {"text": "What does that thing say?", "start": 2763.57, "duration": 1.041}, {"text": "Let's parse it.", "start": 2764.611, "duration": 1.949}, {"text": "That's the probability.", "start": 2766.56, "duration": 2.35}, {"text": "So this is condition on the\nfact that T1 is larger than T.", "start": 2768.91, "duration": 3.71}, {"text": "So T1 is just say the\nfirst arrival time.", "start": 2772.62, "duration": 2.16}, {"text": "That means that\nconditionally on the fact", "start": 2774.78, "duration": 2.04}, {"text": "that I've been waiting\nfor the first T, well,", "start": 2776.82, "duration": 2.88}, {"text": "the first [INAUDIBLE].", "start": 2779.7, "duration": 3.8}, {"text": "Well, I should probably-- the\nfirst subway for more than T", "start": 2783.5, "duration": 3.94}, {"text": "conditionally-- so I've been\nthere T minutes already.", "start": 2787.44, "duration": 2.9}, {"text": "Then the probability that\nI wait for s more minutes.", "start": 2790.34, "duration": 2.786}, {"text": "So that's the probability\nthat T1 is learned,", "start": 2793.126, "duration": 1.874}, {"text": "and the time that we've\nalready waited plus x.", "start": 2795.0, "duration": 3.439}, {"text": "Given that I've been\nwaiting for T minutes,", "start": 2798.439, "duration": 1.791}, {"text": "really I wait for\ns more minutes,", "start": 2800.23, "duration": 2.11}, {"text": "is actually the probability\nthat I wait for s minutes total.", "start": 2802.34, "duration": 4.076}, {"text": "It's completely memoryless.", "start": 2806.416, "duration": 1.124}, {"text": "It doesn't remember how\nlong have you been waiting.", "start": 2807.54, "duration": 2.13}, {"text": "The probability does not change.", "start": 2809.67, "duration": 1.35}, {"text": "You can have waited for\ntwo hours, the probability", "start": 2811.02, "duration": 2.43}, {"text": "that it takes\nanother 10 minutes is", "start": 2813.45, "duration": 1.979}, {"text": "going to be the\nsame as if you had", "start": 2815.429, "duration": 1.416}, {"text": "been waiting for zero minutes.", "start": 2816.845, "duration": 2.405}, {"text": "And that's something\nthat's actually", "start": 2819.25, "duration": 1.5}, {"text": "part of your problem set.", "start": 2820.75, "duration": 1.72}, {"text": "Very easy to compute.", "start": 2822.47, "duration": 0.95}, {"text": "This is just an\nanalytical property.", "start": 2823.42, "duration": 2.31}, {"text": "And you just\nmanipulate functions,", "start": 2825.73, "duration": 1.496}, {"text": "and you see that this thing\njust happen to be true,", "start": 2827.226, "duration": 2.125}, {"text": "and that's something\nthat people like.", "start": 2829.351, "duration": 2.489}, {"text": "Because that's also\nsomething that benefit.", "start": 2831.84, "duration": 3.3}, {"text": "And also what we like is\nthat this thing is positive", "start": 2835.14, "duration": 2.4}, {"text": "almost surely, which is good\nwhen you model arrival times.", "start": 2837.54, "duration": 3.54}, {"text": "To be fair, we're not\ngoing to be that careful.", "start": 2841.08, "duration": 2.052}, {"text": "Because sometimes\nwe are just going", "start": 2843.132, "duration": 1.458}, {"text": "to assume that something\nfollows a normal distribution.", "start": 2844.59, "duration": 4.42}, {"text": "And in particular,\nI mean, I don't", "start": 2849.01, "duration": 1.617}, {"text": "know if we're going to\ngo into that details,", "start": 2850.627, "duration": 1.833}, {"text": "but a good thing that you\ncan model with a Gaussian", "start": 2852.46, "duration": 2.37}, {"text": "distribution are\nheights of students.", "start": 2854.83, "duration": 3.6}, {"text": "But technically with\npositive probability,", "start": 2858.43, "duration": 2.29}, {"text": "you can have a negative\nGaussian random variable, right?", "start": 2860.72, "duration": 3.57}, {"text": "And the probability being it's\nprobably 10 to the minus 25,", "start": 2864.29, "duration": 4.26}, {"text": "but it's positive.", "start": 2868.55, "duration": 1.166}, {"text": "But it's good enough\nfor us for our modeling.", "start": 2869.716, "duration": 1.874}, {"text": "So this thing is nice, but this\nis not going to be required.", "start": 2871.59, "duration": 2.652}, {"text": "When you're modeling\npositive random variables,", "start": 2874.242, "duration": 1.958}, {"text": "you don't always have to use\npositive distributions that are", "start": 2876.2, "duration": 2.85}, {"text": "supported on positive numbers.", "start": 2879.05, "duration": 2.415}, {"text": "You can use distributions\nlike Gaussian.", "start": 2881.465, "duration": 1.932}, {"text": "So now this exponential\ndistribution of T1, Tn", "start": 2886.3, "duration": 3.517}, {"text": "they have the same\nparameter, and that", "start": 2889.817, "duration": 1.583}, {"text": "means that in average they have\nthe same inter-arrival time.", "start": 2891.4, "duration": 3.03}, {"text": "So this lambda is\nactually the expectation.", "start": 2894.43, "duration": 2.46}, {"text": "And what I'm just saying\nis that they're identically", "start": 2896.89, "duration": 2.5}, {"text": "distributed means\nthat I mean some sort", "start": 2899.39, "duration": 2.21}, {"text": "of a stationary regime,\nand it's not always true.", "start": 2901.6, "duration": 2.679}, {"text": "I have to look at a\nshorter period of time,", "start": 2904.279, "duration": 1.791}, {"text": "because at rush\nhour and 11:00 PM", "start": 2906.07, "duration": 2.74}, {"text": "clearly those average\ninter-arrival times", "start": 2908.81, "duration": 2.39}, {"text": "are going to be different\nSo it means that I am really", "start": 2911.2, "duration": 2.34}, {"text": "focusing maybe on rush hour.", "start": 2913.54, "duration": 1.77}, {"text": "Sorry, I said it's lambda.", "start": 2918.567, "duration": 1.083}, {"text": "It's actually 1 over lambda.", "start": 2919.65, "duration": 1.166}, {"text": "I always mix the two.", "start": 2920.816, "duration": 1.644}, {"text": "All right, so you have\nthe density of T1.", "start": 2922.46, "duration": 1.84}, {"text": "So f of T is this.", "start": 2924.3, "duration": 2.67}, {"text": "So it's on the\npositive real line.", "start": 2926.97, "duration": 2.43}, {"text": "The fact that I have strictly\npositive or larger [INAUDIBLE]", "start": 2929.4, "duration": 2.99}, {"text": "to 0 doesn't make\nany difference.", "start": 2932.39, "duration": 2.152}, {"text": "So this is the density.", "start": 2934.542, "duration": 0.958}, {"text": "So it's lambda E to the minus\nlambda T. The lambda in front", "start": 2935.5, "duration": 2.72}, {"text": "just ensures that\nwhen I integrate", "start": 2938.22, "duration": 1.47}, {"text": "this function between 0\nand infinity, I get 1.", "start": 2939.69, "duration": 3.81}, {"text": "And you can see, it decays like\nexponential minus lambda T.", "start": 2943.5, "duration": 2.66}, {"text": "So if I were to draw it, it\nwould just look like this.", "start": 2946.16, "duration": 3.528}, {"text": "So at 0, what\nvalue does it take?", "start": 2953.63, "duration": 4.232}, {"text": "Lambda.", "start": 2957.862, "duration": 1.888}, {"text": "And then I decay like\nexponential minus lambda T.", "start": 2959.75, "duration": 3.41}, {"text": "So this is 0, and\nthis is f of T.", "start": 2963.16, "duration": 7.68}, {"text": "So very small probability\nof being very large.", "start": 2970.84, "duration": 2.89}, {"text": "Of course, it depends on lambda.", "start": 2973.73, "duration": 2.0}, {"text": "Now the expectation, you\ncan compute the expectation", "start": 2975.73, "duration": 2.186}, {"text": "of this thing, right?", "start": 2977.916, "duration": 0.874}, {"text": "So you integrate T\ntimes f of T. This", "start": 2978.79, "duration": 3.091}, {"text": "is part of the little sheet\nthat I gave you last time.", "start": 2981.881, "duration": 2.249}, {"text": "This is one of the\nthings you should", "start": 2984.13, "duration": 1.499}, {"text": "be able to do blindfolded.", "start": 2985.629, "duration": 1.531}, {"text": "And then you get the expectation\nof T1 is 1 over lambda.", "start": 2987.16, "duration": 4.116}, {"text": "That's what comes out.", "start": 2991.276, "duration": 1.734}, {"text": "So as I actually tell many of\nmy students, 99% of statistics", "start": 2993.01, "duration": 4.62}, {"text": "is replacing\nexpectations by averages.", "start": 2997.63, "duration": 2.644}, {"text": "And so what you're tempted to do\nis say, well, if in average I'm", "start": 3000.274, "duration": 2.666}, {"text": "supposed to see 1 over lambda,\nI have 15 observations.", "start": 3002.94, "duration": 2.97}, {"text": "I'm just going to average\nthose observations,", "start": 3005.91, "duration": 1.9}, {"text": "and I'm going to see something\nthat should be close to 1", "start": 3007.81, "duration": 2.333}, {"text": "over lambda.", "start": 3010.143, "duration": 1.567}, {"text": "So statistics is about\nreplacing averages,", "start": 3011.71, "duration": 3.18}, {"text": "expectations with\naverages, and that's we do.", "start": 3014.89, "duration": 3.06}, {"text": "So Tn bar here, which is\nthe average of the Ti's, is", "start": 3017.95, "duration": 3.58}, {"text": "a pretty good estimator\nfor 1 over lambda.", "start": 3021.53, "duration": 3.53}, {"text": "So if I want an\nestimate for lambda,", "start": 3025.06, "duration": 2.08}, {"text": "then I need to\ntake 1 over Tn bar.", "start": 3027.14, "duration": 3.05}, {"text": "So here is one estimator.", "start": 3030.19, "duration": 2.32}, {"text": "I did it without much\nprinciple except that I just", "start": 3032.51, "duration": 3.83}, {"text": "want to replace\nexpectations by averages,", "start": 3036.34, "duration": 2.4}, {"text": "and then I fixed the problem\nthat I was actually estimating", "start": 3038.74, "duration": 2.55}, {"text": "1 over lambda by lambda.", "start": 3041.29, "duration": 1.74}, {"text": "But you could come up with\nother estimators, right?", "start": 3043.03, "duration": 2.46}, {"text": "But let's say this is my way\nof getting to that estimator.", "start": 3045.49, "duration": 4.24}, {"text": "Just like I didn't give you\nany principled way of getting p", "start": 3049.73, "duration": 2.75}, {"text": "hat, which is Xn bar\nin the kiss example.", "start": 3052.48, "duration": 2.29}, {"text": "But that's the\nnatural way to do it.", "start": 3054.77, "duration": 3.08}, {"text": "Everybody is completely\nshocked by this approach?", "start": 3057.85, "duration": 3.53}, {"text": "All right, so let's do this.", "start": 3061.38, "duration": 1.92}, {"text": "So what can I say about the\nproperties of this estimator", "start": 3063.3, "duration": 2.96}, {"text": "lambda hat?", "start": 3066.26, "duration": 1.87}, {"text": "Well, I know that Tn bar\nis going to 1 over lambda", "start": 3068.13, "duration": 4.62}, {"text": "by the law of large number.", "start": 3072.75, "duration": 1.464}, {"text": "It's an average.", "start": 3074.214, "duration": 0.666}, {"text": "It converges to the\nexpectation both almost surely,", "start": 3074.88, "duration": 3.24}, {"text": "and in probability.", "start": 3078.12, "duration": 1.065}, {"text": "So the first one is the\nstrong law of large number,", "start": 3079.185, "duration": 2.125}, {"text": "the second one is the\nweak law of large number.", "start": 3081.31, "duration": 2.216}, {"text": "I can apply the strong one.", "start": 3083.526, "duration": 1.124}, {"text": "I have enough conditions.", "start": 3084.65, "duration": 2.15}, {"text": "And hence, what do I apply\nso that 1 over Tn bar", "start": 3086.8, "duration": 4.81}, {"text": "actually goes to lambda?", "start": 3091.61, "duration": 3.5}, {"text": "So I said hence.", "start": 3095.11, "duration": 1.14}, {"text": "What is hence?", "start": 3096.25, "duration": 0.791}, {"text": "What is it based on?", "start": 3097.041, "duration": 0.833}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 3097.874, "duration": 5.581}, {"text": "PHILIPPE RIGOLLET Yeah,\ncontinuous mapping theorem,", "start": 3103.455, "duration": 2.125}, {"text": "right?", "start": 3105.58, "duration": 0.14}, {"text": "So I have this\nfunction 1 over x.", "start": 3105.72, "duration": 1.65}, {"text": "I just apply this function.", "start": 3107.37, "duration": 1.81}, {"text": "So if it was 1 over\nlambda squared,", "start": 3109.18, "duration": 2.217}, {"text": "I would have the\nsame thing that would", "start": 3111.397, "duration": 1.583}, {"text": "happen just because\nthe function 1 over x", "start": 3112.98, "duration": 1.708}, {"text": "is continuous away from 0.", "start": 3114.688, "duration": 3.442}, {"text": "And now the central\nlimit theorem", "start": 3118.13, "duration": 2.17}, {"text": "is also telling me\nsomething about lambda.", "start": 3120.3, "duration": 2.07}, {"text": "About Tn bar, right?", "start": 3122.37, "duration": 0.886}, {"text": "It's telling me that if\nI look at my average,", "start": 3123.256, "duration": 1.874}, {"text": "I remove the expectation here.", "start": 3125.13, "duration": 3.39}, {"text": "So if I do Tn bar\nminus my expectation,", "start": 3128.52, "duration": 3.0}, {"text": "rescale by this guy here,\nthen this thing is going", "start": 3131.52, "duration": 4.3}, {"text": "to converge to some\nGaussian random variable,", "start": 3135.82, "duration": 2.46}, {"text": "but here I have this\nlambda to the negative 1--", "start": 3138.28, "duration": 2.98}, {"text": "to the negative 2\nhere, and that's", "start": 3141.26, "duration": 2.27}, {"text": "because they did not\ntell you that if you", "start": 3143.53, "duration": 2.19}, {"text": "compute the variance--", "start": 3145.72, "duration": 3.01}, {"text": "so from this, you\ncan probably extract.", "start": 3148.73, "duration": 1.802}, {"text": "So if I have X that follows\nsome exponential distribution", "start": 3154.308, "duration": 4.972}, {"text": "with parameter lambda.", "start": 3159.28, "duration": 1.07}, {"text": "Well, let's call it T.", "start": 3160.35, "duration": 2.23}, {"text": "So we know that T in\nexpectation, the expectation", "start": 3162.58, "duration": 3.96}, {"text": "of T is 1 over lambda.", "start": 3166.54, "duration": 1.8}, {"text": "What is the variance of T?", "start": 3168.34, "duration": 1.22}, {"text": "You should be able to read\nit from the thing here.", "start": 3176.69, "duration": 3.67}, {"text": "1 over lambda squared.", "start": 3189.984, "duration": 0.916}, {"text": "That's what you actually\nread in the variance,", "start": 3190.9, "duration": 1.916}, {"text": "because the central limit\ntheorem is really telling you", "start": 3192.816, "duration": 3.714}, {"text": "the distribution\ngoes through this n.", "start": 3196.53, "duration": 3.06}, {"text": "But this numbers and this\nnumber you can read, right?", "start": 3199.59, "duration": 4.149}, {"text": "If you look at the expectation\nof this guy it's-- of this guy", "start": 3203.739, "duration": 2.541}, {"text": "comes out.", "start": 3206.28, "duration": 0.55}, {"text": "This is 1 over lambda\nminus 1 over lambda.", "start": 3206.83, "duration": 1.83}, {"text": "That's why you read the 0.", "start": 3208.66, "duration": 1.7}, {"text": "And if you look at the\nvariance of the dot,", "start": 3210.36, "duration": 2.19}, {"text": "you get n times the\nvariance of this average.", "start": 3212.55, "duration": 3.78}, {"text": "Variance of the average is\npicking up a factor 1 over n.", "start": 3216.33, "duration": 3.18}, {"text": "So the n cancels.", "start": 3219.51, "duration": 1.08}, {"text": "And then I'm left with only\none of the variances, which", "start": 3220.59, "duration": 2.291}, {"text": "is 1 over lambda squared.", "start": 3222.881, "duration": 2.369}, {"text": "OK, so we're not going\nto do that in details,", "start": 3225.25, "duration": 2.88}, {"text": "because, again, this is just\na pure calculus exercise.", "start": 3228.13, "duration": 2.3}, {"text": "But this is if you compute\nintegral of lambda e", "start": 3230.43, "duration": 4.27}, {"text": "to the minus t lambda\ntimes t squared.", "start": 3234.7, "duration": 3.73}, {"text": "Actually t minus 1\nover lambda squared", "start": 3238.43, "duration": 3.324}, {"text": "dt between 0 and infinity.", "start": 3241.754, "duration": 3.426}, {"text": "You will see that this thing\nis 1 over lambda squared.", "start": 3245.18, "duration": 2.594}, {"text": "How would I do this?", "start": 3254.157, "duration": 0.982}, {"text": "Configuration by\n[INAUDIBLE] or you know it.", "start": 3260.54, "duration": 3.95}, {"text": "All right.", "start": 3264.49, "duration": 1.61}, {"text": "So this is what the central\nlimit theorem tells me.", "start": 3266.1, "duration": 3.1}, {"text": "So this gives me\nif I solve this,", "start": 3269.2, "duration": 2.42}, {"text": "and I plug in so I can\nmultiply by lambda and solve,", "start": 3271.62, "duration": 3.93}, {"text": "it would give me somewhat\na confidence interval for 1", "start": 3275.55, "duration": 4.55}, {"text": "over lambda.", "start": 3280.1, "duration": 2.84}, {"text": "If we just think\nof 1 over lambda", "start": 3282.94, "duration": 1.43}, {"text": "as being the p\nthat I had before,", "start": 3284.37, "duration": 2.22}, {"text": "this would give me a\ncentral limit theorem for--", "start": 3286.59, "duration": 2.236}, {"text": "sorry, a confidence\ninterval for 1 over lambda.", "start": 3291.664, "duration": 2.796}, {"text": "So I'm hiding a little\nbit under the rug", "start": 3294.46, "duration": 1.79}, {"text": "the fact that I have\nto still define it.", "start": 3296.25, "duration": 2.29}, {"text": "Let's just actually\ngo through this.", "start": 3298.54, "duration": 2.415}, {"text": "I see some of you are\nuncomfortable with this,", "start": 3300.955, "duration": 1.935}, {"text": "so let's just do it.", "start": 3302.89, "duration": 1.994}, {"text": "So what we've just proved\nby the central limit", "start": 3304.884, "duration": 1.916}, {"text": "theorem is that the\nprobability, that's", "start": 3306.8, "duration": 2.53}, {"text": "square root of n Tn minus 1 over\nlambda exceeds q alpha over 2", "start": 3309.33, "duration": 11.85}, {"text": "is approximately\nequal to alpha, right?", "start": 3321.18, "duration": 3.51}, {"text": "That's just the statement of\nthe central limit theorem,", "start": 3324.69, "duration": 2.49}, {"text": "and by approximately equal I\nmean as n goes to infinity.", "start": 3327.18, "duration": 3.474}, {"text": "Sorry I did not\nwrite it correctly.", "start": 3334.23, "duration": 2.52}, {"text": "I still have to divide\nby square root of 1", "start": 3336.75, "duration": 2.69}, {"text": "over lambda squared, which is\nthe standard deviation, right?", "start": 3339.44, "duration": 3.61}, {"text": "And we said that\nthis is a bit ugly.", "start": 3343.05, "duration": 1.57}, {"text": "So let's just do it\nthe way it should be.", "start": 3344.62, "duration": 2.2}, {"text": "So multiply all these\nthings by lambda.", "start": 3346.82, "duration": 3.47}, {"text": "So that means now that\nthe absolute value, so", "start": 3350.29, "duration": 5.73}, {"text": "with probability 1 minus\nalpha asymptotically,", "start": 3356.02, "duration": 3.51}, {"text": "I have that square root of\nn times lambda Tn minus 1", "start": 3359.53, "duration": 8.34}, {"text": "is less than or equal\nto q alpha over 2.", "start": 3367.87, "duration": 3.21}, {"text": "So what it means is that, oh,\nI have negative q alpha over 2", "start": 3374.93, "duration": 5.09}, {"text": "less than square root of n.", "start": 3380.02, "duration": 2.62}, {"text": "Let me divide by\nsquare root of n here.", "start": 3382.64, "duration": 2.584}, {"text": "lambda Tn minus\n1 q alpha over 2.", "start": 3385.224, "duration": 9.396}, {"text": "And so now what I have is that\nI get that lambda is between--", "start": 3394.62, "duration": 7.271}, {"text": "that's Tn bar-- is between\n1 plus q alpha over 2", "start": 3401.891, "duration": 8.519}, {"text": "divided by root n.", "start": 3410.41, "duration": 3.1}, {"text": "And the whole thing\nis divided by Tn bar,", "start": 3413.51, "duration": 3.96}, {"text": "and same thing on the other side\nexcept I have 1 minus q alpha", "start": 3417.47, "duration": 6.54}, {"text": "over 2 divided by root\nn divided by Tn bar.", "start": 3424.01, "duration": 4.668}, {"text": "So it's kind of a weird\nshape, but it's still", "start": 3432.98, "duration": 3.29}, {"text": "of the form 1 over Tn bar\nplus or minus something.", "start": 3436.27, "duration": 3.968}, {"text": "But this something\ndepends on Tn bar itself.", "start": 3440.238, "duration": 3.592}, {"text": "And that's actually normal,\nbecause Tn bar is not only", "start": 3443.83, "duration": 2.4}, {"text": "giving me information\nabout the mean,", "start": 3446.23, "duration": 2.79}, {"text": "but it's also giving me\ninformation about the variance.", "start": 3449.02, "duration": 2.34}, {"text": "So it should definitely come\nin the size of my error bars.", "start": 3451.36, "duration": 6.21}, {"text": "And that's the way it comes\nin this fairly natural way.", "start": 3457.57, "duration": 4.14}, {"text": "Everybody agrees?", "start": 3461.71, "duration": 2.1}, {"text": "So now I have actually\nbuilt a confidence interval.", "start": 3463.81, "duration": 3.07}, {"text": "But what I want to show\nyou with this example is,", "start": 3466.88, "duration": 3.89}, {"text": "can I translate this\nin a central limit", "start": 3470.77, "duration": 2.1}, {"text": "theorem for something that\nconverges to lambda, right?", "start": 3472.87, "duration": 4.65}, {"text": "I know that Tn bar\nconverges to 1 over lambda,", "start": 3477.52, "duration": 3.24}, {"text": "but I also know that 1 over\nTn bar converges to lambda.", "start": 3480.76, "duration": 4.5}, {"text": "So do I have a central limit\ntheorem for 1 over Tn bar?", "start": 3485.26, "duration": 4.19}, {"text": "Technically no, right?", "start": 3489.45, "duration": 2.04}, {"text": "Central limit theorems are about\naverages, and 1 over an average", "start": 3491.49, "duration": 3.03}, {"text": "is not an average.", "start": 3494.52, "duration": 1.954}, {"text": "But there's something that\nstatisticians like a lot,", "start": 3496.474, "duration": 4.046}, {"text": "and it's called\nthe Delta method.", "start": 3500.52, "duration": 2.54}, {"text": "The Delta method\nis really something", "start": 3503.06, "duration": 1.74}, {"text": "that's telling you\nthat you can actually", "start": 3504.8, "duration": 2.4}, {"text": "take a function of\nan average, and let", "start": 3507.2, "duration": 3.24}, {"text": "it go to the function\nof the limit,", "start": 3510.44, "duration": 2.13}, {"text": "and you still have a\ncentral limit theorem.", "start": 3512.57, "duration": 2.13}, {"text": "And the factor or the\nprice to pay for this", "start": 3514.7, "duration": 2.58}, {"text": "is something which depends on\nthe derivative of the function.", "start": 3517.28, "duration": 6.76}, {"text": "And so let's just\ngo through this,", "start": 3524.04, "duration": 2.236}, {"text": "and it's, again, just like\nthe proof of the central limit", "start": 3526.276, "duration": 2.374}, {"text": "theorem.", "start": 3528.65, "duration": 0.99}, {"text": "And actually in many of those\nasymptotic statistics results,", "start": 3529.64, "duration": 3.91}, {"text": "this is actually just\na Taylor expansion,", "start": 3533.55, "duration": 2.284}, {"text": "and here it's not\neven the second order,", "start": 3535.834, "duration": 1.666}, {"text": "it's actually the\nfirst order, all right?", "start": 3537.5, "duration": 2.1}, {"text": "So I'm just going to do linear\napproximation of this function.", "start": 3539.6, "duration": 2.583}, {"text": "So let's do it.", "start": 3544.36, "duration": 0.96}, {"text": "So I have that g of Tn bar--", "start": 3545.32, "duration": 7.63}, {"text": "actually let's use the\nnotation of this slide,", "start": 3552.95, "duration": 2.47}, {"text": "which is Zn and theta.", "start": 3555.42, "duration": 2.17}, {"text": "So what I know is that Zn\nminus theta square root of n", "start": 3557.59, "duration": 6.66}, {"text": "goes to some Gaussian,\nthis standard Gaussian.", "start": 3564.25, "duration": 5.204}, {"text": "No, not standard.", "start": 3569.454, "duration": 3.356}, {"text": "OK, so that's the assumptions.", "start": 3572.81, "duration": 1.27}, {"text": "And what I want to show is\nsome convergence of g of Zn", "start": 3574.08, "duration": 6.422}, {"text": "to g of theta.", "start": 3580.502, "duration": 3.088}, {"text": "So I'm not going to\nmultiply by root n just yet.", "start": 3583.59, "duration": 2.76}, {"text": "So I'm going to do a first\norder Taylor expansion.", "start": 3586.35, "duration": 2.775}, {"text": "So what it is telling me is that\nthis is equal to Zn minus theta", "start": 3589.125, "duration": 7.915}, {"text": "times g prime of,\nlet's call it theta bar", "start": 3597.04, "duration": 4.53}, {"text": "where theta bar is\nsomewhere between say", "start": 3601.57, "duration": 4.63}, {"text": "Zn and theta, for sum.", "start": 3606.2, "duration": 4.948}, {"text": "OK, so if theta is less than\nZn you just permute those two.", "start": 3613.98, "duration": 3.72}, {"text": "So that's what the\nTaylor first order Taylor", "start": 3617.7, "duration": 3.469}, {"text": "expansion tells me.", "start": 3621.169, "duration": 0.791}, {"text": "There exists a theta bar\nthat's between the two", "start": 3621.96, "duration": 1.958}, {"text": "values at which I'm expanding\nso that those two things are", "start": 3623.918, "duration": 2.994}, {"text": "equal.", "start": 3626.912, "duration": 2.38}, {"text": "Is everybody shocked?", "start": 3629.292, "duration": 1.88}, {"text": "No?", "start": 3631.172, "duration": 0.5}, {"text": "So that's standard\nTaylor expansion.", "start": 3631.672, "duration": 4.678}, {"text": "Now I'm going to\nmultiply by root n.", "start": 3636.35, "duration": 1.704}, {"text": "And so that's going to be what?", "start": 3644.519, "duration": 1.291}, {"text": "That's going to be\nroot n Zn minus theta.", "start": 3645.81, "duration": 4.39}, {"text": "Ah-ha, that's something I like.", "start": 3650.2, "duration": 1.77}, {"text": "Times g prime of theta bar.", "start": 3651.97, "duration": 5.16}, {"text": "Now the central limit\ntheorem tells me", "start": 3659.887, "duration": 1.583}, {"text": "that this goes to what?", "start": 3661.47, "duration": 1.434}, {"text": "Well, this goes to sum n\n0 sigma squared, right?", "start": 3666.25, "duration": 6.12}, {"text": "That was the first\nline over there.", "start": 3672.37, "duration": 3.03}, {"text": "This guy here, well,\nit's not clear, right?", "start": 3675.4, "duration": 5.12}, {"text": "Actually it is.", "start": 3680.52, "duration": 1.02}, {"text": "Let's start with this guy.", "start": 3681.54, "duration": 3.3}, {"text": "What does theta bar go to?", "start": 3684.84, "duration": 3.61}, {"text": "Well, I know that Zn\nis going to theta.", "start": 3688.45, "duration": 2.302}, {"text": "Just because, well, that's\nmy law of large numbers.", "start": 3693.66, "duration": 4.1}, {"text": "Zn is going to\ntheta, which means", "start": 3697.76, "duration": 3.25}, {"text": "that theta bar is sandwiched\nbetween two values that", "start": 3701.01, "duration": 3.51}, {"text": "converge to theta.", "start": 3704.52, "duration": 2.39}, {"text": "So that means that theta bar\nconverges to theta itself", "start": 3706.91, "duration": 2.67}, {"text": "as n goes to infinity.", "start": 3709.58, "duration": 1.72}, {"text": "That's just the law\nof large numbers.", "start": 3711.3, "duration": 3.64}, {"text": "Everybody agrees?", "start": 3714.94, "duration": 2.51}, {"text": "Just because it's\nsandwiched, right?", "start": 3717.45, "duration": 1.5}, {"text": "So I have Zn.", "start": 3718.95, "duration": 2.23}, {"text": "I have theta, and theta\nbar is somewhere here.", "start": 3721.18, "duration": 4.471}, {"text": "The picture might be reversed.", "start": 3725.651, "duration": 1.249}, {"text": "It might be that Zn end\nis larger than theta.", "start": 3726.9, "duration": 2.08}, {"text": "But the law of large\nnumber tells me", "start": 3728.98, "duration": 1.5}, {"text": "that this guy is not moving,\nbut this guy is moving that way.", "start": 3730.48, "duration": 3.57}, {"text": "So you know when\nn is [INAUDIBLE],,", "start": 3734.05, "duration": 2.394}, {"text": "there's very little\nwiggle room for theta bar,", "start": 3736.444, "duration": 1.916}, {"text": "and it can only get to theta.", "start": 3738.36, "duration": 1.615}, {"text": "And I call it the\nsandwich theorem,", "start": 3743.37, "duration": 1.94}, {"text": "or just find your\nfavorite food in there.", "start": 3745.31, "duration": 3.92}, {"text": "So this guy goes\nto theta, and now I", "start": 3749.23, "duration": 2.486}, {"text": "need to make an extra\nassumption, which", "start": 3751.716, "duration": 1.624}, {"text": "is that g prime is continuous.", "start": 3753.34, "duration": 5.261}, {"text": "And if g prime is continuous,\nthen g prime of theta bar", "start": 3758.601, "duration": 3.699}, {"text": "goes to g prime of theta.", "start": 3762.3, "duration": 2.33}, {"text": "So this thing goes\nto g prime of theta.", "start": 3764.63, "duration": 4.502}, {"text": "But I have an issue here.", "start": 3772.58, "duration": 2.196}, {"text": "Is that now I have\nsomething that", "start": 3774.776, "duration": 1.374}, {"text": "converges in distribution\nand something", "start": 3776.15, "duration": 1.71}, {"text": "that converges in say--", "start": 3777.86, "duration": 3.68}, {"text": "I mean, this converges almost\nsurely or saying probability", "start": 3781.54, "duration": 2.66}, {"text": "just to be safe.", "start": 3784.2, "duration": 2.17}, {"text": "And this one converges\nin distribution.", "start": 3786.37, "duration": 3.45}, {"text": "And I want to combine them.", "start": 3789.82, "duration": 1.23}, {"text": "But I don't have a\nslide that tells me", "start": 3791.05, "duration": 1.583}, {"text": "I'm allowed to take the product\nof something that converges", "start": 3792.633, "duration": 3.027}, {"text": "in distribution, and something\nthat converges in probability.", "start": 3795.66, "duration": 2.8}, {"text": "This does not exist.", "start": 3798.46, "duration": 1.04}, {"text": "Actually, if\nanything it told me,", "start": 3799.5, "duration": 1.95}, {"text": "do not do anything with things\nthat converge in distribution.", "start": 3801.45, "duration": 4.52}, {"text": "And so that gets us to our--", "start": 3805.97, "duration": 6.8}, {"text": "OK, so I'll come back\nto this in a second.", "start": 3812.77, "duration": 3.23}, {"text": "And that gets us to something\ncalled Slutsky's theorem.", "start": 3816.0, "duration": 3.56}, {"text": "And Slutsky's theorem tells us\nthat in very specific cases,", "start": 3819.56, "duration": 3.38}, {"text": "you can do just that.", "start": 3822.94, "duration": 1.8}, {"text": "So you have two sequences\nof random variables, Xn bar,", "start": 3824.74, "duration": 4.26}, {"text": "that's Xn that converges to\nX. And Yn that converges to Y,", "start": 3829.0, "duration": 4.37}, {"text": "but Y is not anything.", "start": 3833.37, "duration": 2.0}, {"text": "Y is not any random variable.", "start": 3835.37, "duration": 2.04}, {"text": "So X converges in\nthis distribution.", "start": 3837.41, "duration": 1.68}, {"text": "Sorry, I forgot to mention,\nthis is very important.", "start": 3839.09, "duration": 2.125}, {"text": "Xn converges in distribution,\nY converges in probability.", "start": 3841.215, "duration": 3.705}, {"text": "And we know that in generality\nwe cannot combine those two", "start": 3844.92, "duration": 2.65}, {"text": "things, but Slutsky tells\nus that if the limit of Y is", "start": 3847.57, "duration": 3.702}, {"text": "a constant, meaning it's\nnot a random variable,", "start": 3851.272, "duration": 1.958}, {"text": "but it's a\ndeterministic number 2,", "start": 3853.23, "duration": 2.85}, {"text": "just a fixed number that's\nnot a random variable,", "start": 3856.08, "duration": 2.86}, {"text": "then you can combine them.", "start": 3858.94, "duration": 2.45}, {"text": "Then you can sum them, and\nthen you can multiply them.", "start": 3861.39, "duration": 3.479}, {"text": "I mean, actually you can do\nwhatever combination you want,", "start": 3868.874, "duration": 2.416}, {"text": "because it actually implies\nthat X, the vector Xn, Yn", "start": 3871.29, "duration": 3.51}, {"text": "converges to the vector Xc.", "start": 3874.8, "duration": 4.45}, {"text": "OK, so here I just\ntook two combinations.", "start": 3879.25, "duration": 2.17}, {"text": "They are very convenient for\nus, the sum and the product", "start": 3881.42, "duration": 2.65}, {"text": "so I could do other\nstuff like the ratio", "start": 3884.07, "duration": 1.78}, {"text": "if c is not 0, things like that.", "start": 3885.85, "duration": 1.713}, {"text": "So that's what\nSlutsky does for us.", "start": 3891.19, "duration": 1.82}, {"text": "So what you're going to have to\nwrite a lot in your homework,", "start": 3893.01, "duration": 3.11}, {"text": "in your mid-terms, by Slutsky.", "start": 3896.12, "duration": 2.76}, {"text": "I know some people are very\ngenerous with their by Slutsky.", "start": 3898.88, "duration": 4.35}, {"text": "They just do numerical\napplications,", "start": 3903.23, "duration": 2.71}, {"text": "mu is equal to 6, and\ntherefore by Slutsky", "start": 3905.94, "duration": 2.31}, {"text": "mu square is equal to 36.", "start": 3908.25, "duration": 2.01}, {"text": "All right, so don't do that.", "start": 3910.26, "duration": 1.43}, {"text": "Just use, write Slutsky when\nyou're actually using Slutsky.", "start": 3911.69, "duration": 3.725}, {"text": "But this is something that's\nvery important for us,", "start": 3915.415, "duration": 2.125}, {"text": "and it turns out\nthat you're going", "start": 3917.54, "duration": 1.32}, {"text": "to feel like you can write\nby Slutsky all the time,", "start": 3918.86, "duration": 2.125}, {"text": "because that's going to\nwork for us all the time.", "start": 3920.985, "duration": 2.377}, {"text": "Everything we're going\nto see is actually", "start": 3923.362, "duration": 1.708}, {"text": "going to be where we're going\nto have to combine stuff.", "start": 3925.07, "duration": 2.52}, {"text": "Since we only rely on\nconvergence from distribution", "start": 3927.59, "duration": 2.67}, {"text": "arising from the\ncentral limit theorem,", "start": 3930.26, "duration": 1.83}, {"text": "we're actually going to have\nto rely on something that", "start": 3932.09, "duration": 2.25}, {"text": "allows us to combine them,\nand the only thing we know", "start": 3934.34, "duration": 2.58}, {"text": "is Slutsky.", "start": 3936.92, "duration": 0.67}, {"text": "So we better hope\nthat this thing works.", "start": 3937.59, "duration": 2.7}, {"text": "So why Slutsky works for us.", "start": 3940.29, "duration": 1.49}, {"text": "Can somebody tell\nme why Slutsky works", "start": 3941.78, "duration": 1.86}, {"text": "to combine those two guys?", "start": 3943.64, "duration": 3.32}, {"text": "So this one is converging\nin distribution.", "start": 3946.96, "duration": 1.86}, {"text": "This one is converging\nin probability,", "start": 3948.82, "duration": 2.92}, {"text": "but to a deterministic number.", "start": 3951.74, "duration": 2.97}, {"text": "g prime of theta is a\ndeterministic number.", "start": 3954.71, "duration": 2.73}, {"text": "I don't know what theta is, but\nit's certainly deterministic.", "start": 3957.44, "duration": 4.76}, {"text": "All right, so I can combine\nthem, multiply them.", "start": 3962.2, "duration": 2.18}, {"text": "So that's just the second\nline of that in particular.", "start": 3964.38, "duration": 4.36}, {"text": "All right, everybody is with me?", "start": 3968.74, "duration": 3.35}, {"text": "So now I'm allowed to do this.", "start": 3972.09, "duration": 1.25}, {"text": "You can actually--\nyou will see something", "start": 3973.34, "duration": 1.708}, {"text": "like counterexample\nquestions in your problem", "start": 3975.048, "duration": 1.902}, {"text": "set just so that you\ncan convince yourself.", "start": 3976.95, "duration": 1.791}, {"text": "It's always a good thing.", "start": 3978.741, "duration": 1.219}, {"text": "I don't like to\ngive them, because I", "start": 3979.96, "duration": 1.19}, {"text": "think it's much better\nfor you to actually come", "start": 3981.15, "duration": 1.958}, {"text": "to the counterexample yourself.", "start": 3983.108, "duration": 1.752}, {"text": "Like what can go wrong\nif Y is not a random--", "start": 3984.86, "duration": 10.81}, {"text": "sorry, if Y is not a--", "start": 3995.67, "duration": 2.78}, {"text": "sorry, if c is not the constant,\nbut it's a random variable.", "start": 3998.45, "duration": 4.122}, {"text": "You can figure that out.", "start": 4002.572, "duration": 2.962}, {"text": "All right, so let's go back.", "start": 4005.534, "duration": 1.166}, {"text": "So we have now this Delta\nmethod that tells us", "start": 4006.7, "duration": 2.34}, {"text": "that now I have a\ncentral limit theorem", "start": 4009.04, "duration": 2.04}, {"text": "for functions of averages,\nand not just for averages.", "start": 4011.08, "duration": 4.42}, {"text": "So the only price to pay\nis this derivative there.", "start": 4015.5, "duration": 2.422}, {"text": "So, for example, if g is\njust a linear function,", "start": 4020.6, "duration": 4.89}, {"text": "then I'm going to have a\nconstant multiplication.", "start": 4025.49, "duration": 2.37}, {"text": "If g is a quadratic\nfunction, then I'm", "start": 4027.86, "duration": 2.82}, {"text": "going to have theta squared\nthat shows up there.", "start": 4030.68, "duration": 3.03}, {"text": "Things like that.", "start": 4033.71, "duration": 0.84}, {"text": "So just think of what\nkind of applications", "start": 4034.55, "duration": 1.75}, {"text": "you could have for this.", "start": 4036.3, "duration": 1.47}, {"text": "Here are the functions\nthat we're interested in,", "start": 4037.77, "duration": 1.999}, {"text": "is x maps to 1 over x.", "start": 4039.769, "duration": 1.501}, {"text": "What is the derivative\nof this guy?", "start": 4041.27, "duration": 1.779}, {"text": "What is the derivative\nof 1 over x?", "start": 4045.947, "duration": 3.799}, {"text": "Negative 1 over\nx squared, right?", "start": 4049.746, "duration": 1.374}, {"text": "That's the thing we're going\nto have to put in there.", "start": 4051.12, "duration": 2.35}, {"text": "And so this is what we get.", "start": 4053.47, "duration": 4.16}, {"text": "So now when I'm actually\ngoing to write this,", "start": 4057.63, "duration": 6.63}, {"text": "so if I want to show square root\nof n lambda hat minus lambda.", "start": 4064.26, "duration": 7.012}, {"text": "That's my application, right?", "start": 4071.272, "duration": 1.208}, {"text": "This is actually 1 over Tn, and\nthis is 1 over 1 over lambda.", "start": 4072.48, "duration": 6.67}, {"text": "So the function g of x\nis 1 over x in this case.", "start": 4079.15, "duration": 6.36}, {"text": "So now I have this thing.", "start": 4085.51, "duration": 1.08}, {"text": "So I know that by\nthe Delta method--", "start": 4086.59, "duration": 2.37}, {"text": "oh, and I knew\nthat Tn, remember,", "start": 4088.96, "duration": 2.28}, {"text": "square root of Tn\nminus 1 over lambda", "start": 4091.24, "duration": 5.55}, {"text": "was going to sum\nnormal with mean 0", "start": 4096.79, "duration": 2.52}, {"text": "and variance 1 over\nlambda squared, right?", "start": 4099.31, "duration": 2.622}, {"text": "So the sigma square over there\nis 1 over lambda squared.", "start": 4101.932, "duration": 4.147}, {"text": "So now this thing goes to what?", "start": 4106.079, "duration": 1.291}, {"text": "Sum normal.", "start": 4107.37, "duration": 1.568}, {"text": "What is going to be the mean?", "start": 4108.938, "duration": 3.252}, {"text": "0.", "start": 4112.19, "duration": 0.5}, {"text": "And what is the variance?", "start": 4115.51, "duration": 1.677}, {"text": "So the variance is going--", "start": 4117.187, "duration": 1.083}, {"text": "I'm going to pick up\nthis guy, 1 over lambda", "start": 4118.27, "duration": 1.98}, {"text": "squared, and then I'm going to\nhave to take g prime of what?", "start": 4120.25, "duration": 6.68}, {"text": "Of 1 over lambda, right?", "start": 4126.93, "duration": 1.779}, {"text": "That's my theta.", "start": 4128.709, "duration": 0.918}, {"text": "So I have g of theta,\nwhich is 1 over theta.", "start": 4132.84, "duration": 2.229}, {"text": "So I'm going to have g\nprime of 1 over lambda.", "start": 4135.069, "duration": 3.337}, {"text": "And what is g prime\nof 1 over lambda?", "start": 4138.406, "duration": 1.888}, {"text": "So we said that g prime is 1\nover negative 1 over x squared.", "start": 4145.029, "duration": 4.231}, {"text": "So it's negative 1 over\n1 over lambda squared--", "start": 4149.26, "duration": 4.625}, {"text": "sorry, squared.", "start": 4157.877, "duration": 0.998}, {"text": "Which is nice, because\ng can be decreasing.", "start": 4161.87, "duration": 2.47}, {"text": "So that would be annoying\nto have a negative variance.", "start": 4164.34, "duration": 2.51}, {"text": "And so g prime is\nnegative 1 over, and so", "start": 4166.85, "duration": 2.4}, {"text": "what I get eventually is\nlambda squared up here,", "start": 4169.25, "duration": 4.319}, {"text": "but then I square it again.", "start": 4173.569, "duration": 2.801}, {"text": "So this whole thing\nhere becomes what?", "start": 4176.37, "duration": 3.394}, {"text": "Can somebody tell me\nwhat the final result is?", "start": 4179.764, "duration": 1.924}, {"text": "Lambda squared right?", "start": 4184.274, "duration": 0.875}, {"text": "So it's lambda 4\ndivided by lambda 2.", "start": 4185.149, "duration": 2.174}, {"text": "So that's what's written there.", "start": 4195.179, "duration": 4.441}, {"text": "And now I can just do my\ngood old computation for a--", "start": 4199.62, "duration": 4.84}, {"text": "I can do a good computation\nfor a confidence interval.", "start": 4210.61, "duration": 3.96}, {"text": "All right, so let's just\ngo from the second line.", "start": 4214.57, "duration": 3.31}, {"text": "So we know that lambda\nhat minus lambda", "start": 4217.88, "duration": 3.32}, {"text": "is less than, we've done\nthat several times already.", "start": 4221.2, "duration": 2.78}, {"text": "So it's q alpha over 2--", "start": 4223.98, "duration": 1.54}, {"text": "sorry, I should put alpha\nover 2 over this thing, right?", "start": 4225.52, "duration": 2.67}, {"text": "So that's really the quintile\nof what our alpha over 2 times", "start": 4228.19, "duration": 2.835}, {"text": "lambda divided by\nsquare root of n.", "start": 4231.025, "duration": 3.845}, {"text": "All right, and so that means\nthat my confidence interval", "start": 4234.87, "duration": 4.74}, {"text": "should be this, lambda hat.", "start": 4239.61, "duration": 3.0}, {"text": "Lambda belongs to lambda\nplus or minus q alpha", "start": 4242.61, "duration": 5.06}, {"text": "over 2 lambda divided\nby root n, right?", "start": 4247.67, "duration": 3.655}, {"text": "So that's my\nconfidence interval.", "start": 4251.325, "duration": 2.315}, {"text": "But again, it's not\nvery suitable, because--", "start": 4253.64, "duration": 3.317}, {"text": "sorry, that's lambda hat.", "start": 4256.957, "duration": 2.335}, {"text": "Because they don't\nknow how to compute it.", "start": 4259.292, "duration": 3.269}, {"text": "So now I'm going to\nrequest from the audience", "start": 4262.561, "duration": 1.949}, {"text": "some remedies for this.", "start": 4264.51, "duration": 1.954}, {"text": "What do you suggest we do?", "start": 4266.464, "duration": 1.476}, {"text": "What is the laziest\nthing I can do?", "start": 4272.86, "duration": 1.968}, {"text": "Anybody?", "start": 4278.272, "duration": 0.976}, {"text": "Yeah.", "start": 4279.248, "duration": 0.5}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 4279.748, "duration": 1.584}, {"text": "PHILIPPE RIGOLLET Replace\nlambda by lambda hat.", "start": 4281.332, "duration": 1.958}, {"text": "What justifies\nfor me to do this?", "start": 4283.29, "duration": 1.862}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 4285.152, "duration": 2.45}, {"text": "PHILIPPE RIGOLLET\nYeah, and Slutsky", "start": 4287.602, "duration": 1.458}, {"text": "tells me I can actually do\nit, because Slutsky tells me,", "start": 4289.06, "duration": 3.79}, {"text": "where does this lambda\ncome from, right?", "start": 4292.85, "duration": 2.36}, {"text": "This lambda comes from here.", "start": 4295.21, "duration": 2.07}, {"text": "That's the one that's here.", "start": 4297.28, "duration": 2.25}, {"text": "So actually I could\nrewrite this entire thing", "start": 4299.53, "duration": 2.28}, {"text": "as square root of n lambda hat\nminus lambda divided by lambda", "start": 4301.81, "duration": 5.19}, {"text": "converges to sum n 0, 1.", "start": 4307.0, "duration": 4.42}, {"text": "Now if I replace this by\nlambda hat, what I have is", "start": 4311.42, "duration": 4.14}, {"text": "that this is actually really\nthe original one times", "start": 4315.56, "duration": 6.04}, {"text": "lambda divided by lambda hat.", "start": 4321.6, "duration": 3.23}, {"text": "And this converges\nto n 0, 1, right?", "start": 4324.83, "duration": 2.68}, {"text": "And now what you're telling\nme is, well, this guy", "start": 4327.51, "duration": 2.99}, {"text": "I know it converges to n 0, 1,\nand this guy is converging to 1", "start": 4330.5, "duration": 4.86}, {"text": "by the law of large number.", "start": 4335.36, "duration": 1.29}, {"text": "But this one is converging to 1,\nwhich happens to be a constant.", "start": 4336.65, "duration": 3.23}, {"text": "It converges in probability,\nso by Slutsky I can actually", "start": 4339.88, "duration": 2.98}, {"text": "take the product and still\nmaintain my conversion", "start": 4342.86, "duration": 2.73}, {"text": "to distribution to\na standard Gaussian.", "start": 4345.59, "duration": 3.48}, {"text": "So you can always do this.", "start": 4349.07, "duration": 1.29}, {"text": "Every time you replace\nsome p by p hat,", "start": 4350.36, "duration": 3.72}, {"text": "as long as their\nratio goes to 1,", "start": 4354.08, "duration": 1.672}, {"text": "which is going to be guaranteed\nby the law of large number,", "start": 4355.752, "duration": 2.458}, {"text": "you're actually\ngoing to be fine.", "start": 4358.21, "duration": 2.171}, {"text": "And that's where we're\ngoing to use Slutsky a lot.", "start": 4360.381, "duration": 2.083}, {"text": "When we do plug in, Slutsky\nis going to be our friend.", "start": 4362.464, "duration": 4.176}, {"text": "OK, so we can do this.", "start": 4366.64, "duration": 1.25}, {"text": "And that's one way.", "start": 4371.18, "duration": 0.93}, {"text": "And then other\nways to just solve", "start": 4372.11, "duration": 1.54}, {"text": "for lambda like we did before.", "start": 4373.65, "duration": 2.51}, {"text": "So the first one we\ngot is actually--", "start": 4376.16, "duration": 2.04}, {"text": "I don't know if I still\nhave it somewhere.", "start": 4378.2, "duration": 2.64}, {"text": "Yeah, that was the one, right?", "start": 4380.84, "duration": 2.84}, {"text": "So we had 1 over Tn q, and\nthat's exactly the same", "start": 4383.68, "duration": 4.56}, {"text": "that we have here.", "start": 4388.24, "duration": 0.94}, {"text": "So your solution is actually\ngiving us exactly this guy when", "start": 4389.18, "duration": 3.532}, {"text": "we actually solve for lambda.", "start": 4392.712, "duration": 1.656}, {"text": "So this is what we get.", "start": 4397.42, "duration": 3.27}, {"text": "Lambda hat.", "start": 4400.69, "duration": 0.93}, {"text": "We replace lambda by\nlambda hat, and we", "start": 4401.62, "duration": 2.52}, {"text": "have our asymptotic\nconvergence theorem.", "start": 4404.14, "duration": 3.61}, {"text": "And that's exactly what we\ndid in Slutsky's theorem.", "start": 4407.75, "duration": 2.65}, {"text": "Now we're getting to it at\nthis point is just telling us", "start": 4410.4, "duration": 2.417}, {"text": "that we can actually do this.", "start": 4412.817, "duration": 3.823}, {"text": "Are there any questions\nabout what we did here?", "start": 4416.64, "duration": 3.04}, {"text": "So this derivation right\nhere is exactly what I", "start": 4419.68, "duration": 2.84}, {"text": "did on the board I showed you.", "start": 4422.52, "duration": 1.67}, {"text": "So let me just show you\nwith a little more space", "start": 4424.19, "duration": 2.5}, {"text": "just so that we all\nunderstand, right?", "start": 4426.69, "duration": 2.404}, {"text": "So we know that square root of n\nlambda hat minus lambda divided", "start": 4429.094, "duration": 9.476}, {"text": "by lambda, the\ntrue lambda defined", "start": 4438.57, "duration": 2.19}, {"text": "converges to sum n 0, 1.", "start": 4440.76, "duration": 3.34}, {"text": "So that was CLT\nplus Delta method.", "start": 4444.1, "duration": 3.115}, {"text": "Applying those two,\nwe got to here.", "start": 4451.7, "duration": 2.01}, {"text": "And we know that\nlambda hat converges", "start": 4453.71, "duration": 3.69}, {"text": "to lambda in probability and\nalmost surely, and that's what?", "start": 4457.4, "duration": 4.2}, {"text": "That was law of large number\nplus continued mapping theorem,", "start": 4461.6, "duration": 3.38}, {"text": "right?", "start": 4464.98, "duration": 0.749}, {"text": "Because we only knew that\none of our lambda hat", "start": 4465.729, "duration": 1.958}, {"text": "converges to 1 over lambda.", "start": 4467.687, "duration": 1.461}, {"text": "So we had to flip\nthose things around.", "start": 4469.148, "duration": 2.442}, {"text": "And now what I said is\nthat I apply Slutsky,", "start": 4471.59, "duration": 2.33}, {"text": "so I write square root of n\nlambda hat minus lambda divided", "start": 4473.92, "duration": 4.29}, {"text": "by lambda hat, which is the\nsuggestion that was made to me.", "start": 4478.21, "duration": 4.05}, {"text": "They said, I want\nthis, but I would", "start": 4482.26, "duration": 1.9}, {"text": "want to show that it\nconverges to sum n 0,", "start": 4484.16, "duration": 1.75}, {"text": "1 so I can legitimately use\nq alpha over 2 in this one", "start": 4485.91, "duration": 4.06}, {"text": "though.", "start": 4489.97, "duration": 0.775}, {"text": "And the way we said is like,\nwell, this thing is actually", "start": 4490.745, "duration": 2.375}, {"text": "really q divided by lambda times\nlambda divided by lambda hat.", "start": 4493.12, "duration": 7.617}, {"text": "So this thing that\nwas proposed to me,", "start": 4500.737, "duration": 1.583}, {"text": "I can decompose\nit in the product", "start": 4502.32, "duration": 1.41}, {"text": "of those two random variables.", "start": 4503.73, "duration": 2.25}, {"text": "The first one here converges\nthrough the Gaussian", "start": 4505.98, "duration": 3.08}, {"text": "from the central limit theorem.", "start": 4509.06, "duration": 1.54}, {"text": "And the second one converges\nto 1 from this guy,", "start": 4510.6, "duration": 4.118}, {"text": "but in probability this time.", "start": 4514.718, "duration": 2.32}, {"text": "That was the ratio of two\nthings in probability,", "start": 4520.62, "duration": 2.64}, {"text": "we can actually get it.", "start": 4523.26, "duration": 1.77}, {"text": "And so now I apply Slutsky.", "start": 4525.03, "duration": 1.723}, {"text": "And Slutsky tells me that\nI can actually do that.", "start": 4531.18, "duration": 3.357}, {"text": "But when I take the product\nof this thing that converges", "start": 4534.537, "duration": 2.333}, {"text": "to some standard Gaussian,\nand this thing that converges", "start": 4536.87, "duration": 3.14}, {"text": "in probability to 1, then\ntheir product actually", "start": 4540.01, "duration": 3.37}, {"text": "converges to still this\nstandard Gaussian [INAUDIBLE]", "start": 4543.38, "duration": 5.238}, {"text": "Well, that's exactly\nwhat's done here,", "start": 4555.37, "duration": 3.51}, {"text": "and I think I'm getting there.", "start": 4558.88, "duration": 3.46}, {"text": "So in our case, OK, so just a\nremark for Slutsky's theorem.", "start": 4562.34, "duration": 5.23}, {"text": "So that's the last line.", "start": 4567.57, "duration": 1.5}, {"text": "So in the first example we used\nthe problem dependent trick,", "start": 4569.07, "duration": 2.78}, {"text": "which was to say,\nwell, turns out", "start": 4571.85, "duration": 2.13}, {"text": "that we knew that p\nis between 0 and 1.", "start": 4573.98, "duration": 2.4}, {"text": "So we have this p 1 minus\np that was annoying to us.", "start": 4576.38, "duration": 2.58}, {"text": "We just said, let's\njust bound it by 1/4,", "start": 4578.96, "duration": 2.28}, {"text": "because that's going to be\ntrue for any value of p.", "start": 4581.24, "duration": 2.63}, {"text": "But here, lambda takes any\nvalue between 0 and infinity,", "start": 4583.87, "duration": 2.44}, {"text": "so we didn't have such a trick.", "start": 4586.31, "duration": 1.302}, {"text": "It's something like we could\nsee that lambda was less", "start": 4587.612, "duration": 2.208}, {"text": "than something.", "start": 4589.82, "duration": 1.15}, {"text": "Maybe we know it, in which\ncase we could use that.", "start": 4590.97, "duration": 3.1}, {"text": "But then in this case,\nwe could actually also", "start": 4594.07, "duration": 2.774}, {"text": "have used Slutsky's theorem\nby doing plug in, right?", "start": 4596.844, "duration": 2.166}, {"text": "So here this is my p 1 minus\np that's replaced by p hat 1", "start": 4599.01, "duration": 2.88}, {"text": "minus p hat.", "start": 4601.89, "duration": 1.17}, {"text": "And Slutsky justify,\nso we did that", "start": 4603.06, "duration": 2.024}, {"text": "without really\nthinking last time.", "start": 4605.084, "duration": 1.416}, {"text": "But Slutsky actually\njustifies the fact", "start": 4606.5, "duration": 2.2}, {"text": "that this is valid, and\nstill allows me to use", "start": 4608.7, "duration": 2.525}, {"text": "this q alpha over 2 here.", "start": 4611.225, "duration": 1.715}, {"text": "All right, so that's\nthe end of this lecture.", "start": 4616.23, "duration": 1.95}, {"text": "Tonight I will post the next\nset of slides, chapter two.", "start": 4618.18, "duration": 3.12}, {"text": "And, well, hopefully the video.", "start": 4621.3, "duration": 2.76}, {"text": "I'm not sure when it's\ngoing to come out.", "start": 4624.06, "duration": 2.75}]