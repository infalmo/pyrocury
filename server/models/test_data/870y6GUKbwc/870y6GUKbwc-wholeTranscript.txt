 You have probably heard entropy defined or described as "disorder." The usual example is that of a college dorm room, which, without regular tidying, becomes "messier" or "less ordered" over time. Supposedly the entropy of the messy room is higher than that of the tidy room. This analogy is easy to picture, but it's misleading. In this video, you'll learn a more accurate description of entropy and understand how it relates to the concept of spontaneity. This video is part of the Governing Rules video series. A small number of rules describe the physical and chemical interactions that are possible in our universe. Hi. My name is John Lienhard and I am a professor in the Department of Mechanical Engineering at MIT. Today, I'm going to talk to you about entropy, a fascinating, but often confusing topic. In order to understand the topic of this video, you should be familiar with the idea that energy is quantized and the thermodynamic definition of a system and its surroundings. After watching this video, you should be able to describe, at a basic level, the concept of a microstate. You should also be able to discuss what entropy measures in a conceptual way. First, what do we mean by a spontaneous process? In thermodynamics, a spontaneous process is one that will occur without any outside intervention given enough time. In the world around us, many everyday events proceed in a particular manner. We would call them spontaneous. You have observed spontaneous processes yourself, but because they seem so natural, you may not have taken particular note of them. For example, think of an inflated balloon that hasn't been tied and is simply pinched between someone's fingers. Once the person releases the balloon, what is going to happen? Experience tells us that the gas inside the balloon will rapidly escape from the opening, moving from high pressure to low pressure. This will propel the balloon through the air, until finally, we are left with a deflated balloon. The gas that was once in the balloon is now dispersed throughout the surroundings. You have probably also seen food coloring or hydrophilic dye dropped into water. What happens? From experience, you may know that the dye disperses. You may also have had some experience removing hot pans from the stovetop. While they come off of the stovetop hot, we know they will eventually cool. Here, we see a liquid crystal in the pan change color, first as the pan is heated, and then again, as the pan cools. Experience tells us in which direction these everyday events will proceed. But what about processes with which we don't have experience? For example, it would be nice if we had a way of knowing whether or not a given chemical reaction will happen at given conditions. The 2nd law of thermodynamics can help us with this. The 2nd law of thermodynamics states that during any spontaneous process, the total entropy change of a system and its surroundings is positive. In other words, the entropy of the "universe," that is, the system plus surroundings, can only increase. But what is entropy? Is entropy a magical force that overturns your furniture and creates havoc in your office or home? No. Entropy is a measure of the number of possible ways energy can be distributed in a system of molecules. Molecules in a system at equilibrium have the same average energy. However, at a given instant in time, it is highly unlikely that all of the molecules have the same exact energy. Molecules in a system are constantly interacting and transferring energy amongst each other. As a result, one molecule may have a certain amount of energy at one instant and at the next; it could have more or less. Depending on the energy the molecule has, it will be able to access different energy levels. The total energy of the system, determines what energy levels will be accessible to the molecules. Higher energy levels will not be accessible because the energy required to reach them is not available. So when we say that entropy is a measure of the number of possible ways energy can be distributed in a system of molecules, we have to account for all of the possible combinations. And the way we do that is by considering the microstates available to the molecules in the system. Let's use an analogy to understand the term "microstate". Let's say that you have two dice. What are all of the possible sums for a pair of dice? Pause the video here and take a moment to jot them down. Okay, you should have a list that looks something like this. We would call these sums possible macrostates of our system -- the macrostate doesn't tell us what each individual die reads when we roll them, just the total, or "macroscopic view" if you will. What are all of the possible dice combinations that will produce each of those sums? For example, we can produce the sum of three by rolling a one on the first die and a two on the 2nd die. Or, we can roll a 2 on the first die and a one on the 2nd die. So there are two combinations that will produce the sum of 3. The dice combinations that produce the remaining sums are shown here. We would call each of these combinations "microstates" that correspond to each macrostate. The microstate gives us information about the individual conditions of each die. We see that the most likely macrostate, a sum of 7, has the greatest number of possible microstates. Do you think that the entropy change for the system (the cold bar) was positive, negative, or equal to zero? Please pause the video here and discuss your reasoning with a classmate. Let's start with the system first. The transfer of energy to the cold bar will allow the molecules in the cold bar to access new energy levels that they could not reach before, increasing the number of possible microstates for that system. So we would suspect that the entropy change for the system is positive. But what about the surroundings? The total entropy of a system and its surroundings has to increase if the process is spontaneous. Let's use a very simplified diagram to think about the heat diffusion demo. We have two bars made of the same material. One bar is hot and one is cold. We'll look at 4 atoms making up each bar. The hot bar has more energy than the cold bar -- its atoms are moving more than the atoms in the cold bar, which seem barely to move. Now, before we put the cold bar in contact with the hot bar, let's think about each bar separately. In our simplified drawing of the cold bar, let's say that three of the atoms have no energy and one atom has one quantum of energy and is at a slightly higher energy level, symbolized by the set of curved lines representing its motion. How many different microstates can this system exhibit? If we think about the different ways we can distribute the quantum of energy amongst the 4 atoms, we see that there are 4 possible microstates. If we do the same for our hot bar, where we have 5 quanta of energy that can be distributed in a variety of ways amongst the 4 atoms, we use some math to see that there are 56 possible microstates. When we brought the two bars in contact in our demonstration, we saw that they reached thermal equilibrium. Here, in our simplified example, we will bring the cold bar (defined as our system) and the hot bar (defined as our surroundings) together and divide the 6 quanta of energy equally between the two. The first law of thermodynamics tells us that the total of 6 quanta will be conserved. Now, how many microstates are now possible in each bar? As you might have expected, the number of possible microstates in what was originally our hot bar decreased, and the number of possible microstates in what was originally our cold bar increased. Let's see what this means for our total entropy change. We will use a relationship for entropy that was derived by Ludwig Boltzmann. It states that entropy is equal to a constant, called the Boltzmann constant, times the natural log of the number of microstates. When calculating entropy change, whether it be for the system or surroundings, delta S would be equal to Boltzmann's constant times the natural log of the ratio of the final number of microstates to the initial number of microstates. The entropy change in our cold bar was positive while the entropy change in our hot bar was negative. But remember, it's the total entropy change that matters. We see that our total entropy change for this process is positive. The spontaneous transfer of heat from our hot bar to our cold bar is consistent with the 2nd law of thermodynamics. If you did a similar calculation for the reverse process, that of heat transferring from the cold bar to the hot bar, the total entropy change would be negative indicating that it is not spontaneous. As we hinted earlier and as you may have guessed by our very simplified scenario, calculating the number of microstates in a real system can be very challenging. Generally speaking, you will be calculating entropy in terms of measurable macroscopic quantities such as heat capacity or enthalpy of phase change. However, having a qualitative understanding of the physical meaning of entropy will help you properly interpret the entropy changes caused by various processes. To Review, for a process to proceed spontaneously, the total entropy change for a system and its surroundings must be positive. Entropy measures the number of possible ways energy can be distributed in a system of molecules. A microstate is an instantaneous catalog that describes the energy of each molecule in a system. Because molecules are constantly interacting and exchanging energy, this description constantly needs to be revised. A given system has a large number of possible microstates. As we saw with the Boltzmann equation, entropy is proportional to the number of microstates.