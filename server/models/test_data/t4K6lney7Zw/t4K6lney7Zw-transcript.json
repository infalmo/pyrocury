[{"text": "[SQUEAKING]", "start": 0.68, "duration": 1.44}, {"text": "[PAPERS RUSTLING]", "start": 2.12, "duration": 2.22}, {"text": "[CLICKING]", "start": 4.34, "duration": 1.98}, {"text": "JEREMY KEPNER: All right. Welcome. Great to\nsee everyone here. We're really excited about", "start": 15.6, "duration": 9.44}, {"text": "this opportunity. As you know, our AI accelerator\nhas officially kicked off. All of your teams", "start": 25.04, "duration": 7.189}, {"text": "are ready to go. And we wanted this to be\nan opportunity as a team, come together and", "start": 32.229, "duration": 9.33}, {"text": "develop some common foundation, some common\ntechnological foundation, some common language", "start": 41.559, "duration": 5.881}, {"text": "for talking about these very challenging AI\nproblems.", "start": 47.44, "duration": 2.82}, {"text": "And so with that, I'll hand it over to Vijay.", "start": 50.26, "duration": 6.0}, {"text": "VIJAY GADEPALLY: All right.", "start": 56.26, "duration": 1.14}, {"text": "JEREMY KEPNER: Who will kick off with the first\nlecture, which basically provides some overview", "start": 57.4, "duration": 3.64}, {"text": "AI context for this.", "start": 61.049, "duration": 2.121}, {"text": "VIJAY GADEPALLY: Again, welcome to the class.\nWe're really looking forward to this. What", "start": 63.17, "duration": 4.49}, {"text": "we're going to present this morning is really\na lot of overview material, right? Many of", "start": 67.66, "duration": 4.94}, {"text": "you here know a lot in AI and machine learning.\nThis is really meant to just level set before", "start": 72.6, "duration": 6.83}, {"text": "we start the program, before we start these\nclasses.", "start": 79.43, "duration": 3.46}, {"text": "So you can see this generic title-- Artificial\nIntelligence and Machine Learning. And we're", "start": 82.89, "duration": 4.69}, {"text": "going to try and cover all of that in about\nan hour. So some details might be skipped,", "start": 87.58, "duration": 4.81}, {"text": "but we'll try and hit some of the salient\nfeatures. All of these slides are available", "start": 92.39, "duration": 5.92}, {"text": "for you to use.", "start": 98.31, "duration": 1.0}, {"text": "So if you're presenting back to your own teams,\nplease feel free to pull from these slides.", "start": 99.31, "duration": 4.979}, {"text": "We've actually gone through-- over some time\nputting a good set of survey and overview", "start": 104.289, "duration": 4.75}, {"text": "slides together. So if any of these are useful\nto you, just email us, or we'll make them", "start": 109.039, "duration": 5.241}, {"text": "available to you. You're more than welcome\nto use any and all of these slides if you're", "start": 114.28, "duration": 4.0}, {"text": "trying to present this back to other people.", "start": 118.28, "duration": 3.31}, {"text": "So with that, let's begin. So we're going\nto do a quick overview of artificial intelligence.", "start": 121.59, "duration": 5.22}, {"text": "Again, a lot of level setting going on here.\nWe're going to do a quick, deep dive. These", "start": 126.81, "duration": 5.08}, {"text": "aren't the deepest of dives, again, given\nthe amount of time that we have, but just", "start": 131.89, "duration": 4.53}, {"text": "talk very quickly about supervised, unsupervised,\nand reinforcement learning, and then summarize.", "start": 136.42, "duration": 4.75}, {"text": "And we can certainly stop for questions, philosophical\ndebates, et cetera, towards the end. We'll", "start": 141.17, "duration": 5.56}, {"text": "try not to get a lot of the philosophical\ndebates on camera if we can. All right. So", "start": 146.73, "duration": 5.72}, {"text": "first question-- what is artificial intelligence?\nAnd this is a question that probably a lot", "start": 152.45, "duration": 4.59}, {"text": "of you get. And I certainly have received\nthis from a number of people. And that actually", "start": 157.04, "duration": 4.51}, {"text": "takes a lot of-- it took us a lot of time\nto come up with this.", "start": 161.55, "duration": 3.52}, {"text": "And so we are very fortunate to have Professor\nWinston spend some time with us out at Lincoln", "start": 165.07, "duration": 5.61}, {"text": "Laboratory. And we actually brainstormed for\na good hour or two, really trying to come", "start": 170.68, "duration": 3.91}, {"text": "up with what is a good definition for what\nwe call artificial intelligence. And what", "start": 174.59, "duration": 5.89}, {"text": "we came up with is that there are two aspects\nto artificial intelligence.", "start": 180.48, "duration": 4.26}, {"text": "First, that we should not confuse with each\nother. One is the concept of narrow AI, and", "start": 184.74, "duration": 5.53}, {"text": "another is a concept of general AI. And sometimes\nin conversation, we tend to conflate or mix", "start": 190.27, "duration": 4.37}, {"text": "the two. So narrow AI, according to our definition,\nis the theory and development of computer", "start": 194.64, "duration": 6.31}, {"text": "systems that perform tasks that augment for\nhuman intelligence, such as perceiving, classifying,", "start": 200.95, "duration": 5.62}, {"text": "learning, abstracting, reasoning, and/or acting.", "start": 206.57, "duration": 3.48}, {"text": "Certainly in a lot of the programs that we\nwork in, we're very focused on narrow AI and", "start": 210.05, "duration": 4.64}, {"text": "not necessarily the more general AI, which\nwe define as full autonomy. So that's a very", "start": 214.69, "duration": 7.32}, {"text": "high-level definition of what we mean by AI.\nNow, many of you in the crowd are probably", "start": 222.01, "duration": 4.83}, {"text": "saying, well, AI has been around for a while.\nPeople have been talking about this for 50,", "start": 226.84, "duration": 4.53}, {"text": "60-plus years. Why now? What is so special\nabout it now? Why is this conversation piece", "start": 231.37, "duration": 6.839}, {"text": "now?", "start": 238.209, "duration": 1.0}, {"text": "Well, from what we've seen, it really is the\nconvergence of three different communities", "start": 239.209, "duration": 4.881}, {"text": "that have come together. The first is the\ncommunity on big data. The second is a community", "start": 244.09, "duration": 4.46}, {"text": "on computing in a lot of computing technologies.\nAnd finally, a lot of research and results", "start": 248.55, "duration": 5.81}, {"text": "in machine learning algorithms.", "start": 254.36, "duration": 1.919}, {"text": "The other one I forgot to put is dollar signs\ndown here. People have basically figured out", "start": 256.279, "duration": 3.941}, {"text": "how to make money off of selling advertisements,\nlabeling cat pictures, et cetera. So that's", "start": 260.22, "duration": 7.58}, {"text": "maybe the hidden-- why now in particular.\nBut these are the three large technical areas", "start": 267.8, "duration": 6.13}, {"text": "that have evolved over the past decade or\nso to really make AI something we discuss", "start": 273.93, "duration": 6.08}, {"text": "a lot today.", "start": 280.01, "duration": 2.36}, {"text": "So when we talk about AI, there are a number\nof different pieces which make up an AI system.", "start": 282.37, "duration": 6.289}, {"text": "And we love the algorithms, people, but there\nis a lot more going on outside of that. So", "start": 288.659, "duration": 4.991}, {"text": "we've spent a significant amount of effort\njust trying to figure out what goes into an", "start": 293.65, "duration": 4.25}, {"text": "AI system.", "start": 297.9, "duration": 1.0}, {"text": "And this is what we call a canonical architecture.\nVery much in line with Lincoln Laboratory", "start": 298.9, "duration": 5.03}, {"text": "thinking, we like to think of an end to end\npipeline. What are the various components?", "start": 303.93, "duration": 3.84}, {"text": "And what are the interconnections between\nthese various components? So within our AI", "start": 307.77, "duration": 4.03}, {"text": "canonical architecture shown here, we go all\nthe way from sensors to the end user or missions.", "start": 311.8, "duration": 6.42}, {"text": "And a lot of the projects that you all are\nworking on are going to go all the way from", "start": 318.22, "duration": 3.88}, {"text": "here to there. A lot of our class, however,\nfor the next few weeks is going to focus on", "start": 322.1, "duration": 5.36}, {"text": "step one, where a lot of people get stuck.\nSo we take data that comes in through either", "start": 327.46, "duration": 5.59}, {"text": "structured or unstructured sources.", "start": 333.05, "duration": 3.0}, {"text": "These are typically passed into some data\nconditioning or data curation step. This data", "start": 336.05, "duration": 5.47}, {"text": "is through that process, typically converted\ninto some form of information. That information", "start": 341.52, "duration": 6.8}, {"text": "is then passed into a series of algorithms,\nmaybe one or many algorithms. There are lots", "start": 348.32, "duration": 5.95}, {"text": "of them. There is life beyond neural networks.", "start": 354.27, "duration": 3.34}, {"text": "Once we pass them through the algorithms,\nthese typically form. This information is", "start": 357.61, "duration": 4.059}, {"text": "converted into knowledge. It's typically then\npassed into some module that interacts with", "start": 361.669, "duration": 4.821}, {"text": "the end user, or a human, or the mission.\nAnd that's what we call a human machine teaming", "start": 366.49, "duration": 4.959}, {"text": "step.", "start": 371.449, "duration": 1.0}, {"text": "And that finally-- that knowledge with the\nhuman complement becomes insight that can", "start": 372.449, "duration": 4.951}, {"text": "then be used to execute the mission that the\nAI system was created for. All of these components", "start": 377.4, "duration": 6.71}, {"text": "sit on the bedrock of modern computing. Many\ndifferent technologies that make up modern", "start": 384.11, "duration": 6.33}, {"text": "computing and the system that we're using\ntoday has combination of some of these computing", "start": 390.44, "duration": 4.25}, {"text": "hardware elements.", "start": 394.69, "duration": 2.21}, {"text": "And certainly within the context of a lot\nof the projects that we are interested in,", "start": 396.9, "duration": 4.65}, {"text": "all of this also needs to be wrapped in a\nlayer that we call robust AI, which consists", "start": 401.55, "duration": 5.5}, {"text": "of explainable artificial intelligence, metrics,\nand biased assessment, verification, validation,", "start": 407.05, "duration": 4.88}, {"text": "security, policy, ethics, safety, and training.\nWe'll talk very briefly about each of these", "start": 411.93, "duration": 5.32}, {"text": "pieces in detail in a little bit.", "start": 417.25, "duration": 2.919}, {"text": "As I mentioned, AI has an extremely rich history.\nThis is just a very Lincoln and MIT specific", "start": 420.169, "duration": 7.56}, {"text": "view of the history of artificial intelligence.\nBut certainly, there has been great work since", "start": 427.729, "duration": 6.16}, {"text": "the folks of Minsky, Clark, Dineen, Oliver\nSelfridge, et cetera, since the '50s. We've", "start": 433.889, "duration": 6.461}, {"text": "seen a lot of work in the '80s and '90s. And\ncertainly, recently there has been, again,", "start": 440.35, "duration": 5.55}, {"text": "a resurgence of AI in our parlance in our\nthinking of the way AI works.", "start": 445.9, "duration": 5.67}, {"text": "So without going into too much detail about\neach of these eras and why the winters came", "start": 451.57, "duration": 5.08}, {"text": "about, et cetera, I think John Launchbury\nat DARPA actually put it very well, when he", "start": 456.65, "duration": 6.739}, {"text": "talked about different waves of AI technology\nthat have come about. And when he talks about", "start": 463.389, "duration": 5.381}, {"text": "it, he talks about the three waves of AI or\nthe four waves of AI. And the first wave,", "start": 468.77, "duration": 4.61}, {"text": "which you can think of as the first decade\nof AI technology, resulted in a lot of reasoning-based", "start": 473.38, "duration": 7.53}, {"text": "systems, which were based on handcrafted knowledge.", "start": 480.91, "duration": 3.34}, {"text": "So an example of an output of this would be\nan expert system, right? So a lot of work", "start": 484.25, "duration": 4.58}, {"text": "in that. So if we take the four dimensions\nthat John Launchbury suggests of the ability", "start": 488.83, "duration": 8.54}, {"text": "of the system to perceive, learn, abstract,\nand reason, these are typically pretty good", "start": 497.37, "duration": 4.47}, {"text": "at reasoning. Because they encoded human knowledge,\nright?", "start": 501.84, "duration": 2.49}, {"text": "So a human expert sat down and said, what's\ngoing on in the system? And tried to write", "start": 504.33, "duration": 8.209}, {"text": "a series of rules. So tax software, for example,\ndoes a pretty reasonable job of that where", "start": 512.539, "duration": 5.01}, {"text": "a chartered accountant or a tax expert sits\ndown, encodes a series of rules. We have a", "start": 517.549, "duration": 5.911}, {"text": "question in the back.", "start": 523.46, "duration": 1.0}, {"text": "AUDIENCE: Yeah. [INAUDIBLE] I just wanted\nan example of an expert system from the '50s", "start": 524.46, "duration": 6.12}, {"text": "to [INAUDIBLE].", "start": 530.58, "duration": 1.0}, {"text": "VIJAY GADEPALLY: Yep. So the question is,\nare there examples of expert systems? And", "start": 531.58, "duration": 4.65}, {"text": "certainly, one would be tax software. My graduate\nresearch was actually an autonomous vehicle.", "start": 536.23, "duration": 5.37}, {"text": "Some of the early autonomous vehicles used\na form of expert systems where the states", "start": 541.6, "duration": 5.77}, {"text": "on a finite state machine were maybe handcrafted.", "start": 547.37, "duration": 3.58}, {"text": "And the transitions between them were designed\nthat way. There was some machine learning", "start": 550.95, "duration": 3.84}, {"text": "wrapped around, but expert systems certainly\nplayed a large part in some of the early,", "start": 554.79, "duration": 4.919}, {"text": "even autonomous vehicle research that went\non. All right. So over time, we were able", "start": 559.709, "duration": 7.521}, {"text": "to use these expert systems.", "start": 567.23, "duration": 1.54}, {"text": "And don't get me wrong. These systems are\nstill extremely valid in cases where you have", "start": 568.77, "duration": 3.841}, {"text": "limited data availability, limited compute\npower, a lot of expert systems still being", "start": 572.611, "duration": 4.709}, {"text": "used, or in cases where explainability is\na very important factor. You still see expert", "start": 577.32, "duration": 6.26}, {"text": "systems, because they do have the ability\nto explain why they came up. They can typically", "start": 583.58, "duration": 4.1}, {"text": "point to a set of rules that somebody wrote,\nwhich is usually quite interpretable by a", "start": 587.68, "duration": 5.41}, {"text": "human.", "start": 593.09, "duration": 1.0}, {"text": "However, as we were able to collect more data,\nwe were maybe able to understand a little", "start": 594.09, "duration": 4.39}, {"text": "bit more about what was the underlying process.\nWe were able to apply statistical learning.", "start": 598.48, "duration": 6.82}, {"text": "And this led to the next era or next wave\nof AI technologies, which is often called", "start": 605.3, "duration": 7.11}, {"text": "the learning wave.", "start": 612.41, "duration": 1.489}, {"text": "And this was really enabled by lots of data-enabled\nnon-expert systems. So what we mean by that", "start": 613.899, "duration": 5.071}, {"text": "is we were able to dial back the amount of\nexpert knowledge that we encoded into the", "start": 618.97, "duration": 5.56}, {"text": "algorithm, maybe put a higher level of expert\nknowledge into that. But usually, then used", "start": 624.53, "duration": 6.36}, {"text": "data to learn what some of these rules could\nbe.", "start": 630.89, "duration": 2.9}, {"text": "An example of that, in case someone wants\nto ask, would be in speech processing, for", "start": 633.79, "duration": 6.08}, {"text": "example. So we were able to say, well, I realized\nthat speech follows this Gaussian mixture", "start": 639.87, "duration": 8.68}, {"text": "model. So I can encode that level of statistical\nknowledge, but I'm going to let the system", "start": 648.55, "duration": 4.9}, {"text": "figure out the details of how all that actually\nworks out.", "start": 653.45, "duration": 3.889}, {"text": "And there are many other cases. Again, coming\nback to some of the research I did on autonomous", "start": 657.339, "duration": 4.541}, {"text": "vehicles, we were able to maybe use some high-level\nexpert rules, that here are a set of states", "start": 661.88, "duration": 4.78}, {"text": "that a car may be in. But I'm going to let\nthe algorithm actually figure out when these", "start": 666.66, "duration": 5.429}, {"text": "transitions occur and what constitutes a transition\nbetween different states.", "start": 672.089, "duration": 5.481}, {"text": "So looking at the four vectors that you could\nthink about it, these systems had a little", "start": 677.57, "duration": 5.72}, {"text": "bit more on perception. Obviously, we're doing\na lot more learning. But their ability to", "start": 683.29, "duration": 5.25}, {"text": "abstract and reason was still pretty low.\nAnd by reasoning, we mean, can you explain?", "start": 688.54, "duration": 5.299}, {"text": "Can you tell us what's going on when you give\nme an output to the result?", "start": 693.839, "duration": 4.821}, {"text": "The next wave which we're maybe at the beginning\nstages of is what we call contextual learning", "start": 698.66, "duration": 7.76}, {"text": "or contextual adaptation. This is where an\nAI system can actually add context into what", "start": 706.42, "duration": 5.46}, {"text": "it's doing. I'm not sure I have too many examples\nof people doing this very well.", "start": 711.88, "duration": 5.26}, {"text": "I think most of the work today probably falls\ninto the end stage of the learning wave of", "start": 717.14, "duration": 8.28}, {"text": "AI. But we're able to combine a bunch of these\nlearning things to make it look like it's", "start": 725.42, "duration": 4.53}, {"text": "contextual in nature. But the key concept\nover here is being able to have the system", "start": 729.95, "duration": 6.129}, {"text": "automatically abstract and reason. So the\nway that we think about things, right?", "start": 736.079, "duration": 4.271}, {"text": "So if I see a chair over here and I put a\nchair somewhere else, I still know it's a", "start": 740.35, "duration": 4.109}, {"text": "chair, because I'm using other contexts. Maybe\nit's next to a table or stuff like that. Some", "start": 744.459, "duration": 5.301}, {"text": "early research going on in that area. And\ncertainly, the next wave of this is what we", "start": 749.76, "duration": 5.46}, {"text": "call abstraction. And there is very little\nwork on this, but if we have to think out", "start": 755.22, "duration": 4.01}, {"text": "in the future.", "start": 759.23, "duration": 1.03}, {"text": "But this is really the system of the ability\nof an AI system to actually abstract information", "start": 760.26, "duration": 6.389}, {"text": "that it's learning. So instead of learning\nthat a chair or a table is something with", "start": 766.649, "duration": 5.221}, {"text": "a leg at the bottom, it learns that a table\nis something you put things on and is able", "start": 771.87, "duration": 4.61}, {"text": "to abstract that information or that knowledge\nto any other domain or any other field. Do", "start": 776.48, "duration": 7.87}, {"text": "we have any questions before I continue from\nhere? OK, great.", "start": 784.35, "duration": 8.95}, {"text": "So that's a little bit on the evolution of\nAI. The reason we like to go through this", "start": 793.3, "duration": 4.82}, {"text": "is because there is great work going on in\neach of these waves. And nothing that people", "start": 798.12, "duration": 5.74}, {"text": "are doing in any of these waves is any lesser\nor more. It's typically dependent on what", "start": 803.86, "duration": 4.96}, {"text": "you have at your disposal.", "start": 808.82, "duration": 2.28}, {"text": "What I like to tell people sometimes is the\nway to think about all of this is you have", "start": 811.1, "duration": 4.18}, {"text": "a couple of dials at your disposal-- turning\ndials. The first dial is, how much compute?", "start": 815.28, "duration": 6.29}, {"text": "Right? How much ability do you have to crunch\ndata? The second piece is, how much data do", "start": 821.57, "duration": 6.3}, {"text": "you actually have available? This can be labeled\ndata in many cases.", "start": 827.87, "duration": 3.67}, {"text": "And the third dial is, how much knowledge\nare you able to embed into an algorithm? In", "start": 831.54, "duration": 4.931}, {"text": "certain cases where maybe you have very little\ncomputing, very little labeled data availability,", "start": 836.471, "duration": 5.899}, {"text": "but a lot of expert knowledge or a lot of\nability to encode information into an algorithm,", "start": 842.37, "duration": 5.3}, {"text": "you might be able to use an expert system,\nright? And that's a very good use case for", "start": 847.67, "duration": 4.05}, {"text": "that.", "start": 851.72, "duration": 1.0}, {"text": "An example may be on another dimension where\nyou want to encode very little human knowledge,", "start": 852.72, "duration": 5.15}, {"text": "but you have a lot of computing and data available,\nwould be rare neural networks fall in, where", "start": 857.87, "duration": 4.659}, {"text": "they're essentially learning what the human\nknowledge-- what that encoded information", "start": 862.529, "duration": 4.831}, {"text": "should be.", "start": 867.36, "duration": 1.0}, {"text": "A lot of statistical techniques also fall\ninto that camp where maybe you encode a little", "start": 868.36, "duration": 3.81}, {"text": "bit of information as to what the background\ndistribution of the process is. But it learns", "start": 872.17, "duration": 5.349}, {"text": "the details of exactly how that distribution\nis modeled, based on the data that it sees.", "start": 877.519, "duration": 6.651}, {"text": "So you have a lot of different settings that\nyou can use. And there are a number of different", "start": 884.17, "duration": 4.06}, {"text": "techniques within the broader AI context that\nyou can use to achieve your mission. And I'm", "start": 888.23, "duration": 7.0}, {"text": "sure many of you are going to be doing different\ntypes of algorithms. And a lot of that decision", "start": 895.23, "duration": 5.82}, {"text": "will be dependent on, well, how much data\nwas I given? Right? How good is this data", "start": 901.05, "duration": 5.089}, {"text": "that I'm using? Is there an ability to learn\nanything from this?", "start": 906.139, "duration": 3.931}, {"text": "And if not, you might have to encode some\nknowledge of your own into it saying, well,", "start": 910.07, "duration": 3.6}, {"text": "I know that this process looks like that,\nso let me tell the algorithm to not waste", "start": 913.67, "duration": 5.979}, {"text": "too much time crunching the data to learn\nthe underlying distribution, which I can tell", "start": 919.649, "duration": 3.681}, {"text": "you. Why don't you learn the parameters of\nthe distribution instead? Does that makes", "start": 923.33, "duration": 4.949}, {"text": "sense? All right.", "start": 928.279, "duration": 1.67}, {"text": "And as you know, there's just a lot going\non in AI and machine learning. You can't walk", "start": 929.949, "duration": 5.731}, {"text": "two steps without running into somebody who's\neither starting something up, working for", "start": 935.68, "duration": 5.73}, {"text": "one of these organizations. So it really is\nan exciting time to be in the field. All right.", "start": 941.41, "duration": 6.84}, {"text": "So that's a little bit on the overview, but\nlet's talk now in a little bit of detail on", "start": 948.25, "duration": 5.25}, {"text": "what some of the critical components are within\nthis AI architecture. So one thing that we", "start": 953.5, "duration": 6.57}, {"text": "like to note-- and there's a reason that as\nwe've been reaching out to a number of you,", "start": 960.07, "duration": 3.29}, {"text": "we've been talking about getting data, right?\nWork with stakeholders to get your data in", "start": 963.36, "duration": 5.46}, {"text": "place.", "start": 968.82, "duration": 1.0}, {"text": "And the reason we talk about that is data\nis critical to breakthroughs in AI. A lot", "start": 969.82, "duration": 5.51}, {"text": "of the press may be on the algorithms and\nthe algorithms that have been designed. But", "start": 975.33, "duration": 4.54}, {"text": "really, when we've looked back in history,\nwe've seen that, well, the availability of", "start": 979.87, "duration": 4.01}, {"text": "a good canonical data set actually is equally,\nif not more critical to a breakthrough in", "start": 983.88, "duration": 7.889}, {"text": "AI.", "start": 991.769, "duration": 1.0}, {"text": "So what we've done here is we've just picked\na select number of breakthroughs in AI. Our", "start": 992.769, "duration": 5.242}, {"text": "definition of a breakthrough in this particular\nexample is something that made a lot of press", "start": 998.011, "duration": 4.789}, {"text": "or something that we thought was really cool.\nSo here are some examples of that in different", "start": 1002.8, "duration": 4.96}, {"text": "years.", "start": 1007.76, "duration": 1.81}, {"text": "And we've talked about the data set, the canonical\ndata set that maybe led to that breakthrough", "start": 1009.57, "duration": 4.59}, {"text": "or that was cited in that breakthrough as\nwell as the algorithms that were used in that", "start": 1014.16, "duration": 4.44}, {"text": "breakthrough and when they were first proposed.\nThis is notional in nature. Clearly, you could", "start": 1018.6, "duration": 5.979}, {"text": "adjust these dates a few years here or there.", "start": 1024.579, "duration": 3.151}, {"text": "But what we really want to get across is that\nthe average number of years to a breakthrough", "start": 1027.73, "duration": 5.099}, {"text": "from the availability of a cool data set or\na very important, well-structured, well-labeled", "start": 1032.829, "duration": 5.789}, {"text": "data set is much smaller than from the algorithm's\nfirst proposal or when the algorithm first", "start": 1038.618, "duration": 6.501}, {"text": "comes out.", "start": 1045.119, "duration": 1.09}, {"text": "So as you're developing your challenge problems,\nas you're developing your interactions with", "start": 1046.209, "duration": 4.68}, {"text": "stakeholders, certainly something to keep\nin mind that there's clearly a lot of algorithmic", "start": 1050.889, "duration": 6.14}, {"text": "research that's going to go on. But having\na good, strong, well-labeled, and documented", "start": 1057.029, "duration": 7.12}, {"text": "data set can be equally important. And making\nthat available to the wider AI community,", "start": 1064.149, "duration": 5.061}, {"text": "the wider AI ecosystem can be very, very valuable\nto your work and the work of many other people.", "start": 1069.21, "duration": 6.799}, {"text": "All right.", "start": 1076.009, "duration": 1.38}, {"text": "So back to the AI architecture, we're going\nto just go through very briefly-- different", "start": 1077.389, "duration": 4.711}, {"text": "pieces of this architecture. So the first\npiece we're going to talk about is data conditioning,", "start": 1082.1, "duration": 5.49}, {"text": "which is converting unstructured and structured\ndata. Within the structured and unstructured", "start": 1087.59, "duration": 6.01}, {"text": "data, you might have structured sources coming\nfrom sensors, network logs for some of you,", "start": 1093.6, "duration": 6.179}, {"text": "metadata associated with sensors, maybe speech\nor other such signals.", "start": 1099.779, "duration": 5.78}, {"text": "There's also a lot of unstructured data. You\nthink of things that you might collect from", "start": 1105.559, "duration": 4.031}, {"text": "the internet that you might download from,\nsay, a social media site, maybe reports, other", "start": 1109.59, "duration": 5.21}, {"text": "types of sensors that maybe don't have well--\nthat don't have the strong structure within", "start": 1114.8, "duration": 5.219}, {"text": "the data set itself.", "start": 1120.019, "duration": 1.49}, {"text": "And typically, this first step, what we call\nthe data conditioning step, consists of a", "start": 1121.509, "duration": 5.201}, {"text": "number of different elements. You might want\nto first figure out where to put this data.", "start": 1126.71, "duration": 5.36}, {"text": "That can often take a lot of time. And there\nhave been religious wars fought on this topic.", "start": 1132.07, "duration": 4.819}, {"text": "We're here to tell you that you're probably\nOK, picking most technologies. But if you", "start": 1136.889, "duration": 5.991}, {"text": "have any questions, feel free to reach out\nto me or to others on the team. We have a", "start": 1142.88, "duration": 4.82}, {"text": "lot of opinions on what's the right infrastructure\nto solve the problem. Typically, these infrastructure", "start": 1147.7, "duration": 8.439}, {"text": "or databases might provide capabilities such\nas indexing, organization, and structure.", "start": 1156.139, "duration": 4.821}, {"text": "Very important in unstructured data to convert\nit into some format that you can do things", "start": 1160.96, "duration": 3.88}, {"text": "with.", "start": 1164.84, "duration": 1.0}, {"text": "They may allow you to connect to them using\ndomain specific languages. So it's converting", "start": 1165.84, "duration": 4.769}, {"text": "it into a language that maybe you're used\nto talking. They can provide high-performance", "start": 1170.609, "duration": 5.38}, {"text": "data access and in many cases, a declarative\ninterface. Because maybe you don't really", "start": 1175.989, "duration": 3.64}, {"text": "care about how the data is being accessed.\nYou want to just say select the data, give", "start": 1179.629, "duration": 3.991}, {"text": "it to me. And then move forward from there.", "start": 1183.62, "duration": 3.039}, {"text": "Another important part of the data conditioning\nstep is data curation. This unfortunately", "start": 1186.659, "duration": 6.681}, {"text": "will probably take you a very long time. And\nit requires a lot of knowledge of the data", "start": 1193.34, "duration": 6.699}, {"text": "itself, what you want to do with the data,\nand how you receive the data.", "start": 1200.039, "duration": 5.901}, {"text": "But what you might do in the data curation\nstep is perform some unsupervised learning,", "start": 1205.94, "duration": 6.939}, {"text": "maybe reduce the dimensionality of your problem.\nYou might do some clustering or pattern recognition", "start": 1212.879, "duration": 4.971}, {"text": "to maybe remove certain pieces of your data\nor to highlight certain pieces of the data", "start": 1217.85, "duration": 5.029}, {"text": "that look important.", "start": 1222.879, "duration": 1.37}, {"text": "You might do some outlier detection. You might\nhighlight missing values. There's just dot,", "start": 1224.249, "duration": 6.141}, {"text": "dot, dot, et cetera, et cetera, et cetera.\nA lot goes on in the data curation step. We", "start": 1230.39, "duration": 3.99}, {"text": "could certainly spend hours just talking about\nthat. And the final thing, especially within", "start": 1234.38, "duration": 6.1}, {"text": "the context of supervised machine learning,\nbut even in the world of unsupervised learning", "start": 1240.48, "duration": 5.819}, {"text": "would be spending some time on data labeling,\nright?", "start": 1246.299, "duration": 2.68}, {"text": "So this is taking data that you've received,\ntypically doing an initial data exploration.", "start": 1248.979, "duration": 5.751}, {"text": "Could be as simple as opening it up in Excel\nto see what the different columns and rows", "start": 1254.73, "duration": 4.36}, {"text": "look like if that's a suitable place to open\nit up. You might look for highlight, missing,", "start": 1259.09, "duration": 6.25}, {"text": "or incomplete data, just from your initial\ndata exploration.", "start": 1265.34, "duration": 3.35}, {"text": "You might be able to go back to the data provider\nor to the sensor and say, can you reorient", "start": 1268.69, "duration": 5.069}, {"text": "the sensors or recapture the data? I noticed\nthat every time you've measured this particular", "start": 1273.759, "duration": 6.081}, {"text": "quantity, it always shows up as 3. I can't\nimagine that that's correct. Can you go back", "start": 1279.84, "duration": 5.26}, {"text": "and tell me if that sensor is actually working?\nOr is it actually 3? In which case, you might", "start": 1285.1, "duration": 4.36}, {"text": "want to know that.", "start": 1289.46, "duration": 1.469}, {"text": "And you might look for errors, biases, and\ncollection, of course, on top of the actual", "start": 1290.929, "duration": 4.401}, {"text": "labeling process that you're doing to highlight\nphenomenology within the data that you'd like", "start": 1295.33, "duration": 4.319}, {"text": "to then look for through your machine learning\nalgorithms. I'll pause for a second. Yes?", "start": 1299.649, "duration": 6.551}, {"text": "AUDIENCE: I have a quick question.", "start": 1306.2, "duration": 1.459}, {"text": "VIJAY GADEPALLY: Yeah?", "start": 1307.659, "duration": 1.0}, {"text": "AUDIENCE: What's the ratio that you see between\nstructured data and unstructured data?", "start": 1308.659, "duration": 3.831}, {"text": "VIJAY GADEPALLY: So the question is, what's\nthe ratio we see between structured and unstructured", "start": 1312.49, "duration": 4.159}, {"text": "data? That's a great question. So the ratio\nin terms of the volume or the ratio in terms", "start": 1316.649, "duration": 5.72}, {"text": "of what you can do with it? Because those\nare actually almost the opposite.", "start": 1322.369, "duration": 5.13}, {"text": "So, again, I'm talking about a few data sets\nthat I'm very familiar with. The unstructured", "start": 1327.499, "duration": 4.751}, {"text": "data can often be 90% of the volume. And maybe\nthe 10% is the metadata associated with the", "start": 1332.25, "duration": 7.621}, {"text": "unstructured data. Most of the value, however,\ncomes from the structured data where people", "start": 1339.871, "duration": 6.128}, {"text": "really analyze the crap out of these structured\ndata, because they know how to.", "start": 1345.999, "duration": 4.981}, {"text": "There is certainly a lot of potential within\nthe unstructured data. So when we talk to", "start": 1350.98, "duration": 7.669}, {"text": "people, that's why we talk a lot about infrastructure\nand databases as being an important first", "start": 1358.649, "duration": 4.35}, {"text": "step. Because if you can just take the unstructured\ndata and put it into a structured or semi-structured", "start": 1362.999, "duration": 5.8}, {"text": "form, that itself can provide a lot of value.", "start": 1368.799, "duration": 3.061}, {"text": "Because very often in problems that we see,\nthe 90% volume of data is largely untapped.", "start": 1371.86, "duration": 8.36}, {"text": "Because people don't know how to get into\nit, or don't know what to do with it, or it's", "start": 1380.22, "duration": 3.929}, {"text": "not in a form that you can really deal with.\nSo I think next class, we're going to be talking", "start": 1384.149, "duration": 5.071}, {"text": "to you about how to organize your data, strategies\nfor organizing data that can get you a lot", "start": 1389.22, "duration": 7.569}, {"text": "more value out of the unstructured data. Does\nthat answer your question? Yes?", "start": 1396.789, "duration": 9.591}, {"text": "AUDIENCE: [INAUDIBLE]", "start": 1406.38, "duration": 6.08}, {"text": "VIJAY GADEPALLY: So the question is when you\napply AI or machine learning techniques to", "start": 1412.46, "duration": 11.899}, {"text": "a problem domain, is it typically a single\nmodality or multiple modalities? I'd say the", "start": 1424.359, "duration": 5.4}, {"text": "answer is both. Certainly, there's a lot of\nresearch. And back there, we have Matthew,", "start": 1429.759, "duration": 5.711}, {"text": "who's actually doing research on that right\nnow on how to fuse multiple modalities of", "start": 1435.47, "duration": 5.339}, {"text": "data.", "start": 1440.809, "duration": 1.0}, {"text": "I know a lot of projects that are being discussed\nhere are certainly looking at multiple modalities.", "start": 1441.809, "duration": 4.61}, {"text": "If I had to say as of today, a lot of the\nwork that's out there-- the published work", "start": 1446.419, "duration": 10.271}, {"text": "may be focused on a single modality. But that's\nnot to say-- I mean, I think there is a lot", "start": 1456.69, "duration": 4.8}, {"text": "of value on multiple modalities. But the challenge\nstill comes up on, how do you integrate this", "start": 1461.49, "duration": 4.439}, {"text": "data, especially if they're collected from\ndifferent systems? Yep?", "start": 1465.929, "duration": 4.511}, {"text": "AUDIENCE: Just on the structure versus unstructured.\nSo it's not really my area, but I am surprised", "start": 1470.44, "duration": 5.03}, {"text": "to see speech in the structured [INAUDIBLE].\nAnd I wonder. Is that just because the technologies", "start": 1475.47, "duration": 3.65}, {"text": "that can force the [INAUDIBLE] and all of\nthis data conditioning are mature enough that", "start": 1479.12, "duration": 7.72}, {"text": "you can basically treat it [INAUDIBLE]?", "start": 1486.84, "duration": 3.689}, {"text": "VIJAY GADEPALLY: So the question is, why would\nspeech or something else like that fall into", "start": 1490.529, "duration": 4.71}, {"text": "structured versus unstructured? And you're\nabsolutely right. I think when we pick speech--", "start": 1495.239, "duration": 4.73}, {"text": "and I'm sure there are others in the room\nthat might disagree with that and might stick", "start": 1499.969, "duration": 2.94}, {"text": "it over here.", "start": 1502.909, "duration": 2.08}, {"text": "When we look at the type of acquisition processes\nthat are used, the software that's used, they", "start": 1504.989, "duration": 3.99}, {"text": "typically come out with some known metadata.\nThey follow a certain pattern that we can", "start": 1508.979, "duration": 4.651}, {"text": "then use, right? There is a clear range to\nwhere there is-- the frequency to which the", "start": 1513.63, "duration": 3.98}, {"text": "data is collected. And that's why we stuck\nit in the structured data type.", "start": 1517.61, "duration": 4.76}, {"text": "Of course, if you're collecting data out in\nthe field without that, you could probably", "start": 1522.37, "duration": 4.159}, {"text": "stick it into the unstructured world as well.\nBut that's probably a good example of something", "start": 1526.529, "duration": 4.591}, {"text": "that can fall in between the two places. OK.\nAll right. Now, for the part everyone's really", "start": 1531.12, "duration": 8.359}, {"text": "interested in-- machine learning, right?", "start": 1539.479, "duration": 1.92}, {"text": "So, all right, you got through the boring\ndata conditioning stuff, which will take you", "start": 1541.399, "duration": 4.941}, {"text": "a couple of years or something like that.\nNothing serious. And now, you're ready to", "start": 1546.34, "duration": 6.139}, {"text": "do the machine learning. And now, you're given\na choice. Well, which algorithm do you use?", "start": 1552.479, "duration": 4.9}, {"text": "Neural networks, you might say, right?", "start": 1557.379, "duration": 2.441}, {"text": "There is a lot more, though, beyond the neural\nnetwork world. So there is numerous taxonomies.", "start": 1559.82, "duration": 8.029}, {"text": "I'm going to give you two of them today for\nhow you describe machine learning algorithms.", "start": 1567.849, "duration": 4.38}, {"text": "One that's really an interesting way is from\nPedro Domingos at the University of Washington", "start": 1572.229, "duration": 5.351}, {"text": "in which he says that there are five tribes\nof machine learning.", "start": 1577.58, "duration": 4.849}, {"text": "So there are the symbolists, which an example\nof that would be expert systems. There are", "start": 1582.429, "duration": 4.94}, {"text": "the Bayesian tribes, which an example of an\nalgorithm within that might be naive Bayes.", "start": 1587.369, "duration": 5.43}, {"text": "There are the analogizers, which an example\nof that would be a support vector machine", "start": 1592.799, "duration": 5.0}, {"text": "and the connectionists, an example of which\nwould be deep neural networks. And evolutionary", "start": 1597.799, "duration": 5.37}, {"text": "is an example of that which might be genetic\nprogramming.", "start": 1603.169, "duration": 3.76}, {"text": "What really I'm trying to get across-- I'm\nsure the author is trying to get across here", "start": 1606.929, "duration": 5.69}, {"text": "is that lots and lots of different algorithms.\nEach have their relative merits and relative", "start": 1612.619, "duration": 4.961}, {"text": "strengths. Apply the right one for your application.\nApply the right one for-- again, given these", "start": 1617.58, "duration": 5.529}, {"text": "dials that I talked about earlier, the amount\nof computing that you have available, the", "start": 1623.109, "duration": 3.861}, {"text": "amount of data that you have available, and\nthe amount of expert knowledge that you're", "start": 1626.97, "duration": 3.36}, {"text": "able to encode into your algorithm that you\nthink is generalizable enough.", "start": 1630.33, "duration": 5.779}, {"text": "If we actually talk about-- this is a very\nuseful chart I found in describing to folks", "start": 1636.109, "duration": 7.2}, {"text": "that are not familiar with AI that might say,\nwasn't AI just neural networks? And neural", "start": 1643.309, "duration": 6.22}, {"text": "networks are a part of AI, but not necessarily\nall of it. So if we think of the big circle", "start": 1649.529, "duration": 6.09}, {"text": "is the broad field of artificial intelligence,\nwithin that is the world of machine learning.", "start": 1655.619, "duration": 5.831}, {"text": "Within machine learning are connectionists\nor neural networks that fall into a small", "start": 1661.45, "duration": 4.9}, {"text": "camp within that. And deep neural networks\nis a part of neural network. So can anyone", "start": 1666.35, "duration": 6.539}, {"text": "maybe give me an example-- although, I've\nsaid it numerous times-- of something that", "start": 1672.889, "duration": 3.37}, {"text": "might fall out of machine learning, but into\nartificial intelligence from an algorithmic", "start": 1676.259, "duration": 3.79}, {"text": "point of view? Yes?", "start": 1680.049, "duration": 3.5}, {"text": "AUDIENCE: Graph search.", "start": 1683.549, "duration": 1.563}, {"text": "VIJAY GADEPALLY: Graph search could be an\nexample. I would maybe stick that into some", "start": 1685.112, "duration": 4.857}, {"text": "of the connectionists, however.", "start": 1689.969, "duration": 1.44}, {"text": "AUDIENCE: Expert systems.", "start": 1691.409, "duration": 1.11}, {"text": "VIJAY GADEPALLY: Yes, exactly. So expert systems--\nit's the one that comes to my mind. Or knowledge-based", "start": 1692.519, "duration": 5.27}, {"text": "systems are an example of maybe something\nthat fall outside of the realm of machine", "start": 1697.789, "duration": 5.49}, {"text": "learning, again in the very strict sense,\nbut maybe within the realm of artificial intelligence", "start": 1703.279, "duration": 6.11}, {"text": "from an algorithmic point of view.", "start": 1709.389, "duration": 4.4}, {"text": "OK, so that's a little bit on the algorithms.\nNext, let's talk about some of the modern", "start": 1713.789, "duration": 3.171}, {"text": "computing engines that are out there. I mentioned\nthat data compute as well as algorithms have", "start": 1716.96, "duration": 7.009}, {"text": "been key drivers to the resurgence of AI over\nthe past few years. What are some of these", "start": 1723.969, "duration": 6.231}, {"text": "computing technologies, for example? So clearly,\nCPUs and GPUs. They're very popular computing", "start": 1730.2, "duration": 7.959}, {"text": "platforms. Lots of software written to work\nwith these computing platforms.", "start": 1738.159, "duration": 4.52}, {"text": "But what we're seeing now is that with the\nend of Moore's Law and a lot more performance", "start": 1742.679, "duration": 6.34}, {"text": "engineering going on, we're seeing a lot more\nwork, research, and hardware architectures", "start": 1749.019, "duration": 7.38}, {"text": "that are custom in nature. And custom architectures\nare almost the new commercial off-the-shelf", "start": 1756.399, "duration": 5.52}, {"text": "solutions that are out there.", "start": 1761.919, "duration": 2.061}, {"text": "So an example of a custom architecture could\nbe Google's Tensor Processing Unit, or TPU.", "start": 1763.98, "duration": 6.0}, {"text": "There is some very exciting research going\non in the world of neuromorphic computing.", "start": 1769.98, "duration": 4.289}, {"text": "I'm happy to chat with you all later if you're\ninterested to know what's going on in that", "start": 1774.269, "duration": 4.01}, {"text": "area and maybe our role in some of that work.", "start": 1778.279, "duration": 3.551}, {"text": "And there is just some stuff that we would\nstill call custom. These are still people", "start": 1781.83, "duration": 4.079}, {"text": "deciding, designing, basically looking at\nan algorithm saying, OK, here's the data layout.", "start": 1785.909, "duration": 5.781}, {"text": "Here is the movement of data or information\nwithin this algorithm. Let's create a custom", "start": 1791.69, "duration": 6.429}, {"text": "processor that does that. An example of that\ncould be the graph processor, which is being", "start": 1798.119, "duration": 5.38}, {"text": "developed at Lincoln Laboratory.", "start": 1803.499, "duration": 3.18}, {"text": "And obviously, no slide on computing architectures\nor computing technologies would be complete", "start": 1806.679, "duration": 6.47}, {"text": "without mentioning the word quantum in it.\nThere is some early results on solving linear", "start": 1813.149, "duration": 5.6}, {"text": "system of equations. But I think applied to\nAI, it's still unsure, or unknown, or unproven", "start": 1818.749, "duration": 7.72}, {"text": "where quantum may play a part. But certainly,\na technology that all of us, I'm sure, have", "start": 1826.469, "duration": 4.861}, {"text": "heard of, or continue to track, or just interested\nin seeing where that goes to.", "start": 1831.33, "duration": 4.74}, {"text": "So within the first few, however, these are\nall products that you can buy today. You can", "start": 1836.07, "duration": 6.319}, {"text": "go out to your favorite-- your computing store\nand just purchase these off-the-shelf solutions.", "start": 1842.389, "duration": 5.29}, {"text": "A lot of software has been written to work\nwith these different technologies. And it's", "start": 1847.679, "duration": 6.031}, {"text": "a really nice time to be involved. Yeah?", "start": 1853.71, "duration": 3.27}, {"text": "AUDIENCE: Can you give a brief just concept\nof what is attached to the [INAUDIBLE]? I", "start": 1856.98, "duration": 13.35}, {"text": "see [INAUDIBLE], but I don't really have a\nhigh-level concept of why I should associate", "start": 1870.33, "duration": 2.599}, {"text": "with that.", "start": 1872.929, "duration": 1.0}, {"text": "VIJAY GADEPALLY: OK, so the question is, what\nshould I think about when I'm thinking about", "start": 1873.929, "duration": 1.96}, {"text": "neuromorphic? So there's a few features which\nI say fall into the camp of what people are", "start": 1875.889, "duration": 6.23}, {"text": "calling neuromorphic computing. One is what\nthey're calling a brain inspired architecture,", "start": 1882.119, "duration": 4.34}, {"text": "which often means its clockless.", "start": 1886.459, "duration": 2.04}, {"text": "So you typically have some-- so a lot of these\ntechnologies have clocked movement of information.", "start": 1888.499, "duration": 7.581}, {"text": "These might be clockless in nature. They typically\nsit on top of different types of memory architectures.", "start": 1896.08, "duration": 8.689}, {"text": "And I'm trying to think of what would be another\nparameter that would be very useful. I can", "start": 1904.769, "duration": 10.521}, {"text": "probably send you a couple things that help\nhighlight that. I certainly wouldn't call", "start": 1915.29, "duration": 3.69}, {"text": "myself an expert in this area.", "start": 1918.98, "duration": 1.639}, {"text": "AUDIENCE: OK, thanks.", "start": 1920.619, "duration": 1.0}, {"text": "VIJAY GADEPALLY: But, yeah. I think the term\nthat's used is it's supposed to mimic the", "start": 1921.619, "duration": 3.69}, {"text": "brain in the way that the computing architecture\nactually performs or functions. So lots of", "start": 1925.309, "duration": 8.011}, {"text": "research as well. And this is work that we've\ndone here at the lab on actually trying to", "start": 1933.32, "duration": 4.959}, {"text": "map the performance of these different processors\nand how they perform for different types of", "start": 1938.279, "duration": 5.61}, {"text": "functions.", "start": 1943.889, "duration": 1.6}, {"text": "So what we're doing here is basically looking\nat the power on the x-axis. And the y-axis", "start": 1945.489, "duration": 5.68}, {"text": "is the peak performance in giga operations\nper second. Different types of precision are", "start": 1951.169, "duration": 5.47}, {"text": "noted over there by the different shapes of\nthe boxes and then different form factors.", "start": 1956.639, "duration": 5.41}, {"text": "And the idea here is basically to say there's\nso much going on in the world of computing.", "start": 1962.049, "duration": 4.901}, {"text": "How can we compare them? They all have their\nown individual areas where they're strong.", "start": 1966.95, "duration": 4.389}, {"text": "So one can't come up and say, well, the GPU\nis better than the CPU. Well, it depends on", "start": 1971.339, "duration": 4.94}, {"text": "what you're trying to do and what your goals\nof the operation are.", "start": 1976.279, "duration": 3.601}, {"text": "So some of the key lines to note here is that\nthere seems to be a lot of existing systems", "start": 1979.88, "duration": 5.629}, {"text": "on this 100 giga operations per watt on this\nline over here, this dash line. Some of the", "start": 1985.509, "duration": 6.461}, {"text": "newer offerings maybe fit into the 1 tera\nop per watt. And some of the research chips", "start": 1991.97, "duration": 5.41}, {"text": "like IBM's TrueNorth or Intel's Arria fall\ninto just a bit under the 10 tera operations", "start": 1997.38, "duration": 6.099}, {"text": "per watt line that we see there.", "start": 2003.479, "duration": 5.28}, {"text": "But depending on the type of application,\nyou may be OK with a certain amount of peak", "start": 2008.759, "duration": 4.36}, {"text": "power. So if you're looking at embedded applications,\nyou're probably somewhere over here, right?", "start": 2013.119, "duration": 3.61}, {"text": "If you're trying to get something that's on\na little drone or something like that, you", "start": 2016.729, "duration": 5.57}, {"text": "might want to go here. And if you have a data\ncenter, you're probably OK with that type", "start": 2022.299, "duration": 3.51}, {"text": "of power utilization or peak power utilization.\nBut you do need the performance that goes", "start": 2025.809, "duration": 4.99}, {"text": "along with that.", "start": 2030.799, "duration": 1.0}, {"text": "So I'd say the most important parts to look\nat are essentially these different lines.", "start": 2031.799, "duration": 4.04}, {"text": "Those are the trajectories for maybe some\nof the existing systems, all the way up to", "start": 2035.839, "duration": 6.78}, {"text": "some of the more research oriented processors\nout there. OK? All right.", "start": 2042.619, "duration": 7.04}, {"text": "So we talked about modern computing. Let's\ntalk a little bit about the robust AI side", "start": 2049.659, "duration": 4.259}, {"text": "of things. And the basic idea between robust\nAI is that it's extremely important. And the", "start": 2053.918, "duration": 5.611}, {"text": "reason that it's important is that the consequence\nof actions on certain applications of AI can", "start": 2059.529, "duration": 5.65}, {"text": "be quite high.", "start": 2065.179, "duration": 2.821}, {"text": "So what we've done here is think about, where\nare the places that maybe humans and machines", "start": 2068.0, "duration": 5.989}, {"text": "have their relative strength? So on the x-axis,\nwe're talking about the consequence of action.", "start": 2073.989, "duration": 4.279}, {"text": "So this could be, does somebody get hurt if\nthe system doesn't do the right thing? All", "start": 2078.268, "duration": 5.091}, {"text": "the way down to, no worries if the system\ndoesn't do the right thing, which could be", "start": 2083.359, "duration": 6.22}, {"text": "maybe some of the labeling of images that\nwe see online, might fall into this category.", "start": 2089.579, "duration": 5.81}, {"text": "I'm sure people disagree with me on that.", "start": 2095.389, "duration": 2.851}, {"text": "But maybe a lot of national security applications.\nHealth applications certainly fall into the", "start": 2098.24, "duration": 4.18}, {"text": "area of high consequence of action. If you\ngive someone the wrong treatment, that's a", "start": 2102.42, "duration": 5.119}, {"text": "deal. And then on the y-axis, we're talking\nabout the confidence level in the machine", "start": 2107.539, "duration": 4.81}, {"text": "making the decision. So how much confidence\ndo we have in the system that's actually making", "start": 2112.349, "duration": 4.491}, {"text": "the decision?", "start": 2116.84, "duration": 1.019}, {"text": "In certain cases, we might have very high\nconfidence in the system that's making a decision.", "start": 2117.859, "duration": 4.801}, {"text": "And obviously in certain cases, we do not\nhave much confidence in the system making", "start": 2122.66, "duration": 3.689}, {"text": "the decision. So in areas where you have a\nlow consequence of action, maybe high confidence", "start": 2126.349, "duration": 4.621}, {"text": "level in the machine making the decision,\nwe might say those are best matched to machines.", "start": 2130.97, "duration": 4.22}, {"text": "Those are good candidates for automation.", "start": 2135.19, "duration": 3.32}, {"text": "On the contrary, there might be areas where\nthat consequence of action is very high. And", "start": 2138.51, "duration": 4.82}, {"text": "we have very little confidence in the system\nthat's making the decision, probably an area", "start": 2143.33, "duration": 3.67}, {"text": "we want humans to be intricately, if not solely\nor involved or responsible. And the area in", "start": 2147.0, "duration": 6.299}, {"text": "between is where machines might be augmenting\nhumans.", "start": 2153.299, "duration": 3.741}, {"text": "Does anybody want to venture maybe a couple\nof examples-- help come up with a couple of", "start": 2157.04, "duration": 6.65}, {"text": "examples here that we might put into each\nof these categories? So maybe what's a good", "start": 2163.69, "duration": 5.5}, {"text": "problem that you can think of that might be\nbest matched to machines, beyond labeling", "start": 2169.19, "duration": 4.78}, {"text": "images for advertisements?", "start": 2173.97, "duration": 1.21}, {"text": "AUDIENCE: Assembly lines.", "start": 2175.18, "duration": 1.649}, {"text": "VIJAY GADEPALLY: Assembly lines? Yep, that's\na good example. I'm thinking within spam filtering,", "start": 2176.829, "duration": 7.591}, {"text": "could be another example where-- I mean, there\nis some machine augmenting human. It does", "start": 2184.42, "duration": 4.73}, {"text": "send you an email saying this is spam. Are\nyou sure? But for the most part, it's largely", "start": 2189.15, "duration": 5.369}, {"text": "automated.", "start": 2194.519, "duration": 1.621}, {"text": "I'd say a lot of the work that many of us\nare probably doing falls into this category,", "start": 2196.14, "duration": 3.879}, {"text": "maybe on different sides of the spectrum,\nbut of where machines are augmenting humans.", "start": 2200.019, "duration": 3.84}, {"text": "So the system can be providing data back to\na human that can then select. It might filter", "start": 2203.859, "duration": 5.801}, {"text": "information out for humans that then the humans\ncan then go ahead and say, OK, well, instead", "start": 2209.66, "duration": 4.59}, {"text": "of looking at a thousand documents, I can\nonly look at 10, which is much better.", "start": 2214.25, "duration": 5.2}, {"text": "And then there's obviously certain-- probably\nwe want humans to be heavily involved with", "start": 2219.45, "duration": 5.879}, {"text": "any kinetic-- anything that involves life\nor death-- we probably want. And there are", "start": 2225.329, "duration": 5.332}, {"text": "probably legal reasons, also, that we want\nhumans involved with things like that.", "start": 2230.661, "duration": 3.849}, {"text": "One of the examples that we often get which\nis autonomous vehicles-- and it's always a", "start": 2234.51, "duration": 6.069}, {"text": "little confusing where autonomous vehicles\nfall into this. Certainly, the consequence", "start": 2240.579, "duration": 4.23}, {"text": "of action of a mistake in an autonomous vehicle\ncan be pretty high.", "start": 2244.809, "duration": 3.891}, {"text": "And as of today, the confidence and the decision-making\nis medium at best. But people still seem to", "start": 2248.7, "duration": 6.68}, {"text": "somehow be OK with fully automating. That\njust shows how terrible Boston roads or driving", "start": 2255.38, "duration": 5.33}, {"text": "in general is, that we're like, I'm not really\nsure if this thing will kill me or not, but", "start": 2260.71, "duration": 5.23}, {"text": "totally worth trying it out.", "start": 2265.94, "duration": 2.49}, {"text": "AUDIENCE: Do you think the trend in this chart\nis to slowly expand the yellow out?", "start": 2268.43, "duration": 6.98}, {"text": "VIJAY GADEPALLY: Yes, I'd say-- the question\nis, is the yellow expanding? I think so. One", "start": 2275.41, "duration": 8.45}, {"text": "could make the argument that, is it shifting\nthat direction? Are we finding areas where--", "start": 2283.86, "duration": 4.77}, {"text": "and I think that's maybe the direction. We\nare probably looking at automating certain", "start": 2288.63, "duration": 4.83}, {"text": "things a little bit more as confidence in\ndecision-making goes up.", "start": 2293.46, "duration": 5.02}, {"text": "So you might think about this frontier moving\ndown so that maybe the green expanding slightly", "start": 2298.48, "duration": 5.549}, {"text": "and the yellow taking over a little bit of\nthe red. There might be some places where", "start": 2304.029, "duration": 5.53}, {"text": "over time, we're more open to the machine\nmaking a decision and the human having a largely", "start": 2309.559, "duration": 9.421}, {"text": "supervisory role, which I would put right\nat this frontier between the yellow and the", "start": 2318.98, "duration": 3.93}, {"text": "red.", "start": 2322.91, "duration": 1.0}, {"text": "AUDIENCE: Again, I guess it depends on what\naugmenting means. But I guess [INAUDIBLE]", "start": 2323.91, "duration": 1.0}, {"text": "is truly red without any-- even cognitive\naugmenting.", "start": 2324.91, "duration": 6.07}, {"text": "VIJAY GADEPALLY: I can think of some examples,\nbut maybe I'll share it with you later. So", "start": 2330.98, "duration": 10.25}, {"text": "certainly, a robust artificial intelligence\nplays a very important part in the development", "start": 2341.23, "duration": 4.66}, {"text": "and deployment of AI systems. I won't go through\nthe details of each of these.", "start": 2345.89, "duration": 4.219}, {"text": "I'm sure many of you are very familiar with\nit. And I know a few of you are far more knowledgeable", "start": 2350.109, "duration": 4.45}, {"text": "about this, maybe than I am. But some of the\nkey features would be explainable AI, which", "start": 2354.559, "duration": 6.691}, {"text": "is a system being able to describe what it's\ndoing in an interpretable fashion.", "start": 2361.25, "duration": 5.53}, {"text": "Metrics-- so being able to provide the right\nmetric if you want to go beyond accuracy or", "start": 2366.78, "duration": 7.48}, {"text": "performance. Validation and verification--\nthere might be cases where you're not really", "start": 2374.26, "duration": 4.099}, {"text": "concerned about the explainability, but you\njust want to know that when I pass an input,", "start": 2378.359, "duration": 4.641}, {"text": "I get a known output out of it. And is there\na way to confirm that I'm able to do that?", "start": 2383.0, "duration": 5.359}, {"text": "Another could be on security. So an example\nof this-- or not having security would be", "start": 2388.359, "duration": 4.411}, {"text": "counter AI, right? So when we talk about security\nwithin the context of robust AI, it's almost", "start": 2392.77, "duration": 7.2}, {"text": "like the cryptographic way of thinking about\nit, which is, can I protect the confidentiality,", "start": 2399.97, "duration": 4.569}, {"text": "integrity, and availability of my algorithm,\nthe data sets, the outputs, the weights, the", "start": 2404.539, "duration": 7.891}, {"text": "biases, et cetera?", "start": 2412.43, "duration": 2.31}, {"text": "And finally, a lot of significant importance\nis policy, ethics, safety, and training. This", "start": 2414.74, "duration": 6.23}, {"text": "is actually very important in some of those\napplications where in the previous slide,", "start": 2420.97, "duration": 4.66}, {"text": "we had the yellow and the red where humans\nand machines augmenting humans, where that", "start": 2425.63, "duration": 6.09}, {"text": "falls.", "start": 2431.72, "duration": 1.0}, {"text": "A lot of that might be governed by policy,\nethics, safety, and training, which is some", "start": 2432.72, "duration": 3.38}, {"text": "of the examples that I can think of, where\nthere are policy reasons that make it that", "start": 2436.1, "duration": 4.729}, {"text": "only a human can be involved with this, maybe\nwith minimal input from a system. OK.", "start": 2440.829, "duration": 8.381}, {"text": "And the final component of our AI architecture--\nwe've gone through conditioning, algorithms,", "start": 2449.21, "duration": 5.099}, {"text": "computing, robust AI-- is human machine teaming.\nAnd I think what we want to get across with", "start": 2454.309, "duration": 6.77}, {"text": "human machine teaming-- that is it really\ndepends on the application and what you're", "start": 2461.079, "duration": 3.811}, {"text": "trying to do. But it is important to think\nabout the human and the machine working together.", "start": 2464.89, "duration": 4.29}, {"text": "And there is a spectrum of where the machine\nwill largely-- will play a large part and", "start": 2469.18, "duration": 5.45}, {"text": "the human largely supervisory or to where\nthe human plays a large part and the machine", "start": 2474.63, "duration": 4.17}, {"text": "is very targeted in what you do with the machine\nor the AI of the system.", "start": 2478.8, "duration": 6.209}, {"text": "But a couple of ways to think about it would\nbe-- of course, we talked about the confidence", "start": 2485.009, "duration": 5.6}, {"text": "level versus consequence of actions, but also,\nthe scale versus application complexity. So", "start": 2490.609, "duration": 5.781}, {"text": "on the top chart over there, we have on the\nx-axis is the application complexities. How", "start": 2496.39, "duration": 4.919}, {"text": "complex is this application? And on the y-axis\nis the scale. How many times do you need to", "start": 2501.309, "duration": 4.871}, {"text": "keep doing this thing?", "start": 2506.18, "duration": 2.169}, {"text": "Places that machines might be more effective\nthan humans are where we have low application", "start": 2508.349, "duration": 4.25}, {"text": "complexity, but very, very high skill. So\nagain, spam filtering falls into this. The", "start": 2512.599, "duration": 6.071}, {"text": "complexity of spam filtering has gone up over\ntime, but is something that is reasonable", "start": 2518.67, "duration": 6.21}, {"text": "within systems. But the scale is very high,\nthat we just don't want a human being involved", "start": 2524.88, "duration": 3.52}, {"text": "with that process.", "start": 2528.4, "duration": 1.179}, {"text": "And on the other end of the spectrum is where\nyou have very high application complexity", "start": 2529.579, "duration": 3.77}, {"text": "that'll only happen a couple of times. So\nthis could be, say, reviewing a situation.", "start": 2533.349, "duration": 6.341}, {"text": "Maybe a company is trying to make an acquisition.\nIt's not going to happen over and over.", "start": 2539.69, "duration": 4.599}, {"text": "So you might have a human involved with that,\nthat goes through a lot of that. Maybe they", "start": 2544.289, "duration": 5.371}, {"text": "target the system to go look for specific\npieces of information. But really, it's the", "start": 2549.66, "duration": 3.93}, {"text": "human that might be more effective in that,\nespecially given that the situation would", "start": 2553.59, "duration": 3.31}, {"text": "change over and over. All right.", "start": 2556.9, "duration": 2.83}, {"text": "So with that, we're going do take a quick\ntour of the world of machine learning. I'll", "start": 2559.73, "duration": 5.67}, {"text": "stop there for a second. Any questions? OK.\nAll right. So what is machine learning? Always", "start": 2565.4, "duration": 8.67}, {"text": "a good place to start. It's the study of algorithms\nto improve their performance at some task", "start": 2574.07, "duration": 5.38}, {"text": "with experience. In this context, experience\nis data.", "start": 2579.45, "duration": 4.609}, {"text": "And they typically do this by optimizing based\non some performance criteria that uses example", "start": 2584.059, "duration": 5.77}, {"text": "data or past experience. So in the world of\nsupervised learning, that could be the example", "start": 2589.829, "duration": 5.751}, {"text": "data. Or past experience could be the correct\nlabel, given an input data set or input data", "start": 2595.58, "duration": 5.81}, {"text": "point.", "start": 2601.39, "duration": 2.24}, {"text": "Machine learning is a combination of techniques\nfrom statistics, computer, and computer science", "start": 2603.63, "duration": 4.61}, {"text": "communities. And it's the idea of getting\ncomputers to program themselves. Common tasks", "start": 2608.24, "duration": 5.91}, {"text": "within the world of machine learning could\nbe things like classification, regression,", "start": 2614.15, "duration": 3.8}, {"text": "prediction, clustering, et cetera.", "start": 2617.95, "duration": 3.26}, {"text": "For those who are maybe making the shift to\nmachine learning from traditional programming,", "start": 2621.21, "duration": 4.899}, {"text": "I found this, again, from Pedro Domingos to\nbe a very useful way of describing it to people.", "start": 2626.109, "duration": 6.151}, {"text": "So in traditional programming, you have a\ndata set. You write a program, which would", "start": 2632.26, "duration": 4.049}, {"text": "be if you see this, do that. When you see\nthis, do that. For this many instances, do", "start": 2636.309, "duration": 5.341}, {"text": "the following thing on it and then write an\noutput out, right?", "start": 2641.65, "duration": 2.83}, {"text": "So you input a data into the program into\na computer, and the computer produces an output", "start": 2644.48, "duration": 5.05}, {"text": "where it says, OK, I've applied this program\non that data. And this gives me the output.", "start": 2649.53, "duration": 5.319}, {"text": "Machine learning is a very different way of\nthinking about it in which you're almost inputting", "start": 2654.849, "duration": 4.44}, {"text": "the data as well as the output.", "start": 2659.289, "duration": 2.0}, {"text": "So in this case, the data could be unlabeled\nimages. The output could be the labels associated", "start": 2661.289, "duration": 4.521}, {"text": "with those images. And you tell the computer,\nfigure out what the program would look like.", "start": 2665.81, "duration": 5.029}, {"text": "And this is a slightly different way of thinking\nabout machine learning versus traditional", "start": 2670.839, "duration": 3.76}, {"text": "programming.", "start": 2674.599, "duration": 1.42}, {"text": "What are some of these programs or algorithms\nthat the computer might use to figure it out?", "start": 2676.019, "duration": 5.74}, {"text": "So within the large realm of machine learning,\nwe have supervised, unsupervised reinforcement", "start": 2681.759, "duration": 5.79}, {"text": "learning. What we have in the brackets is\nessentially what you're providing in the world.", "start": 2687.549, "duration": 5.481}, {"text": "In the case of supervised learning, you're\nproviding labels, which is the correct label", "start": 2693.03, "duration": 3.559}, {"text": "associated with an input feature or with an\ninput data set or data point. In unsupervised", "start": 2696.589, "duration": 5.821}, {"text": "learning, you typically have no labels, but\nalso are limited by what the algorithm itself", "start": 2702.41, "duration": 3.67}, {"text": "can do.", "start": 2706.08, "duration": 1.0}, {"text": "And in the world of reinforcement learning,\ninstead of a label per data point, you're", "start": 2707.08, "duration": 5.029}, {"text": "providing the reward information to the system\nthat says if you're doing more-- if you're", "start": 2712.109, "duration": 3.75}, {"text": "doing the right thing, I'm going to give you\nsome points. If you're doing the wrong thing,", "start": 2715.859, "duration": 2.901}, {"text": "I'm going to take away some points-- very\nuseful in very complex applications where", "start": 2718.76, "duration": 4.72}, {"text": "you can't really figure out the labels associated\nwith each data point.", "start": 2723.48, "duration": 4.73}, {"text": "Within the world of supervised learning, the\ntypical tasks that people have-- and I should", "start": 2728.21, "duration": 4.369}, {"text": "note before I go through this. There's a lot\nof overlap between all of these different", "start": 2732.579, "duration": 3.881}, {"text": "pieces. So this is a high-level view. But\nwe can certainly argue about the specific", "start": 2736.46, "duration": 5.609}, {"text": "positioning of everything. I'm sure we can.", "start": 2742.069, "duration": 3.78}, {"text": "So within supervised learning, you can fall\ninto classification regression. Unsupervised", "start": 2745.849, "duration": 4.25}, {"text": "learning is typically clustering dimensionality\nreduction. And within these, there are different", "start": 2750.099, "duration": 5.321}, {"text": "algorithms that fall into place. So examples\ncould be things like neural nets that cover", "start": 2755.42, "duration": 5.34}, {"text": "all of these spaces.", "start": 2760.76, "duration": 1.589}, {"text": "You got-- just take regression, PCA, which\nmight fall into dimensionality reduction,", "start": 2762.349, "duration": 8.24}, {"text": "lots and lots of different techniques and\nalso some in the reinforcement learning world.", "start": 2770.589, "duration": 4.371}, {"text": "And there's just more and more and more. If\nyou open up a survey of machine learning,", "start": 2774.96, "duration": 5.649}, {"text": "it'll give you even more than all of these\ntechniques over here.", "start": 2780.609, "duration": 4.531}, {"text": "And the thing to remember when you're using\nmachine learning is that there are some common", "start": 2785.14, "duration": 3.85}, {"text": "pitfalls that you can fall into. An example\nof that would be overfitting versus underfitting", "start": 2788.99, "duration": 5.319}, {"text": "where you come up with this awesome model\nthat does really, really well on your training", "start": 2794.309, "duration": 4.381}, {"text": "data.", "start": 2798.69, "duration": 1.0}, {"text": "You apply it to your test data, and you get\nterrible results. You might have done a really", "start": 2799.69, "duration": 7.21}, {"text": "good job learning the training data, but not\nnecessarily learning-- being able to generalize", "start": 2806.9, "duration": 4.409}, {"text": "beyond that. Sometimes it could be just the\nalgorithm itself is unable to correctly model", "start": 2811.309, "duration": 7.821}, {"text": "the behavior that's exhibited by the training\nand test data.", "start": 2819.13, "duration": 2.82}, {"text": "I won't go through each of these again, but\nthere might just be bad, noisy, missing data.", "start": 2821.95, "duration": 4.401}, {"text": "That certainly happens where you end up with\nan algorithm with terrible results. And you", "start": 2826.351, "duration": 3.339}, {"text": "look at it and you're like, well, why is that?\nAnd you actually look at the data that you", "start": 2829.69, "duration": 3.01}, {"text": "did. And it was incorrect, that there was\njust missing features. Or it was noisy in", "start": 2832.7, "duration": 4.899}, {"text": "nature, such that the actual phenomenology\nthat you were trying to look for was hidden", "start": 2837.599, "duration": 5.46}, {"text": "within the noise.", "start": 2843.059, "duration": 1.0}, {"text": "You might have picked the wrong model. You\nmight have used a linear model in a non-linear", "start": 2844.059, "duration": 4.671}, {"text": "case where the phenomenology you're trying\nto describe is non-linear in nature, but maybe", "start": 2848.73, "duration": 6.109}, {"text": "you've used a linear model. You've not done\na good job of separating training versus testing", "start": 2854.839, "duration": 5.41}, {"text": "data, et cetera, et cetera.", "start": 2860.249, "duration": 4.261}, {"text": "So we'll just take a quick view into each\nof these different learning paradigms. So", "start": 2864.51, "duration": 4.71}, {"text": "the first is on supervised learning. And you\nbasically start with label data or what we", "start": 2869.22, "duration": 5.869}, {"text": "call-- it was often referred to as ground\ntruth. And you build a model that predicts", "start": 2875.089, "duration": 4.371}, {"text": "labels, given new pieces of data.", "start": 2879.46, "duration": 2.889}, {"text": "And you have two general goals. One is in\nregression, which is to predict some continuous", "start": 2882.349, "duration": 5.051}, {"text": "variable or a classification, which is to\npredict a class or label. So if we look at", "start": 2887.4, "duration": 5.439}, {"text": "this, the diagram on the right, we have training\ndata that we provide, which is data and labels.", "start": 2892.839, "duration": 8.291}, {"text": "That goes into a trained model. That's typically\nan iterative process where we find out, well,", "start": 2901.13, "duration": 6.219}, {"text": "did we do a good job? That is now called a\nsupervised learning model that we then apply", "start": 2907.349, "duration": 5.301}, {"text": "new data, or test data, or unseen data and\nlook at the predicted labels.", "start": 2912.65, "duration": 4.889}, {"text": "Typically, when you are designing an algorithm\nlike this, you'd separate out. You'd take", "start": 2917.539, "duration": 3.421}, {"text": "your training data. You'd remove a small portion\nof it that you do know the labels for. That's", "start": 2920.96, "duration": 4.65}, {"text": "your test data over here. And then you run\nthat. And you can see, well, is it working", "start": 2925.61, "duration": 4.45}, {"text": "well or not?", "start": 2930.06, "duration": 2.63}, {"text": "And most of these algorithms have a training\nstep that forms a model. So when we talk about", "start": 2932.69, "duration": 4.71}, {"text": "machine learning in both the supervised and\nunsupervised sense, we'll often talk about", "start": 2937.4, "duration": 5.099}, {"text": "training the model, which is this process,\nand then inference, which is the second step,", "start": 2942.499, "duration": 5.78}, {"text": "which is where you apply unseen data. So this\nis the trained model in deployment or in the", "start": 2948.279, "duration": 5.381}, {"text": "field. It's performing inference at that point.", "start": 2953.66, "duration": 2.919}, {"text": "Of course, no class these days on machine\nlearning and AI could go without talking about", "start": 2956.579, "duration": 7.071}, {"text": "neural networks. And as I mentioned, neural\nnetworks do form a very important part of", "start": 2963.65, "duration": 6.48}, {"text": "machine learning. And they certainly are an\nalgorithm that many of you, I'm sure, are", "start": 2970.13, "duration": 3.55}, {"text": "familiar with. And they fall well within the\nsupervised and unsupervised. And they've been", "start": 2973.68, "duration": 5.13}, {"text": "used for so many different applications at\nthis point.", "start": 2978.81, "duration": 3.199}, {"text": "So what's a neural network? A computing system\ninspired by biological networks. And the system", "start": 2982.009, "duration": 4.981}, {"text": "essentially learns by repetitive training\nto do tasks based on examples. Much of the", "start": 2986.99, "duration": 5.72}, {"text": "work that we've seen is typically it being\napplied to supervised learning, though I'll", "start": 2992.71, "duration": 3.7}, {"text": "mention some that we are doing, some research\nand actually applying it for unsupervised", "start": 2996.41, "duration": 4.099}, {"text": "learning as well. And they're quite powerful.", "start": 3000.509, "duration": 3.59}, {"text": "The components of a neural network include\ninputs, layers, outputs, and weights. So these", "start": 3004.099, "duration": 5.24}, {"text": "are often the terms that someone will use.\nAnd a deep neural network has lots of hidden", "start": 3009.339, "duration": 4.7}, {"text": "layers. Does anyone here have a better definition\nfor what deep neural network means beyond", "start": 3014.039, "duration": 6.76}, {"text": "lots? I've heard definitions anywhere, 3 and\nabove. Yes?", "start": 3020.799, "duration": 1.846}, {"text": "AUDIENCE: [INAUDIBLE] deep neural network\nwill occur at any recurrent networks. Because", "start": 3022.645, "duration": 1.915}, {"text": "that has more than one layer, but not necessarily\nmore than one layer after you have actually", "start": 3024.56, "duration": 11.739}, {"text": "written the code for it.", "start": 3036.299, "duration": 1.443}, {"text": "VIJAY GADEPALLY: OK, so one definition here\nfor deep is-- and this is-- anyone have a", "start": 3037.742, "duration": 3.838}, {"text": "better-- no. So the one to beat right now\nis-- a feature of a deep neural network could", "start": 3041.58, "duration": 6.959}, {"text": "be recurrence within the network architecture,\nwhich implies that there is some depth to", "start": 3048.539, "duration": 6.441}, {"text": "the overall network. So above 3 with recurrence--\ndeep. All right.", "start": 3054.98, "duration": 7.73}, {"text": "Lots of variance within the supervised world\nof neural networks, such as convolutional", "start": 3062.71, "duration": 5.33}, {"text": "neural networks, recursive neural networks,\ndeep belief networks. One, I think, in my", "start": 3068.04, "duration": 4.501}, {"text": "opinion-- again, since you've all asked me\nto opine here. I know you've not, but I think", "start": 3072.541, "duration": 6.089}, {"text": "a reason that these are so popular these days\nis there's so many tools out there that are", "start": 3078.63, "duration": 3.76}, {"text": "very easy to use.", "start": 3082.39, "duration": 2.219}, {"text": "You can just go online and within about five\nminutes, write your first neural network.", "start": 3084.609, "duration": 3.76}, {"text": "Try writing a hidden mark-off model that quickly.\nMaybe there are people who can, but in general.", "start": 3088.369, "duration": 7.761}, {"text": "So what are the features of a deep neural\nnetwork? So you have some input features.", "start": 3096.13, "duration": 5.52}, {"text": "You have weights, which are essentially associated\nwith each line over here, as well as biases", "start": 3101.65, "duration": 5.709}, {"text": "for each of the layers that govern the interaction\nbetween the layers and then an output layer.", "start": 3107.359, "duration": 4.43}, {"text": "So these input features can often be combined\nto each other. So these feature vectors that", "start": 3111.789, "duration": 5.25}, {"text": "are coming in can often be combined. Think\nJeremy we'll talk a little bit about how the", "start": 3117.039, "duration": 4.52}, {"text": "matrix view of all of this.", "start": 3121.559, "duration": 2.961}, {"text": "But you can think of it as if your-- an example\ncould be if you have an image, it could be", "start": 3124.52, "duration": 5.319}, {"text": "the RGB pixel values of each pixel in that\nimage, could be the input feature. So you", "start": 3129.839, "duration": 7.96}, {"text": "could have large numbers of input features.\nIf you have a time series signal, it could", "start": 3137.799, "duration": 4.711}, {"text": "be the amplitude or the magnitude at a particular\nfrequency or at a particular step.", "start": 3142.51, "duration": 5.9}, {"text": "There's often a combination of features that\nyou might do. So in addition to the pixel", "start": 3148.41, "duration": 4.73}, {"text": "intensities for an image, you might also then\ncombine the spatial distance between two pixels.", "start": 3153.14, "duration": 5.86}, {"text": "Or its position within the image may also\nbe another input feature. And you can really", "start": 3159.0, "duration": 4.369}, {"text": "go hog wild over here, just trying to come\nup with new features.", "start": 3163.369, "duration": 3.911}, {"text": "And there's a lot of research just in that\narea, which is I take a data set that everyone", "start": 3167.28, "duration": 4.75}, {"text": "knows. And I'm just going to spend a lot of\ntime doing feature engineering, which is coming", "start": 3172.03, "duration": 4.71}, {"text": "up with, well, what is the right way to do\nthe features? So coming back to an earlier", "start": 3176.74, "duration": 4.99}, {"text": "question, this is an area where people are\noften looking at supplementing maybe a given", "start": 3181.73, "duration": 5.67}, {"text": "data set with additional data.", "start": 3187.4, "duration": 2.399}, {"text": "And then fusing those two pieces together,\nfor example, could be audio and text together", "start": 3189.799, "duration": 7.45}, {"text": "as input features to a network, that you can\nthen learn that might do a better job. But", "start": 3197.249, "duration": 7.33}, {"text": "all of this is governed by this really, really\nsimple, but powerful equation, which is that", "start": 3204.579, "duration": 6.021}, {"text": "the output at the i plus 1th layer is given\nby some non-linear function of the weights", "start": 3210.6, "duration": 9.149}, {"text": "multiplied by the inputs from the previous\nstep, plus some bias term then.", "start": 3219.749, "duration": 5.901}, {"text": "And when you're learning-- when you're training\na machine learning model, you're essentially", "start": 3225.65, "duration": 3.459}, {"text": "trying to figure out what the Ws are and what\nthe Bs are. That's really what a model is", "start": 3229.109, "duration": 4.891}, {"text": "defined as. So if we zoom into one of these\npieces, it's actually pretty straightforward", "start": 3234.0, "duration": 6.64}, {"text": "what's going on over here.", "start": 3240.64, "duration": 1.6}, {"text": "So you have your inputs that are coming from\nthe previous layers, so this could be your", "start": 3242.24, "duration": 3.509}, {"text": "Y sub i. Here are the different weights, so\nW1, W2, W3. These are the connections or the", "start": 3245.749, "duration": 5.801}, {"text": "weights going into a neuron or a node. And\nyou're performing some function on these inputs.", "start": 3251.55, "duration": 7.269}, {"text": "And that function is referred to as an activation\nfunction.", "start": 3258.819, "duration": 3.881}, {"text": "So let's just take an example where we have\nsome actual numbers. Maybe I've gone through.", "start": 3262.7, "duration": 3.43}, {"text": "I've trained my models. I figured out that\njust for this one dot in that big network", "start": 3266.13, "duration": 5.1}, {"text": "that we saw earlier, that my weights are 2.7,\n8.6, and 0.002. My inputs from the previous", "start": 3271.23, "duration": 8.849}, {"text": "layer is maybe -0.06, 2.5, 1.4.", "start": 3280.079, "duration": 6.7}, {"text": "And all I'm doing is coming up with this x,\nwhich is -0.06 multiplied by 2.7, plus 2.5,", "start": 3286.779, "duration": 9.29}, {"text": "times 8.6, plus 1.4 times that. That gives\nme some number-- 21.34. I apply my non-linear", "start": 3296.069, "duration": 7.711}, {"text": "function, which in this case is a sigmoid\ngoverned by that equation at the top right.", "start": 3303.78, "duration": 5.049}, {"text": "And I say f of 21.34, so somewhere way over\nthere is approximately 1, right? So this--", "start": 3308.829, "duration": 6.841}, {"text": "probably a little less than 1, but approximately\n1 for the purpose of this.", "start": 3315.67, "duration": 6.119}, {"text": "And you just do that over and over. So really,\na neural network-- I think the power of a", "start": 3321.789, "duration": 4.431}, {"text": "neural network is it allows you to encode\na lot less information than many of the other", "start": 3326.22, "duration": 4.389}, {"text": "machine learning algorithms out there at the\ncost, typically, of a lot more data being", "start": 3330.609, "duration": 4.5}, {"text": "used and a lot more computing being used.\nBut for many people, that's perfectly fine,", "start": 3335.109, "duration": 5.41}, {"text": "right?", "start": 3340.519, "duration": 1.0}, {"text": "But it does take-- it's just over and over,\nback and forth, back and forth, back and forth", "start": 3341.519, "duration": 3.73}, {"text": "to come up with, what's the right Ws in order\nfor this to give me a result that looks reasonable?", "start": 3345.249, "duration": 9.421}, {"text": "Lots of work going on and just deciding the\nright activation function.", "start": 3354.67, "duration": 4.319}, {"text": "I showed you a sigmoid over there. We do a\nlot of work with ReLU units. The choices--", "start": 3358.989, "duration": 7.211}, {"text": "there are certain applications-- certain,\nI should say, domains or applications where", "start": 3366.2, "duration": 4.169}, {"text": "people have found that a particular activation\nfunction tends to work well.", "start": 3370.369, "duration": 6.191}, {"text": "But that choice is something I leave to domain\nexperts to maybe look at their problem and", "start": 3376.56, "duration": 4.88}, {"text": "figure out what are the relative advantages.\nEach of these have their own advantages. I", "start": 3381.44, "duration": 4.549}, {"text": "know, for example, one of the big advantages\nof rectified linear unit is that since you're", "start": 3385.989, "duration": 4.241}, {"text": "not limiting yourself between a -0 and 1 range,\nyou don't have to do that. You don't run into", "start": 3390.23, "duration": 5.67}, {"text": "a problem of vanishing gradients. That doesn't\nmean much for people. That's OK. We're not", "start": 3395.9, "duration": 3.939}, {"text": "going to spend too much time talking about\nthat anyhow.", "start": 3399.839, "duration": 4.141}, {"text": "AUDIENCE: Vijay?", "start": 3403.98, "duration": 5.109}, {"text": "VIJAY GADEPALLY: Yeah?", "start": 3409.089, "duration": 7.671}, {"text": "AUDIENCE: So in general, [INAUDIBLE].", "start": 3416.76, "duration": 2.623}, {"text": "VIJAY GADEPALLY: So the question is picking\nthe activation functions, picking the number", "start": 3419.383, "duration": 4.416}, {"text": "of layers. We'll talk about that in a couple\nof slides. But there is a lot of art. Trial", "start": 3423.799, "duration": 5.951}, {"text": "and error-- yes, but also, we'll call it art\nas well that's involved with coming up with", "start": 3429.75, "duration": 4.83}, {"text": "that.", "start": 3434.58, "duration": 1.0}, {"text": "A lot of what happens in practice, however,\nis you find an application area, which looks", "start": 3435.58, "duration": 4.959}, {"text": "very similar to the problem that you are trying\nto solve. And you might borrow the architecture", "start": 3440.539, "duration": 4.141}, {"text": "from there and use that as a starting point\nin coming up with where you start. Yeah?", "start": 3444.68, "duration": 4.53}, {"text": "AUDIENCE: Are you aware of any research of\nsome type of parameterizing the activation", "start": 3449.21, "duration": 8.93}, {"text": "function and then trying to learn the activation\nfunction?", "start": 3458.14, "duration": 5.06}, {"text": "VIJAY GADEPALLY: I'm sure people are doing\nit. I'm personally not familiar with that", "start": 3463.2, "duration": 4.879}, {"text": "research. I don't if anyone else in the room\nhas-- yep?", "start": 3468.079, "duration": 2.361}, {"text": "AUDIENCE: [INAUDIBLE] DARPA D3M program, so\ndata-driven machine learning. You're trying", "start": 3470.44, "duration": 1.399}, {"text": "to learn both the architecture of the network\nand the activation function and therefore", "start": 3471.839, "duration": 3.411}, {"text": "all the other attributes. Because you're trying\nto just go from data set to machine learning", "start": 3475.25, "duration": 12.65}, {"text": "system with no human intervention.", "start": 3487.9, "duration": 2.119}, {"text": "VIJAY GADEPALLY: So the question was, is there\nany research into parameterizing the activation", "start": 3490.019, "duration": 6.59}, {"text": "function? So I guess the model as a whole.\nSo, yeah, there is. And one of the responses", "start": 3496.609, "duration": 6.99}, {"text": "was that there is a program run by DARPA,\nwhich is the D3M program, which is really", "start": 3503.599, "duration": 5.171}, {"text": "looking at, can you go from data to result\nwith no or almost no human intervention?", "start": 3508.77, "duration": 8.67}, {"text": "I'm not familiar with activation function\nparameterization. But certainly, network model", "start": 3517.44, "duration": 4.78}, {"text": "parameterization is absolutely there. So people\nwho are running optimization models to basically", "start": 3522.22, "duration": 5.51}, {"text": "look for-- I have this particular set of resources.\nWhat is the best model architecture that fits", "start": 3527.73, "duration": 4.93}, {"text": "into that?", "start": 3532.66, "duration": 1.25}, {"text": "Maybe I want to deploy this on a really tiny\nprocessor that only gives me 16 megabytes", "start": 3533.91, "duration": 5.28}, {"text": "of memory. I want to make sure that my model\nand data can fit on that. Can you find what", "start": 3539.19, "duration": 4.669}, {"text": "would be the ideal model for that? So that's\nabsolutely something that people are doing", "start": 3543.859, "duration": 4.24}, {"text": "right now. But I'm not sure if people are\ntrying to come up with, I guess, brand new", "start": 3548.099, "duration": 5.951}, {"text": "activation functions. All right.", "start": 3554.05, "duration": 5.13}, {"text": "So lots of stuff in the neural network landscape.\nAnd as I mentioned earlier, neural network", "start": 3559.18, "duration": 6.07}, {"text": "training is essentially adjusting weights\nuntil the function represented by the neural", "start": 3565.25, "duration": 3.779}, {"text": "network essentially does what you would like\nit to do. And the key idea here is to iteratively", "start": 3569.029, "duration": 5.23}, {"text": "adjust weights to reduce the error.", "start": 3574.259, "duration": 2.641}, {"text": "So what you do is you take some random instantiation\nof your neural network or maybe based on another", "start": 3576.9, "duration": 5.14}, {"text": "domain or another problem. You might borrow\nthat. And you start there. And then you pass", "start": 3582.04, "duration": 5.769}, {"text": "a data set in. You look at the output and\nyou say, that's not right. What went wrong", "start": 3587.809, "duration": 4.73}, {"text": "over here?", "start": 3592.539, "duration": 1.0}, {"text": "And you go back and adjust things and do that\nagain, and again, and again, and again, and", "start": 3593.539, "duration": 4.941}, {"text": "again, over and over, until you get something\nthat looks reasonable. That's really what's", "start": 3598.48, "duration": 4.2}, {"text": "going on over there. And so real neural networks\ncan have thousands of input, data points--", "start": 3602.68, "duration": 5.089}, {"text": "hundreds of layers, and millions to billions\nof weight changes per iteration. Yes?", "start": 3607.769, "duration": 3.03}, {"text": "AUDIENCE: So what you're talking about is\n[INAUDIBLE] adjustment [INAUDIBLE]. Do you", "start": 3610.799, "duration": 1.0}, {"text": "know of any [INAUDIBLE] this process?", "start": 3611.799, "duration": 2.5}, {"text": "VIJAY GADEPALLY: Yes, there's a lot of work\nbeing done to parallelize this--", "start": 3614.299, "duration": 10.7}, {"text": "AUDIENCE: Like, for--", "start": 3624.999, "duration": 1.0}, {"text": "VIJAY GADEPALLY: --and by default.", "start": 3625.999, "duration": 1.0}, {"text": "AUDIENCE: [INAUDIBLE]?", "start": 3626.999, "duration": 1.0}, {"text": "VIJAY GADEPALLY: So the question is when--\nas I just described it right now, it's a serial", "start": 3627.999, "duration": 4.741}, {"text": "process where I pass one data point in. It\ngoes all the way to the end. It says, oh,", "start": 3632.74, "duration": 5.66}, {"text": "this is the output-- goes back and adjusts.\nAre there techniques that people are doing", "start": 3638.4, "duration": 4.58}, {"text": "to do this in a distributed fashion? And the\nanswer to that is a strong yes. It's a very", "start": 3642.98, "duration": 5.44}, {"text": "active area in especially high-performance\ncomputing and machine learning.", "start": 3648.42, "duration": 5.28}, {"text": "We might talk about this in-- are we talking\nabout this on day three? We might talk a little", "start": 3653.7, "duration": 6.109}, {"text": "bit about it. But there is model parallelism,\nwhich is I have the model itself distributed", "start": 3659.809, "duration": 4.8}, {"text": "across multiple pieces. And I want to adjust\ndifferent pieces of the model at the same", "start": 3664.609, "duration": 4.97}, {"text": "time. There's research and lots of results.\nI think we might even have some examples that", "start": 3669.579, "duration": 5.46}, {"text": "people are doing with that.", "start": 3675.039, "duration": 1.841}, {"text": "AUDIENCE: Have you got some examples on the\n[INAUDIBLE] approach, the [INAUDIBLE] approach?", "start": 3676.88, "duration": 8.939}, {"text": "VIJAY GADEPALLY: A little bit earlier.", "start": 3685.819, "duration": 1.651}, {"text": "AUDIENCE: Communication [INAUDIBLE].", "start": 3687.47, "duration": 1.0}, {"text": "VIJAY GADEPALLY: So there are many different\nways to parallelize it. One would be data", "start": 3688.47, "duration": 5.359}, {"text": "parallelism, which is I take my big data set\nor big data point, and I distribute that across", "start": 3693.829, "duration": 6.441}, {"text": "my different nodes. And each one independently\nlearns a model that works well. And then I", "start": 3700.27, "duration": 4.089}, {"text": "do some synchronization across these different\npieces.", "start": 3704.359, "duration": 3.391}, {"text": "There are also techniques where you have--\nthe model itself may be too big to sit on", "start": 3707.75, "duration": 3.789}, {"text": "a single node or a single processing element.\nAnd you might have to distribute that. So,", "start": 3711.539, "duration": 4.161}, {"text": "yes, a lot of very interesting research going\non in that area. And by default, when you", "start": 3715.7, "duration": 6.909}, {"text": "do run things, they are running in parallel,\njust even on your GPU. They're using multiple", "start": 3722.609, "duration": 5.2}, {"text": "cores at once. So there is some level of--\nwithin the node itself, parallelism that runs", "start": 3727.809, "duration": 4.72}, {"text": "by default on most machine learning software.", "start": 3732.529, "duration": 5.601}, {"text": "So inferences-- I mentioned is just using\nthe trained model again. And the power of", "start": 3738.13, "duration": 4.01}, {"text": "neural networks really falls within their\nnon-linearity. So you have that non-linear", "start": 3742.14, "duration": 3.81}, {"text": "F function that you're applying over and over\nand over across your layers. And this crudely", "start": 3745.95, "duration": 5.28}, {"text": "drawn diagram on my iPad-- this is not clear\nat all.", "start": 3751.23, "duration": 7.279}, {"text": "If you had Xs and Os, right? It reminds me\nof a song. And you have features over here.", "start": 3758.509, "duration": 6.029}, {"text": "And you're trying to basically classify it.\nWhich is an X? And which is an O? A linear", "start": 3764.538, "duration": 4.041}, {"text": "classifier could do a pretty good job in this\ntype of situation. And you could apply a neural", "start": 3768.579, "duration": 5.44}, {"text": "network to this, but maybe it's overkill in\nthat type of situation.", "start": 3774.019, "duration": 3.08}, {"text": "But in some feature space, if this is how\nyour Xs and Os are divided amongst each other", "start": 3777.099, "duration": 5.24}, {"text": "and you're trying to come up with the right\nlabel, one thing I might suggest is maybe", "start": 3782.339, "duration": 3.571}, {"text": "find another feature space that you could\nmaybe get a better separation between the", "start": 3785.91, "duration": 3.501}, {"text": "two. Or a technique like a neural network\nmight do a very good job. Or any of these", "start": 3789.411, "duration": 4.188}, {"text": "non-linear machine learning techniques might\ndo a very good job for looking for these really", "start": 3793.599, "duration": 3.7}, {"text": "complex decision boundaries that are out there.\nAll right.", "start": 3797.299, "duration": 3.681}, {"text": "So you mentioned earlier when you're designing\na neural network, what do you have to do?", "start": 3800.98, "duration": 6.019}, {"text": "What are the different choices, et cetera?\nThere is a lot going on here. So you have", "start": 3806.999, "duration": 3.771}, {"text": "to pick the depth, the number of layers, the\ninputs, and what the inputs are, the type", "start": 3810.77, "duration": 4.64}, {"text": "of network that you're using, the types of\nlayers, the training algorithm and metrics", "start": 3815.41, "duration": 4.5}, {"text": "that you're using to assess the performance\nof this neural network.", "start": 3819.91, "duration": 2.929}, {"text": "The good thing, however, is it so expensive\nto train a neural network, that you largely", "start": 3822.839, "duration": 4.071}, {"text": "are not making these decisions in many cases.\nYou just pick up what somebody else has done,", "start": 3826.91, "duration": 4.01}, {"text": "and you start from there, and then you start.\nThat might be-- I don't know if that's a good", "start": 3830.92, "duration": 3.74}, {"text": "or a bad thing. But that's often a way in\npractice that people end up doing this.", "start": 3834.66, "duration": 6.089}, {"text": "But there is some theory on the general approach.\nI think in this short amount of time, which", "start": 3840.749, "duration": 6.681}, {"text": "I'm already over, we won't be able to get\ninto it. But I'm happy to-- actually, these", "start": 3847.43, "duration": 4.31}, {"text": "slides have backups on them. So when I share\nthem with you, they do have a lot more detail", "start": 3851.74, "duration": 4.25}, {"text": "on each of these different pieces. All right.", "start": 3855.99, "duration": 2.74}, {"text": "Very quickly, we'll talk about unsupervised\nlearning. And the basic idea is the task of", "start": 3858.73, "duration": 3.99}, {"text": "describing a hidden structure from unlabeled\ndata. So in contrast to supervised learning,", "start": 3862.72, "duration": 4.921}, {"text": "we are not providing labels. We're just giving\nthe algorithm a data set and saying, tell", "start": 3867.641, "duration": 3.938}, {"text": "me something cool that's going on over here.", "start": 3871.579, "duration": 2.751}, {"text": "Now, clearly, you can't label the data if\nyou do that. But what you can do is maybe", "start": 3874.33, "duration": 5.3}, {"text": "look for clusters or look for dimensions or\npieces of the data that are unimportant or", "start": 3879.63, "duration": 6.81}, {"text": "extraneous. So if we observe certain features,\nwe would like to observe the patterns amongst", "start": 3886.44, "duration": 5.609}, {"text": "these features.", "start": 3892.049, "duration": 1.3}, {"text": "And the typical tasks that one would do in\nunsupervised learning is clustering and data", "start": 3893.349, "duration": 4.621}, {"text": "projection, or data pre-processing, or dimensionality\nreduction. And the goal is to discover interesting", "start": 3897.97, "duration": 4.899}, {"text": "things about the data set, such as subgroups,\npatterns, clusters, et cetera.", "start": 3902.869, "duration": 7.18}, {"text": "In unsupervised learning-- one of the difficulties\nin supervised learning-- we know, right? We", "start": 3910.049, "duration": 3.851}, {"text": "have an input. We have a label. And we're\nlike, OK, if that input-- if my algorithm", "start": 3913.9, "duration": 3.75}, {"text": "doesn't give me the label, bad. Go retrain.\nOr I know what-- I can go back, use that as", "start": 3917.65, "duration": 6.609}, {"text": "my performance metric.", "start": 3924.259, "duration": 1.57}, {"text": "On unsupervised learning, there is no simple\ngoal such as maximizing a certain probability", "start": 3925.829, "duration": 4.45}, {"text": "for the algorithm. Some of that is going to\nbe something that you have to work on, is", "start": 3930.279, "duration": 4.451}, {"text": "at the interclass or intraclass distance that\nI'm most having that separation. Is that going", "start": 3934.73, "duration": 4.819}, {"text": "to be my performance metric? Is it the number\nof clusters that I'm creating? Is that the", "start": 3939.549, "duration": 3.711}, {"text": "number of-- is that the metric that I'm using?", "start": 3943.26, "duration": 2.809}, {"text": "But it is very popular, because it works on\nunlabeled data. And I'm sure many of us work", "start": 3946.069, "duration": 4.621}, {"text": "on data sets, which are just too large or\ntoo difficult to sit and label. An example", "start": 3950.69, "duration": 4.669}, {"text": "that comes to my mind, certainly, is in the\nworld of cybersecurity where you're collecting", "start": 3955.359, "duration": 5.281}, {"text": "billions and billions of networked packets.\nAnd you're trying to look for an almost behavior.", "start": 3960.64, "duration": 4.5}, {"text": "You're not going to go through and look at\neach pack and be like, bad, good, what it", "start": 3965.14, "duration": 4.26}, {"text": "is. But you might use an unsupervised technique\nto maybe extract out some of the relevant", "start": 3969.4, "duration": 4.379}, {"text": "pieces, then use a supervised-- then go through\nthe trouble of labeling that data, and then", "start": 3973.779, "duration": 4.401}, {"text": "pass that on to a supervised learning technique.\nAnd I'm happy to share some research that", "start": 3978.18, "duration": 3.31}, {"text": "we've been doing on that front.", "start": 3981.49, "duration": 2.25}, {"text": "Some common techniques are within clustering\nand data projection. Clustering is the basic", "start": 3983.74, "duration": 5.81}, {"text": "idea that we want to group objects or sets\nof features, such that objects in the same", "start": 3989.55, "duration": 3.719}, {"text": "cluster are more similar to those of another\ncluster. And what you typically do for that", "start": 3993.269, "duration": 4.461}, {"text": "is you put your data in some feature space,\nand you try to maximize some intracluster", "start": 3997.73, "duration": 7.819}, {"text": "measure, which is basically saying, I want\nthe points within my cluster to be closer", "start": 4005.549, "duration": 4.45}, {"text": "than anything outside of my cluster, right?", "start": 4009.999, "duration": 2.34}, {"text": "So that's a metric. And you iteratively move\nthe membership from each. You set a number", "start": 4012.339, "duration": 5.491}, {"text": "of clusters, saying, I need five clusters.\nIt'll randomly assign things. And it'll keep", "start": 4017.83, "duration": 4.279}, {"text": "adjusting the membership of a particular data\npoint within a cluster, based on a metric", "start": 4022.109, "duration": 4.821}, {"text": "such as the squared error.", "start": 4026.93, "duration": 2.79}, {"text": "So in this example, we might say that, OK,\nthese are three clusters that I get out of", "start": 4029.72, "duration": 4.089}, {"text": "it. Dimensionality reduction is the idea of\nreducing the number of random variables under", "start": 4033.809, "duration": 5.69}, {"text": "consideration. Very often, you'll collect\na data set that has hundreds to thousands", "start": 4039.499, "duration": 4.651}, {"text": "of different features.", "start": 4044.15, "duration": 1.6}, {"text": "Maybe some of these features are not that\nimportant. Maybe they're unchanging. Or even", "start": 4045.75, "duration": 4.259}, {"text": "if they are changing, it's not by much. And\nso maybe you want to remove them from consideration.", "start": 4050.009, "duration": 5.931}, {"text": "That's when you use a technique like dimensionality\nreduction. And this is really, really important", "start": 4055.94, "duration": 5.539}, {"text": "when you're doing feature selection and feature\nextraction in your real data sets. And you", "start": 4061.479, "duration": 5.63}, {"text": "might also use it for other techniques, such\nas compression or visualization.", "start": 4067.109, "duration": 3.67}, {"text": "So if you want to show things on Excel, showing\na thousand dimensional object may be difficult.", "start": 4070.779, "duration": 5.22}, {"text": "You might try to project it down to the two\nor three dimensions that are easiest to visualize.", "start": 4075.999, "duration": 6.37}, {"text": "And of course, you can use neural networks\nfor unsupervised learning as well. Surprise,", "start": 4082.369, "duration": 5.74}, {"text": "surprise.", "start": 4088.109, "duration": 1.23}, {"text": "So as much as a lot of the press you've seen\nhas been on things like image classification", "start": 4089.339, "duration": 4.171}, {"text": "using nice labeled data sets, there's a lot\nof work where you can apply it in an unsupervised", "start": 4093.51, "duration": 5.05}, {"text": "case. And these are largely used to find better\nrepresentations for data, such as clustering", "start": 4098.56, "duration": 5.339}, {"text": "and dimensionality reduction. And they're\nreally powerful because of their non-linear", "start": 4103.899, "duration": 3.79}, {"text": "capabilities.", "start": 4107.689, "duration": 1.0}, {"text": "So one example-- I won't spend way too much\ntime on this-- is an autoencoder. And the", "start": 4108.689, "duration": 4.929}, {"text": "basic idea behind an autoencoder is you're\ntrying to find some compressed representation", "start": 4113.618, "duration": 3.803}, {"text": "for data. And the way we do this is by changing\nthe metric that we use to say that the system", "start": 4117.421, "duration": 6.428}, {"text": "has done a good job.", "start": 4123.849, "duration": 1.809}, {"text": "And the metric is basically-- if I have a\nset of input features that I'm passing in,", "start": 4125.658, "duration": 3.83}, {"text": "I would like to do the best job in reconstructing\nthat input at my output. And what I do is", "start": 4129.488, "duration": 6.041}, {"text": "I squeeze it through a smaller number of layers,\nwhich forms this compressed representation", "start": 4135.529, "duration": 4.892}, {"text": "for my data set.", "start": 4140.421, "duration": 1.918}, {"text": "And so the idea here is, how can I pass my\ninputs through this narrow waste to come up", "start": 4142.339, "duration": 6.041}, {"text": "with a reconstructed input that's very similar\nto my original input? And so my metric in", "start": 4148.38, "duration": 4.688}, {"text": "this particular case is essentially the difference\nbetween the reconstructed input or the output", "start": 4153.068, "duration": 6.611}, {"text": "and the input. And the compressed representation--\nyou can think of as the reduced dimensionality", "start": 4159.679, "duration": 8.281}, {"text": "version of my problem.", "start": 4167.96, "duration": 3.96}, {"text": "We've also done some work on replicator networks,\nwhich are also really, really cool. Happy", "start": 4171.92, "duration": 5.299}, {"text": "to chat about that as well. And finally, we\nhave to talk very briefly on reinforcement", "start": 4177.219, "duration": 4.71}, {"text": "learning. And the basic-- again, at a very\nhigh level, the reason reinforcement learning", "start": 4181.929, "duration": 6.72}, {"text": "is fundamentally different than supervised\nor unsupervised learning is that you're not", "start": 4188.649, "duration": 4.57}, {"text": "passing in a label associated with an input\nfeature.", "start": 4193.219, "duration": 4.331}, {"text": "So there is no supervisor or a person that\ncan label it, but just a reward signal. And", "start": 4197.55, "duration": 5.06}, {"text": "the feedback is often delayed. And time is\nimportant, so it steps through a process.", "start": 4202.61, "duration": 5.85}, {"text": "And the agent's actions often change the input\ndata that it receives. So just to maybe--", "start": 4208.46, "duration": 6.59}, {"text": "in the interest of time, just to give you\nexamples of where reinforcement learning could", "start": 4215.05, "duration": 4.21}, {"text": "work and why you would use a technique like\nreinforcement learning.", "start": 4219.26, "duration": 3.5}, {"text": "So flying stunt maneuvers in a helicopter.\nSo if your helicopter is straight, you say", "start": 4222.76, "duration": 6.839}, {"text": "keep doing more of whatever you're doing to\nkeep it there. If the helicopter tips over,", "start": 4229.599, "duration": 3.941}, {"text": "you say stop doing whatever you just did to\ndo that. Could you create a supervised learning", "start": 4233.54, "duration": 4.99}, {"text": "algorithm for doing this? Sure. Right?", "start": 4238.53, "duration": 3.18}, {"text": "You would basically look for all the configurations\nof your entire system every time the helicopter", "start": 4241.71, "duration": 5.32}, {"text": "was upright. And you would look for all the\nexamples where your helicopter was tipping", "start": 4247.03, "duration": 4.3}, {"text": "over or falling. And you would basically say,\nOK, my engine speed was this much. My rotor", "start": 4251.33, "duration": 6.18}, {"text": "speed was this much.", "start": 4257.51, "duration": 1.35}, {"text": "And there are probably people here who fly\nhelicopters, so pardon me if I am completely", "start": 4258.86, "duration": 6.12}, {"text": "oversimplifying this problem here. However,\nyou could certainly label it that way and", "start": 4264.98, "duration": 5.88}, {"text": "say all these configurations of the helicopter\nmeant the helicopter was upright. All these", "start": 4270.86, "duration": 5.35}, {"text": "configurations of the helicopter meant the\nhelicopter was not upright.", "start": 4276.21, "duration": 3.42}, {"text": "That would be pretty expensive and difficult\ndata-- collect to do. Not sure how many people", "start": 4279.63, "duration": 4.48}, {"text": "want to volunteer for-- let's do all the ones\nthat are at faults. And lots of other applications", "start": 4284.11, "duration": 5.93}, {"text": "beyond that. So these are really useful, especially\nin cases where-- what you're trying to model", "start": 4290.04, "duration": 6.22}, {"text": "is just extremely complex. And the other really\npowerful thing is this tends to mimic human", "start": 4296.26, "duration": 5.71}, {"text": "behavior. And so they're very useful in those\ntype of applications.", "start": 4301.97, "duration": 5.1}, {"text": "AUDIENCE: Can you explain, shortly, what a\nreward would look like?", "start": 4307.07, "duration": 3.41}, {"text": "VIJAY GADEPALLY: So a reward would just be--\nit would be very similar until you get points.", "start": 4310.48, "duration": 5.18}, {"text": "So you have your algorithm that's basically\ntrying to maximize the number of points that", "start": 4315.66, "duration": 3.42}, {"text": "it receives, for example. And as you do--\nit's very similar to what you or I would consider", "start": 4319.08, "duration": 6.19}, {"text": "a reward playing a video game, right?", "start": 4325.27, "duration": 2.42}, {"text": "Every time I get points, I do more of the\nactivities that make me get points. And it's", "start": 4327.69, "duration": 6.69}, {"text": "essentially the same concept over here. All\nright. So with that, I will conclude only", "start": 4334.38, "duration": 9.029}, {"text": "20 minutes behind schedule. So I guess the\nlong story short is there's lots of exciting", "start": 4343.409, "duration": 6.94}, {"text": "research into AI and machine learning techniques\nout here.", "start": 4350.349, "duration": 3.54}, {"text": "We did a one-hour view of this broad field\nthat research has dedicated about six to seven", "start": 4353.889, "duration": 6.08}, {"text": "decades of work to words, so my apologies\nto anyone watching this or in the room whose", "start": 4359.969, "duration": 6.201}, {"text": "work I just jumped over. The key ingredients,\nhowever-- and I think this is most important", "start": 4366.17, "duration": 6.11}, {"text": "to this group-- is I look at what are the\nproblems where AI has done really well.", "start": 4372.28, "duration": 6.37}, {"text": "These are some of the key ingredients-- data\navailability, computing infrastructure, and", "start": 4378.65, "duration": 4.83}, {"text": "the domain expertise and algorithms. And I\nthink it's very exciting to see this group", "start": 4383.48, "duration": 3.179}, {"text": "over here, because we do have all of these\npieces coming together. So great things are", "start": 4386.659, "duration": 5.25}, {"text": "bound to happen.", "start": 4391.909, "duration": 1.75}, {"text": "There are, I think, large challenges in data\navailability and readiness for AI, which is", "start": 4393.659, "duration": 5.181}, {"text": "what we're just going to scrape the edge off\nduring this class. And some of the computing", "start": 4398.84, "duration": 5.55}, {"text": "infrastructure is something that we'll be\ntalking to you about in a couple of minutes.", "start": 4404.39, "duration": 3.999}, {"text": "And if you're interested in some of the more\ndetailed look at any of these things, a number", "start": 4408.389, "duration": 4.92}, {"text": "of us actually wrote-- maybe I'm biased. I\nthink it's a great, great, great write-up.", "start": 4413.309, "duration": 5.841}, {"text": "But, no, I think it's useful. It has its places.\nObviously, a lot of material in here. But", "start": 4419.15, "duration": 6.759}, {"text": "we try to do our best job to at least cite\nsome of this really, really interesting work", "start": 4425.909, "duration": 5.19}, {"text": "that's going on in the field. So with that,\nI'll pause for any additional questions, but", "start": 4431.099, "duration": 5.201}, {"text": "thank you very much for your attention.", "start": 4436.3, "duration": 1.0}]