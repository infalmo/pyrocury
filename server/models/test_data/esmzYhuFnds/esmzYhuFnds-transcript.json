[{"text": "The following content is\nprovided under a Creative", "start": 0.79, "duration": 2.34}, {"text": "Commons license.", "start": 3.13, "duration": 1.42}, {"text": "Your support will help\nMIT OpenCourseWare", "start": 4.55, "duration": 2.21}, {"text": "continue to offer high-quality\neducational resources for free.", "start": 6.76, "duration": 4.09}, {"text": "To make a donation, or to\nview additional materials", "start": 10.85, "duration": 2.54}, {"text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare", "start": 13.39, "duration": 3.93}, {"text": "at ocw.mit.edu.", "start": 17.32, "duration": 1.25}, {"text": "JOHN GUTTAG: I'm\na little reluctant", "start": 21.462, "duration": 1.458}, {"text": "to say good afternoon,\ngiven the weather,", "start": 22.92, "duration": 2.96}, {"text": "but I'll say it anyway.", "start": 25.88, "duration": 2.62}, {"text": "I guess now we all do know\nthat we live in Boston.", "start": 28.5, "duration": 4.4}, {"text": "And I should say,\nI hope none of you", "start": 32.9, "duration": 1.98}, {"text": "were affected too much by the\nfire yesterday in Cambridge,", "start": 34.88, "duration": 4.86}, {"text": "but that seems to have been\na pretty disastrous event", "start": 39.74, "duration": 2.91}, {"text": "for some.", "start": 42.65, "duration": 1.35}, {"text": "Anyway, here's the reading.", "start": 44.0, "duration": 1.74}, {"text": "This is a chapter in\nthe book on clustering,", "start": 45.74, "duration": 3.1}, {"text": "a topic that Professor\nGrimson introduced last week.", "start": 48.84, "duration": 3.77}, {"text": "And I'm going to try and finish\nup with respect to this course", "start": 52.61, "duration": 4.95}, {"text": "today, though not with\nrespect to everything", "start": 57.56, "duration": 2.52}, {"text": "there is to know\nabout clustering.", "start": 60.08, "duration": 2.7}, {"text": "Quickly just reviewing\nwhere we were.", "start": 62.78, "duration": 4.92}, {"text": "We're in the unit of a\ncourse on machine learning,", "start": 67.7, "duration": 2.94}, {"text": "and we always follow\nthe same paradigm.", "start": 70.64, "duration": 2.55}, {"text": "We observe some set\nof examples, which", "start": 73.19, "duration": 2.97}, {"text": "we call the training data.", "start": 76.16, "duration": 2.28}, {"text": "We try and infer something\nabout the process", "start": 78.44, "duration": 3.57}, {"text": "that created those examples.", "start": 82.01, "duration": 3.44}, {"text": "And then we use inference\ntechniques, different kinds", "start": 85.45, "duration": 2.94}, {"text": "of techniques, to\nmake predictions", "start": 88.39, "duration": 2.37}, {"text": "about previously unseen data.", "start": 90.76, "duration": 3.06}, {"text": "We call that the test data.", "start": 93.82, "duration": 3.01}, {"text": "As Professor Grimson said, you\ncan think of two broad classes.", "start": 96.83, "duration": 3.96}, {"text": "Supervised, where we have a\nset of examples and some label", "start": 100.79, "duration": 3.66}, {"text": "associated with the example--", "start": 104.45, "duration": 2.22}, {"text": "Democrat, Republican,\nsmart, dumb,", "start": 106.67, "duration": 3.93}, {"text": "whatever you want to\nassociate with them--", "start": 110.6, "duration": 4.17}, {"text": "and then we try and\ninfer the labels.", "start": 114.77, "duration": 3.15}, {"text": "Or unsupervised, where we're\ngiven a set of feature vectors", "start": 117.92, "duration": 4.35}, {"text": "without labels, and\nthen we attempt to group", "start": 122.27, "duration": 3.39}, {"text": "them into natural clusters.", "start": 125.66, "duration": 4.2}, {"text": "That's going to be\ntoday's topic, clustering.", "start": 129.86, "duration": 3.61}, {"text": "So clustering is an\noptimization problem.", "start": 133.47, "duration": 4.97}, {"text": "As we'll see later,\nsupervised machine learning", "start": 138.44, "duration": 2.34}, {"text": "is also an optimization problem.", "start": 140.78, "duration": 2.55}, {"text": "Clustering's a\nrather simple one.", "start": 143.33, "duration": 3.33}, {"text": "We're going to start first\nwith the notion of variability.", "start": 146.66, "duration": 4.52}, {"text": "So this little c is\na single cluster,", "start": 151.18, "duration": 3.76}, {"text": "and we're going to talk about\nthe variability in that cluster", "start": 154.94, "duration": 3.81}, {"text": "of the sum of the distance\nbetween the mean of the cluster", "start": 158.75, "duration": 6.69}, {"text": "and each example in the cluster.", "start": 165.44, "duration": 2.44}, {"text": "And then we square it.", "start": 167.88, "duration": 3.04}, {"text": "OK?", "start": 170.92, "duration": 0.88}, {"text": "Pretty straightforward.", "start": 171.8, "duration": 3.06}, {"text": "For the moment,\nwe can just assume", "start": 174.86, "duration": 1.65}, {"text": "that we're using Euclidean\ndistance as our distance", "start": 176.51, "duration": 3.21}, {"text": "metric.", "start": 179.72, "duration": 1.19}, {"text": "Minkowski with p equals two.", "start": 180.91, "duration": 3.17}, {"text": "So variability should look\npretty similar to something", "start": 184.08, "duration": 5.95}, {"text": "we've seen before, right?", "start": 190.03, "duration": 2.98}, {"text": "It's not quite variance,\nright, but it's very close.", "start": 193.01, "duration": 3.09}, {"text": "In a minute, we'll look\nat why it's different.", "start": 196.1, "duration": 3.55}, {"text": "And then we can look\nat the dissimilarity", "start": 199.65, "duration": 3.51}, {"text": "of a set of clusters, a group\nof clusters, which I'm writing", "start": 203.16, "duration": 4.41}, {"text": "as capital C, and\nthat's just the sum", "start": 207.57, "duration": 3.03}, {"text": "of all the variabilities.", "start": 210.6, "duration": 1.59}, {"text": "Now, if I had\ndivided variability", "start": 214.72, "duration": 5.43}, {"text": "by the size of the\ncluster, what would I have?", "start": 220.15, "duration": 5.364}, {"text": "Something we've seen before.", "start": 225.514, "duration": 1.166}, {"text": "What would that be?", "start": 226.68, "duration": 2.73}, {"text": "Somebody?", "start": 229.41, "duration": 2.48}, {"text": "Isn't that just the variance?", "start": 231.89, "duration": 3.18}, {"text": "So the question is, why\nam I not doing that?", "start": 235.07, "duration": 2.84}, {"text": "If up til now, we always\nwanted to talk about variance,", "start": 237.91, "duration": 4.26}, {"text": "why suddenly am I not doing it?", "start": 242.17, "duration": 3.14}, {"text": "Why do I define this\nnotion of variability", "start": 245.31, "duration": 2.49}, {"text": "instead of good old variance?", "start": 247.8, "duration": 2.95}, {"text": "Any thoughts?", "start": 250.75, "duration": 0.645}, {"text": "What am I accomplishing\nby not dividing", "start": 255.12, "duration": 3.18}, {"text": "by the size of the cluster?", "start": 258.3, "duration": 2.159}, {"text": "Or what would happen\nif I did divide", "start": 260.459, "duration": 1.891}, {"text": "by the size of the cluster?", "start": 262.35, "duration": 2.07}, {"text": "Yes.", "start": 264.42, "duration": 0.838}, {"text": "AUDIENCE: You normalize it?", "start": 265.258, "duration": 1.453}, {"text": "JOHN GUTTAG: Absolutely.", "start": 266.711, "duration": 0.999}, {"text": "I'd normalize it.", "start": 267.71, "duration": 2.01}, {"text": "That's exactly what\nit would be doing.", "start": 269.72, "duration": 2.1}, {"text": "And what might be good or\nbad about normalizing it?", "start": 271.82, "duration": 4.56}, {"text": "What does it essentially\nmean to normalize?", "start": 281.01, "duration": 3.27}, {"text": "It means that the\npenalty for a big cluster", "start": 284.28, "duration": 4.14}, {"text": "with a lot of variance\nin it is no higher", "start": 288.42, "duration": 3.12}, {"text": "than the penalty of\na tiny little cluster", "start": 291.54, "duration": 1.98}, {"text": "with a lot of variance in it.", "start": 293.52, "duration": 3.2}, {"text": "By not normalizing,\nwhat I'm saying is", "start": 296.72, "duration": 3.87}, {"text": "I want to penalize big,\nhighly-diverse clusters", "start": 300.59, "duration": 4.92}, {"text": "more than small,\nhighly-diverse clusters.", "start": 305.51, "duration": 3.86}, {"text": "OK?", "start": 309.37, "duration": 0.5}, {"text": "And if you think about it,\nthat probably makes sense.", "start": 309.87, "duration": 3.12}, {"text": "Big and bad is worse\nthan small and bad.", "start": 315.77, "duration": 2.7}, {"text": "All right, so now we define\nthe objective function.", "start": 321.5, "duration": 4.61}, {"text": "And can we say that the\noptimization problem", "start": 326.11, "duration": 3.14}, {"text": "we want to solve by clustering\nis simply finding a capital", "start": 329.25, "duration": 5.22}, {"text": "C that minimizes dissimilarity?", "start": 334.47, "duration": 3.39}, {"text": "Is that a reasonable definition?", "start": 341.5, "duration": 1.96}, {"text": "Well, hint-- no.", "start": 346.743, "duration": 4.307}, {"text": "What foolish thing could\nwe do that would optimize", "start": 351.05, "duration": 3.63}, {"text": "that objective function?", "start": 354.68, "duration": 1.83}, {"text": "Yeah.", "start": 356.51, "duration": 0.5}, {"text": "AUDIENCE: You could\nhave the same number", "start": 357.01, "duration": 1.666}, {"text": "of clusters as points?", "start": 358.676, "duration": 1.044}, {"text": "JOHN GUTTAG: Yeah.", "start": 359.72, "duration": 0.78}, {"text": "I can have the same\nnumber of clusters", "start": 360.5, "duration": 1.6}, {"text": "as points, assign each point\nto its own cluster, whoops.", "start": 362.1, "duration": 5.6}, {"text": "Ooh, almost a relay.", "start": 367.7, "duration": 2.31}, {"text": "The dissimilarity of\neach cluster would be 0.", "start": 370.01, "duration": 4.51}, {"text": "The variability would be 0, so\nthe dissimilarity would be 0,", "start": 374.52, "duration": 2.75}, {"text": "and I just solved the problem.", "start": 377.27, "duration": 2.36}, {"text": "Well, that's clearly not\na very useful thing to do.", "start": 379.63, "duration": 4.41}, {"text": "So, well, what do you think\nwe do to get around that?", "start": 384.04, "duration": 4.83}, {"text": "Yeah.", "start": 388.87, "duration": 0.5}, {"text": "AUDIENCE: We apply a constraint?", "start": 389.37, "duration": 1.38}, {"text": "JOHN GUTTAG: We\napply a constraint.", "start": 390.75, "duration": 1.78}, {"text": "Exactly.", "start": 392.53, "duration": 0.5}, {"text": "And so we have to\npick some constraint.", "start": 395.83, "duration": 2.9}, {"text": "What would be a suitable\nconstraint, for example?", "start": 402.97, "duration": 5.05}, {"text": "Well, maybe we'd\nsay, OK, the clusters", "start": 408.02, "duration": 3.06}, {"text": "have to have some minimum\ndistance between them.", "start": 411.08, "duration": 2.37}, {"text": "Or-- and this is the constraint\nwe'll be using today--", "start": 415.96, "duration": 3.62}, {"text": "we could constrain the\nnumber of clusters.", "start": 419.58, "duration": 3.16}, {"text": "Say, all right, I only want\nto have at most five clusters.", "start": 422.74, "duration": 4.42}, {"text": "Do the best you can to\nminimize dissimilarity,", "start": 427.16, "duration": 4.52}, {"text": "but you're not allowed to\nuse more than five clusters.", "start": 431.68, "duration": 2.95}, {"text": "That's the most\ncommon constraint that", "start": 434.63, "duration": 2.6}, {"text": "gets placed in the problem.", "start": 437.23, "duration": 3.32}, {"text": "All right, we're going to\nlook at two algorithms.", "start": 440.55, "duration": 2.486}, {"text": "Maybe I should say two\nmethods, because there", "start": 443.036, "duration": 1.874}, {"text": "are multiple implementations\nof these methods.", "start": 444.91, "duration": 3.87}, {"text": "The first is called\nhierarchical clustering,", "start": 448.78, "duration": 2.87}, {"text": "and the second is\ncalled k-means.", "start": 451.65, "duration": 2.1}, {"text": "There should be an S\non the word mean there.", "start": 453.75, "duration": 2.71}, {"text": "Sorry about that.", "start": 456.46, "duration": 2.19}, {"text": "All right, let's look at\nhierarchical clustering first.", "start": 458.65, "duration": 2.35}, {"text": "It's a strange algorithm.", "start": 464.33, "duration": 3.13}, {"text": "We start by assigning\neach item, each example,", "start": 467.46, "duration": 4.41}, {"text": "to its own cluster.", "start": 471.87, "duration": 2.35}, {"text": "So this is the trivial solution\nwe talked about before.", "start": 474.22, "duration": 3.39}, {"text": "So if you have N items,\nyou now have N clusters,", "start": 477.61, "duration": 2.24}, {"text": "each containing just one item.", "start": 479.85, "duration": 2.43}, {"text": "In the next step, we find\nthe two most similar clusters", "start": 487.05, "duration": 5.82}, {"text": "we have and merge them\ninto a single cluster,", "start": 492.87, "duration": 4.6}, {"text": "so that now instead\nof N clusters,", "start": 497.47, "duration": 1.83}, {"text": "we have N minus 1 clusters.", "start": 499.3, "duration": 1.56}, {"text": "And we continue this\nprocess until all items", "start": 506.21, "duration": 2.93}, {"text": "are clustered into a\nsingle cluster of size N.", "start": 509.14, "duration": 4.87}, {"text": "Now of course,\nthat's kind of silly,", "start": 514.01, "duration": 2.97}, {"text": "because if all I\nwanted to put them", "start": 516.98, "duration": 1.476}, {"text": "all it in is in\na single cluster,", "start": 518.456, "duration": 1.374}, {"text": "I don't need to iterate.", "start": 519.83, "duration": 0.999}, {"text": "I just go wham, right?", "start": 520.829, "duration": 2.451}, {"text": "But what's interesting about\nhierarchical clustering", "start": 523.28, "duration": 2.73}, {"text": "is you stop it, typically,\nsomewhere along the way.", "start": 526.01, "duration": 4.76}, {"text": "You produce something\ncalled a [? dendogram. ?]", "start": 530.77, "duration": 3.19}, {"text": "Let me write that down.", "start": 533.96, "duration": 1.28}, {"text": "At each step here, it shows you\nwhat you've merged thus far.", "start": 542.96, "duration": 5.96}, {"text": "We'll see an example\nof that shortly.", "start": 548.92, "duration": 2.41}, {"text": "And then you can have\nsome stopping criteria.", "start": 551.33, "duration": 2.84}, {"text": "We'll talk about that.", "start": 554.17, "duration": 2.56}, {"text": "This is called\nagglomerative hierarchical", "start": 556.73, "duration": 3.09}, {"text": "clustering because we start\nwith a bunch of things", "start": 559.82, "duration": 3.18}, {"text": "and we agglomerate them.", "start": 563.0, "duration": 1.2}, {"text": "That is to say, we\nput them together.", "start": 564.2, "duration": 3.85}, {"text": "All right?", "start": 568.05, "duration": 0.87}, {"text": "Make sense?", "start": 568.92, "duration": 2.56}, {"text": "Well, there's a catch.", "start": 571.48, "duration": 2.58}, {"text": "What do we mean by distance?", "start": 574.06, "duration": 2.7}, {"text": "And there are multiple plausible\ndefinitions of distance,", "start": 576.76, "duration": 5.4}, {"text": "and you would get a\ndifferent answer depending", "start": 582.16, "duration": 2.31}, {"text": "upon which measure you used.", "start": 584.47, "duration": 1.515}, {"text": "These are called\nlinkage metrics.", "start": 590.41, "duration": 2.94}, {"text": "The most common one used\nis probably single-linkage,", "start": 593.35, "duration": 4.69}, {"text": "and that says the distance\nbetween a pair of clusters", "start": 598.04, "duration": 3.89}, {"text": "is equal to the shortest\ndistance from any member of one", "start": 601.93, "duration": 4.2}, {"text": "cluster to any member\nof the other cluster.", "start": 606.13, "duration": 2.86}, {"text": "So if I have two\nclusters, here and here,", "start": 612.1, "duration": 5.48}, {"text": "and they have bunches\nof points in them,", "start": 617.58, "duration": 3.65}, {"text": "single-linkage distance\nwould say, well,", "start": 621.23, "duration": 2.28}, {"text": "let's use these two points\nwhich are the closest,", "start": 623.51, "duration": 3.75}, {"text": "and the distance\nbetween these two", "start": 627.26, "duration": 2.52}, {"text": "is the distance\nbetween the clusters.", "start": 629.78, "duration": 2.435}, {"text": "You can also use\ncomplete-linkage,", "start": 637.09, "duration": 6.9}, {"text": "and that says the distance\nbetween any two clusters", "start": 643.99, "duration": 3.15}, {"text": "is equal to the greatest\ndistance from any member", "start": 647.14, "duration": 3.03}, {"text": "to any other member.", "start": 650.17, "duration": 3.271}, {"text": "OK?", "start": 653.441, "duration": 0.499}, {"text": "So if we had the same\npicture we had before--", "start": 653.94, "duration": 2.21}, {"text": "probably not the same\npicture, but it's a picture.", "start": 661.86, "duration": 2.95}, {"text": "Whoops.", "start": 664.81, "duration": 2.64}, {"text": "Then we would say, well, I guess\ncomplete-linkage is probably", "start": 667.45, "duration": 3.48}, {"text": "the distance, maybe,\nbetween those two.", "start": 670.93, "duration": 1.83}, {"text": "And finally, not\nsurprisingly, you", "start": 679.078, "duration": 5.472}, {"text": "can take the average distance.", "start": 684.55, "duration": 3.98}, {"text": "These are all plausible metrics.", "start": 688.53, "duration": 2.52}, {"text": "They're all used and practiced\nfor different kinds of results", "start": 691.05, "duration": 5.4}, {"text": "depending upon the\napplication of the clustering.", "start": 696.45, "duration": 3.29}, {"text": "All right, let's\nlook at an example.", "start": 702.74, "duration": 3.01}, {"text": "So what I have here\nis the air distance", "start": 705.75, "duration": 3.32}, {"text": "between six different cities,\nBoston, New York, Chicago,", "start": 709.07, "duration": 6.13}, {"text": "Denver, San Francisco,\nand Seattle.", "start": 715.2, "duration": 4.69}, {"text": "And now let's say we're-- want\nto cluster these airports just", "start": 719.89, "duration": 5.02}, {"text": "based upon their distance.", "start": 724.91, "duration": 2.56}, {"text": "So we start.", "start": 727.47, "duration": 2.15}, {"text": "The first piece of our\n[? dendogram ?] says,", "start": 729.62, "duration": 3.24}, {"text": "well, all right,\nI have six cities,", "start": 732.86, "duration": 2.22}, {"text": "I have six clusters,\neach containing one city.", "start": 735.08, "duration": 2.4}, {"text": "All right, what happens next?", "start": 742.777, "duration": 1.208}, {"text": "What's the next level\ngoing to look like?", "start": 747.03, "duration": 3.52}, {"text": "Yeah?", "start": 750.55, "duration": 0.5}, {"text": "AUDIENCE: You're going\nfrom Boston [INAUDIBLE]", "start": 751.05, "duration": 1.93}, {"text": "JOHN GUTTAG: I'm going to\njoin Boston and New York, as", "start": 752.98, "duration": 2.64}, {"text": "improbable as that sounds.", "start": 755.62, "duration": 3.24}, {"text": "All right, so that's\nthe next level.", "start": 758.86, "duration": 3.27}, {"text": "And if for some reason I only\nwanted to have five clusters,", "start": 762.13, "duration": 3.51}, {"text": "well, I could stop here.", "start": 765.64, "duration": 3.25}, {"text": "Next, what happens?", "start": 768.89, "duration": 1.44}, {"text": "Well, I look at it,\nI say well, I'll", "start": 773.26, "duration": 2.84}, {"text": "join up Chicago with\nBoston and New York.", "start": 776.1, "duration": 2.69}, {"text": "All right.", "start": 784.32, "duration": 0.5}, {"text": "What do I get at the next level?", "start": 784.82, "duration": 1.77}, {"text": "Somebody?", "start": 786.59, "duration": 0.56}, {"text": "Yeah.", "start": 787.15, "duration": 0.5}, {"text": "AUDIENCE: Seattle [INAUDIBLE]", "start": 787.65, "duration": 4.5}, {"text": "JOHN GUTTAG: Doesn't\nlook like it to me.", "start": 792.15, "duration": 1.96}, {"text": "If you look at San Francisco\nand Seattle, they are 808 miles,", "start": 794.11, "duration": 7.02}, {"text": "and Denver and San\nFrancisco is 1,235.", "start": 801.13, "duration": 6.01}, {"text": "So I'd end up, in fact, joining\nSan Francisco and Seattle.", "start": 807.14, "duration": 4.101}, {"text": "AUDIENCE: That's what I said.", "start": 811.241, "duration": 2.889}, {"text": "JOHN GUTTAG: Well, that explains\nwhy I need my hearing fixed.", "start": 814.13, "duration": 3.954}, {"text": "[LAUGHTER]", "start": 818.084, "duration": 1.296}, {"text": "All right.", "start": 819.38, "duration": 1.11}, {"text": "So I combine San\nFrancisco and Seattle,", "start": 820.49, "duration": 3.99}, {"text": "and now it gets interesting.", "start": 824.48, "duration": 2.63}, {"text": "I have two choices with Denver.", "start": 827.11, "duration": 3.12}, {"text": "Obviously, there are\nonly two choices,", "start": 830.23, "duration": 7.29}, {"text": "and which I choose depends upon\nwhich linkage criterion I use.", "start": 837.52, "duration": 5.76}, {"text": "If I'm using single-linkage,\nwell, then Denver", "start": 843.28, "duration": 3.75}, {"text": "gets joined with Boston,\nNew York, and Chicago,", "start": 847.03, "duration": 2.88}, {"text": "because it's closer to Chicago\nthan it is to either San", "start": 849.91, "duration": 3.66}, {"text": "Francisco or Seattle.", "start": 853.57, "duration": 1.19}, {"text": "But if I use\ncomplete-linkage, it", "start": 857.42, "duration": 2.74}, {"text": "gets joined up with San\nFrancisco and Seattle,", "start": 860.16, "duration": 3.79}, {"text": "because it is further from\nBoston than it is from,", "start": 863.95, "duration": 7.11}, {"text": "I guess it's San\nFrancisco or Seattle.", "start": 871.06, "duration": 1.86}, {"text": "Whichever it is, right?", "start": 872.92, "duration": 2.39}, {"text": "So this is a place\nwhere you see what", "start": 875.31, "duration": 2.61}, {"text": "answer I get depends upon\nthe linkage criteria.", "start": 877.92, "duration": 3.24}, {"text": "And then if I want, I can\nconsider to the next step", "start": 881.16, "duration": 2.94}, {"text": "and just join them all.", "start": 884.1, "duration": 1.99}, {"text": "All right?", "start": 886.09, "duration": 1.01}, {"text": "That's hierarchical clustering.", "start": 887.1, "duration": 3.57}, {"text": "So it's good because you get\nthis whole history of the", "start": 890.67, "duration": 5.44}, {"text": "[? dendograms, ?] and\nyou get to look at it,", "start": 896.11, "duration": 3.21}, {"text": "say, well, all right,\nthat looks pretty good.", "start": 899.32, "duration": 3.28}, {"text": "I'll stick with this clustering.", "start": 902.6, "duration": 3.96}, {"text": "It's deterministic.", "start": 906.56, "duration": 3.04}, {"text": "Given a linkage criterion, you\nalways get the same answer.", "start": 909.6, "duration": 4.08}, {"text": "There's nothing random here.", "start": 913.68, "duration": 1.22}, {"text": "Notice, by the way,\nthe answer might not", "start": 917.5, "duration": 3.0}, {"text": "be optimal with regards\nto that linkage criteria.", "start": 920.5, "duration": 3.18}, {"text": "Why not?", "start": 923.68, "duration": 2.8}, {"text": "What kind of algorithm is this?", "start": 926.48, "duration": 2.652}, {"text": "AUDIENCE: Greedy.", "start": 929.132, "duration": 0.708}, {"text": "JOHN GUTTAG: It's a\ngreedy algorithm, exactly.", "start": 929.84, "duration": 2.58}, {"text": "And so I'm making\nlocally optimal decisions", "start": 932.42, "duration": 2.52}, {"text": "at each point which may or\nmay not be globally optimal.", "start": 934.94, "duration": 3.57}, {"text": "It's flexible.", "start": 943.16, "duration": 1.29}, {"text": "Choosing different\nlinkage criteria,", "start": 944.45, "duration": 1.62}, {"text": "I get different results.", "start": 946.07, "duration": 1.98}, {"text": "But it's also potentially\nreally, really slow.", "start": 948.05, "duration": 5.61}, {"text": "This is not something you want\nto do on a million examples.", "start": 953.66, "duration": 4.95}, {"text": "The naive algorithm, the one\nI just sort of showed you,", "start": 958.61, "duration": 3.96}, {"text": "is N cubed.", "start": 962.57, "duration": 3.16}, {"text": "N cubed is typically\nimpractical.", "start": 965.73, "duration": 4.39}, {"text": "For some linkage criteria, for\nexample, single-linkage, there", "start": 970.12, "duration": 4.47}, {"text": "exists very clever N\nsquared algorithms.", "start": 974.59, "duration": 4.09}, {"text": "For others, you\ncan't beat N cubed.", "start": 978.68, "duration": 2.7}, {"text": "But even N squared is\nreally not very good.", "start": 981.38, "duration": 6.04}, {"text": "Which gets me to a much\nfaster greedy algorithm called", "start": 987.42, "duration": 3.25}, {"text": "k-means.", "start": 990.67, "duration": 0.5}, {"text": "Now, the k in k-means is the\nnumber of clusters you want.", "start": 993.74, "duration": 6.61}, {"text": "So the catch with\nk-means is if you", "start": 1000.35, "duration": 2.16}, {"text": "don't have any idea how\nmany clusters you want,", "start": 1002.51, "duration": 3.54}, {"text": "it's problematical,\nwhereas hierarchical, you", "start": 1006.05, "duration": 4.21}, {"text": "get to inspect it and\nsee what you're getting.", "start": 1010.26, "duration": 3.38}, {"text": "If you know how many you\nwant, it's a good choice", "start": 1013.64, "duration": 3.69}, {"text": "because it's much faster.", "start": 1017.33, "duration": 1.68}, {"text": "All right, the algorithm,\nagain, is very simple.", "start": 1022.17, "duration": 5.149}, {"text": "This is the one that Professor\nGrimson briefly discussed.", "start": 1027.319, "duration": 3.77}, {"text": "You randomly choose k examples\nas your initial centroids.", "start": 1031.089, "duration": 5.26}, {"text": "Doesn't matter which of\nthe examples you choose.", "start": 1036.349, "duration": 3.621}, {"text": "Then you create k clusters\nby assigning each example", "start": 1039.97, "duration": 4.05}, {"text": "to the closest centroid,\ncompute k new centroids", "start": 1044.02, "duration": 7.42}, {"text": "by averaging the\nexamples in each cluster.", "start": 1051.44, "duration": 4.03}, {"text": "So in the first iteration,\nthe centroids are all examples", "start": 1055.47, "duration": 5.48}, {"text": "that you started with.", "start": 1060.95, "duration": 1.51}, {"text": "But after that, they're\nprobably not examples,", "start": 1062.46, "duration": 3.95}, {"text": "because you're now taking the\naverage of two examples, which", "start": 1066.41, "duration": 3.21}, {"text": "may not correspond to\nany example you have.", "start": 1069.62, "duration": 3.45}, {"text": "Actually the average\nof N examples.", "start": 1073.07, "duration": 3.74}, {"text": "And then you just\nkeep doing this", "start": 1076.81, "duration": 2.31}, {"text": "until the centroids don't move.", "start": 1079.12, "duration": 3.61}, {"text": "Right?", "start": 1082.73, "duration": 0.5}, {"text": "Once you go through\none iteration", "start": 1083.23, "duration": 1.645}, {"text": "where they don't\nmove, there's no point", "start": 1084.875, "duration": 1.625}, {"text": "in recomputing them again\nand again and again,", "start": 1086.5, "duration": 3.6}, {"text": "so it is converged.", "start": 1090.1, "duration": 2.34}, {"text": "So let's look at the complexity.", "start": 1096.61, "duration": 4.12}, {"text": "Well, at the moment,\nwe can't tell you", "start": 1100.73, "duration": 3.08}, {"text": "how many iterations\nyou're going to have,", "start": 1103.81, "duration": 2.16}, {"text": "but what's the complexity\nof one iteration?", "start": 1105.97, "duration": 2.4}, {"text": "Well, let's think about\nwhat you're doing here.", "start": 1114.64, "duration": 4.25}, {"text": "You've got k centroids.", "start": 1118.89, "duration": 4.35}, {"text": "Now I have to take each\nexample and compare it", "start": 1123.24, "duration": 3.33}, {"text": "to each-- in a naively, at\nleast-- to each centroid", "start": 1126.57, "duration": 3.45}, {"text": "to see which it's closest to.", "start": 1130.02, "duration": 2.73}, {"text": "Right?", "start": 1132.75, "duration": 1.56}, {"text": "So that's k comparisons\nper example.", "start": 1134.31, "duration": 7.2}, {"text": "So that's k times\nn times d, where", "start": 1141.51, "duration": 5.97}, {"text": "how much time each of\nthese comparison takes,", "start": 1147.48, "duration": 3.0}, {"text": "which is likely to depend\nupon the dimensionality", "start": 1150.48, "duration": 2.43}, {"text": "of the features, right?", "start": 1152.91, "duration": 1.83}, {"text": "Just the Euclidean\ndistance, for example.", "start": 1154.74, "duration": 2.57}, {"text": "But this is a way small number\nthan N squared, typically.", "start": 1160.15, "duration": 5.45}, {"text": "So each iteration\nis pretty quick,", "start": 1165.6, "duration": 1.89}, {"text": "and in practice, as\nwe'll see, this typically", "start": 1167.49, "duration": 3.84}, {"text": "converges quite\nquickly, so you usually", "start": 1171.33, "duration": 3.21}, {"text": "need a very small\nnumber of iterations.", "start": 1174.54, "duration": 4.58}, {"text": "So it is quite\nefficient, and then there", "start": 1179.12, "duration": 2.46}, {"text": "are various ways\nyou can optimize it", "start": 1181.58, "duration": 2.25}, {"text": "to make it even more efficient.", "start": 1183.83, "duration": 2.07}, {"text": "This is the most commonly-used\nclustering algorithm", "start": 1185.9, "duration": 4.02}, {"text": "because it works really fast.", "start": 1189.92, "duration": 3.28}, {"text": "Let's look at an example.", "start": 1193.2, "duration": 2.02}, {"text": "So I've got a bunch\nof blue points here,", "start": 1195.22, "duration": 3.66}, {"text": "and I actually wrote\nthe code to do this.", "start": 1198.88, "duration": 3.21}, {"text": "I'm not going to\nshow you the code.", "start": 1202.09, "duration": 1.68}, {"text": "And I chose four centroids\nat random, colored stars.", "start": 1203.77, "duration": 9.25}, {"text": "A green one, a fuchsia-colored\none, a red one, and a blue one.", "start": 1213.02, "duration": 5.37}, {"text": "So maybe they're not the\nones you would have chosen,", "start": 1221.41, "duration": 3.07}, {"text": "but there they are.", "start": 1224.48, "duration": 0.9}, {"text": "And I then, having chosen\nthem, assign each point", "start": 1228.03, "duration": 5.6}, {"text": "to one of those centroids,\nwhichever one it's closest to.", "start": 1233.63, "duration": 4.92}, {"text": "All right?", "start": 1238.55, "duration": 2.11}, {"text": "Step one.", "start": 1240.66, "duration": 0.63}, {"text": "And then I recompute\nthe centroid.", "start": 1245.68, "duration": 4.67}, {"text": "So let's go back.", "start": 1250.35, "duration": 0.91}, {"text": "So we're here, and these\nare the initial centroids.", "start": 1253.78, "duration": 5.24}, {"text": "Now, when I find\nthe new centroids,", "start": 1259.02, "duration": 4.26}, {"text": "if we look at where\nthe red one is,", "start": 1263.28, "duration": 2.85}, {"text": "the red one is this point,\nthis point, and this point.", "start": 1266.13, "duration": 4.41}, {"text": "Clearly, the new centroid\nis going to move, right?", "start": 1270.54, "duration": 3.63}, {"text": "It's going to move somewhere\nalong in here or something", "start": 1274.17, "duration": 2.58}, {"text": "like that, right?", "start": 1276.75, "duration": 3.2}, {"text": "So we'll get those\nnew centroids.", "start": 1279.95, "duration": 4.204}, {"text": "There it is.", "start": 1284.154, "duration": 2.306}, {"text": "And now we'll re-assign points.", "start": 1286.46, "duration": 5.41}, {"text": "And what we'll see is this point\nis now closer to the red star", "start": 1291.87, "duration": 6.32}, {"text": "than it is to the fuchsia\nstar, because we've", "start": 1298.19, "duration": 3.15}, {"text": "moved the red star.", "start": 1301.34, "duration": 2.58}, {"text": "Whoops.", "start": 1303.92, "duration": 1.05}, {"text": "That one.", "start": 1304.97, "duration": 1.225}, {"text": "Said the wrong thing.", "start": 1306.195, "duration": 0.875}, {"text": "They were red to start with.", "start": 1307.07, "duration": 1.59}, {"text": "This one is now suddenly\ncloser to the purple, so--", "start": 1308.66, "duration": 4.83}, {"text": "and to the red.", "start": 1313.49, "duration": 0.66}, {"text": "It will get recolored.", "start": 1314.15, "duration": 1.77}, {"text": "We compute the new centroids.", "start": 1315.92, "duration": 1.43}, {"text": "We're going to move\nsomething again.", "start": 1319.97, "duration": 2.13}, {"text": "We continue.", "start": 1322.1, "duration": 1.47}, {"text": "Points will move around.", "start": 1323.57, "duration": 1.72}, {"text": "This time we move two points.", "start": 1325.29, "duration": 3.33}, {"text": "Here we go again.", "start": 1328.62, "duration": 1.2}, {"text": "Notice, again, the\ncentroids don't", "start": 1329.82, "duration": 2.16}, {"text": "correspond to actual examples.", "start": 1331.98, "duration": 2.11}, {"text": "This one is close, but it's\nnot really one of them.", "start": 1334.09, "duration": 2.33}, {"text": "Move two more.", "start": 1339.21, "duration": 1.72}, {"text": "Recompute centroids,\nand we're done.", "start": 1340.93, "duration": 3.11}, {"text": "So here we've converged, and I\nthink it was five iterations,", "start": 1344.04, "duration": 5.26}, {"text": "and nothing will move again.", "start": 1349.3, "duration": 2.181}, {"text": "All right?", "start": 1351.481, "duration": 0.499}, {"text": "Does that make\nsense to everybody?", "start": 1351.98, "duration": 2.374}, {"text": "So it's pretty simple.", "start": 1354.354, "duration": 0.916}, {"text": "What are the downsides?", "start": 1358.42, "duration": 1.35}, {"text": "Well, choosing k foolishly\ncan lead to strange results.", "start": 1359.77, "duration": 5.4}, {"text": "So if I chose k\nequal to 3, looking", "start": 1365.17, "duration": 3.93}, {"text": "at this particular\narrangement of points,", "start": 1369.1, "duration": 2.37}, {"text": "it's not obvious what \"the\nright answer\" is, right?", "start": 1371.47, "duration": 4.2}, {"text": "Maybe it's making all\nof this one cluster.", "start": 1375.67, "duration": 2.46}, {"text": "I don't know.", "start": 1378.13, "duration": 1.97}, {"text": "But there are weird\nk's and if you", "start": 1380.1, "duration": 2.79}, {"text": "choose a k that is nonsensical\nwith respect to your data,", "start": 1382.89, "duration": 5.16}, {"text": "then your clustering\nwill be nonsensical.", "start": 1388.05, "duration": 3.42}, {"text": "So that's one problem\nwe have think about.", "start": 1391.47, "duration": 1.77}, {"text": "How do we choose k?", "start": 1393.24, "duration": 3.09}, {"text": "Another problem, and this is\none somebody raised last time,", "start": 1396.33, "duration": 3.79}, {"text": "is that the results can depend\nupon the initial centroids.", "start": 1400.12, "duration": 4.44}, {"text": "Unlike hierarchical clustering,\nk-means is non-deterministic.", "start": 1404.56, "duration": 4.77}, {"text": "Depending upon what\nrandom examples we choose,", "start": 1409.33, "duration": 5.13}, {"text": "we can get a different\nnumber of iterations.", "start": 1414.46, "duration": 2.01}, {"text": "If we choose them poorly, it\ncould take longer to converge.", "start": 1416.47, "duration": 3.72}, {"text": "More worrisome, you\nget a different answer.", "start": 1420.19, "duration": 3.92}, {"text": "You're running this\ngreedy algorithm,", "start": 1424.11, "duration": 1.56}, {"text": "and you might actually\nget to a different place,", "start": 1425.67, "duration": 2.25}, {"text": "depending upon which\ncentroids you chose.", "start": 1427.92, "duration": 1.8}, {"text": "So these are the\ntwo issues we have", "start": 1432.39, "duration": 1.82}, {"text": "to think about dealing with.", "start": 1434.21, "duration": 2.79}, {"text": "So let's first think\nabout choosing k.", "start": 1437.0, "duration": 3.98}, {"text": "What often happens\nis people choose", "start": 1440.98, "duration": 3.42}, {"text": "k using a priori knowledge\nabout the application.", "start": 1444.4, "duration": 3.42}, {"text": "If I'm in medicine,\nI actually know", "start": 1450.67, "duration": 2.4}, {"text": "that there are only\nfive different kinds", "start": 1453.07, "duration": 2.01}, {"text": "of bacteria in the world.", "start": 1455.08, "duration": 2.2}, {"text": "That's true.", "start": 1457.28, "duration": 1.83}, {"text": "I mean, there are subspecies,\nbut five large categories.", "start": 1459.11, "duration": 3.82}, {"text": "And if I had a bunch of\nbacterium I wanted to cluster,", "start": 1462.93, "duration": 3.05}, {"text": "may just set k equal to 5.", "start": 1465.98, "duration": 4.07}, {"text": "Maybe I believe there are\nonly two kinds of people", "start": 1470.05, "duration": 2.34}, {"text": "in the world, those who are\nat MIT and those who are not.", "start": 1472.39, "duration": 3.195}, {"text": "And so I'll choose k equal to 2.", "start": 1475.585, "duration": 1.965}, {"text": "Often, we know enough about the\napplication, we can choose k.", "start": 1480.2, "duration": 4.86}, {"text": "As we'll see later, often we\ncan think we do, and we don't.", "start": 1485.06, "duration": 4.05}, {"text": "A better approach is\nto search for a good k.", "start": 1491.94, "duration": 4.22}, {"text": "So you can try\ndifferent values of k", "start": 1501.05, "duration": 2.85}, {"text": "and evaluate the\nquality of the result.", "start": 1503.9, "duration": 4.15}, {"text": "Assume you have some\nmetric, as to say yeah,", "start": 1508.05, "duration": 1.875}, {"text": "I like this clustering, I\ndon't like this clustering.", "start": 1509.925, "duration": 3.365}, {"text": "And we'll talk about\ndo that in detail.", "start": 1513.29, "duration": 3.12}, {"text": "Or you can run hierarchical\nclustering on a subset of data.", "start": 1516.41, "duration": 5.85}, {"text": "I've got a million points.", "start": 1522.26, "duration": 1.71}, {"text": "All right, what I'm going to\ndo is take a subset of 1,000", "start": 1523.97, "duration": 3.09}, {"text": "of them or 10,000.", "start": 1527.06, "duration": 1.57}, {"text": "Run hierarchical clustering.", "start": 1528.63, "duration": 2.92}, {"text": "From that, get a sense of the\nstructure underlying the data.", "start": 1531.55, "duration": 5.2}, {"text": "Decide k should be 6, and then\nrun k-means with k equals 6.", "start": 1536.75, "duration": 4.9}, {"text": "People often do this.", "start": 1541.65, "duration": 1.29}, {"text": "They run hierarchical clustering\non a small subset of the data", "start": 1542.94, "duration": 4.44}, {"text": "and then choose k.", "start": 1547.38, "duration": 1.19}, {"text": "And we'll look-- but one we're\ngoing to look at is that one.", "start": 1551.86, "duration": 5.97}, {"text": "What about unlucky centroids?", "start": 1557.83, "duration": 2.98}, {"text": "So here I got the same\npoints we started with.", "start": 1560.81, "duration": 4.83}, {"text": "Different initial centroids.", "start": 1565.64, "duration": 2.75}, {"text": "I've got a fuchsia\none, a black one,", "start": 1568.39, "duration": 2.92}, {"text": "and then I've got red\nand blue down here,", "start": 1571.31, "duration": 4.82}, {"text": "which I happened to accidentally\nchoose close to one another.", "start": 1576.13, "duration": 5.65}, {"text": "Well, if I start\nwith these centroids,", "start": 1581.78, "duration": 3.18}, {"text": "certainly you\nwould expect things", "start": 1584.96, "duration": 2.34}, {"text": "to take longer to converge.", "start": 1587.3, "duration": 2.17}, {"text": "But in fact, what\nhappens is this--", "start": 1589.47, "duration": 2.11}, {"text": "I get this assignment of\nblue, this assignment of red,", "start": 1594.45, "duration": 5.61}, {"text": "and I'm done.", "start": 1600.06, "duration": 3.1}, {"text": "It converges on this,\nwhich probably is not", "start": 1603.16, "duration": 5.82}, {"text": "what we wanted out of this.", "start": 1608.98, "duration": 2.43}, {"text": "Maybe it is, but the\nfact that I converged", "start": 1611.41, "duration": 2.94}, {"text": "on some very\ndifferent place shows", "start": 1614.35, "duration": 3.15}, {"text": "that it's a real weakness\nof the algorithm,", "start": 1617.5, "duration": 1.98}, {"text": "that it's sensitive to the\nrandomly-chosen initial", "start": 1619.48, "duration": 2.94}, {"text": "conditions.", "start": 1622.42, "duration": 3.318}, {"text": "Well, couple of things\nyou can do about that.", "start": 1625.738, "duration": 5.262}, {"text": "You could be clever and try and\nselect good initial centroids.", "start": 1631.0, "duration": 6.18}, {"text": "So people often will do that,\nand what they'll do is try", "start": 1637.18, "duration": 2.97}, {"text": "and just make sure that they're\ndistributed over the space.", "start": 1640.15, "duration": 4.59}, {"text": "So they would look at\nsome picture like this", "start": 1644.74, "duration": 2.55}, {"text": "and say, well, let's just put\nmy centroids at the corners", "start": 1647.29, "duration": 4.65}, {"text": "or something like that so\nthat they're far apart.", "start": 1651.94, "duration": 3.63}, {"text": "Another approach is\nto try multiple sets", "start": 1659.76, "duration": 3.2}, {"text": "of randomly-chosen\ncentroids, and then", "start": 1662.96, "duration": 3.32}, {"text": "just select the best results.", "start": 1666.28, "duration": 1.545}, {"text": "And that's what this little\nalgorithm on the screen does.", "start": 1670.83, "duration": 5.15}, {"text": "So I'll say best is equal\nto k-means of the points", "start": 1675.98, "duration": 4.56}, {"text": "themselves, or\nsomething, then for t", "start": 1680.54, "duration": 4.81}, {"text": "in range number of trials, I'll\nsay C equals k-means of points,", "start": 1685.35, "duration": 5.28}, {"text": "and I'll just keep track and\nchoose the one with the least", "start": 1690.63, "duration": 3.45}, {"text": "dissimilarity.", "start": 1694.08, "duration": 1.326}, {"text": "The thing I'm\ntrying to minimize.", "start": 1695.406, "duration": 1.374}, {"text": "OK?", "start": 1696.78, "duration": 0.5}, {"text": "The first one is got all\nthe points in one cluster.", "start": 1701.45, "duration": 3.46}, {"text": "So it's very dissimilar.", "start": 1704.91, "duration": 2.55}, {"text": "And then I'll just\nkeep generating", "start": 1707.46, "duration": 1.59}, {"text": "for different k's\nand I'll choose", "start": 1709.05, "duration": 2.16}, {"text": "the k that seems to\nbe the best, that", "start": 1711.21, "duration": 3.49}, {"text": "does the best job of minimizing\nmy objective function.", "start": 1714.7, "duration": 5.04}, {"text": "And this is a very common\nsolution, by the way,", "start": 1719.74, "duration": 2.91}, {"text": "for any randomized\ngreedy algorithm.", "start": 1722.65, "duration": 3.36}, {"text": "And there are a lot of\nrandomized greedy algorithms", "start": 1726.01, "duration": 3.27}, {"text": "that you just choose\nmultiple initial conditions,", "start": 1729.28, "duration": 3.99}, {"text": "try them all out\nand pick the best.", "start": 1733.27, "duration": 2.31}, {"text": "All right, now I\nwant to show you", "start": 1739.45, "duration": 1.38}, {"text": "a slightly more real example.", "start": 1740.83, "duration": 3.755}, {"text": "So this is a file we've\ngot with medical patients,", "start": 1747.53, "duration": 5.94}, {"text": "and we're going to try\nand cluster them and see", "start": 1753.47, "duration": 3.81}, {"text": "whether the clusters\ntell us anything", "start": 1757.28, "duration": 1.89}, {"text": "about the probability\nof them dying", "start": 1759.17, "duration": 2.82}, {"text": "of a heart attack in, say,\nthe next year or some period", "start": 1761.99, "duration": 4.35}, {"text": "of time.", "start": 1766.34, "duration": 1.57}, {"text": "So to simplify things,\nand this is something", "start": 1767.91, "duration": 2.66}, {"text": "I have done with research,\nbut we're looking", "start": 1770.57, "duration": 2.49}, {"text": "at only four features here--", "start": 1773.06, "duration": 2.49}, {"text": "the heart rate in\nbeats per minute,", "start": 1775.55, "duration": 4.02}, {"text": "the number of previous heart\nattacks, the age, and something", "start": 1779.57, "duration": 6.68}, {"text": "called ST elevation,\na binary attribute.", "start": 1786.25, "duration": 3.43}, {"text": "So the first three are obvious.", "start": 1789.68, "duration": 3.02}, {"text": "If you take an ECG of somebody's\nheart, it looks like this.", "start": 1792.7, "duration": 4.81}, {"text": "This is a normal one.", "start": 1797.51, "duration": 2.39}, {"text": "They have the S, the\nT, and then there's", "start": 1799.9, "duration": 1.95}, {"text": "this region between the\nS wave and the T wave.", "start": 1801.85, "duration": 4.63}, {"text": "And if it's higher, hence\nelevated, that's a bad thing.", "start": 1806.48, "duration": 5.47}, {"text": "And so this is about\nthe first thing", "start": 1811.95, "duration": 1.94}, {"text": "that they measure if someone\nis having cardiac problems.", "start": 1813.89, "duration": 3.66}, {"text": "Do they have ST elevation?", "start": 1817.55, "duration": 1.94}, {"text": "And then with each\npatient, we're", "start": 1822.37, "duration": 1.92}, {"text": "going to have an outcome,\nwhether they died,", "start": 1824.29, "duration": 3.98}, {"text": "and it's related\nto the features,", "start": 1828.27, "duration": 3.12}, {"text": "but it's probabilistic\nnot deterministic.", "start": 1831.39, "duration": 4.06}, {"text": "So for example, an older person\nwith multiple heart attacks", "start": 1835.45, "duration": 4.47}, {"text": "is at higher risk than\na young person who's", "start": 1839.92, "duration": 2.55}, {"text": "never had a heart attack.", "start": 1842.47, "duration": 2.222}, {"text": "That doesn't mean,\nthough, that the older", "start": 1844.692, "duration": 1.708}, {"text": "person will die first.", "start": 1846.4, "duration": 2.04}, {"text": "It's just more probable.", "start": 1848.44, "duration": 1.275}, {"text": "We're going to take this data,\nwe're going to cluster it,", "start": 1854.29, "duration": 3.037}, {"text": "and then we're going\nto look at what's", "start": 1857.327, "duration": 1.583}, {"text": "called the purity\nof the clusters", "start": 1858.91, "duration": 4.06}, {"text": "relative to the outcomes.", "start": 1862.97, "duration": 3.06}, {"text": "So is the cluster, say,\nenriched by people who died?", "start": 1866.03, "duration": 5.35}, {"text": "If you have one cluster\nand everyone in it died,", "start": 1871.38, "duration": 3.0}, {"text": "then the clustering is\nclearly finding some structure", "start": 1874.38, "duration": 3.03}, {"text": "related to the outcome.", "start": 1877.41, "duration": 1.08}, {"text": "So the file is in the\nzip file I uploaded.", "start": 1883.99, "duration": 3.92}, {"text": "It looks more or less like this.", "start": 1887.91, "duration": 2.325}, {"text": "Right?", "start": 1890.235, "duration": 0.705}, {"text": "So it's very straightforward.", "start": 1890.94, "duration": 2.1}, {"text": "The outcomes are binary.", "start": 1893.04, "duration": 1.27}, {"text": "1 is a positive outcome.", "start": 1894.31, "duration": 2.63}, {"text": "Strangely enough in\nthe medical jargon,", "start": 1896.94, "duration": 2.28}, {"text": "a death is a positive outcome.", "start": 1899.22, "duration": 3.0}, {"text": "I guess maybe if you're\nresponsible for the medical", "start": 1902.22, "duration": 2.58}, {"text": "bills, it's positive.", "start": 1904.8, "duration": 1.55}, {"text": "If you're the patient, it's hard\nto think of it as a good thing.", "start": 1906.35, "duration": 4.06}, {"text": "Nevertheless, that's\nthe way that they talk.", "start": 1910.41, "duration": 3.12}, {"text": "And the others are\nall there, right?", "start": 1913.53, "duration": 1.92}, {"text": "Heart rate, other things.", "start": 1915.45, "duration": 4.26}, {"text": "All right, let's\nlook at some code.", "start": 1919.71, "duration": 1.77}, {"text": "So I've extracted some code.", "start": 1924.16, "duration": 1.321}, {"text": "I'm not going to\nshow you all of it.", "start": 1925.481, "duration": 1.499}, {"text": "There's quite a lot\nof it, as you'll see.", "start": 1926.98, "duration": 3.93}, {"text": "So we'll start-- one\nof the files you've got", "start": 1930.91, "duration": 3.54}, {"text": "is called cluster dot pi.", "start": 1934.45, "duration": 2.73}, {"text": "I decided there\nwas enough code, I", "start": 1937.18, "duration": 1.71}, {"text": "didn't want to put\nit all in one file.", "start": 1938.89, "duration": 2.13}, {"text": "I was getting confused.", "start": 1941.02, "duration": 1.84}, {"text": "So I said, let me\ncreate a file that", "start": 1942.86, "duration": 1.7}, {"text": "has some of the code\nand a different file", "start": 1944.56, "duration": 3.39}, {"text": "that will then\nimport it and use it.", "start": 1947.95, "duration": 2.16}, {"text": "Cluster has things\nthat are pretty much", "start": 1950.11, "duration": 3.39}, {"text": "unrelated to this example, but\njust useful for clustering.", "start": 1953.5, "duration": 5.2}, {"text": "So an example here has\nname, features, and label.", "start": 1958.7, "duration": 6.27}, {"text": "And really, the only\ninteresting thing in it--", "start": 1964.97, "duration": 2.77}, {"text": "and it's not that\ninteresting-- is distance.", "start": 1967.74, "duration": 3.14}, {"text": "And the fact that I'm\nusing Minkowski with 2", "start": 1970.88, "duration": 4.11}, {"text": "says we're using\nEuclidean distance.", "start": 1974.99, "duration": 1.77}, {"text": "Class cluster.", "start": 1982.29, "duration": 2.11}, {"text": "It's a lot more\ncode to that one.", "start": 1984.4, "duration": 4.01}, {"text": "So we start with a\nnon-empty list of examples.", "start": 1988.41, "duration": 2.94}, {"text": "That's what init does.", "start": 1991.35, "duration": 1.05}, {"text": "You can imagine what\nthe code looks like,", "start": 1992.4, "duration": 1.98}, {"text": "or you can look at it.", "start": 1994.38, "duration": 2.7}, {"text": "Update is interesting in that it\ntakes the cluster and examples", "start": 1997.08, "duration": 8.5}, {"text": "and puts them in-- if you\nthink of k-means in the cluster", "start": 2005.58, "duration": 9.97}, {"text": "closest to the\nprevious centroids", "start": 2015.55, "duration": 3.09}, {"text": "and then returns the amount\nthe centroid has changed.", "start": 2018.64, "duration": 4.86}, {"text": "So if the centroid\nhas changed by 0,", "start": 2023.5, "duration": 2.2}, {"text": "then you don't have\nanything, right?", "start": 2025.7, "duration": 2.44}, {"text": "Creates the new cluster.", "start": 2028.14, "duration": 2.13}, {"text": "And the most interesting\nthing is computeCentroid.", "start": 2030.27, "duration": 3.78}, {"text": "And if you look\nat this code, you", "start": 2034.05, "duration": 1.38}, {"text": "can see that I'm a slightly\nunreconstructed Python 2", "start": 2035.43, "duration": 3.39}, {"text": "programmers.", "start": 2038.82, "duration": 1.47}, {"text": "I just noticed this.", "start": 2040.29, "duration": 1.62}, {"text": "I really shouldn't\nhave written 0.0.", "start": 2041.91, "duration": 2.7}, {"text": "I should have just written\n0, but in Python 2,", "start": 2044.61, "duration": 3.81}, {"text": "you had to write that 0.0.", "start": 2048.42, "duration": 2.34}, {"text": "Sorry about that.", "start": 2050.76, "duration": 1.56}, {"text": "Thought I'd fixed these.", "start": 2052.32, "duration": 3.129}, {"text": "Anyway, so how do we\ncompute the centroid?", "start": 2055.449, "duration": 3.431}, {"text": "We start by creating\nan array of all 0s.", "start": 2058.88, "duration": 6.87}, {"text": "The dimensionality is the number\nof features in the example.", "start": 2065.75, "duration": 4.6}, {"text": "It's one of the methods from--", "start": 2070.35, "duration": 3.75}, {"text": "I didn't put up\non the PowerPoint.", "start": 2074.1, "duration": 3.03}, {"text": "And then for e in\nexamples, I'm going", "start": 2077.13, "duration": 3.18}, {"text": "to add to vals\ne.getFeatures, and then I'm", "start": 2080.31, "duration": 7.48}, {"text": "just going to divide vals by\nthe length of self.examples,", "start": 2087.79, "duration": 5.07}, {"text": "the number of examples.", "start": 2092.86, "duration": 1.62}, {"text": "So now you see why I made it a\npylab array, or a numpy array", "start": 2094.48, "duration": 5.0}, {"text": "rather than a\nlist, so I could do", "start": 2099.48, "duration": 2.7}, {"text": "nice things like divide the\nwhole thing in one expression.", "start": 2102.18, "duration": 5.71}, {"text": "As you do math, any\nkind of math things,", "start": 2107.89, "duration": 2.46}, {"text": "you'll find these arrays\nare incredibly convenient.", "start": 2110.35, "duration": 3.66}, {"text": "Rather than having to\nwrite recursive functions", "start": 2114.01, "duration": 2.43}, {"text": "or do bunches of\niterations, the fact", "start": 2116.44, "duration": 2.7}, {"text": "that you can do it in one\nkeystroke is incredibly nice.", "start": 2119.14, "duration": 4.68}, {"text": "And then I'm going to\nreturn the centroid.", "start": 2123.82, "duration": 1.75}, {"text": "Variability is exactly\nwhat we saw in the formula.", "start": 2130.33, "duration": 3.235}, {"text": "And then just for fun,\nso you could see this,", "start": 2136.36, "duration": 3.33}, {"text": "I used an iterator here.", "start": 2139.69, "duration": 2.58}, {"text": "I don't know that\nany of you have used", "start": 2142.27, "duration": 1.68}, {"text": "the yield statement in Python.", "start": 2143.95, "duration": 3.39}, {"text": "I recommend it.", "start": 2147.34, "duration": 1.14}, {"text": "It's very convenient.", "start": 2148.48, "duration": 2.02}, {"text": "One of the nice\nthings about Python", "start": 2150.5, "duration": 2.24}, {"text": "is almost anything\nthat's built in,", "start": 2152.74, "duration": 3.03}, {"text": "you can make your\nown version of it.", "start": 2155.77, "duration": 2.77}, {"text": "And so once I've done\nthis, if c is a cluster,", "start": 2158.54, "duration": 5.93}, {"text": "I can now write something\nlike for c in big C,", "start": 2164.47, "duration": 6.85}, {"text": "and this will make it work just\nlike iterating over a list.", "start": 2171.32, "duration": 6.42}, {"text": "Right, so this makes it\npossible to iterate over it.", "start": 2177.74, "duration": 4.04}, {"text": "If you haven't read\nabout yield, you probably", "start": 2181.78, "duration": 2.58}, {"text": "should read the probably\nabout two paragraphs", "start": 2184.36, "duration": 3.3}, {"text": "in the textbook\nexplaining how it works,", "start": 2187.66, "duration": 2.68}, {"text": "but it's very convenient.", "start": 2190.34, "duration": 2.98}, {"text": "Dissimilarity\nwe've already seen.", "start": 2193.32, "duration": 2.21}, {"text": "All right, now we\nget to patients.", "start": 2198.57, "duration": 3.3}, {"text": "This is in the file lec\n12, lecture 12 dot py.", "start": 2201.87, "duration": 6.43}, {"text": "In addition to importing\nthe usual suspects of pylab", "start": 2208.3, "duration": 3.51}, {"text": "and numpy, and probably it\nshould import random too,", "start": 2211.81, "duration": 5.45}, {"text": "it imports cluster, the\none we just looked at.", "start": 2217.26, "duration": 4.29}, {"text": "And so patient is a\nsub-type of cluster.Example.", "start": 2224.16, "duration": 7.43}, {"text": "Then I'm going to define\nthis interesting thing called", "start": 2231.59, "duration": 3.21}, {"text": "scale attributes.", "start": 2234.8, "duration": 3.53}, {"text": "So you might remember,\nin the last lecture", "start": 2238.33, "duration": 3.39}, {"text": "when Professor Grimson was\nlooking at these reptiles,", "start": 2241.72, "duration": 3.96}, {"text": "he ran into this\nproblem about alligators", "start": 2245.68, "duration": 3.09}, {"text": "looking like chickens\nbecause they each have", "start": 2248.77, "duration": 2.43}, {"text": "a large number of legs.", "start": 2251.2, "duration": 2.37}, {"text": "And he said, well, what can\nwe do to get around this?", "start": 2253.57, "duration": 3.76}, {"text": "Well, we can represent the\nfeature as a binary number.", "start": 2257.33, "duration": 4.34}, {"text": "Has legs, doesn't have legs.", "start": 2261.67, "duration": 1.545}, {"text": "0 or 1.", "start": 2263.215, "duration": 1.995}, {"text": "And the problem he\nwas dealing with", "start": 2265.21, "duration": 2.73}, {"text": "is that when you\nhave a feature vector", "start": 2267.94, "duration": 3.92}, {"text": "and the dynamic range\nof some features", "start": 2271.86, "duration": 4.05}, {"text": "is much greater than\nthe others, they", "start": 2275.91, "duration": 3.3}, {"text": "tend to dominate because the\ndistances just look bigger when", "start": 2279.21, "duration": 4.05}, {"text": "you get Euclidean distance.", "start": 2283.26, "duration": 2.93}, {"text": "So for example, if we\nwanted to cluster the people", "start": 2286.19, "duration": 2.57}, {"text": "in this room, and I\nhad one feature that", "start": 2288.76, "duration": 5.22}, {"text": "was, say, 1 for male\nand 0 for female,", "start": 2293.98, "duration": 4.53}, {"text": "and another feature that\nwas 1 for wears glasses,", "start": 2298.51, "duration": 3.3}, {"text": "0 for doesn't wear glasses,\nand then a third feature which", "start": 2301.81, "duration": 4.68}, {"text": "was weight, and\nI clustered them,", "start": 2306.49, "duration": 4.77}, {"text": "well, weight would\nalways completely", "start": 2311.26, "duration": 1.98}, {"text": "dominate the Euclidean\ndistance, right?", "start": 2313.24, "duration": 3.45}, {"text": "Because the dynamic range\nof the weights in this", "start": 2316.69, "duration": 2.34}, {"text": "room is much higher than\nthe dynamic range of 0 to 1.", "start": 2319.03, "duration": 6.42}, {"text": "And so for the reptiles,\nhe said, well, OK, we'll", "start": 2325.45, "duration": 5.67}, {"text": "just make it a binary variable.", "start": 2331.12, "duration": 2.52}, {"text": "But maybe we don't\nwant to make weight", "start": 2333.64, "duration": 1.77}, {"text": "a binary variable, because\nmaybe it is something", "start": 2335.41, "duration": 2.76}, {"text": "we want to take into account.", "start": 2338.17, "duration": 2.71}, {"text": "So what we do is we scale it.", "start": 2340.88, "duration": 3.47}, {"text": "So this is a method\ncalled z-scaling.", "start": 2344.35, "duration": 4.74}, {"text": "More general than just\nmaking things 0 or 1.", "start": 2349.09, "duration": 5.19}, {"text": "It's a simple code.", "start": 2354.28, "duration": 1.92}, {"text": "It takes in all of the\nvalues of a specific feature", "start": 2356.2, "duration": 6.04}, {"text": "and then performs some\nsimple calculations,", "start": 2362.24, "duration": 3.79}, {"text": "and when it's done, the\nresulting array it returns", "start": 2366.03, "duration": 8.94}, {"text": "has a known mean and a\nknown standard deviation.", "start": 2374.97, "duration": 5.35}, {"text": "So what's the mean going to be?", "start": 2380.32, "duration": 1.64}, {"text": "It's always going to be\nthe same thing, independent", "start": 2381.96, "duration": 2.219}, {"text": "of the initial values.", "start": 2384.179, "duration": 0.916}, {"text": "Take a look at the code.", "start": 2387.66, "duration": 1.26}, {"text": "Try and see if you\ncan figure it out.", "start": 2388.92, "duration": 1.59}, {"text": "Anybody want to\ntake a guess at it?", "start": 2395.19, "duration": 2.78}, {"text": "0.", "start": 2397.97, "duration": 1.58}, {"text": "Right?", "start": 2399.55, "duration": 0.57}, {"text": "So the mean will always be 0.", "start": 2400.12, "duration": 4.04}, {"text": "And the standard deviation,\na little harder to figure,", "start": 2404.16, "duration": 2.88}, {"text": "but it will always be 1.", "start": 2407.04, "duration": 1.29}, {"text": "OK?", "start": 2413.32, "duration": 0.5}, {"text": "So it's done this scaling.", "start": 2413.82, "duration": 3.32}, {"text": "This is a very common kind\nof scaling called z-scaling.", "start": 2417.14, "duration": 5.02}, {"text": "The other way people\nscale is interpolate.", "start": 2422.16, "duration": 2.99}, {"text": "They take the smallest value and\ncall it 0, the biggest value,", "start": 2425.15, "duration": 4.29}, {"text": "they call it 1, and then they\ndo a linear interpolation", "start": 2429.44, "duration": 4.14}, {"text": "of all the values\nbetween 0 and 1.", "start": 2433.58, "duration": 2.65}, {"text": "So the range is 0 to 1.", "start": 2436.23, "duration": 3.34}, {"text": "That's also very common.", "start": 2439.57, "duration": 3.66}, {"text": "So this is a general\nway to get all", "start": 2443.23, "duration": 2.37}, {"text": "of the features sort\nof in the same ballpark", "start": 2445.6, "duration": 3.236}, {"text": "so that we can compare them.", "start": 2448.836, "duration": 1.166}, {"text": "And we'll look at what\nhappens when we scale", "start": 2453.1, "duration": 2.04}, {"text": "and when we don't scale.", "start": 2455.14, "duration": 2.34}, {"text": "And that's why my getData\nfunction has this parameter", "start": 2457.48, "duration": 3.72}, {"text": "to scale.", "start": 2461.2, "duration": 1.62}, {"text": "It either creates a set of\nexamples with the attributes", "start": 2462.82, "duration": 3.33}, {"text": "as initially or scaled.", "start": 2466.15, "duration": 3.94}, {"text": "And then there's k-means.", "start": 2470.09, "duration": 1.89}, {"text": "It's exactly the\nalgorithm I showed you", "start": 2471.98, "duration": 2.94}, {"text": "with one little wrinkle,\nwhich is this part.", "start": 2474.92, "duration": 5.28}, {"text": "You don't want to end\nup with empty clusters.", "start": 2480.2, "duration": 3.0}, {"text": "If I tell you I\nwant four clusters,", "start": 2483.2, "duration": 2.97}, {"text": "I don't mean I want\nthree with examples", "start": 2486.17, "duration": 2.07}, {"text": "and one that's empty, right?", "start": 2488.24, "duration": 2.15}, {"text": "Because then I really\ndon't have four clusters.", "start": 2490.39, "duration": 3.66}, {"text": "And so this is one\nof multiple ways", "start": 2494.05, "duration": 2.79}, {"text": "to avoid having empty clusters.", "start": 2496.84, "duration": 2.67}, {"text": "Basically what I\ndid here is say,", "start": 2499.51, "duration": 1.96}, {"text": "well, I'm going to try a lot of\ndifferent initial conditions.", "start": 2501.47, "duration": 3.17}, {"text": "If one of them is so unlucky\nto give me an empty cluster,", "start": 2504.64, "duration": 3.24}, {"text": "I'm just going to skip it\nand go on to the next one", "start": 2507.88, "duration": 3.67}, {"text": "by raising a value\nerror, empty cluster.", "start": 2511.55, "duration": 4.342}, {"text": "And if you look at\nthe code, you'll", "start": 2515.892, "duration": 1.458}, {"text": "see how this value\nerror is used.", "start": 2517.35, "duration": 3.1}, {"text": "And then try k-means.", "start": 2520.45, "duration": 2.24}, {"text": "We'll call k-means numTrial\ntimes, each one getting", "start": 2522.69, "duration": 4.8}, {"text": "a different set of\ninitial centroids,", "start": 2527.49, "duration": 3.57}, {"text": "and return the result with\nthe lowest dissimilarity.", "start": 2531.06, "duration": 2.49}, {"text": "Then I have various ways\nto examine the results.", "start": 2536.82, "duration": 6.27}, {"text": "Nothing very\ninteresting, and here's", "start": 2543.09, "duration": 1.95}, {"text": "the key place where we're\ngoing to run the whole thing.", "start": 2545.04, "duration": 3.15}, {"text": "We'll get the data,\ninitially not scaling it,", "start": 2548.19, "duration": 3.78}, {"text": "because remember,\nit defaults to true.", "start": 2551.97, "duration": 2.23}, {"text": "Then initially, I'm only going\nto try one k. k equals 2.", "start": 2554.2, "duration": 4.57}, {"text": "And we'll call testClustering\nwith the patients.", "start": 2558.77, "duration": 9.18}, {"text": "The number of clusters, k.", "start": 2567.95, "duration": 2.97}, {"text": "I put in seed as\na parameter here", "start": 2570.92, "duration": 2.85}, {"text": "because I wanted to be\nable to play with it", "start": 2573.77, "duration": 2.31}, {"text": "and make sure I got different\nthings for 0 and 1 and 2", "start": 2576.08, "duration": 3.63}, {"text": "just as a testing thing.", "start": 2579.71, "duration": 1.92}, {"text": "And five trials\nit's defaulting to.", "start": 2581.63, "duration": 4.6}, {"text": "And then we'll look\nat testClustering", "start": 2586.23, "duration": 6.25}, {"text": "is returning the fraction\nof positive examples", "start": 2592.48, "duration": 4.62}, {"text": "for each cluster.", "start": 2597.1, "duration": 2.68}, {"text": "OK?", "start": 2599.78, "duration": 1.95}, {"text": "So let's see what\nhappens when we run it.", "start": 2601.73, "duration": 1.8}, {"text": "All right.", "start": 2619.69, "duration": 1.77}, {"text": "So we got two clusters.", "start": 2621.46, "duration": 2.25}, {"text": "Cluster of size 118 with\n.3305, and a cluster", "start": 2623.71, "duration": 5.88}, {"text": "of size 132 with a positive\nfraction of point quadruple 3.", "start": 2629.59, "duration": 5.42}, {"text": "Should we be happy?", "start": 2639.23, "duration": 4.0}, {"text": "Does our clustering tell\nus anything, somehow", "start": 2643.23, "duration": 4.64}, {"text": "correspond to the expected\noutcome for patients here?", "start": 2647.87, "duration": 5.35}, {"text": "Probably not, right?", "start": 2653.22, "duration": 2.41}, {"text": "Those numbers are pretty\nmuch indistinguishable", "start": 2655.63, "duration": 2.97}, {"text": "statistically.", "start": 2658.6, "duration": 1.68}, {"text": "And you'd have to guess that\nthe fraction of positives", "start": 2660.28, "duration": 2.79}, {"text": "in the whole population\nis around .33, right?", "start": 2663.07, "duration": 3.474}, {"text": "That about a third\nof these people", "start": 2666.544, "duration": 1.416}, {"text": "died of their heart attack.", "start": 2667.96, "duration": 2.39}, {"text": "And I might as well have\nsigned them randomly", "start": 2670.35, "duration": 4.69}, {"text": "to the two clusters, right?", "start": 2675.04, "duration": 1.544}, {"text": "There's not much\ndifference between this", "start": 2676.584, "duration": 1.666}, {"text": "and what you would get\nwith the random result.", "start": 2678.25, "duration": 4.23}, {"text": "Well, why do we\nthink that's true?", "start": 2682.48, "duration": 2.01}, {"text": "Because I didn't scale, right?", "start": 2687.27, "duration": 2.28}, {"text": "And so one of the issues\nwe had to deal with", "start": 2689.55, "duration": 3.6}, {"text": "is, well, age had a\nbig dynamic range,", "start": 2693.15, "duration": 3.61}, {"text": "and, say, ST elevation, which I\ntold you was highly diagnostic,", "start": 2696.76, "duration": 5.54}, {"text": "was either 0 or 1.", "start": 2702.3, "duration": 2.3}, {"text": "And so probably\neverything is getting", "start": 2704.6, "duration": 1.68}, {"text": "swamped by age or\nsomething else, right?", "start": 2706.28, "duration": 6.54}, {"text": "All right, so we have\nan easy way to fix that.", "start": 2712.82, "duration": 4.53}, {"text": "We'll just scale the data.", "start": 2717.35, "duration": 3.09}, {"text": "Now let's see what we get.", "start": 2720.44, "duration": 1.23}, {"text": "All right.", "start": 2726.66, "duration": 0.74}, {"text": "That's interesting.", "start": 2727.4, "duration": 3.74}, {"text": "With casting rule?", "start": 2731.14, "duration": 1.95}, {"text": "Good grief.", "start": 2733.09, "duration": 2.51}, {"text": "That caught me by surprise.", "start": 2735.6, "duration": 1.41}, {"text": "Good thing I have the answers\nin PowerPoint to show you,", "start": 2748.15, "duration": 3.21}, {"text": "because the code doesn't\nseem to be working.", "start": 2751.36, "duration": 1.876}, {"text": "Try it once more.", "start": 2760.19, "duration": 0.94}, {"text": "No.", "start": 2765.31, "duration": 0.5}, {"text": "All right, well, in\nthe interest of getting", "start": 2765.81, "duration": 4.08}, {"text": "through this\nlecture on schedule,", "start": 2769.89, "duration": 1.74}, {"text": "we'll go look at the\nresults that we get--", "start": 2771.63, "duration": 3.06}, {"text": "I got last time I ran it.", "start": 2774.69, "duration": 1.601}, {"text": "All right.", "start": 2780.281, "duration": 0.499}, {"text": "When I scaled, what we see here\nis that now there is a pretty", "start": 2783.72, "duration": 8.39}, {"text": "dramatic difference, right?", "start": 2792.11, "duration": 2.66}, {"text": "One of the clusters has\na much higher fraction", "start": 2794.77, "duration": 2.4}, {"text": "of positive patients\nthan others,", "start": 2797.17, "duration": 5.86}, {"text": "but it's still a\nbit problematic.", "start": 2803.03, "duration": 3.88}, {"text": "So this has pretty\ngood specificity,", "start": 2806.91, "duration": 5.76}, {"text": "or positive predictive value,\nbut its sensitivity is lousy.", "start": 2812.67, "duration": 4.605}, {"text": "Remember, a third of our\ninitial population more or less,", "start": 2822.17, "duration": 4.47}, {"text": "was positive.", "start": 2826.64, "duration": 1.62}, {"text": "26 is way less than a\nthird, so in fact I've", "start": 2828.26, "duration": 5.06}, {"text": "got a class, a cluster,\nthat is strongly enriched,", "start": 2833.32, "duration": 5.37}, {"text": "but I'm still lumping most\nof the positive patients", "start": 2838.69, "duration": 4.56}, {"text": "into the other cluster.", "start": 2843.25, "duration": 1.1}, {"text": "And in fact, there\nare 83 positives.", "start": 2847.03, "duration": 4.76}, {"text": "Wrote some code to do that.", "start": 2851.79, "duration": 2.05}, {"text": "And so we see that\nof the 83 positives,", "start": 2853.84, "duration": 4.03}, {"text": "only this class,\nwhich is 70% positive,", "start": 2857.87, "duration": 3.93}, {"text": "only has 26 in it\nto start with it.", "start": 2861.8, "duration": 2.91}, {"text": "So I'm clearly missing\nmost of the positives.", "start": 2864.71, "duration": 4.27}, {"text": "So why?", "start": 2868.98, "duration": 2.15}, {"text": "Well, my hypothesis was\nthat different subgroups", "start": 2871.13, "duration": 3.51}, {"text": "of positive patients have\ndifferent characteristics.", "start": 2874.64, "duration": 4.212}, {"text": "And so we could test this\nby trying other values of k", "start": 2881.59, "duration": 7.49}, {"text": "to see with-- we would\nget more clusters.", "start": 2889.08, "duration": 2.49}, {"text": "So here, I said, let's\ntry k equals 2, 4, and 6.", "start": 2891.57, "duration": 2.97}, {"text": "And here's what I\ngot when I ran that.", "start": 2898.09, "duration": 1.65}, {"text": "So what you'll notice here, as\nwe get to, say, 4, that I have", "start": 2903.87, "duration": 8.14}, {"text": "two clusters, this\none and this one,", "start": 2912.01, "duration": 7.02}, {"text": "which are heavily enriched\nwith positive patients.", "start": 2919.03, "duration": 4.2}, {"text": "26 as before in the first\none, but 76 patients", "start": 2923.23, "duration": 6.3}, {"text": "in the third one.", "start": 2929.53, "duration": 1.71}, {"text": "So I'm now getting a much\nhigher fraction of patients", "start": 2931.24, "duration": 4.32}, {"text": "in one of the \"risky\" clusters.", "start": 2935.56, "duration": 5.37}, {"text": "And I can continue to do that,\nbut if I look at k equals 6,", "start": 2940.93, "duration": 8.0}, {"text": "we now look at the\npositive clusters.", "start": 2948.93, "duration": 2.49}, {"text": "There were three of them\nsignificantly positive.", "start": 2951.42, "duration": 4.14}, {"text": "But I'm not really getting\na lot more patients total,", "start": 2955.56, "duration": 4.65}, {"text": "so maybe 4 is the right answer.", "start": 2960.21, "duration": 2.05}, {"text": "So what you see here is that\nwe have at least two parameters", "start": 2964.86, "duration": 4.61}, {"text": "to play with, scaling and k.", "start": 2969.47, "duration": 3.06}, {"text": "Even though I was only\nwanted a structure", "start": 2972.53, "duration": 2.67}, {"text": "that would separate the risk--", "start": 2975.2, "duration": 1.89}, {"text": "high-risk patients\nfrom the lower-risk,", "start": 2977.09, "duration": 2.55}, {"text": "which is why I started\nwith 2, I later", "start": 2979.64, "duration": 5.5}, {"text": "discovered that, in fact,\nthere are multiple reasons", "start": 2985.14, "duration": 3.12}, {"text": "for being high-risk.", "start": 2988.26, "duration": 2.13}, {"text": "And so maybe one\nof these clusters", "start": 2990.39, "duration": 1.68}, {"text": "is heavily enriched\nby old people.", "start": 2992.07, "duration": 2.73}, {"text": "Maybe another one\nis heavily enriched", "start": 2994.8, "duration": 1.62}, {"text": "by people who have had three\nheart attacks in the past,", "start": 2996.42, "duration": 4.08}, {"text": "or ST elevation or\nsome combination.", "start": 3000.5, "duration": 3.49}, {"text": "And when I had\nonly two clusters,", "start": 3003.99, "duration": 1.55}, {"text": "I couldn't get that\nfine gradation.", "start": 3005.54, "duration": 3.1}, {"text": "So this is what data\nscientists spend", "start": 3008.64, "duration": 2.88}, {"text": "their time doing when\nthey're doing clustering,", "start": 3011.52, "duration": 2.61}, {"text": "is they actually have\nmultiple parameters.", "start": 3014.13, "duration": 3.84}, {"text": "They try different things out.", "start": 3017.97, "duration": 1.8}, {"text": "They look at the\nresults, and that's", "start": 3019.77, "duration": 2.25}, {"text": "why you actually have to think\nto manipulate data rather", "start": 3022.02, "duration": 4.02}, {"text": "than just push a button\nand wait for the answer.", "start": 3026.04, "duration": 2.82}, {"text": "All right.", "start": 3028.86, "duration": 1.2}, {"text": "More of this general\ntopic on Wednesday", "start": 3030.06, "duration": 4.29}, {"text": "when we're going to talk\nabout classification.", "start": 3034.35, "duration": 3.09}, {"text": "Thank you.", "start": 3037.44, "duration": 1.388}]