[{"text": "GILBERT STRANG: OK.", "start": 0.25, "duration": 0.8}, {"text": "More about eigenvalues\nand eigenvectors.", "start": 1.05, "duration": 2.67}, {"text": "Well, actually, it's\ngoing to be the same thing", "start": 3.72, "duration": 2.72}, {"text": "about eigenvalues\nand eigenvectors", "start": 6.44, "duration": 2.26}, {"text": "but I'm going to\nuse matrix notation.", "start": 8.7, "duration": 3.07}, {"text": "So, you remember I have a\nmatrix A, 2 by 2 for example.", "start": 11.77, "duration": 5.9}, {"text": "It's got two eigenvectors.", "start": 17.67, "duration": 2.91}, {"text": "Each eigenvector\nhas its eigenvalue.", "start": 20.58, "duration": 3.6}, {"text": "So I could write the\neigenvalue world that way.", "start": 24.18, "duration": 7.06}, {"text": "I want to write\nit in matrix form.", "start": 31.24, "duration": 2.53}, {"text": "I want to create an\neigenvector matrix", "start": 33.77, "duration": 3.81}, {"text": "by taking the two\neigenvectors and putting them", "start": 37.58, "duration": 3.99}, {"text": "in the columns of my matrix.", "start": 41.57, "duration": 1.345}, {"text": "If I have n of them, that\nallows me to give one name.", "start": 47.23, "duration": 4.67}, {"text": "The eigenvector matrix, maybe\nI'll call it V for vectors.", "start": 51.9, "duration": 5.76}, {"text": "So that's A times V. And\nnow, just bear with me", "start": 57.66, "duration": 7.29}, {"text": "while I do that\nmultiplication of A times", "start": 64.95, "duration": 2.84}, {"text": "the eigenvector matrix.", "start": 67.79, "duration": 2.32}, {"text": "So what do I get?", "start": 70.11, "duration": 1.01}, {"text": "I get a matrix.", "start": 71.12, "duration": 1.14}, {"text": "That's 2 by 2.", "start": 72.26, "duration": 1.15}, {"text": "That's 2 by 2.", "start": 73.41, "duration": 1.46}, {"text": "You get a 2 by 2 matrix.", "start": 74.87, "duration": 2.03}, {"text": "What's the first column?", "start": 76.9, "duration": 2.14}, {"text": "The first column of\nthe output is A times", "start": 79.04, "duration": 3.68}, {"text": "the first column of the input.", "start": 82.72, "duration": 2.44}, {"text": "And what is A times x1?", "start": 85.16, "duration": 3.28}, {"text": "Well, A times x1 is\nlambda 1 times x1.", "start": 88.44, "duration": 4.64}, {"text": "So that first column\nis lambda 1 x1.", "start": 93.08, "duration": 4.05}, {"text": "And A times the second column\nis Ax2, which is lambda 2 x2.", "start": 97.13, "duration": 6.39}, {"text": "So I'm seeing lambda\n2 x2 in that column.", "start": 103.52, "duration": 5.51}, {"text": "OK.", "start": 109.03, "duration": 1.64}, {"text": "Matrix notation.", "start": 110.67, "duration": 1.75}, {"text": "Those were the eigenvectors.", "start": 112.42, "duration": 1.79}, {"text": "This is the result of A times V.\nBut I can look at this a little", "start": 114.21, "duration": 7.38}, {"text": "differently.", "start": 121.59, "duration": 1.38}, {"text": "I can say, wait a minute, that\nis my eigenvector matrix, x1", "start": 122.97, "duration": 5.789}, {"text": "and x2-- those two\ncolumns-- times a matrix.", "start": 128.759, "duration": 5.891}, {"text": "Yes.", "start": 134.65, "duration": 0.5}, {"text": "Taking this first column, lambda\n1 x1, is lambda 1 times x1,", "start": 138.07, "duration": 9.49}, {"text": "plus 0 times x2.", "start": 147.56, "duration": 4.35}, {"text": "Right there I did a\nmatrix multiplication.", "start": 151.91, "duration": 3.37}, {"text": "I did it without\npreparing you for it.", "start": 155.28, "duration": 4.52}, {"text": "I'll go back and do that\npreparation in a moment.", "start": 159.8, "duration": 3.86}, {"text": "But when I multiply a matrix by\na vector, I take lambda 1 times", "start": 163.66, "duration": 7.35}, {"text": "that one, 0 times that one.", "start": 171.01, "duration": 2.62}, {"text": "I get lambda 1 x1,\nwhich is what I want.", "start": 173.63, "duration": 3.5}, {"text": "Can you see what I want\nin the second column here?", "start": 177.13, "duration": 4.02}, {"text": "The result I want\nis lambda 2 x2.", "start": 181.15, "duration": 3.69}, {"text": "So I want no x1's, and\nlambda 2 of that column.", "start": 184.84, "duration": 6.59}, {"text": "So that's 0 times that\ncolumn, plus lambda 2,", "start": 191.43, "duration": 3.08}, {"text": "times that column.", "start": 194.51, "duration": 2.49}, {"text": "Are we OK?", "start": 197.0, "duration": 1.44}, {"text": "So, what do I have now?", "start": 198.44, "duration": 2.95}, {"text": "I have the whole thing\nin a beautiful form,", "start": 201.39, "duration": 3.74}, {"text": "as this A times the\neigenvector matrix", "start": 205.13, "duration": 3.01}, {"text": "equals, there is the\neigenvector matrix again, V.", "start": 208.14, "duration": 5.67}, {"text": "And here is a new matrix\nthat's the eigenvalue matrix.", "start": 213.81, "duration": 7.9}, {"text": "And everybody calls\nthat-- because those", "start": 224.95, "duration": 4.01}, {"text": "are lambda 1 and lambda 2.", "start": 228.96, "duration": 2.12}, {"text": "So the natural letter\nis a capital lambda.", "start": 231.08, "duration": 3.82}, {"text": "That's a capital Greek lambda\nthere, the best I could do.", "start": 234.9, "duration": 3.8}, {"text": "So do you see that the two\nequations written separately,", "start": 238.7, "duration": 5.61}, {"text": "or the four equations\nor the n equations,", "start": 244.31, "duration": 3.73}, {"text": "combine into one\nmatrix equation.", "start": 248.04, "duration": 2.94}, {"text": "This is the same as\nthose two together.", "start": 250.98, "duration": 4.06}, {"text": "Good.", "start": 255.04, "duration": 1.35}, {"text": "But now that I have\nit in matrix form,", "start": 256.39, "duration": 2.8}, {"text": "I can mess around with it.", "start": 259.19, "duration": 1.6}, {"text": "I can multiply both\nsides by V inverse.", "start": 260.79, "duration": 6.26}, {"text": "If I multiply both sides by\nV inverse I discover-- well,", "start": 267.05, "duration": 5.37}, {"text": "shall I multiply on\nthe left by V inverse?", "start": 272.42, "duration": 2.72}, {"text": "Yes, I'll do that.", "start": 275.14, "duration": 1.55}, {"text": "If I multiply on the left by\nV inverse that's V inverse AV.", "start": 276.69, "duration": 5.052}, {"text": "This is matrix multiplication\nand my next video", "start": 284.84, "duration": 2.95}, {"text": "is going to recap\nmatrix multiplication.", "start": 287.79, "duration": 5.39}, {"text": "So I multiply both\nsides by V inverse.", "start": 293.18, "duration": 3.23}, {"text": "V inverse times V\nis the identity.", "start": 296.41, "duration": 2.74}, {"text": "That's what the\ninverse matrix is.", "start": 299.15, "duration": 1.92}, {"text": "V inverse, V is the identity.", "start": 301.07, "duration": 2.05}, {"text": "So there you go.", "start": 303.12, "duration": 1.95}, {"text": "Let me push that up.", "start": 305.07, "duration": 1.6}, {"text": "That's really nice.", "start": 306.67, "duration": 2.27}, {"text": "That's really nice.", "start": 308.94, "duration": 1.98}, {"text": "That's called diagonalizing\nA. I diagonalize", "start": 310.92, "duration": 4.64}, {"text": "A by taking the eigenvector\nmatrix on the right,", "start": 315.56, "duration": 4.19}, {"text": "its inverse on the left,\nmultiply those three matrices,", "start": 319.75, "duration": 3.96}, {"text": "and I get this diagonal matrix.", "start": 323.71, "duration": 2.81}, {"text": "This is the diagonal\nmatrix lambda.", "start": 326.52, "duration": 2.5}, {"text": "Or other times I might want\nto multiply by both sides", "start": 331.53, "duration": 5.2}, {"text": "here by V inverse\ncoming on the right.", "start": 336.73, "duration": 4.57}, {"text": "So that would give me A, V,\nV inverse is the identity.", "start": 341.3, "duration": 5.05}, {"text": "So I can move V over\nthere as V inverse.", "start": 346.35, "duration": 5.09}, {"text": "That's what it amounts to.", "start": 351.44, "duration": 2.05}, {"text": "I multiply both\nsides by V inverse.", "start": 353.49, "duration": 2.1}, {"text": "So this is just A and this is\nthe V, and the lambda, and now", "start": 355.59, "duration": 6.68}, {"text": "the V inverse.", "start": 362.27, "duration": 2.77}, {"text": "That's great.", "start": 365.04, "duration": 0.743}, {"text": "So that's a way to see how\nA is built up or broken down", "start": 370.16, "duration": 8.48}, {"text": "into the eigenvector matrix,\ntimes the eigenvalue matrix,", "start": 378.64, "duration": 5.0}, {"text": "times the inverse of\nthe eigenvector matrix.", "start": 383.64, "duration": 3.33}, {"text": "OK.", "start": 386.97, "duration": 0.95}, {"text": "Let me just use\nthat for a moment.", "start": 387.92, "duration": 3.88}, {"text": "Just so you see how it\nconnects with what we already", "start": 391.8, "duration": 4.16}, {"text": "know about eigenvalues\nand eigenvectors.", "start": 395.96, "duration": 2.94}, {"text": "OK.", "start": 398.9, "duration": 0.5}, {"text": "So I'll copy that great fact,\nthat A is V lambda, V inverse.", "start": 399.4, "duration": 12.72}, {"text": "Oh, what do I want to do?", "start": 412.12, "duration": 2.25}, {"text": "I want to look at A squared.", "start": 414.37, "duration": 2.21}, {"text": "So if I look at\nA squared, that's", "start": 416.58, "duration": 2.55}, {"text": "V lambda V inverse\ntimes another one.", "start": 419.13, "duration": 5.54}, {"text": "Right?", "start": 424.67, "duration": 0.66}, {"text": "There's an A, there's an\nA. So that's A squared.", "start": 425.33, "duration": 4.46}, {"text": "Well, you may say I've made\na mess out of A squared,", "start": 429.79, "duration": 2.35}, {"text": "but not true.", "start": 432.14, "duration": 1.94}, {"text": "V inverse V is the identity.", "start": 434.08, "duration": 4.33}, {"text": "So that it's just the identity\nsitting in the middle.", "start": 438.41, "duration": 3.16}, {"text": "So the V at the far left,\nthen I have the lambda,", "start": 441.57, "duration": 5.31}, {"text": "and then I have the other\nlambda-- lambda squared--", "start": 446.88, "duration": 3.9}, {"text": "and then the V inverse\nat the far right.", "start": 450.78, "duration": 2.58}, {"text": "That's A squared.", "start": 457.21, "duration": 2.81}, {"text": "And if I did it n\ntimes, I would have", "start": 460.02, "duration": 3.71}, {"text": "A to the n-th what would be\nthe lambda to the n-th power V", "start": 463.73, "duration": 8.67}, {"text": "inverse.", "start": 472.4, "duration": 1.19}, {"text": "What is this?", "start": 473.59, "duration": 0.73}, {"text": "What is this saying about?", "start": 474.32, "duration": 2.21}, {"text": "This is A squared.", "start": 476.53, "duration": 1.06}, {"text": "How do I understand\nthat equation?", "start": 481.416, "duration": 3.804}, {"text": "To me that says that the\neigenvalues of A squared", "start": 485.22, "duration": 3.98}, {"text": "are lambda squared.", "start": 489.2, "duration": 1.97}, {"text": "I'm just squaring\neach eigenvalue.", "start": 491.17, "duration": 2.17}, {"text": "And the eigenvectors?", "start": 493.34, "duration": 1.86}, {"text": "What are the eigenvectors\nof A squared?", "start": 495.2, "duration": 2.77}, {"text": "They're the same V, the\nsame vectors, x1, x2,", "start": 497.97, "duration": 6.01}, {"text": "that went into v. They're\nalso the eigenvectors", "start": 503.98, "duration": 4.21}, {"text": "of A squared, of A cubed, of\nA to the n-th, of A inverse.", "start": 508.19, "duration": 5.67}, {"text": "So that's the point of\ndiagonalizing a matrix?", "start": 513.86, "duration": 3.85}, {"text": "Diagonalizing a\nmatrix is another way", "start": 517.71, "duration": 2.51}, {"text": "to see that when I square\nthe matrix, which is usually", "start": 520.22, "duration": 4.37}, {"text": "a big mess, looking at the\neigenvalues and eigenvectors", "start": 524.59, "duration": 5.74}, {"text": "it's the opposite of a big mess.", "start": 530.33, "duration": 1.64}, {"text": "It's very clear.", "start": 531.97, "duration": 1.67}, {"text": "The eigenvectors are\nthe same as for A.", "start": 533.64, "duration": 8.07}, {"text": "And the eigenvalues are squares\nof the eigenvalues of A.", "start": 541.71, "duration": 15.42}, {"text": "In other words, we can\ntake the n-th power", "start": 557.13, "duration": 3.86}, {"text": "and we have a nice\nnotation for it.", "start": 560.99, "duration": 2.88}, {"text": "We learned already\nthat the n-th power", "start": 563.87, "duration": 3.17}, {"text": "has the eigenvalues\nto the n-th power,", "start": 567.04, "duration": 3.31}, {"text": "and the eigenvectors the same.", "start": 570.35, "duration": 1.98}, {"text": "But now I just see it here.", "start": 572.33, "duration": 2.94}, {"text": "And there it is\nfor the n-th power.", "start": 575.27, "duration": 2.05}, {"text": "So if I took the same\nmatrix step 1,000 times,", "start": 580.05, "duration": 5.39}, {"text": "what would be important?", "start": 585.44, "duration": 1.6}, {"text": "What controls the thousandth\npower of a matrix?", "start": 587.04, "duration": 4.82}, {"text": "The eigenvectors stay.", "start": 591.86, "duration": 2.85}, {"text": "They're just set.", "start": 594.71, "duration": 2.39}, {"text": "It would be the thousandth\npower of the eigenvalue.", "start": 597.1, "duration": 4.05}, {"text": "So if this is a matrix with\nan eigenvalue larger than 1,", "start": 601.15, "duration": 4.4}, {"text": "then the thousandth\npower is going", "start": 605.55, "duration": 2.15}, {"text": "to be much larger than one.", "start": 607.7, "duration": 1.84}, {"text": "If this is a matrix with\neigenvalues smaller than 1,", "start": 609.54, "duration": 3.7}, {"text": "there are going to\nbe very small when", "start": 613.24, "duration": 3.45}, {"text": "I take the thousandth power.", "start": 616.69, "duration": 2.72}, {"text": "If there's an eigenvalue\nthat's exactly 1,", "start": 619.41, "duration": 3.36}, {"text": "that will be a steady state.", "start": 622.77, "duration": 2.11}, {"text": "And 1 to the thousandth\npower will still be 1", "start": 624.88, "duration": 2.95}, {"text": "and nothing will change.", "start": 627.83, "duration": 1.76}, {"text": "So, the stability.", "start": 629.59, "duration": 2.33}, {"text": "What happens as I multiply,\ntake powers of a matrix,", "start": 631.92, "duration": 4.28}, {"text": "is a basic question parallel\nto the question what", "start": 636.2, "duration": 3.82}, {"text": "happens with a\ndifferential equation", "start": 640.02, "duration": 3.05}, {"text": "when I solve forward in time?", "start": 643.07, "duration": 5.1}, {"text": "I think of those two\nproblems as quite parallel.", "start": 648.17, "duration": 3.62}, {"text": "This is taking steps, single\nsteps, discrete steps.", "start": 651.79, "duration": 5.35}, {"text": "The differential equation is\nmoving forward continuously.", "start": 657.14, "duration": 4.9}, {"text": "This is a difference\nbetween hop,", "start": 662.04, "duration": 1.65}, {"text": "hop, hop in the discrete case\nand run forward continuously", "start": 663.69, "duration": 6.5}, {"text": "in the differential case.", "start": 670.19, "duration": 2.32}, {"text": "In both cases, the eigenvectors\nand the eigenvalues", "start": 672.51, "duration": 4.88}, {"text": "are the guide to what\nhappens as time goes forward.", "start": 677.39, "duration": 4.561}, {"text": "OK.", "start": 681.951, "duration": 0.499}, {"text": "I have to do more about\nworking with matrices.", "start": 682.45, "duration": 5.18}, {"text": "Let me come to that next.", "start": 687.63, "duration": 2.7}, {"text": "Thanks.", "start": 690.33, "duration": 1.55}]