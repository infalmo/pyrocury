[{"text": "[SQUEAKING][PAPERS RUSTLING][CLICKING]JEREMY KEPNER: All right. Welcome. Great to\nsee everyone here. We're really excited aboutthis opportunity. As you know, our AI accelerator\nhas officially kicked off. All of your teamsare ready to go. And we wanted this to be\nan opportunity as a team, come together anddevelop some common foundation, some common\ntechnological foundation, some common languagefor talking about these very challenging AI\nproblems.And so with that, I'll hand it over to Vijay.VIJAY GADEPALLY: All right.JEREMY KEPNER: Who will kick off with the first\nlecture, which basically provides some overviewAI context for this.VIJAY GADEPALLY: Again, welcome to the class.\nWe're really looking forward to this. Whatwe're going to present this morning is really\na lot of overview material, right? Many ofyou here know a lot in AI and machine learning.\nThis is really meant to just level set beforewe start the program, before we start these\nclasses.So you can see this generic title-- Artificial\nIntelligence and Machine Learning. And we'regoing to try and cover all of that in about\nan hour. So some details might be skipped,but we'll try and hit some of the salient\nfeatures. All of these slides are availablefor you to use.So if you're presenting back to your own teams,\nplease feel free to pull from these slides.We've actually gone through-- over some time\nputting a good set of survey and overviewslides together. So if any of these are useful\nto you, just email us, or we'll make themavailable to you. You're more than welcome\nto use any and all of these slides if you'retrying to present this back to other people.", "start": 0.0, "heat": 0.267}, {"text": "So with that, let's begin. So we're going\nto do a quick overview of artificial intelligence.Again, a lot of level setting going on here.\nWe're going to do a quick, deep dive. Thesearen't the deepest of dives, again, given\nthe amount of time that we have, but justtalk very quickly about supervised, unsupervised,\nand reinforcement learning, and then summarize.And we can certainly stop for questions, philosophical\ndebates, et cetera, towards the end. We'lltry not to get a lot of the philosophical\ndebates on camera if we can. All right. Sofirst question-- what is artificial intelligence?\nAnd this is a question that probably a lotof you get. And I certainly have received\nthis from a number of people. And that actuallytakes a lot of-- it took us a lot of time\nto come up with this.And so we are very fortunate to have Professor\nWinston spend some time with us out at LincolnLaboratory. And we actually brainstormed for\na good hour or two, really trying to comeup with what is a good definition for what\nwe call artificial intelligence. And whatwe came up with is that there are two aspects\nto artificial intelligence.First, that we should not confuse with each\nother. One is the concept of narrow AI, andanother is a concept of general AI. And sometimes\nin conversation, we tend to conflate or mixthe two. So narrow AI, according to our definition,\nis the theory and development of computersystems that perform tasks that augment for\nhuman intelligence, such as perceiving, classifying,learning, abstracting, reasoning, and/or acting.Certainly in a lot of the programs that we\nwork in, we're very focused on narrow AI andnot necessarily the more general AI, which\nwe define as full autonomy. So that's a veryhigh-level definition of what we mean by AI.\nNow, many of you in the crowd are probablysaying, well, AI has been around for a while.\nPeople have been talking about this for 50,60-plus years. Why now? What is so special\nabout it now? Why is this conversation piecenow?Well, from what we've seen, it really is the\nconvergence of three different communities", "start": 120.0, "heat": 0.126}, {"text": "that have come together. The first is the\ncommunity on big data. The second is a communityon computing in a lot of computing technologies.\nAnd finally, a lot of research and resultsin machine learning algorithms.The other one I forgot to put is dollar signs\ndown here. People have basically figured outhow to make money off of selling advertisements,\nlabeling cat pictures, et cetera. So that'smaybe the hidden-- why now in particular.\nBut these are the three large technical areasthat have evolved over the past decade or\nso to really make AI something we discussa lot today.So when we talk about AI, there are a number\nof different pieces which make up an AI system.And we love the algorithms, people, but there\nis a lot more going on outside of that. Sowe've spent a significant amount of effort\njust trying to figure out what goes into anAI system.And this is what we call a canonical architecture.\nVery much in line with Lincoln Laboratorythinking, we like to think of an end to end\npipeline. What are the various components?And what are the interconnections between\nthese various components? So within our AIcanonical architecture shown here, we go all\nthe way from sensors to the end user or missions.And a lot of the projects that you all are\nworking on are going to go all the way fromhere to there. A lot of our class, however,\nfor the next few weeks is going to focus onstep one, where a lot of people get stuck.\nSo we take data that comes in through eitherstructured or unstructured sources.These are typically passed into some data\nconditioning or data curation step. This datais through that process, typically converted\ninto some form of information. That informationis then passed into a series of algorithms,\nmaybe one or many algorithms. There are lotsof them. There is life beyond neural networks.Once we pass them through the algorithms,\nthese typically form. This information is", "start": 240.0, "heat": 0.147}, {"text": "converted into knowledge. It's typically then\npassed into some module that interacts withthe end user, or a human, or the mission.\nAnd that's what we call a human machine teamingstep.And that finally-- that knowledge with the\nhuman complement becomes insight that canthen be used to execute the mission that the\nAI system was created for. All of these componentssit on the bedrock of modern computing. Many\ndifferent technologies that make up moderncomputing and the system that we're using\ntoday has combination of some of these computinghardware elements.And certainly within the context of a lot\nof the projects that we are interested in,all of this also needs to be wrapped in a\nlayer that we call robust AI, which consistsof explainable artificial intelligence, metrics,\nand biased assessment, verification, validation,security, policy, ethics, safety, and training.\nWe'll talk very briefly about each of thesepieces in detail in a little bit.As I mentioned, AI has an extremely rich history.\nThis is just a very Lincoln and MIT specificview of the history of artificial intelligence.\nBut certainly, there has been great work sincethe folks of Minsky, Clark, Dineen, Oliver\nSelfridge, et cetera, since the '50s. We'veseen a lot of work in the '80s and '90s. And\ncertainly, recently there has been, again,a resurgence of AI in our parlance in our\nthinking of the way AI works.So without going into too much detail about\neach of these eras and why the winters cameabout, et cetera, I think John Launchbury\nat DARPA actually put it very well, when hetalked about different waves of AI technology\nthat have come about. And when he talks aboutit, he talks about the three waves of AI or\nthe four waves of AI. And the first wave,which you can think of as the first decade\nof AI technology, resulted in a lot of reasoning-based", "start": 360.0, "heat": 0.0}, {"text": "systems, which were based on handcrafted knowledge.So an example of an output of this would be\nan expert system, right? So a lot of workin that. So if we take the four dimensions\nthat John Launchbury suggests of the abilityof the system to perceive, learn, abstract,\nand reason, these are typically pretty goodat reasoning. Because they encoded human knowledge,\nright?So a human expert sat down and said, what's\ngoing on in the system? And tried to writea series of rules. So tax software, for example,\ndoes a pretty reasonable job of that wherea chartered accountant or a tax expert sits\ndown, encodes a series of rules. We have aquestion in the back.AUDIENCE: Yeah. [INAUDIBLE] I just wanted\nan example of an expert system from the '50sto [INAUDIBLE].VIJAY GADEPALLY: Yep. So the question is,\nare there examples of expert systems? Andcertainly, one would be tax software. My graduate\nresearch was actually an autonomous vehicle.Some of the early autonomous vehicles used\na form of expert systems where the stateson a finite state machine were maybe handcrafted.And the transitions between them were designed\nthat way. There was some machine learningwrapped around, but expert systems certainly\nplayed a large part in some of the early,even autonomous vehicle research that went\non. All right. So over time, we were ableto use these expert systems.And don't get me wrong. These systems are\nstill extremely valid in cases where you havelimited data availability, limited compute\npower, a lot of expert systems still beingused, or in cases where explainability is\na very important factor. You still see expertsystems, because they do have the ability\nto explain why they came up. They can typicallypoint to a set of rules that somebody wrote,\nwhich is usually quite interpretable by ahuman.However, as we were able to collect more data,\nwe were maybe able to understand a littlebit more about what was the underlying process.\nWe were able to apply statistical learning.", "start": 480.0, "heat": 0.0}, {"text": "And this led to the next era or next wave\nof AI technologies, which is often calledthe learning wave.And this was really enabled by lots of data-enabled\nnon-expert systems. So what we mean by thatis we were able to dial back the amount of\nexpert knowledge that we encoded into thealgorithm, maybe put a higher level of expert\nknowledge into that. But usually, then useddata to learn what some of these rules could\nbe.An example of that, in case someone wants\nto ask, would be in speech processing, forexample. So we were able to say, well, I realized\nthat speech follows this Gaussian mixturemodel. So I can encode that level of statistical\nknowledge, but I'm going to let the systemfigure out the details of how all that actually\nworks out.And there are many other cases. Again, coming\nback to some of the research I did on autonomousvehicles, we were able to maybe use some high-level\nexpert rules, that here are a set of statesthat a car may be in. But I'm going to let\nthe algorithm actually figure out when thesetransitions occur and what constitutes a transition\nbetween different states.So looking at the four vectors that you could\nthink about it, these systems had a littlebit more on perception. Obviously, we're doing\na lot more learning. But their ability toabstract and reason was still pretty low.\nAnd by reasoning, we mean, can you explain?Can you tell us what's going on when you give\nme an output to the result?The next wave which we're maybe at the beginning\nstages of is what we call contextual learningor contextual adaptation. This is where an\nAI system can actually add context into whatit's doing. I'm not sure I have too many examples\nof people doing this very well.I think most of the work today probably falls\ninto the end stage of the learning wave of", "start": 600.0, "heat": 0.0}, {"text": "AI. But we're able to combine a bunch of these\nlearning things to make it look like it'scontextual in nature. But the key concept\nover here is being able to have the systemautomatically abstract and reason. So the\nway that we think about things, right?So if I see a chair over here and I put a\nchair somewhere else, I still know it's achair, because I'm using other contexts. Maybe\nit's next to a table or stuff like that. Someearly research going on in that area. And\ncertainly, the next wave of this is what wecall abstraction. And there is very little\nwork on this, but if we have to think outin the future.But this is really the system of the ability\nof an AI system to actually abstract informationthat it's learning. So instead of learning\nthat a chair or a table is something witha leg at the bottom, it learns that a table\nis something you put things on and is ableto abstract that information or that knowledge\nto any other domain or any other field. Dowe have any questions before I continue from\nhere? OK, great.So that's a little bit on the evolution of\nAI. The reason we like to go through thisis because there is great work going on in\neach of these waves. And nothing that peopleare doing in any of these waves is any lesser\nor more. It's typically dependent on whatyou have at your disposal.What I like to tell people sometimes is the\nway to think about all of this is you havea couple of dials at your disposal-- turning\ndials. The first dial is, how much compute?Right? How much ability do you have to crunch\ndata? The second piece is, how much data doyou actually have available? This can be labeled\ndata in many cases.And the third dial is, how much knowledge\nare you able to embed into an algorithm? Incertain cases where maybe you have very little\ncomputing, very little labeled data availability,", "start": 720.0, "heat": 0.0}, {"text": "but a lot of expert knowledge or a lot of\nability to encode information into an algorithm,you might be able to use an expert system,\nright? And that's a very good use case forthat.An example may be on another dimension where\nyou want to encode very little human knowledge,but you have a lot of computing and data available,\nwould be rare neural networks fall in, wherethey're essentially learning what the human\nknowledge-- what that encoded informationshould be.A lot of statistical techniques also fall\ninto that camp where maybe you encode a littlebit of information as to what the background\ndistribution of the process is. But it learnsthe details of exactly how that distribution\nis modeled, based on the data that it sees.So you have a lot of different settings that\nyou can use. And there are a number of differenttechniques within the broader AI context that\nyou can use to achieve your mission. And I'msure many of you are going to be doing different\ntypes of algorithms. And a lot of that decisionwill be dependent on, well, how much data\nwas I given? Right? How good is this datathat I'm using? Is there an ability to learn\nanything from this?And if not, you might have to encode some\nknowledge of your own into it saying, well,I know that this process looks like that,\nso let me tell the algorithm to not wastetoo much time crunching the data to learn\nthe underlying distribution, which I can tellyou. Why don't you learn the parameters of\nthe distribution instead? Does that makessense? All right.And as you know, there's just a lot going\non in AI and machine learning. You can't walktwo steps without running into somebody who's\neither starting something up, working forone of these organizations. So it really is\nan exciting time to be in the field. All right.So that's a little bit on the overview, but\nlet's talk now in a little bit of detail onwhat some of the critical components are within\nthis AI architecture. So one thing that we", "start": 840.0, "heat": 0.0}, {"text": "like to note-- and there's a reason that as\nwe've been reaching out to a number of you,we've been talking about getting data, right?\nWork with stakeholders to get your data inplace.And the reason we talk about that is data\nis critical to breakthroughs in AI. A lotof the press may be on the algorithms and\nthe algorithms that have been designed. Butreally, when we've looked back in history,\nwe've seen that, well, the availability ofa good canonical data set actually is equally,\nif not more critical to a breakthrough inAI.So what we've done here is we've just picked\na select number of breakthroughs in AI. Ourdefinition of a breakthrough in this particular\nexample is something that made a lot of pressor something that we thought was really cool.\nSo here are some examples of that in differentyears.And we've talked about the data set, the canonical\ndata set that maybe led to that breakthroughor that was cited in that breakthrough as\nwell as the algorithms that were used in thatbreakthrough and when they were first proposed.\nThis is notional in nature. Clearly, you couldadjust these dates a few years here or there.But what we really want to get across is that\nthe average number of years to a breakthroughfrom the availability of a cool data set or\na very important, well-structured, well-labeleddata set is much smaller than from the algorithm's\nfirst proposal or when the algorithm firstcomes out.So as you're developing your challenge problems,\nas you're developing your interactions withstakeholders, certainly something to keep\nin mind that there's clearly a lot of algorithmicresearch that's going to go on. But having\na good, strong, well-labeled, and documenteddata set can be equally important. And making\nthat available to the wider AI community,the wider AI ecosystem can be very, very valuable\nto your work and the work of many other people.All right.So back to the AI architecture, we're going\nto just go through very briefly-- different", "start": 960.0, "heat": 0.0}, {"text": "pieces of this architecture. So the first\npiece we're going to talk about is data conditioning,which is converting unstructured and structured\ndata. Within the structured and unstructureddata, you might have structured sources coming\nfrom sensors, network logs for some of you,metadata associated with sensors, maybe speech\nor other such signals.There's also a lot of unstructured data. You\nthink of things that you might collect fromthe internet that you might download from,\nsay, a social media site, maybe reports, othertypes of sensors that maybe don't have well--\nthat don't have the strong structure withinthe data set itself.And typically, this first step, what we call\nthe data conditioning step, consists of anumber of different elements. You might want\nto first figure out where to put this data.That can often take a lot of time. And there\nhave been religious wars fought on this topic.We're here to tell you that you're probably\nOK, picking most technologies. But if youhave any questions, feel free to reach out\nto me or to others on the team. We have alot of opinions on what's the right infrastructure\nto solve the problem. Typically, these infrastructureor databases might provide capabilities such\nas indexing, organization, and structure.Very important in unstructured data to convert\nit into some format that you can do thingswith.They may allow you to connect to them using\ndomain specific languages. So it's convertingit into a language that maybe you're used\nto talking. They can provide high-performancedata access and in many cases, a declarative\ninterface. Because maybe you don't reallycare about how the data is being accessed.\nYou want to just say select the data, giveit to me. And then move forward from there.Another important part of the data conditioning\nstep is data curation. This unfortunatelywill probably take you a very long time. And\nit requires a lot of knowledge of the data", "start": 1080.0, "heat": 0.0}, {"text": "itself, what you want to do with the data,\nand how you receive the data.But what you might do in the data curation\nstep is perform some unsupervised learning,maybe reduce the dimensionality of your problem.\nYou might do some clustering or pattern recognitionto maybe remove certain pieces of your data\nor to highlight certain pieces of the datathat look important.You might do some outlier detection. You might\nhighlight missing values. There's just dot,dot, dot, et cetera, et cetera, et cetera.\nA lot goes on in the data curation step. Wecould certainly spend hours just talking about\nthat. And the final thing, especially withinthe context of supervised machine learning,\nbut even in the world of unsupervised learningwould be spending some time on data labeling,\nright?So this is taking data that you've received,\ntypically doing an initial data exploration.Could be as simple as opening it up in Excel\nto see what the different columns and rowslook like if that's a suitable place to open\nit up. You might look for highlight, missing,or incomplete data, just from your initial\ndata exploration.You might be able to go back to the data provider\nor to the sensor and say, can you reorientthe sensors or recapture the data? I noticed\nthat every time you've measured this particularquantity, it always shows up as 3. I can't\nimagine that that's correct. Can you go backand tell me if that sensor is actually working?\nOr is it actually 3? In which case, you mightwant to know that.And you might look for errors, biases, and\ncollection, of course, on top of the actuallabeling process that you're doing to highlight\nphenomenology within the data that you'd liketo then look for through your machine learning\nalgorithms. I'll pause for a second. Yes?AUDIENCE: I have a quick question.VIJAY GADEPALLY: Yeah?AUDIENCE: What's the ratio that you see between\nstructured data and unstructured data?VIJAY GADEPALLY: So the question is, what's\nthe ratio we see between structured and unstructureddata? That's a great question. So the ratio\nin terms of the volume or the ratio in terms", "start": 1200.0, "heat": 0.0}, {"text": "of what you can do with it? Because those\nare actually almost the opposite.So, again, I'm talking about a few data sets\nthat I'm very familiar with. The unstructureddata can often be 90% of the volume. And maybe\nthe 10% is the metadata associated with theunstructured data. Most of the value, however,\ncomes from the structured data where peoplereally analyze the crap out of these structured\ndata, because they know how to.There is certainly a lot of potential within\nthe unstructured data. So when we talk topeople, that's why we talk a lot about infrastructure\nand databases as being an important firststep. Because if you can just take the unstructured\ndata and put it into a structured or semi-structuredform, that itself can provide a lot of value.Because very often in problems that we see,\nthe 90% volume of data is largely untapped.Because people don't know how to get into\nit, or don't know what to do with it, or it'snot in a form that you can really deal with.\nSo I think next class, we're going to be talkingto you about how to organize your data, strategies\nfor organizing data that can get you a lotmore value out of the unstructured data. Does\nthat answer your question? Yes?AUDIENCE: [INAUDIBLE]VIJAY GADEPALLY: So the question is when you\napply AI or machine learning techniques toa problem domain, is it typically a single\nmodality or multiple modalities? I'd say theanswer is both. Certainly, there's a lot of\nresearch. And back there, we have Matthew,who's actually doing research on that right\nnow on how to fuse multiple modalities of", "start": 1320.0, "heat": 0.0}, {"text": "data.I know a lot of projects that are being discussed\nhere are certainly looking at multiple modalities.If I had to say as of today, a lot of the\nwork that's out there-- the published workmay be focused on a single modality. But that's\nnot to say-- I mean, I think there is a lotof value on multiple modalities. But the challenge\nstill comes up on, how do you integrate thisdata, especially if they're collected from\ndifferent systems? Yep?AUDIENCE: Just on the structure versus unstructured.\nSo it's not really my area, but I am surprisedto see speech in the structured [INAUDIBLE].\nAnd I wonder. Is that just because the technologiesthat can force the [INAUDIBLE] and all of\nthis data conditioning are mature enough thatyou can basically treat it [INAUDIBLE]?VIJAY GADEPALLY: So the question is, why would\nspeech or something else like that fall intostructured versus unstructured? And you're\nabsolutely right. I think when we pick speech--and I'm sure there are others in the room\nthat might disagree with that and might stickit over here.When we look at the type of acquisition processes\nthat are used, the software that's used, theytypically come out with some known metadata.\nThey follow a certain pattern that we canthen use, right? There is a clear range to\nwhere there is-- the frequency to which thedata is collected. And that's why we stuck\nit in the structured data type.Of course, if you're collecting data out in\nthe field without that, you could probablystick it into the unstructured world as well.\nBut that's probably a good example of somethingthat can fall in between the two places. OK.\nAll right. Now, for the part everyone's reallyinterested in-- machine learning, right?So, all right, you got through the boring\ndata conditioning stuff, which will take youa couple of years or something like that.\nNothing serious. And now, you're ready todo the machine learning. And now, you're given\na choice. Well, which algorithm do you use?Neural networks, you might say, right?There is a lot more, though, beyond the neural\nnetwork world. So there is numerous taxonomies.", "start": 1440.0, "heat": 0.0}, {"text": "I'm going to give you two of them today for\nhow you describe machine learning algorithms.One that's really an interesting way is from\nPedro Domingos at the University of Washingtonin which he says that there are five tribes\nof machine learning.So there are the symbolists, which an example\nof that would be expert systems. There arethe Bayesian tribes, which an example of an\nalgorithm within that might be naive Bayes.There are the analogizers, which an example\nof that would be a support vector machineand the connectionists, an example of which\nwould be deep neural networks. And evolutionaryis an example of that which might be genetic\nprogramming.What really I'm trying to get across-- I'm\nsure the author is trying to get across hereis that lots and lots of different algorithms.\nEach have their relative merits and relativestrengths. Apply the right one for your application.\nApply the right one for-- again, given thesedials that I talked about earlier, the amount\nof computing that you have available, theamount of data that you have available, and\nthe amount of expert knowledge that you'reable to encode into your algorithm that you\nthink is generalizable enough.If we actually talk about-- this is a very\nuseful chart I found in describing to folksthat are not familiar with AI that might say,\nwasn't AI just neural networks? And neuralnetworks are a part of AI, but not necessarily\nall of it. So if we think of the big circleis the broad field of artificial intelligence,\nwithin that is the world of machine learning.Within machine learning are connectionists\nor neural networks that fall into a smallcamp within that. And deep neural networks\nis a part of neural network. So can anyonemaybe give me an example-- although, I've\nsaid it numerous times-- of something thatmight fall out of machine learning, but into\nartificial intelligence from an algorithmic", "start": 1560.0, "heat": 0.0}, {"text": "point of view? Yes?AUDIENCE: Graph search.VIJAY GADEPALLY: Graph search could be an\nexample. I would maybe stick that into someof the connectionists, however.AUDIENCE: Expert systems.VIJAY GADEPALLY: Yes, exactly. So expert systems--\nit's the one that comes to my mind. Or knowledge-basedsystems are an example of maybe something\nthat fall outside of the realm of machinelearning, again in the very strict sense,\nbut maybe within the realm of artificial intelligencefrom an algorithmic point of view.OK, so that's a little bit on the algorithms.\nNext, let's talk about some of the moderncomputing engines that are out there. I mentioned\nthat data compute as well as algorithms havebeen key drivers to the resurgence of AI over\nthe past few years. What are some of thesecomputing technologies, for example? So clearly,\nCPUs and GPUs. They're very popular computingplatforms. Lots of software written to work\nwith these computing platforms.But what we're seeing now is that with the\nend of Moore's Law and a lot more performanceengineering going on, we're seeing a lot more\nwork, research, and hardware architecturesthat are custom in nature. And custom architectures\nare almost the new commercial off-the-shelfsolutions that are out there.So an example of a custom architecture could\nbe Google's Tensor Processing Unit, or TPU.There is some very exciting research going\non in the world of neuromorphic computing.I'm happy to chat with you all later if you're\ninterested to know what's going on in thatarea and maybe our role in some of that work.And there is just some stuff that we would\nstill call custom. These are still peopledeciding, designing, basically looking at\nan algorithm saying, OK, here's the data layout.Here is the movement of data or information\nwithin this algorithm. Let's create a customprocessor that does that. An example of that\ncould be the graph processor, which is being", "start": 1680.0, "heat": 0.0}, {"text": "developed at Lincoln Laboratory.And obviously, no slide on computing architectures\nor computing technologies would be completewithout mentioning the word quantum in it.\nThere is some early results on solving linearsystem of equations. But I think applied to\nAI, it's still unsure, or unknown, or unprovenwhere quantum may play a part. But certainly,\na technology that all of us, I'm sure, haveheard of, or continue to track, or just interested\nin seeing where that goes to.So within the first few, however, these are\nall products that you can buy today. You cango out to your favorite-- your computing store\nand just purchase these off-the-shelf solutions.A lot of software has been written to work\nwith these different technologies. And it'sa really nice time to be involved. Yeah?AUDIENCE: Can you give a brief just concept\nof what is attached to the [INAUDIBLE]? Isee [INAUDIBLE], but I don't really have a\nhigh-level concept of why I should associatewith that.VIJAY GADEPALLY: OK, so the question is, what\nshould I think about when I'm thinking aboutneuromorphic? So there's a few features which\nI say fall into the camp of what people arecalling neuromorphic computing. One is what\nthey're calling a brain inspired architecture,which often means its clockless.So you typically have some-- so a lot of these\ntechnologies have clocked movement of information.These might be clockless in nature. They typically\nsit on top of different types of memory architectures.And I'm trying to think of what would be another\nparameter that would be very useful. I canprobably send you a couple things that help\nhighlight that. I certainly wouldn't callmyself an expert in this area.", "start": 1800.0, "heat": 0.0}, {"text": "AUDIENCE: OK, thanks.VIJAY GADEPALLY: But, yeah. I think the term\nthat's used is it's supposed to mimic thebrain in the way that the computing architecture\nactually performs or functions. So lots ofresearch as well. And this is work that we've\ndone here at the lab on actually trying tomap the performance of these different processors\nand how they perform for different types offunctions.So what we're doing here is basically looking\nat the power on the x-axis. And the y-axisis the peak performance in giga operations\nper second. Different types of precision arenoted over there by the different shapes of\nthe boxes and then different form factors.And the idea here is basically to say there's\nso much going on in the world of computing.How can we compare them? They all have their\nown individual areas where they're strong.So one can't come up and say, well, the GPU\nis better than the CPU. Well, it depends onwhat you're trying to do and what your goals\nof the operation are.So some of the key lines to note here is that\nthere seems to be a lot of existing systemson this 100 giga operations per watt on this\nline over here, this dash line. Some of thenewer offerings maybe fit into the 1 tera\nop per watt. And some of the research chipslike IBM's TrueNorth or Intel's Arria fall\ninto just a bit under the 10 tera operationsper watt line that we see there.But depending on the type of application,\nyou may be OK with a certain amount of peakpower. So if you're looking at embedded applications,\nyou're probably somewhere over here, right?If you're trying to get something that's on\na little drone or something like that, youmight want to go here. And if you have a data\ncenter, you're probably OK with that typeof power utilization or peak power utilization.\nBut you do need the performance that goesalong with that.So I'd say the most important parts to look\nat are essentially these different lines.Those are the trajectories for maybe some\nof the existing systems, all the way up to", "start": 1920.0, "heat": 0.0}, {"text": "some of the more research oriented processors\nout there. OK? All right.So we talked about modern computing. Let's\ntalk a little bit about the robust AI sideof things. And the basic idea between robust\nAI is that it's extremely important. And thereason that it's important is that the consequence\nof actions on certain applications of AI canbe quite high.So what we've done here is think about, where\nare the places that maybe humans and machineshave their relative strength? So on the x-axis,\nwe're talking about the consequence of action.So this could be, does somebody get hurt if\nthe system doesn't do the right thing? Allthe way down to, no worries if the system\ndoesn't do the right thing, which could bemaybe some of the labeling of images that\nwe see online, might fall into this category.I'm sure people disagree with me on that.But maybe a lot of national security applications.\nHealth applications certainly fall into thearea of high consequence of action. If you\ngive someone the wrong treatment, that's adeal. And then on the y-axis, we're talking\nabout the confidence level in the machinemaking the decision. So how much confidence\ndo we have in the system that's actually makingthe decision?In certain cases, we might have very high\nconfidence in the system that's making a decision.And obviously in certain cases, we do not\nhave much confidence in the system makingthe decision. So in areas where you have a\nlow consequence of action, maybe high confidencelevel in the machine making the decision,\nwe might say those are best matched to machines.Those are good candidates for automation.On the contrary, there might be areas where\nthat consequence of action is very high. Andwe have very little confidence in the system\nthat's making the decision, probably an areawe want humans to be intricately, if not solely\nor involved or responsible. And the area inbetween is where machines might be augmenting\nhumans.Does anybody want to venture maybe a couple\nof examples-- help come up with a couple of", "start": 2040.0, "heat": 0.0}, {"text": "examples here that we might put into each\nof these categories? So maybe what's a goodproblem that you can think of that might be\nbest matched to machines, beyond labelingimages for advertisements?AUDIENCE: Assembly lines.VIJAY GADEPALLY: Assembly lines? Yep, that's\na good example. I'm thinking within spam filtering,could be another example where-- I mean, there\nis some machine augmenting human. It doessend you an email saying this is spam. Are\nyou sure? But for the most part, it's largelyautomated.I'd say a lot of the work that many of us\nare probably doing falls into this category,maybe on different sides of the spectrum,\nbut of where machines are augmenting humans.So the system can be providing data back to\na human that can then select. It might filterinformation out for humans that then the humans\ncan then go ahead and say, OK, well, insteadof looking at a thousand documents, I can\nonly look at 10, which is much better.And then there's obviously certain-- probably\nwe want humans to be heavily involved withany kinetic-- anything that involves life\nor death-- we probably want. And there areprobably legal reasons, also, that we want\nhumans involved with things like that.One of the examples that we often get which\nis autonomous vehicles-- and it's always alittle confusing where autonomous vehicles\nfall into this. Certainly, the consequenceof action of a mistake in an autonomous vehicle\ncan be pretty high.And as of today, the confidence and the decision-making\nis medium at best. But people still seem tosomehow be OK with fully automating. That\njust shows how terrible Boston roads or drivingin general is, that we're like, I'm not really\nsure if this thing will kill me or not, buttotally worth trying it out.AUDIENCE: Do you think the trend in this chart\nis to slowly expand the yellow out?VIJAY GADEPALLY: Yes, I'd say-- the question\nis, is the yellow expanding? I think so. One", "start": 2160.0, "heat": 0.0}, {"text": "could make the argument that, is it shifting\nthat direction? Are we finding areas where--and I think that's maybe the direction. We\nare probably looking at automating certainthings a little bit more as confidence in\ndecision-making goes up.So you might think about this frontier moving\ndown so that maybe the green expanding slightlyand the yellow taking over a little bit of\nthe red. There might be some places whereover time, we're more open to the machine\nmaking a decision and the human having a largelysupervisory role, which I would put right\nat this frontier between the yellow and thered.AUDIENCE: Again, I guess it depends on what\naugmenting means. But I guess [INAUDIBLE]is truly red without any-- even cognitive\naugmenting.VIJAY GADEPALLY: I can think of some examples,\nbut maybe I'll share it with you later. Socertainly, a robust artificial intelligence\nplays a very important part in the developmentand deployment of AI systems. I won't go through\nthe details of each of these.I'm sure many of you are very familiar with\nit. And I know a few of you are far more knowledgeableabout this, maybe than I am. But some of the\nkey features would be explainable AI, whichis a system being able to describe what it's\ndoing in an interpretable fashion.Metrics-- so being able to provide the right\nmetric if you want to go beyond accuracy orperformance. Validation and verification--\nthere might be cases where you're not reallyconcerned about the explainability, but you\njust want to know that when I pass an input,I get a known output out of it. And is there\na way to confirm that I'm able to do that?Another could be on security. So an example\nof this-- or not having security would becounter AI, right? So when we talk about security\nwithin the context of robust AI, it's almostlike the cryptographic way of thinking about\nit, which is, can I protect the confidentiality,", "start": 2280.0, "heat": 0.0}, {"text": "integrity, and availability of my algorithm,\nthe data sets, the outputs, the weights, thebiases, et cetera?And finally, a lot of significant importance\nis policy, ethics, safety, and training. Thisis actually very important in some of those\napplications where in the previous slide,we had the yellow and the red where humans\nand machines augmenting humans, where thatfalls.A lot of that might be governed by policy,\nethics, safety, and training, which is someof the examples that I can think of, where\nthere are policy reasons that make it thatonly a human can be involved with this, maybe\nwith minimal input from a system. OK.And the final component of our AI architecture--\nwe've gone through conditioning, algorithms,computing, robust AI-- is human machine teaming.\nAnd I think what we want to get across withhuman machine teaming-- that is it really\ndepends on the application and what you'retrying to do. But it is important to think\nabout the human and the machine working together.And there is a spectrum of where the machine\nwill largely-- will play a large part andthe human largely supervisory or to where\nthe human plays a large part and the machineis very targeted in what you do with the machine\nor the AI of the system.But a couple of ways to think about it would\nbe-- of course, we talked about the confidencelevel versus consequence of actions, but also,\nthe scale versus application complexity. Soon the top chart over there, we have on the\nx-axis is the application complexities. Howcomplex is this application? And on the y-axis\nis the scale. How many times do you need tokeep doing this thing?Places that machines might be more effective\nthan humans are where we have low applicationcomplexity, but very, very high skill. So\nagain, spam filtering falls into this. Thecomplexity of spam filtering has gone up over\ntime, but is something that is reasonable", "start": 2400.0, "heat": 0.0}, {"text": "within systems. But the scale is very high,\nthat we just don't want a human being involvedwith that process.And on the other end of the spectrum is where\nyou have very high application complexitythat'll only happen a couple of times. So\nthis could be, say, reviewing a situation.Maybe a company is trying to make an acquisition.\nIt's not going to happen over and over.So you might have a human involved with that,\nthat goes through a lot of that. Maybe theytarget the system to go look for specific\npieces of information. But really, it's thehuman that might be more effective in that,\nespecially given that the situation wouldchange over and over. All right.So with that, we're going do take a quick\ntour of the world of machine learning. I'llstop there for a second. Any questions? OK.\nAll right. So what is machine learning? Alwaysa good place to start. It's the study of algorithms\nto improve their performance at some taskwith experience. In this context, experience\nis data.And they typically do this by optimizing based\non some performance criteria that uses exampledata or past experience. So in the world of\nsupervised learning, that could be the exampledata. Or past experience could be the correct\nlabel, given an input data set or input datapoint.Machine learning is a combination of techniques\nfrom statistics, computer, and computer sciencecommunities. And it's the idea of getting\ncomputers to program themselves. Common taskswithin the world of machine learning could\nbe things like classification, regression,prediction, clustering, et cetera.For those who are maybe making the shift to\nmachine learning from traditional programming,I found this, again, from Pedro Domingos to\nbe a very useful way of describing it to people.So in traditional programming, you have a\ndata set. You write a program, which wouldbe if you see this, do that. When you see\nthis, do that. For this many instances, do", "start": 2520.0, "heat": 0.0}, {"text": "the following thing on it and then write an\noutput out, right?So you input a data into the program into\na computer, and the computer produces an outputwhere it says, OK, I've applied this program\non that data. And this gives me the output.Machine learning is a very different way of\nthinking about it in which you're almost inputtingthe data as well as the output.So in this case, the data could be unlabeled\nimages. The output could be the labels associatedwith those images. And you tell the computer,\nfigure out what the program would look like.And this is a slightly different way of thinking\nabout machine learning versus traditionalprogramming.What are some of these programs or algorithms\nthat the computer might use to figure it out?So within the large realm of machine learning,\nwe have supervised, unsupervised reinforcementlearning. What we have in the brackets is\nessentially what you're providing in the world.In the case of supervised learning, you're\nproviding labels, which is the correct labelassociated with an input feature or with an\ninput data set or data point. In unsupervisedlearning, you typically have no labels, but\nalso are limited by what the algorithm itselfcan do.And in the world of reinforcement learning,\ninstead of a label per data point, you'reproviding the reward information to the system\nthat says if you're doing more-- if you'redoing the right thing, I'm going to give you\nsome points. If you're doing the wrong thing,I'm going to take away some points-- very\nuseful in very complex applications whereyou can't really figure out the labels associated\nwith each data point.Within the world of supervised learning, the\ntypical tasks that people have-- and I shouldnote before I go through this. There's a lot\nof overlap between all of these differentpieces. So this is a high-level view. But\nwe can certainly argue about the specificpositioning of everything. I'm sure we can.So within supervised learning, you can fall\ninto classification regression. Unsupervisedlearning is typically clustering dimensionality\nreduction. And within these, there are differentalgorithms that fall into place. So examples\ncould be things like neural nets that cover", "start": 2640.0, "heat": 0.0}, {"text": "all of these spaces.You got-- just take regression, PCA, which\nmight fall into dimensionality reduction,lots and lots of different techniques and\nalso some in the reinforcement learning world.And there's just more and more and more. If\nyou open up a survey of machine learning,it'll give you even more than all of these\ntechniques over here.And the thing to remember when you're using\nmachine learning is that there are some commonpitfalls that you can fall into. An example\nof that would be overfitting versus underfittingwhere you come up with this awesome model\nthat does really, really well on your trainingdata.You apply it to your test data, and you get\nterrible results. You might have done a reallygood job learning the training data, but not\nnecessarily learning-- being able to generalizebeyond that. Sometimes it could be just the\nalgorithm itself is unable to correctly modelthe behavior that's exhibited by the training\nand test data.I won't go through each of these again, but\nthere might just be bad, noisy, missing data.That certainly happens where you end up with\nan algorithm with terrible results. And youlook at it and you're like, well, why is that?\nAnd you actually look at the data that youdid. And it was incorrect, that there was\njust missing features. Or it was noisy innature, such that the actual phenomenology\nthat you were trying to look for was hiddenwithin the noise.You might have picked the wrong model. You\nmight have used a linear model in a non-linearcase where the phenomenology you're trying\nto describe is non-linear in nature, but maybeyou've used a linear model. You've not done\na good job of separating training versus testingdata, et cetera, et cetera.So we'll just take a quick view into each\nof these different learning paradigms. Sothe first is on supervised learning. And you\nbasically start with label data or what wecall-- it was often referred to as ground\ntruth. And you build a model that predictslabels, given new pieces of data.", "start": 2760.0, "heat": 0.0}, {"text": "And you have two general goals. One is in\nregression, which is to predict some continuousvariable or a classification, which is to\npredict a class or label. So if we look atthis, the diagram on the right, we have training\ndata that we provide, which is data and labels.That goes into a trained model. That's typically\nan iterative process where we find out, well,did we do a good job? That is now called a\nsupervised learning model that we then applynew data, or test data, or unseen data and\nlook at the predicted labels.Typically, when you are designing an algorithm\nlike this, you'd separate out. You'd takeyour training data. You'd remove a small portion\nof it that you do know the labels for. That'syour test data over here. And then you run\nthat. And you can see, well, is it workingwell or not?And most of these algorithms have a training\nstep that forms a model. So when we talk aboutmachine learning in both the supervised and\nunsupervised sense, we'll often talk abouttraining the model, which is this process,\nand then inference, which is the second step,which is where you apply unseen data. So this\nis the trained model in deployment or in thefield. It's performing inference at that point.Of course, no class these days on machine\nlearning and AI could go without talking aboutneural networks. And as I mentioned, neural\nnetworks do form a very important part ofmachine learning. And they certainly are an\nalgorithm that many of you, I'm sure, arefamiliar with. And they fall well within the\nsupervised and unsupervised. And they've beenused for so many different applications at\nthis point.So what's a neural network? A computing system\ninspired by biological networks. And the systemessentially learns by repetitive training\nto do tasks based on examples. Much of thework that we've seen is typically it being\napplied to supervised learning, though I'llmention some that we are doing, some research\nand actually applying it for unsupervised", "start": 2880.0, "heat": 0.0}, {"text": "learning as well. And they're quite powerful.The components of a neural network include\ninputs, layers, outputs, and weights. So theseare often the terms that someone will use.\nAnd a deep neural network has lots of hiddenlayers. Does anyone here have a better definition\nfor what deep neural network means beyondlots? I've heard definitions anywhere, 3 and\nabove. Yes?AUDIENCE: [INAUDIBLE] deep neural network\nwill occur at any recurrent networks. Becausethat has more than one layer, but not necessarily\nmore than one layer after you have actuallywritten the code for it.VIJAY GADEPALLY: OK, so one definition here\nfor deep is-- and this is-- anyone have abetter-- no. So the one to beat right now\nis-- a feature of a deep neural network couldbe recurrence within the network architecture,\nwhich implies that there is some depth tothe overall network. So above 3 with recurrence--\ndeep. All right.Lots of variance within the supervised world\nof neural networks, such as convolutionalneural networks, recursive neural networks,\ndeep belief networks. One, I think, in myopinion-- again, since you've all asked me\nto opine here. I know you've not, but I thinka reason that these are so popular these days\nis there's so many tools out there that arevery easy to use.You can just go online and within about five\nminutes, write your first neural network.Try writing a hidden mark-off model that quickly.\nMaybe there are people who can, but in general.So what are the features of a deep neural\nnetwork? So you have some input features.You have weights, which are essentially associated\nwith each line over here, as well as biasesfor each of the layers that govern the interaction\nbetween the layers and then an output layer.So these input features can often be combined\nto each other. So these feature vectors thatare coming in can often be combined. Think\nJeremy we'll talk a little bit about how the", "start": 3000.0, "heat": 0.0}, {"text": "matrix view of all of this.But you can think of it as if your-- an example\ncould be if you have an image, it could bethe RGB pixel values of each pixel in that\nimage, could be the input feature. So youcould have large numbers of input features.\nIf you have a time series signal, it couldbe the amplitude or the magnitude at a particular\nfrequency or at a particular step.There's often a combination of features that\nyou might do. So in addition to the pixelintensities for an image, you might also then\ncombine the spatial distance between two pixels.Or its position within the image may also\nbe another input feature. And you can reallygo hog wild over here, just trying to come\nup with new features.And there's a lot of research just in that\narea, which is I take a data set that everyoneknows. And I'm just going to spend a lot of\ntime doing feature engineering, which is comingup with, well, what is the right way to do\nthe features? So coming back to an earlierquestion, this is an area where people are\noften looking at supplementing maybe a givendata set with additional data.And then fusing those two pieces together,\nfor example, could be audio and text togetheras input features to a network, that you can\nthen learn that might do a better job. Butall of this is governed by this really, really\nsimple, but powerful equation, which is thatthe output at the i plus 1th layer is given\nby some non-linear function of the weightsmultiplied by the inputs from the previous\nstep, plus some bias term then.And when you're learning-- when you're training\na machine learning model, you're essentiallytrying to figure out what the Ws are and what\nthe Bs are. That's really what a model isdefined as. So if we zoom into one of these\npieces, it's actually pretty straightforward", "start": 3120.0, "heat": 0.0}, {"text": "what's going on over here.So you have your inputs that are coming from\nthe previous layers, so this could be yourY sub i. Here are the different weights, so\nW1, W2, W3. These are the connections or theweights going into a neuron or a node. And\nyou're performing some function on these inputs.And that function is referred to as an activation\nfunction.So let's just take an example where we have\nsome actual numbers. Maybe I've gone through.I've trained my models. I figured out that\njust for this one dot in that big networkthat we saw earlier, that my weights are 2.7,\n8.6, and 0.002. My inputs from the previouslayer is maybe -0.06, 2.5, 1.4.And all I'm doing is coming up with this x,\nwhich is -0.06 multiplied by 2.7, plus 2.5,times 8.6, plus 1.4 times that. That gives\nme some number-- 21.34. I apply my non-linearfunction, which in this case is a sigmoid\ngoverned by that equation at the top right.And I say f of 21.34, so somewhere way over\nthere is approximately 1, right? So this--probably a little less than 1, but approximately\n1 for the purpose of this.And you just do that over and over. So really,\na neural network-- I think the power of aneural network is it allows you to encode\na lot less information than many of the othermachine learning algorithms out there at the\ncost, typically, of a lot more data beingused and a lot more computing being used.\nBut for many people, that's perfectly fine,right?But it does take-- it's just over and over,\nback and forth, back and forth, back and forthto come up with, what's the right Ws in order\nfor this to give me a result that looks reasonable?Lots of work going on and just deciding the\nright activation function.I showed you a sigmoid over there. We do a\nlot of work with ReLU units. The choices--", "start": 3240.0, "heat": 0.0}, {"text": "there are certain applications-- certain,\nI should say, domains or applications wherepeople have found that a particular activation\nfunction tends to work well.But that choice is something I leave to domain\nexperts to maybe look at their problem andfigure out what are the relative advantages.\nEach of these have their own advantages. Iknow, for example, one of the big advantages\nof rectified linear unit is that since you'renot limiting yourself between a -0 and 1 range,\nyou don't have to do that. You don't run intoa problem of vanishing gradients. That doesn't\nmean much for people. That's OK. We're notgoing to spend too much time talking about\nthat anyhow.AUDIENCE: Vijay?VIJAY GADEPALLY: Yeah?AUDIENCE: So in general, [INAUDIBLE].VIJAY GADEPALLY: So the question is picking\nthe activation functions, picking the numberof layers. We'll talk about that in a couple\nof slides. But there is a lot of art. Trialand error-- yes, but also, we'll call it art\nas well that's involved with coming up withthat.A lot of what happens in practice, however,\nis you find an application area, which looksvery similar to the problem that you are trying\nto solve. And you might borrow the architecturefrom there and use that as a starting point\nin coming up with where you start. Yeah?AUDIENCE: Are you aware of any research of\nsome type of parameterizing the activationfunction and then trying to learn the activation\nfunction?VIJAY GADEPALLY: I'm sure people are doing\nit. I'm personally not familiar with thatresearch. I don't if anyone else in the room\nhas-- yep?AUDIENCE: [INAUDIBLE] DARPA D3M program, so\ndata-driven machine learning. You're tryingto learn both the architecture of the network\nand the activation function and thereforeall the other attributes. Because you're trying\nto just go from data set to machine learning", "start": 3360.0, "heat": 0.0}, {"text": "system with no human intervention.VIJAY GADEPALLY: So the question was, is there\nany research into parameterizing the activationfunction? So I guess the model as a whole.\nSo, yeah, there is. And one of the responseswas that there is a program run by DARPA,\nwhich is the D3M program, which is reallylooking at, can you go from data to result\nwith no or almost no human intervention?I'm not familiar with activation function\nparameterization. But certainly, network modelparameterization is absolutely there. So people\nwho are running optimization models to basicallylook for-- I have this particular set of resources.\nWhat is the best model architecture that fitsinto that?Maybe I want to deploy this on a really tiny\nprocessor that only gives me 16 megabytesof memory. I want to make sure that my model\nand data can fit on that. Can you find whatwould be the ideal model for that? So that's\nabsolutely something that people are doingright now. But I'm not sure if people are\ntrying to come up with, I guess, brand newactivation functions. All right.So lots of stuff in the neural network landscape.\nAnd as I mentioned earlier, neural networktraining is essentially adjusting weights\nuntil the function represented by the neuralnetwork essentially does what you would like\nit to do. And the key idea here is to iterativelyadjust weights to reduce the error.So what you do is you take some random instantiation\nof your neural network or maybe based on anotherdomain or another problem. You might borrow\nthat. And you start there. And then you passa data set in. You look at the output and\nyou say, that's not right. What went wrongover here?And you go back and adjust things and do that\nagain, and again, and again, and again, andagain, over and over, until you get something\nthat looks reasonable. That's really what's", "start": 3480.0, "heat": 0.0}, {"text": "going on over there. And so real neural networks\ncan have thousands of input, data points--hundreds of layers, and millions to billions\nof weight changes per iteration. Yes?AUDIENCE: So what you're talking about is\n[INAUDIBLE] adjustment [INAUDIBLE]. Do youknow of any [INAUDIBLE] this process?VIJAY GADEPALLY: Yes, there's a lot of work\nbeing done to parallelize this--AUDIENCE: Like, for--VIJAY GADEPALLY: --and by default.AUDIENCE: [INAUDIBLE]?VIJAY GADEPALLY: So the question is when--\nas I just described it right now, it's a serialprocess where I pass one data point in. It\ngoes all the way to the end. It says, oh,this is the output-- goes back and adjusts.\nAre there techniques that people are doingto do this in a distributed fashion? And the\nanswer to that is a strong yes. It's a veryactive area in especially high-performance\ncomputing and machine learning.We might talk about this in-- are we talking\nabout this on day three? We might talk a littlebit about it. But there is model parallelism,\nwhich is I have the model itself distributedacross multiple pieces. And I want to adjust\ndifferent pieces of the model at the sametime. There's research and lots of results.\nI think we might even have some examples thatpeople are doing with that.AUDIENCE: Have you got some examples on the\n[INAUDIBLE] approach, the [INAUDIBLE] approach?VIJAY GADEPALLY: A little bit earlier.AUDIENCE: Communication [INAUDIBLE].VIJAY GADEPALLY: So there are many different\nways to parallelize it. One would be dataparallelism, which is I take my big data set\nor big data point, and I distribute that acrossmy different nodes. And each one independently\nlearns a model that works well. And then Ido some synchronization across these different\npieces.There are also techniques where you have--\nthe model itself may be too big to sit ona single node or a single processing element.\nAnd you might have to distribute that. So,yes, a lot of very interesting research going\non in that area. And by default, when you", "start": 3600.0, "heat": 0.0}, {"text": "do run things, they are running in parallel,\njust even on your GPU. They're using multiplecores at once. So there is some level of--\nwithin the node itself, parallelism that runsby default on most machine learning software.So inferences-- I mentioned is just using\nthe trained model again. And the power ofneural networks really falls within their\nnon-linearity. So you have that non-linearF function that you're applying over and over\nand over across your layers. And this crudelydrawn diagram on my iPad-- this is not clear\nat all.If you had Xs and Os, right? It reminds me\nof a song. And you have features over here.And you're trying to basically classify it.\nWhich is an X? And which is an O? A linearclassifier could do a pretty good job in this\ntype of situation. And you could apply a neuralnetwork to this, but maybe it's overkill in\nthat type of situation.But in some feature space, if this is how\nyour Xs and Os are divided amongst each otherand you're trying to come up with the right\nlabel, one thing I might suggest is maybefind another feature space that you could\nmaybe get a better separation between thetwo. Or a technique like a neural network\nmight do a very good job. Or any of thesenon-linear machine learning techniques might\ndo a very good job for looking for these reallycomplex decision boundaries that are out there.\nAll right.So you mentioned earlier when you're designing\na neural network, what do you have to do?What are the different choices, et cetera?\nThere is a lot going on here. So you haveto pick the depth, the number of layers, the\ninputs, and what the inputs are, the typeof network that you're using, the types of\nlayers, the training algorithm and metricsthat you're using to assess the performance\nof this neural network.The good thing, however, is it so expensive\nto train a neural network, that you largelyare not making these decisions in many cases.\nYou just pick up what somebody else has done,and you start from there, and then you start.\nThat might be-- I don't know if that's a goodor a bad thing. But that's often a way in\npractice that people end up doing this.", "start": 3720.0, "heat": 0.0}, {"text": "But there is some theory on the general approach.\nI think in this short amount of time, whichI'm already over, we won't be able to get\ninto it. But I'm happy to-- actually, theseslides have backups on them. So when I share\nthem with you, they do have a lot more detailon each of these different pieces. All right.Very quickly, we'll talk about unsupervised\nlearning. And the basic idea is the task ofdescribing a hidden structure from unlabeled\ndata. So in contrast to supervised learning,we are not providing labels. We're just giving\nthe algorithm a data set and saying, tellme something cool that's going on over here.Now, clearly, you can't label the data if\nyou do that. But what you can do is maybelook for clusters or look for dimensions or\npieces of the data that are unimportant orextraneous. So if we observe certain features,\nwe would like to observe the patterns amongstthese features.And the typical tasks that one would do in\nunsupervised learning is clustering and dataprojection, or data pre-processing, or dimensionality\nreduction. And the goal is to discover interestingthings about the data set, such as subgroups,\npatterns, clusters, et cetera.In unsupervised learning-- one of the difficulties\nin supervised learning-- we know, right? Wehave an input. We have a label. And we're\nlike, OK, if that input-- if my algorithmdoesn't give me the label, bad. Go retrain.\nOr I know what-- I can go back, use that asmy performance metric.On unsupervised learning, there is no simple\ngoal such as maximizing a certain probabilityfor the algorithm. Some of that is going to\nbe something that you have to work on, isat the interclass or intraclass distance that\nI'm most having that separation. Is that goingto be my performance metric? Is it the number\nof clusters that I'm creating? Is that thenumber of-- is that the metric that I'm using?But it is very popular, because it works on\nunlabeled data. And I'm sure many of us workon data sets, which are just too large or\ntoo difficult to sit and label. An examplethat comes to my mind, certainly, is in the\nworld of cybersecurity where you're collecting", "start": 3840.0, "heat": 0.0}, {"text": "billions and billions of networked packets.\nAnd you're trying to look for an almost behavior.You're not going to go through and look at\neach pack and be like, bad, good, what itis. But you might use an unsupervised technique\nto maybe extract out some of the relevantpieces, then use a supervised-- then go through\nthe trouble of labeling that data, and thenpass that on to a supervised learning technique.\nAnd I'm happy to share some research thatwe've been doing on that front.Some common techniques are within clustering\nand data projection. Clustering is the basicidea that we want to group objects or sets\nof features, such that objects in the samecluster are more similar to those of another\ncluster. And what you typically do for thatis you put your data in some feature space,\nand you try to maximize some intraclustermeasure, which is basically saying, I want\nthe points within my cluster to be closerthan anything outside of my cluster, right?So that's a metric. And you iteratively move\nthe membership from each. You set a numberof clusters, saying, I need five clusters.\nIt'll randomly assign things. And it'll keepadjusting the membership of a particular data\npoint within a cluster, based on a metricsuch as the squared error.So in this example, we might say that, OK,\nthese are three clusters that I get out ofit. Dimensionality reduction is the idea of\nreducing the number of random variables underconsideration. Very often, you'll collect\na data set that has hundreds to thousandsof different features.Maybe some of these features are not that\nimportant. Maybe they're unchanging. Or evenif they are changing, it's not by much. And\nso maybe you want to remove them from consideration.That's when you use a technique like dimensionality\nreduction. And this is really, really importantwhen you're doing feature selection and feature\nextraction in your real data sets. And youmight also use it for other techniques, such\nas compression or visualization.So if you want to show things on Excel, showing\na thousand dimensional object may be difficult.You might try to project it down to the two\nor three dimensions that are easiest to visualize.", "start": 3960.0, "heat": 0.0}, {"text": "And of course, you can use neural networks\nfor unsupervised learning as well. Surprise,surprise.So as much as a lot of the press you've seen\nhas been on things like image classificationusing nice labeled data sets, there's a lot\nof work where you can apply it in an unsupervisedcase. And these are largely used to find better\nrepresentations for data, such as clusteringand dimensionality reduction. And they're\nreally powerful because of their non-linearcapabilities.So one example-- I won't spend way too much\ntime on this-- is an autoencoder. And thebasic idea behind an autoencoder is you're\ntrying to find some compressed representationfor data. And the way we do this is by changing\nthe metric that we use to say that the systemhas done a good job.And the metric is basically-- if I have a\nset of input features that I'm passing in,I would like to do the best job in reconstructing\nthat input at my output. And what I do isI squeeze it through a smaller number of layers,\nwhich forms this compressed representationfor my data set.And so the idea here is, how can I pass my\ninputs through this narrow waste to come upwith a reconstructed input that's very similar\nto my original input? And so my metric inthis particular case is essentially the difference\nbetween the reconstructed input or the outputand the input. And the compressed representation--\nyou can think of as the reduced dimensionalityversion of my problem.We've also done some work on replicator networks,\nwhich are also really, really cool. Happyto chat about that as well. And finally, we\nhave to talk very briefly on reinforcementlearning. And the basic-- again, at a very\nhigh level, the reason reinforcement learningis fundamentally different than supervised\nor unsupervised learning is that you're notpassing in a label associated with an input\nfeature.So there is no supervisor or a person that\ncan label it, but just a reward signal. And", "start": 4080.0, "heat": 0.0}, {"text": "the feedback is often delayed. And time is\nimportant, so it steps through a process.And the agent's actions often change the input\ndata that it receives. So just to maybe--in the interest of time, just to give you\nexamples of where reinforcement learning couldwork and why you would use a technique like\nreinforcement learning.So flying stunt maneuvers in a helicopter.\nSo if your helicopter is straight, you saykeep doing more of whatever you're doing to\nkeep it there. If the helicopter tips over,you say stop doing whatever you just did to\ndo that. Could you create a supervised learningalgorithm for doing this? Sure. Right?You would basically look for all the configurations\nof your entire system every time the helicopterwas upright. And you would look for all the\nexamples where your helicopter was tippingover or falling. And you would basically say,\nOK, my engine speed was this much. My rotorspeed was this much.And there are probably people here who fly\nhelicopters, so pardon me if I am completelyoversimplifying this problem here. However,\nyou could certainly label it that way andsay all these configurations of the helicopter\nmeant the helicopter was upright. All theseconfigurations of the helicopter meant the\nhelicopter was not upright.That would be pretty expensive and difficult\ndata-- collect to do. Not sure how many peoplewant to volunteer for-- let's do all the ones\nthat are at faults. And lots of other applicationsbeyond that. So these are really useful, especially\nin cases where-- what you're trying to modelis just extremely complex. And the other really\npowerful thing is this tends to mimic humanbehavior. And so they're very useful in those\ntype of applications.AUDIENCE: Can you explain, shortly, what a\nreward would look like?VIJAY GADEPALLY: So a reward would just be--\nit would be very similar until you get points.So you have your algorithm that's basically\ntrying to maximize the number of points thatit receives, for example. And as you do--\nit's very similar to what you or I would consider", "start": 4200.0, "heat": 0.0}, {"text": "a reward playing a video game, right?Every time I get points, I do more of the\nactivities that make me get points. And it'sessentially the same concept over here. All\nright. So with that, I will conclude only20 minutes behind schedule. So I guess the\nlong story short is there's lots of excitingresearch into AI and machine learning techniques\nout here.We did a one-hour view of this broad field\nthat research has dedicated about six to sevendecades of work to words, so my apologies\nto anyone watching this or in the room whosework I just jumped over. The key ingredients,\nhowever-- and I think this is most importantto this group-- is I look at what are the\nproblems where AI has done really well.These are some of the key ingredients-- data\navailability, computing infrastructure, andthe domain expertise and algorithms. And I\nthink it's very exciting to see this groupover here, because we do have all of these\npieces coming together. So great things arebound to happen.There are, I think, large challenges in data\navailability and readiness for AI, which iswhat we're just going to scrape the edge off\nduring this class. And some of the computinginfrastructure is something that we'll be\ntalking to you about in a couple of minutes.And if you're interested in some of the more\ndetailed look at any of these things, a numberof us actually wrote-- maybe I'm biased. I\nthink it's a great, great, great write-up.But, no, I think it's useful. It has its places.\nObviously, a lot of material in here. Butwe try to do our best job to at least cite\nsome of this really, really interesting workthat's going on in the field. So with that,\nI'll pause for any additional questions, butthank you very much for your attention.", "start": 4320.0, "heat": 0.0}]