[{"text": "OK.So this is the first lecture on\neigenvalues and eigenvectors,and that's a big subject\nthat will take upmost of the rest of the course.It's, again, matrices are\nsquare and we're looking nowfor some special\nnumbers, the eigenvalues,and some special vectors,\nthe eigenvectors.And so this lecture is mostly\nabout what are these numbers,and then the other lectures\nare about how do we use them,why do we want them.OK, so what's an eigenvector?Maybe I'll start\nwith eigenvector.What's an eigenvector?So I have a matrix A.OK.What does a matrix do?It acts on vectors.It multiplies vectors x.So the way that matrix acts\nis in goes a vector x and outcomes a vector Ax.It's like a function.With a function in\ncalculus, in goesa number x, out comes f(x).Here in linear algebra\nwe're up in more dimensions.In goes a vector x,\nout comes a vector Ax.And the vectors I'm\nspecially interested inare the ones the come\nout in the same directionthat they went in.That won't be typical.Most vectors, Ax is in -- points\nin some different direction.But there are certain vectors\nwhere Ax comes out parallel", "start": 0.0, "heat": 0.1}, {"text": "to x.And those are the eigenvectors.So Ax parallel to x.Those are the eigenvectors.And what do I mean by parallel?Oh, much easier to just\nstate it in an equation.Ax is some multiple -- and\neverybody calls that multiplelambda -- of x.That's our big equation.We look for special vectors\n-- and remember most vectorswon't be eigenvectors --that -- for which Ax is in\nthe same direction as x,and by same direction I allow\nit to be the very oppositedirection, I allow lambda\nto be negative or zero.Well, I guess we've met\nthe eigenvectors thathave eigenvalue zero.Those are in the same\ndirection, but they're --in a kind of very special way.So this -- the eigenvector x.Lambda, whatever this\nmultiplying factoris, whether it's six or\nminus six or zero or evensome imaginary number,\nthat's the eigenvalue.So there's the eigenvalue,\nthere's the eigenvector.Let's just take a second\non eigenvalue zero.From the point of view of\neigenvalues, that's no specialdeal.That's, we have an eigenvector.If the eigenvalue\nhappened to be zero,that would mean that Ax was\nzero x, in other words zero.So what would x, where would we\nlook for -- what are the x-s?", "start": 120.0, "heat": 0.1}, {"text": "What are the eigenvectors\nwith eigenvalue zero?They're the guys in the\nnull space, Ax equals zero.So if our matrix is singular,\nlet me write this down.If, if A is singular, then that\n-- what does singular mean?It means that it takes\nsome vector x into zero.Some non-zero\nvector, that's why --will be the\neigenvector into zero.Then lambda equals\nzero is an eigenvalue.But we're interested\nin all eigenvalues now,lambda equals zero is not,\nlike, so special anymore.OK.So the question is, how do we\nfind these x-s and lambdas?And notice -- we don't have an\nequation Ax equal B anymore.I can't use elimination.I've got two unknowns,\nand in fact they'remultiplied together.Lambda and x are\nboth unknowns here.So, we need to, we need a\ngood idea of how to find them.But before I, before\nI do that, and that'swhere determinant will\ncome in, can I justgive you some matrices?Like here you go.Take the matrix, a\nprojection matrix.OK.So suppose we have a plane\nand our matrix P is --what I've called A, now\nI'm going to call it Pfor the moment, because it's --I'm thinking OK, let's\nlook at a then this,this other new matrix, I just\nhave an Ax, projection matrix.What are the eigenvalues\nof a projection matrix?", "start": 240.0, "heat": 0.1}, {"text": "So that's my question.What are the x-s, the\neigenvectors, and the lambdas,the eigenvalues, thing,4 but the\nroots of that quadratic for --and now let me say\na projection matrix.My, my point is that we --before we get into\ndeterminants and, and formulasand all that stuff,\nlet's take some matriceswhere we know what they do.We know that if we take a\nvector b, what this matrix doesis it projects it down to Pb.So is b an eigenvector\nin, in that picture?Is that vector b an eigenvector?No.Not so, so b is\nnot an eigenvectorc- because Pb, its projection,\nis in a different direction.So now tell me what vectors\nare eigenvectors of P?What vectors do get projected\nin the same direction that theystart?So, so answer, tell me some x-s.Do you see what3 so it's\nif Ax equals lambda x,In this picture, where could\nI start with a vector b or x,do its projection, and end\nup in the same direction?Well, that would happen if the\nvector was right in that planealready.If the vector x was --\nso let the vector x --so any vector, any x in the\nplane will be an eigenvector.And what will happen\nwhen I multiply by P,when I project a vector x --I called it b here, because\nthis is our familiar picture,", "start": 360.0, "heat": 0.1}, {"text": "but now I'm going to say that\nb was no good for, for the,for our purposes.I'm interested in a vector x\nthat's actually in the plane,and I project it, and\nwhat do I get back?x, of course.Doesn't move. can\nbe complex numbers.So any x in the plane\nis unchanged by P,and what's that telling me?That's telling me that\nx is an eigenvector,and it's also telling me what's\nthe eigenvalue, which is --just compare it with that.The eigenvalue, the\nmultiplier, is just one.Good.So we have actually a whole\nplane of eigenvectors.Now I ask, are there\nany other eigenvectors?And I expect the\nanswer to be yes,because I would\nlike to get three,if I'm in three\ndimensions, I wouldlike to hope for three\nindependent eigenvectors, twoof them in the plane and\none not in the plane.OK.So this guy b that I drew\nthere was not any good.What's the right eigenvector\nthat's not in the plane?The, the good one is the one\nthat's perpendicular to theplane.There's an, another good x,\nbecause what's the projection?So these are eigenvectors.Another guy here would\nbe another eigenvector.But now here is\nanother one. two.Any x that's perpendicular\nto the plane,what's Px for that,\nfor that, vector?What's the projection of this\nguy perpendicular to the plane?It is zero, of course.So -- there's the null space.Px and n- for those guys are\nzero, or zero x if we like,and the eigenvalue is zero.", "start": 480.0, "heat": 0.1}, {"text": "So my answer to the question\nis, what are the eigenvalues forIn our example, the\none we worked out,a projection matrix?There they are.One and zero.OK.We know projection matrices.We can write them down as that\nA, A transpose, A inverse,A transpose thing, but without\ndoing that from the picturewe could see what\nare the eigenvectors.OK.Are there other matrices?Let me take a second example.How about a permutation matrix?What about the matrix,\nI'll call it A now.Zero one, one zero.A equals zero one one zero,\nthat had eigenvalue one andCan you tell me a vector x --see, we'll have a\nsystem soon enough,so I, I would like\nto just do these e-these couple of examples, just\nto see the picture before we,before we let it\nall, go into a systemwhere that, matrix\nisn't anything special.Because it is special.And what, so what vector\ncould I multiply by and end upin the same direction?Can you spot an\neigenvector for this guy?That's a matrix that\npermutes x1 and x2, right?It switches the two\ncomponents of x.How could the vector\nwith its x2 x1, with --permuted turn out to\nbe a multiple of x1 x2,the vector we start with?Can you tell me an\neigenvector here for this guy?x equal -- what is -- actually,\ncan you tell me one vector thatwhich is lambda x,\nand I have a three x,And of course you -- everybody\nknows that they're -- what,", "start": 600.0, "heat": 0.1}, {"text": "has eigenvalue one?So what, what vector\nwould have eigenvalue one,just above what we2\nfound here. so that if I,if I permute it it\ndoesn't change? right?There, that could\nbe one one, thanks.One one.OK, take that vector one one.That will be an eigenvector,\nbecause if I do AxI get one one.So that's the eigenvalue is one.Great.That's one eigenvalue.But I have here a\ntwo by two matrix,and I figure there's going\nto be a second eigenvalue.And eigenvector.Now, what about that?What's a vector, OK, maybe\nwe can just, like, guess it.A vector that the\nother -- actually,this one that I'm thinking of\nis going to be a vector that haseigenvalue minus one.That's going to be my other\neigenvalue for this matrix.It's a -- notice the nice\npositive or not negativematrix, but an eigenvalue is\ngoing to come out negative.And can you guess, spot\nthe x that will work forTimes x is supposed to\ngive me zero, right? that?So I want a, a vector.When I multiply by A, which\nreverses the two components,I want the thing to come\nout minus the original.So what shall I send\nin in that case?If I send in negative one one.Then when I apply A, I get\nI do that multiplication,and I get one negative\none, so it reversed sign.So Ax is -x.Lambda is minus one.Ax -- so Ax was x there\nand Ax is minus x here.", "start": 720.0, "heat": 0.1}, {"text": "Can I just mention,\nlike, jump ahead, have,give a perfectly\ninnocent-looking quadraticand point out a special\nlittle fact about eigenvalues.n by n matrices will\nhave n eigenvalues.And I get this matrix4\nzero zero zero one,And it's not like -- suppose\nn is three or four or more.It's not so easy to find them.We'd have a third degree or a\nfourth degree or an n-th degreeequation.But here's one nice fact.There, there's one\npleasant fact. we --the eigenvalues came\nout four and two.That the sum of the\neigenvalues equals the sumdown the diagonal.That's called the trace, and\nI put that in the lectureNow I add three I to that\nmatrix. content specifically.So this is a neat fact, the fact\nthat sthe sum of the lambdas,add up the lambdas,\nequals the sum --what would you like me to,\nshall I write that down?What I'm want to say in words is\nthe sum down the diagonal of A.Shall I write a11+a22+...+ ann.That's add up the\ndiagonal entries.In this example, it's zero.In other words, once I found\nthis eigenvalue of one,I knew the other one\nhad to be minus onein this two by two case, because\nin the two by two case, whichis a good one to, to, play\nwith, the trace tells youright away what the\nother eigenvalue is.So if I tell you one\neigenvalue, you can tell me theother one.We'll, we'll have that -- we'll,\nminus one and eigenvectors one", "start": 840.0, "heat": 0.1}, {"text": "one and eigenvector minus\none we'll see that again.OK.Now can I --I could give more\nexamples, but maybe it'stime to face the, the equation,\nAx equal lambda x, and figurehow are we going to\nfind x and lambda.And that is lambda\none times lambda3OK.So this, so the\nquestion now is howto find eigenvalues\nand eigenvectors.How to solve, how to solve Ax\nequal lambda x from the threex, so it's just I mean,\nwhen we've got two unknownsboth in the equation.OK.Here's the trick.Simple idea.Bring this onto the same side.Rewrite.Bring this over as A minus\nlambda times the identity xOne. equals zero.Right?I have Ax minus lambda\nx, so I brought that overand I've got zero left on\nthe, on the right-hand side.What's the relation\nbetween that problem and --let me writeOK.I don't know lambda and I don't\nknow x, but I do know somethinghere.What I know is if\nI, if I'm goingto be able to solve this thing,\nfor some x that's not the zerovector, that's not, that's\na useless eigenvector,doesn't count.What I know now is that\nthis matrix must be what?If I'm going to be --\nif there is an x --I don't -- right now I\ndon't know what it is.I'm going to find\nlambda first, actually.And -- but if there is an x,\nit tells me that this matrix,", "start": 960.0, "heat": 0.1}, {"text": "this special combination,\nwhich is like the matrix A withlambda -- shifted by\nlambda, shifted by lambda I,that it has to be singular.This matrix must be\nsingular, otherwisethe only x would be the\nzero x, and zero matrix.OK.So this is singular.And what do I now know\nabout singular matrices?So, so take three away.Their determinant is zero.So I've -- so from the fact\nthat that has to be singular,I know that the determinant of\nA minus lambda I has to be zero.And that, now I've\ngot x out of it.I've got an equation for\nlambda, that the key equation --it's called the characteristic\nequation or the eigenvalueequation.And that -- in other words,\nI'm now in a position to findlambda first.So -- the idea will be\nto find lambda first.And actually, I won't\nfind one lambda,I'll find N different lambdas.Well, n lambdas, maybe\nnot n different ones.A lambda could be repeated.A repeated lambda is the\nsource of all trouble in 18.06.So, let's hope for the moment\nthat they're not repeated.There, there they\nwere different, right?One and minus one in that, in\nthat, for that permutation.OK.So and after I found this\nlambda, can I just look ahead?How I going to find x?", "start": 1080.0, "heat": 0.1}, {"text": "After I have found this lambda,\nthe lambda being this --one of the numbers that\nmakes this matrix singular.Their product was eight.Then of course finding x\nis just by elimination.Right?It's just -- now I've\ngot a singular matrix,I'm looking for the null space.We're experts at\nfinding the null space.You know, you do\nelimination, you identifythe, the, the pivot columns\nand so on, you're --and, give values to\nthe free variables.Probably there'll only\nbe one free variable.We'll give it the\nvalue one, like there.And we find the other variable.OK.So let's -- find the x\nsecond will be a doable job.That's my big equation for x.Let's go, let's look at the\nfirst job of finding lambda.Can I take another example?OK.And let's, let's\nwork that one out.OK.So let me take the example,\nsay, let me make it easy.it's just sitting there.Three three one and\none. what do youknow about the complex numbers?So I've made it easy.I've made it two by two.I've made it symmetric.And I even made it\nconstant down the diagonal.That a matrix, a perfectly\nreal matrix couldSo that -- so the more, like,\nspecial properties I stickinto the matrix, the more\nspecial outcome I getfor the eigenvalues.For example, this\nsymmetric matrix,I know that it'll come out\nwith real eigenvalues. one.The eigenvalues will turn\nout to be nice real numbers.And up in our previous example,\nthat was a symmetric matrix.Actually, while we're at it,\nthat was a symmetric matrix.", "start": 1200.0, "heat": 0.1}, {"text": "Its eigenvalues were nice real\nnumbers, one and minus one.And do you notice anything\nabout its eigenvectors?And what do you notice?Anything particular about those\ntwo vectors, one one and minusAnd now comes that thing that\nI wanted to be reminded of.one one?They just happen to be -- no,\nI can't say they just happento be, because that's\nthe whole point,is that they had to be -- what?What are they?They're perpendicular.The vector, when I -- if I see\na vector one one and a one --and a minus one one, my\nmind immediately takes thatdot product.It's zero. what's the\ndeterminant of that matrix?Those vectors are perpendicular.That'll happen here too.Well, let's find\nthe eigenvalues.Actually, oh, my\nexample's too easy.My example is too easy.Let me tell you in advance\nwhat's going to happen.May I?Or shall I do the determinant\nof A minus lambda,and then point out at the end?Will you remind me at\nthe -- after I've foundthe eigenvalues to say why they\nwere -- why they were easy fromThat -- it had to be eight,\nbecause we factored into lambdathe, from the example we did?OK, let's do the job here.Let's compute determinant\nof A minus lambda I.So that's a determinant.And what's, what is this thing?It's the matrix A with lambda\nremoved from the diagonal.for this matrix?So the diagonal\nmatrix is shifted,and then I'm taking\nthe determinant.OK.So I multiply this out.So what is that determinant?Do you notice, I\ndidn't take lambda awayfrom all the entries.It's lambda I, so\nit's lambda along theLambda plus three x. diagonal.So I get three minus lambda\nsquared and then minus one,", "start": 1320.0, "heat": 0.1}, {"text": "right?And I want that to be zero.And what is A minus lambda I x?Well, I'm going to simplify it.And what will I get?So if I multiply this out, I\nget lambda squared minus sixWhat's -- how is this matrix\nrelated to that matrix?lambda plus what?Plus eight.But it's out there.And that I'm going\nto set to zero.And I'm going to solve it.So and it's, it's a\nquadratic equation.I can use factorization, I\ncan use the quadratic formula.I'll get two lambdas.Before I do it, tell me\nwhat's that number six that'sshowing up in this equation?It's the trace.That number six is\nthree plus three.And while we're at it, what's\nthe number eight that'sshowing up in this equation?It's the determinant.That our matrix has\ndeterminant eight.So in a two by two\ncase, it's really nice.It's lambda squared minus\nthe trace times lambda --the trace is the\nlinear coefficient --and plus the determinant,\nthe constant term.OK.So let's -- can, can\nwe find the roots?I guess the easy way is to\nfactor that as something timessomething.If we couldn't factor it,\nthen we'd have to use the oldb^2-4ac formula, but I, I think\nwe can factor that into lambdaminus what times\nlambda minus what?Can you do that factorization?Four and two?Lambda minus four\ntimes lambda minus two.So the, the eigenvalues\nare four and two.", "start": 1440.0, "heat": 0.1}, {"text": "So the eigenvalues are --\none eigenvalue, lambda one,Now I'm looking for x, the\neigenvector. let's say,is four.Lambda two, the other\neigenvalue, is two.The eigenvalues\nare four and two.And then I can go\nfor the eigenvectors.Suppose I have a matrix\nA, and Ax equal lambda x.equals zero.You see I got the\neigenvalues first.So if they, if this\nhad eigenvalue lambda,Four and two.Now for the eigenvectors.So what are the eigenvectors?They're these guys in\nthe null space whenI take away, when I make the\nmatrix singular by takingfour I or two I away.So we're -- we got to\ndo those separately.I'll -- let me find the\neigenvector for four first.So I'll subtract four,\nso A minus four I is --so taking four away will\nput minus ones there.And what's the point\nabout that matrix?If four is an eigenvalue,\nthen A minus fourI had better be a\nwhat kind of matrix?Singular.If that matrix isn't singular,\nthe four wasn't correct.But we're OK, that\nmatrix is singular.And what's the x now?The x is in the null space.So what's the x1 that goes\nwith, with the lambda one?eigenvalue, eigenvector,\neigenvalue for this,So that A -- so this is -- now\nI'm doing A x1 is lambda onex1.So I took A minus lambda\none I, that's this matrix,and now I'm looking for\nthe x1 in its null space,and who is he?What's the vector x\nin the null space?Of course it's one one.So that's the eigenvector that\ngoes with that eigenvalue.So, so now --Let's just spend one\nmore minute on this bad", "start": 1560.0, "heat": 0.1}, {"text": "Now how about the\neigenvector thatgoes with the other eigenvalue?Can I do that\nwith, with erasing?I take A minus two I.So now I take two away\nfrom the diagonal,and that leaves me\nwith a one and a one.So A minus two I has again\nproduced a singular matrix,as it had to.I'm looking for the\nnull space of that guy.What vector is in\nits null space?Well, of course, a\nwhole line of vectors.So when I say the eigenvector,\nI'm not speaking correctly.There's a whole line of\neigenvectors, and you just --I just want a basis.And for a line I\njust want one vector.But -- You could, you're\n-- there's some freedomin choosing that one, but\nchoose a reasonable one.What's a vector in the\nnull space of that?Well, the natural vector\nto pick as the eigenvectorwith, with lambda\ntwo is minus one one.If I did elimination\non that vectorand set that, the free\nvariable to be one,I would get minus one\nand get that eigenvector.So you see then that\nI've got eigenvector,Now the other neat fact\nis that the determinant,How are those two\nmatrices related?Well, one is just three I more\nthan the other one, right? two.I just took that matrix and I --I took this matrix\nand I added three I.", "start": 1680.0, "heat": 0.1}, {"text": "So my question is, what happened\nto the minus four times lambdaminus two. eigenvalues and what\nhappened to the eigenvectors?That's the, that's like the\nquestion we keep asking nowin this chapter.If I, if I do something to the\nmatrix, what happens if I --or I know something\nabout the matrix,what's the what's the\nconclusion for its eigenvectorsand eigenvalues?Because -- those eigenvalues and\neigenvectors are going to tellus important information\nabout the matrix.And here what are we seeing?What's happening to these\neigenvalues, one and minusone, when I add three I?It just added three\nto the eigenvalues.I got four and two, three\nmore than one and minusone.What happened to\nthe eigenvectors?Nothing at all.One one is -- and minus -- and\none -- and minus one one are --is still the eigenvectors.In other words, simple\nbut useful observation.If I add three I to a matrix,\nits eigenvectors don't changeand its eigenvalues\nare three bigger.Let's, let's just see why.Let me keep all this on the same\nboard. but just so you see --", "start": 1800.0, "heat": 0.1}, {"text": "so I'll try to do that.this has eigenvalue\nlambda plus three.And x, the eigenvector, is\nthe same x for both matrices.OK.So that's, great.Of course, it's special.We got the new matrix\nby adding three I.Suppose I had added\nanother matrix.Suppose I know the eigenvalues\nand eigenvectors of A.So I took A minus lambda I x,\nand what kind of a matrix ISo this is, this,\nthis little boardhere is going to\nbe not so great.Suppose I have a matrix A and\nit has an eigenvector x withan eigenvalue lambda.You remember, I solve\nA minus lambda I xAnd now I add on\nsome other matrix.So, so what I'm asking you is,\nif you know the eigenvaluesof A and you know\nthe eigenvalues of B,let me say suppose B -- so this\nis if -- let me put an if here.If Ax equals lambda x, fine,\nand B has, eigenvalues,has eigenvalues --what shall we call them?Alpha, alpha one and alpha --", "start": 1920.0, "heat": 0.1}, {"text": "let's say --I'll use alpha for\nthe eigenvalues of Bfor no good reason.What a- you see what I'm going\nto ask is, how about A plus B?Let me, let me give you\nthe, let me give you,what you might think first.OK.If Ax equals lambda x and if\nB has an eigenvalue alpha,then I allowed to say -- what's\nthe matter with this argument?That gave us the\nconstant term eight.It's wrong.What I'm going to\nwrite up is wrong.I'm going to say Bx is alpha x.Add those up, and you get A plus\nB x equals lambda plus alpha x.So you would think that if\nyou know the eigenvalues of Aand you knew the\neigenvalues of B,then if you added you would know\nthe eigenvalues of A plus B.But that's false.A plus B -- well, when B was\nthree I, that worked great.But this is not so great.And what's the matter\nwith that argument there?We have no reason to\nbelieve that x is alsoan eigenvector ofB has some eigenvalues,\nB. but it'sgot some different\neigenvectors normally.It's a different matrix.I don't know anything special.If I don't know anything\nspecial, then as far as I know,it's got some different\neigenvector y,and when I add I\nget just rubbish.I mean, I get --I can add, but I\ndon't learn anything.So not so great is A plus B.", "start": 2040.0, "heat": 0.1}, {"text": "Or A times B.Normally the\neigenvalues of A plus Bor A times B are not eigenvalues\nof A plus eigenvalues of B.Ei- eigenvalues are\nnot, like, linear.Or -- and they don't multiply.Because, eigenvectors\nare usually differentand, and there's just\nno way to find outwhat A plus B does to affectWhat do I do now? it.OK.So that's, like, a caution.Don't, if B is a multiple\nof the identity, great,but if B is some general matrix,\nthen for A plus B you've gotto find -- you've got to\nsolve the eigenvalue problem.Now I want to do another\nexample that brings out a,OK. another point\nabout eigenvalues.Let me make this example\na rotation matrix.possibility of complex numbers.OK.So here's another example.So a rotate --oh, I'd better call it Q.I often use Q for,\nfor, rotationsbecause those are the, like,\nvery important examplesof orthogonal matrices.Let me make it a\nninety degree rotation.So -- my matrix is going to\nbe the one that rotates everyAnd that's the sum, that's\nlambda one plus lambdavector by ninety degrees.So do you remember that matrix?It's the cosine of\nninety degrees, whichis zero, the sine\nof ninety degrees,which is one, minus the sine of\nninety, the cosine of ninety.", "start": 2160.0, "heat": 0.1}, {"text": "So that matrix\ndeserves the letter Q.It's an orthogonal matrix,\nvery, very orthogonal matrix.Now I'm interested in its\neigenvalues and eigenvectors.Two by two, it\ncan't be that tough.We know that the\neigenvalues add to zero.Actually, we know\nsomething already here.The eigen- what's the sum\nof the two eigenvalues?Just tell me what I just said.Zero, right.From that trace business.The sum of the eigenvalues\nis, is going to come out zero.And the product of\nthe eigenvalues,did I tell you about\nthe determinant beingthe product of the eigenvalues?No.But that's a good thing to know.We pointed out how\nthat eight appeared inthe, in the quadratic\nequation. eigenvalues,we can postpone that evil day,So let me just say this.The trace is zero\nplus zero, obviously.And that was the determinant.OK.What I'm leading up\nto with this exampleis that something's\ngoing to go wrong.", "start": 2280.0, "heat": 0.1}, {"text": "Something goes\nwrong for rotationbecause what vector can\ncome out parallel to itselfafter a rotation?If this matrix rotates every\nvector by ninety degrees,what could be an eigenvector?Do you see we're, we're,\nwe're going to have trouble.eigenvectors are --Well.Our, our picture\nof eigenvectors,of, of coming out in the same\ndirection that they went in,there won't be it.And with, and with eigenvalues\nwe're going to have trouble.From these equations.Let's see.Why I expecting trouble?The, the first equation\nsays that the eigenvaluesadd to zero.So there's a plus and a minus.So I take the eigenvalue.But then the second\nequation saysthat the product is plus one.We're in trouble.But there's a way out.So how -- let's do\nthe usual stuff.Look at determinant\nof Q minus lambda I.So I'll just follow the\nrules, take the determinant,subtract lambda from the\ndiagonal, where I had zeros,the rest is the same.Rest of Q is just copied.Compute that determinant.OK, so what does that\ndeterminant equal?Lambda squared minus\nminus one plus what?What's up?There's my equation.My equation for the\neigenvalues is lambdasquared plus one equals zero.", "start": 2400.0, "heat": 0.1}, {"text": "What are the eigenvalues\nlambda one and lambda two?They're I, whatever that\nis, and minus it, right.Those are the right numbers.To be real numbers even though\nthe matrix was perfectly real.So this can happen.Complex numbers are going to --\nhave to enter eighteen oh sixat this moment.Boo, right.All right.If I just choose good\nmatrices that have realsupposed to have here?We do know a little\ninformation about the,the two complex numbers.They're complex\nconjugates of each other.If, if lambda is an\neigenvalue, then when I change,when I go -- you remember\nwhat complex conjugates are?You switch the sign\nof the imaginary part.Well, this was only\nimaginary, had no real part,so we just switched its sign.", "start": 2520.0, "heat": 0.1}, {"text": "So that eigenvalues\ncome in pairs like that,but they're complex.A complex conjugate pair.And that can happen with\na perfectly real matrix.And as a matter of fact --so that was my,\nmy point earlier,that if a matrix was\nsymmetric, it wouldn't happen.So if we stick to matrices that\nare symmetric or, like, closeto symmetric, then the\neigenvalues will stay real.But if we move far\naway from symmetric --and that's as far as you can\nmove, because that matrix is --how is Q transpose related\nto Q for that matrix?That matrix is anti-symmetric.Q transpose is minus Q.That's the very\nopposite of symmetry.When I flip across\nthe diagonal I get --I reverse all the signs.Those are the guys that have\npure imaginary eigenvalues.So they're the extreme case.And in between are,\nare matrices thatare not symmetric or\nanti-symmetric but,but they have partly\na symmetric partand an anti-symmetric part.OK.So I'm doing a bunch of examples\nhere to show the possibilities.The good possibilities being\nperpendicular eigenvectors,real eigenvalues.The bad possibilities\nbeing complex eigenvalues.We could say that's bad.There's another even worse.I'm getting through the,\nthe bad things here today.Then, then the next\nlecture can, can,can be like pure happiness.OK.Here's one more bad\nthing that could happen.", "start": 2640.0, "heat": 0.1}, {"text": "So I, again, I'll do\nit with an example.Suppose my matrix is, suppose\nI take this three three oneand I change that guy to zero.What are the eigenvalues\nof that matrix?What are the eigenvectors?This is always our question.Of course, the\nnext section we'regoing to show why\nare, why do we care.But for the moment, this\nlecture is introducingthem.And let's just find them.OK.What are the eigenvalues\nof that matrix?Let me tell you -- at a glance\nwe could answer that question.Because the matrix\nis triangular.It's really useful to know --\nif you've got properties likea triangular matrix.It's very useful to know\nyou can read the eigenvaluesoff.They're right on the diagonal.So the eigenvalue is\nthree and also three.Three is a repeated eigenvalue.But let's see that happen.Let me do it right.The determinant of A minus\nlambda I, what I alwayshave to do is this determinant.I take away lambda\nfrom the diagonal.I leave the rest.I compute the determinant,\nso I get a three minus lambdatimes a three minus lambda.And nothing.So that's where the\ntriangular part came in.Triangular part, the one\nthing we know about triangularmatrices is the determinant\nis just the product downthe diagonal.And in this case, it's\nthis same, repeated --so lambda one is one --sorry, lambda one is three\nand lambda two is three.That was easy.I mean, no -- why should I\nbe pessimistic about a matrix", "start": 2760.0, "heat": 0.1}, {"text": "whose eigenvalues can\nbe read off right away?The problem with this matrix\nis in the eigenvectors.So let's go to the eigenvectors.So how do I find\nthe eigenvectors?I'm looking for a\ncouple of eigenvectors.Singular, right?It's supposed to be singular.And then it's got some\nvectors -- which it is.So it's got some vector\nx in the null space.And what, what's the, what's\n-- give me a basis for the nullspace for that guy.Tell me, what's a vector x\nin the null space, so that'llbe the, the eigenvector\nthat goes with lambda oneequals three.The eigenvector is -- so\nwhat's in the null space?One zero, is it?Great.Now, what's the\nother eigenvector?What's, what's the eigenvector\nthat goes with lambda two?Well, lambda two is three again.So I get the same thing again.Give me another vector --I want it to be independent.If I'm going to\nwrite down an x2,I'm never going to let\nit be dependent on x1.", "start": 2880.0, "heat": 0.1}, {"text": "I'm looking for\nindependent eigenvectors,and what's the conclusion?There isn't one.This is a degenerate matrix.It's only got one line of\neigenvectors instead of two.It's this possibility\nof a repeated eigenvalueopens this further possibility\nof a shortage of eigenvectors.And so there's no second\nindependent eigenvector x2.So it's a matrix, it's\na two by two matrix,but with only one\nindependent eigenvector.So that will be --\nthe matrices that --where eigenvectors are --\ndon't give the complete story.OK.My lecture on Monday will\ngive the complete storyfor all the other matrices.Thanks.Have a good weekend.A real New England weekend.", "start": 3000.0, "heat": 0.1}]