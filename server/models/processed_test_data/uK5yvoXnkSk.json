[{"text": "The following content is\nprovided under a CreativeCommons license.Your support will help\nMIT OpenCourseWarecontinue to offer high quality\neducational resources for free.To make a donation or to\nview additional materialsfrom hundreds of MIT courses\nvisit MIT OpenCourseWareat ocw.mit.edu.JOHN GUTTAG: We ended\nthe last lecturelooking at greedy algorithms.Today I want to discuss the\npros and cons of greedy.Oh, I should mention--in response to popular demand,\nI have put the PowerPoint up,so if you download the ZIP\nfile, you'll find the questions,including question 1, the\nfirst question, plus the code,plus the PowerPoint.We actually do read Piazza,\nand sometimes, at least,pay attention.We should pay\nattention all the time.So what are the pros\nand cons of greedy?The pro-- and it's\na big pro-- isthat it's really easy to\nimplement, as you could see.Also enormously important--\nit's really fast.We looked at the\ncomplexity last time--it was m log n-- quite quick.The downside-- and this can\nbe either a big problem or nota big problem--is that it doesn't\nactually solvethe problem, in the sense\nthat we've asked ourselvesto optimize something.And we get a solution that\nmay or may not be optimal.Worse-- we don't even\nknow, in this case,how close to optimal it is.Maybe it's almost optimal, but\nmaybe it's really far away.And that's a big problem\nwith many greedy algorithms.There are some very\nsophisticated greedy algorithmswe won't be looking at that\ngive you a bound on how good", "start": 0.0, "heat": 0.1}, {"text": "the approximation is, but\nmost of them don't do that.Last time we looked\nat an alternativeto a greedy algorithm\nthat was guaranteedto find the right solution.It was a brute force algorithm.The basic idea is simple--that you enumerate all\npossible combinations of items,remove the combination\nwhose total units exceedthe allowable weight, and\nthen choose the winnerfrom those that are remaining.Now let's talk about\nhow to implement it.And the way I want to\nimplement it is using somethingcalled a search tree.There are lots of different\nways to implement it.In the second half\nof today's lecture,you'll see why I\nhappen to choosethis particular approach.So what is a search tree?A tree is, basically,\na kind of graph.And we'll hear much more\nabout graphs next week.But this is a simple form\nwhere you have a rootand then children of the root.In this particular\nform, research C,you have two children.So we start with the root.And then we look at\nour list of elementsto be considered\nthat we might take,and we look at the first\nelement in that list.And then we draw a\nleft branch, whichshows the consequence of\nchoosing to take that element,and a right branch, which\nshows the consequences of nottaking that element.And then we consider\nthe second element,and so on and so forth, until we\nget to the bottom of the tree.So by convention, the left\nelement will mean we took it,the right direction will\nmean we didn't take it.And then we apply it recursively\nto the non-leaf children.", "start": 120.0, "heat": 0.169}, {"text": "The leaf means we\nget to the end,we've considered the last\nelement to be considered.Nothing else to think about.When we get to the\ncode, we'll seethat, in addition to the\ndescription being recursive,it's convenient to write\nthe code that way, too.And then finally,\nwe'll choose the nodethat has the highest value\nthat meets our constraints.So let's look at an example.My example is I have\nmy backpack thatcan hold a certain number\nof calories if you will.And I'm choosing between, to\nkeep it small, a beer, a pizza,and a burger--three essential food groups.The first thing I explore on\nthe left is take the beer,and then I have the\npizza and the burgerto continue to consider.I then say, all right,\nlet's take the pizza.Now I have just the burger.Now I taste the burger.This traversal of this\ngeneration of the treeis called left-most depth-most.So I go all the way down\nto the bottom of the tree.I then back up a\nlevel and say, allright, I'm now at the bottom.Let's go back and\nsee what happensif I make the other choice\nat the one level up the tree.So I went up and\nsaid, well, now let'ssee what happens if I\nmake a different decision,as in we didn't take the burger.And then I work my way--this is called backtracking--up another level.I now say, suppose, I didn't\ntake the piece of pizza.Now I have the beer\nonly and only the burgerto think about, so\non and so forth,until I've generated\nthe whole tree.", "start": 240.0, "heat": 0.183}, {"text": "You'll notice it will always be\nthe case that the leftmost leafof this tree has got all\nthe possible items in it,and the rightmost leaf none.And then I just check\nwhich of these leavesmeets the constraint\nand what are the values.And if I compute the value\nand the calories in each one,and if our constraint\nwas 750 calories,then I get to choose\nthe winner, which is--I guess, it's the\npizza and the burger.Is that right?The most value under 750.That's the way I go through.It's quite a\nstraightforward algorithm.And I don't know why we draw our\ntrees with the root at the topand the leaves at the bottom.My only conjecture is\ncomputer scientistsdon't spend enough\ntime outdoors.Now let's think of the\ncomputational complexityof this process.The time is going to be based\non the total number of nodeswe generate.So if we know the number of\nnodes that are in the tree,we then know the complexity\nof the algorithm,the asymptotic complexity.Well, how many levels\ndo we have in the tree?Just the number of items, right?Because at each\nlevel of the treewe're deciding to take\nor not to take an item.And so we can only do that for\nthe number of items we have.So if we go back, for example,\nand we look at the tree--not that tree, that tree--and we count the\nnumber of levels,it's going to be based upon\nthe total number of items.We know that because if you\nlook at, say, the leftmost nodeat the bottom, we've made\nthree separate decisions.", "start": 360.0, "heat": 0.108}, {"text": "So counting the\nroot, it's n plus 1.But we don't care\nabout plus 1 when we'redoing asymptotic complexity.So that tells us how many\nlevels we have in the tree.The next question we\nneed to ask is, how manynodes are there at each level?And you can look at this\nand see-- the deeper we go,the more nodes we\nhave at each level.In fact, if we come\nhere, we can seethat the number of\nnodes at level i--depth i of the\ntree-- is 2 to the i.That makes sense if you\nremember last time welooked at binary numbers.We're saying we're representing\nour choices as either 0or 1 for what we take.If we have n items\nto choose from,then the number of\npossible choicesis 2 to the n, the\nsize of the powerset.So that will tell us the\nnumber of nodes at each level.So if there are n items, the\nnumber of nodes in the treeis going to be the sum\nfrom 0 to n of 2 to the ibecause we have\nthat many levels.And if you've studied\na little math,you know that's exactly\n2 to the n plus 1.Or if you do what I do,\nyou look it up in Wikipediaand you know it's\n2 to the n plus 1.Now, there's an\nobvious optimization.We don't need to\nexplore the whole tree.If we get to a point where\nthe backpack is overstuffed,there's no point in saying,\nshould we take this next item?Because we know we can't.I generated a bunch\nof leaves thatwere useless because\nthe weight was too high.So you could always\nabort early and say, oh,", "start": 480.0, "heat": 0.279}, {"text": "no point in generating the\nrest of this part of the treebecause we know everything\nin it will be too heavy.Adding something cannot\nreduce the weight.It's a nice optimization.It's one you'll see we\nactually do in the code.But it really doesn't\nchange the complexity.It's not going to change\nthe worst-cost complexity.Exponential, as we saw this,\nI think, in Eric's lecture,is a big number.You don't usually\nlike 2 to the n.Does this mean that brute\nforce is never useful?Well, let's give it a try.We'll look at some code.Here is the implementation.So it's maxVal,\ntoConsider, and avail.And then we say, if toConsider\nis empty or avail is 0--avail is an index, we're going\nto go through the list usingthat to tell us\nwhether or not we stillhave an element to consider--then the result will be the\ntuple 0 and the empty tuple.We couldn't take anything.This is the base\nof our recursion.Either there's nothing\nleft to consider or there'sno available weight--the Val, as the\namount of weight,is 0 or toConsider is empty.Well, if either\nof those are true,then we ask whether\nto consider * 0,the first element to look at.Is that cost greater\nthan availability?If it is, we don't need to\nexplore the left branch.because it means we can't\nafford to put that thing", "start": 600.0, "heat": 0.44}, {"text": "in the backpack, the knapsack.There's just no room for it.So we'll explore the\nright branch only.The result will be whatever the\nmaximum value is of toConsiderof the remainder of the list--\nthe list with the first elementsliced off--and availability unchanged.So it's a recursive\nimplementation, saying,now we only have to consider\nthe right branch of the treebecause we knew we\ncouldn't take this element.It just weighs too\nmuch, or costs too much,or was too fattening,\nin my case.Otherwise, we now have to\nconsider both branches.So we'll set next item to\ntoConsider of 0, the first one,and explore the left branch.On this branch, there\nare two possibilitiesto think about, which I'm\ncalling withVal and withToTake.So I'm going to call maxVal\nof toConsider of everythingexcept the current element and\npass in an available weightof avail minus whatever--well, let me widen this so\nwe can see the whole code.This is not going to let me\nwiden this window any more.Shame on it.Let me see if I can\nget rid of the console.Well, we'll have\nto do this instead.So we're going to call\nmaxVal with everythingexcept the current\nelement and give itavail minus the cost of that\nnext item of toConsider sub 0.Because we know that the\navailability, available weight", "start": 720.0, "heat": 0.271}, {"text": "has to have that cost\nsubtracted from it.And then we'll add to withVal\nnext item dot getValue.So that's a value\nif we do take it.Then we'll explore the\nright branch-- whathappens if we don't take it?And then we'll choose\nthe better branch.So it's a pretty simple\nrecursive algorithm.We just go all the\nway to the bottomand make the right\nchoice at the bottom,and then percolate back up, like\nso many recursive algorithms.We have a simple\nprogram to test it.I better start a console\nnow if I'm going to run it.And we'll testGreedys on foods.Well, we'll testGreedys\nand then we'll testMaxVal.So I'm building\nthe same thing wedid in Monday's\nlecture, the same menu.And I'll run the\nsame testGreedyswe looked at last time.And we'll see whether or not\nwe get something better whenwe run the truly optimal one.Well, indeed we do.You remember that last\ntime and, fortunately,this time too, the best\nwe did was a value of 318.But now we see we can\nactually get to 353 if we usethe truly optimal algorithm.", "start": 840.0, "heat": 0.263}, {"text": "So we see it ran pretty\nquickly and actuallygave us a better answer than we\ngot from the greedy algorithm.And it's often the case.If I have time at the\nend, I'll show youan optimization\nprogram you mightwant to run that works\nperfectly fine to usethis kind of brute\nforce algorithm on.Let's go back to the PowerPoint.So I'm just going through\nthe code again we just ran.This was the header we saw--toConsider, as the\nitems that correspondto nodes higher up the\ntree, and avail, as I said,the amount of space.And again, here's what\nthe body of the codeloooked like, I took\nout the comments.One of the things you might\nthink about in your headwhen you look at this code is\nputting the comments back in.I always find that for\nme a really good wayto understand code that I didn't\nwrite is to try and comment it.And that helps me sort of\nforce myself to think aboutwhat is it really doing.So you'll have both versions--\nyou'll have the PowerPointversion without the\ncomments and the actual codewith the comments.You can think about\nlooking at thisand then looking\nat the real codeand making sure that\nyou're understanding jibes.I should point out that\nthis doesn't actuallybuild the search tree.We've got this local variable\nresult, starting here,that records the best\nsolution found so far.So it's not the picture I drew\nwhere I generate all the nodesand then I inspect them.I just keep track--as I generate a node, I\nsay, how good is this?Is it better than the\nbest I've found so far?If so, it becomes the new best.", "start": 960.0, "heat": 0.261}, {"text": "And I can do that because\nevery node I generateis, in some sense, a legal\nsolution to the problem.Probably rarely is it the\nfinal optimal solutionbut it's at least\na legal solution.And so if it's\nbetter than somethingwe saw before, we can\nmake it the new best.This is very common.And this is, in fact, what\nmost people do with itwhen they use a search tree--they don't actually\nbuild the treein the pictorial way\nwe've looked at itbut play some trick like\nthis of just keepingtrack of their results.Any questions about this?All right.We did just try it on\nexample from lecture 1.And we saw that it worked great.It gave us a better answer.It finished quickly.But we should not take too\nmuch solace from the factthat it finished quickly\nbecause 2 to the eighthis actually a\npretty tiny number.Almost any algorithm is fine\nwhen I'm working on somethingthis small.Let's look now at what happens\nif we have a bigger menu.Here is some code\nto do a bigger menu.Since, as you will discover\nif you haven't already,I'm a pretty lazy\nperson, I didn'twant to write out a menu with\na 100 items or even 50 items.So I wrote some code\nto generate the menus.And I used randomness\nto do that.This is a Python\nlibrary we'll beusing a lot for the\nrest of the semester.It's used any time you want\nto generate things at random", "start": 1080.0, "heat": 0.239}, {"text": "and do many other things.We'll come back to it a lot.Here we're just going to\nuse a very small part of it.To build a large menu\nof some numItems--and we're going to\ngive the maximum valueand the maximum\ncost for each item.We'll assume the minimum\nis, in this case, 1.Items will start empty.And then for i in\nrange number of items,I'm going to call this function\nrandom dot randint thattakes a range of integers from\n1 to, actually in this case,maxVal minus 1, or 1 to\nmaxVal, actually, in this case.And it just chooses\none of them at random.So when you run this, you don't\nknow what it's going to get.Random dot randint might\nreturn 1, it might return 23,it might return 54.The only thing you know\nis it will be an integer.And then I'm going to build\nmenus ranging from 5 itemsto 60 items--buildLargeMenu, the number\nof items, with maxVal of 90and a maxCost of 250,\npleasure and calories.And then I'm going to test\nmaxVal on each of these menus.So building menus of\nvarious sizes at randomand then just trying to find the\noptimal value for each of them.Let's look at the code.Let's comment this out, we\ndon't need to run that again.", "start": 1200.0, "heat": 0.288}, {"text": "So we'll build a\nlarge menu and thenwe'll try it for a bunch of\nitems and see what we get.So it's going along.Trying the menu up to\n30 went pretty quickly.So even 2 to the 30\ndidn't take too long.But you might notice it's kind\nof bogging down, we got 35.I guess, I could ask\nthe question now--it was one of the questions\nI was going to ask as a pollbut maybe I won't bother--how much patience do we have?When do you think we'll run\nout of patience and quit?If you're out of\npatience, raise your hand.Well, some of you are way\nmore patient than I am.So we're going to quit anyway.We were trying to do 40.It might have finished 40, 45.I've never waited long\nenough to get to 45.It just is too long.That raises the\nquestion, is it hopeless?And in theory, yes.As I mentioned last time, it\nis an inherently exponentialproblem.The answer is-- in practice, no.Because there's something\ncalled dynamic programming,which was invented by a\nfellow at the RAND Corporationcalled Richard Bellman,\na rather remarkable", "start": 1320.0, "heat": 0.207}, {"text": "mathematician/computer\nscientist.He wrote a whole book\non it, but I'm not surewhy because it's not\nthat complicated.When we talk about\ndynamic programming,it's a kind of a funny\nstory, at least to me.I learned it and I\ndidn't know anythingabout the history of it.And I've had all sorts\nof theories about why itwas called dynamic programming.You know how it is, how people\ntry and fit a theory to data.And then I read a\nhistory book about it,and this was Bellman's\nown descriptionof why he called it\ndynamic programming.And it turned out,\nas you can see,he basically chose a word\nbecause it was the descriptionthat didn't mean anything.Because he was doing\nmathematics, and at the timehe was being funded by a part\nof the Defense Departmentthat didn't approve\nof mathematics.And he wanted to\nconceal that fact.And indeed at the time, the\nhead of Defense Appropriationsin the US Congress didn't\nmuch like mathematics.And he was afraid\nthat he didn't wantto have to go and testify and\ntell people he was doing math.So he just invented\nsomething that no onewould know what it meant.And years of students\nspent time later tryingto figure out what\nit actually did mean.Anyway, what's the basic idea?To understand it I want\nto temporarily abandonthe knapsack problem and look\nat a much simpler problem--Fibonacci numbers.You've seen this already, with\ncute little bunnies, I think,when you saw it.N equals 0, n\nequals 1-- return 1.Otherwise, fib of n minus\n1 plus fib of n minus 2.And as I think you saw\nwhen you first saw it,it takes a long time to run.", "start": 1440.0, "heat": 0.344}, {"text": "Fib of 120, for example,\nis a very big number.It's shocking how\nquickly Fibonacci grows.So let's think about\nimplementing it.If we run Fibonacci--well, maybe we'll just do that.So here is fib of n,\nlet's just try running it.And again, we'll test\npeople's patience.We'll see how long\nwe're letting it run.I'm going to try for\ni in the range of 121.We'll print fib of i.Comes clumping along.It slows down pretty quickly.And if you look at it,\nit's kind of surprisingit's this slow because these\nnumbers aren't that big.These are not enormous numbers.Fib of 35 is not a huge number.Yet it took a long\ntime to compute.So you have the numbers\ngrowing pretty quicklybut the computation, actually,\nseems to be growing fasterthan the results.We're at 37.It's going to gets slower and\nslower, even though our numbersare not that big.The question is,\nwhat's going on?Why is it taking so\nlong for Fibonaccito compute these results?", "start": 1560.0, "heat": 0.509}, {"text": "Well, let's call it and\nlook at the question.And to do that I want to\nlook at the call tree.This is for Fibonacci\nof 6, which is only 13,which, I think, most\nof us would agreewas not a very big number.And let's look\nwhat's going on here.If you look at this,\nwhat in some senseseems really stupid about it?What is it doing that a\nrational person would not wantto do if they could avoid it?It's bad enough to\ndo something once.But to do the same thing\nover and over againis really wasteful.And if we look at this,\nwe'll see, for example,that fib 4 is being\ncomputed here,and fib 4 is being\ncomputed here.Fib 3 is being considered\nhere, and here, and here.And do you think we'll get\na different answer for fib 3in one place when we get\nit in the other place?You sure hope not.So you think, well, what\nshould we do about this?How would we go about avoiding\ndoing the same work overand over again?And there's kind of\nan obvious answer,and that answer is at the\nheart of dynamic programming.What's the answer?AUDIENCE: [INAUDIBLE]JOHN GUTTAG: Exactly.And I'm really happy that\nsomeone in the front rowanswered the question because\nI can throw it that far.You store the answer and then\nlook it up when you need it.", "start": 1680.0, "heat": 0.612}, {"text": "Because we know that we can\nlook things up very quickly.Dictionary, despite what\nEric said in his lecture,almost all the time\nworks in constant timeif you make it big enough,\nand it usually is in Python.We'll see later in the\nterm how to do that trick.So you store it and then you'd\nnever have to compute it again.And that's the basic trick\nbehind dynamic programming.And it's something\ncalled memoization,as in you create a memo and\nyou store it in the memo.So we see this here.Notice that what we're doing\nis trading time for space.It takes some space to store\nthe old results, but negligiblerelated to the time we save.So here's the trick.We're going to create a table\nto record what we've done.And then before\ncomputing fib of x,we'll check if the value\nhas already been computed.If so, we just look\nit up and return it.Otherwise, we'll compute it--it's the first time-- and\nstore it in the table.Here is a fast implementation\nof Fibonacci that does that.It looks like the\nold one, except it'sgot an extra argument--memo-- which is a dictionary.The first time we call it,\nthe memo will be empty.It tries to return\nthe value in the memo.If it's not there, an exception\nwill get raised, we know that.", "start": 1800.0, "heat": 0.259}, {"text": "And it will branch to\nhere, compute the result,and then store it in\nthe memo and return it.It's the same old\nrecursive thingwe did before but with the memo.Notice, by the way, that\nI'm using exceptionsnot as an error\nhandling mechanism,really, but just as\na flow of control.To me, this is cleaner than\nwriting code that says,if this is in the keys, then\ndo this, otherwise, do that.It's slightly fewer lines of\ncode, and for me, at least,easier to read to use try-except\nfor this sort of thing.Let's see what happens\nif we run this one.Get rid of the slow fib\nand we'll run fastFib.Wow.We're already done with fib 120.Pretty amazing, considering last\ntime we got stuck around 40.It really works, this\nmemoization trick.An enormous difference.When can you use it?It's not that memorization\nis a magic bullet thatwill solve all problems.The problems it can solve,\nit can help with, really,", "start": 1920.0, "heat": 0.381}, {"text": "is the right thing.And by the way, as we'll see, it\nfinds an optimal solution, notan approximation.Problems have two things\ncalled optimal substructure,overlapping subproblems.What are these mean?We have optimal\nsubstructure whena globally optimal\nsolution can befound by combining optimal\nsolutions to local subproblems.So for example, when\nx is greater than 1we can solve fib x by solving\nfib x minus 1 and fib x minus 2and adding those\ntwo things together.So there is optimal\nsubstructure--you solve these two smaller\nproblems independentlyof each other and then combine\nthe solutions in a fast way.You also have to have something\ncalled overlapping subproblems.This is why the memo worked.Finding an optimal\nsolution has to involvesolving the same\nproblem multiple times.Even if you have\noptimal substructure,if you don't see the same\nproblem more than once--creating a memo.Well, it'll work, you can\nstill create the memo.You'll just never\nfind anything in itwhen you look things\nup because you'resolving each problem once.So you have to be solving the\nsame problem multiple timesand you have to be able to\nsolve it by combining solutionsto smaller problems.Now, we've seen things with\noptimal substructure before.In some sense, merge\nsort worked that way--we were combining\nseparate problems.", "start": 2040.0, "heat": 0.428}, {"text": "Did merge sort have\noverlapping subproblems?No, because-- well,\nI guess, it mighthave if the list had the same\nelement many, many times.But we would expect, mostly not.Because each time we're\nsolving a different problem,because we have different\nlists that we're nowsorting and merging.So it has half of it\nbut not the other.Dynamic programming will\nnot help us for sorting,cannot be used to\nimprove merge sort.Oh, well, nothing\nis a silver bullet.What about the knapsack problem?Does it have these\ntwo properties?We can look at it in\nterms of these pictures.And it's pretty clear that it\ndoes have optimal substructurebecause we're taking the left\nbranch and the right branchand choosing the winner.But what about\noverlapping subproblems?Are we ever solving, in this\ncase, the same problem--add two nodes?Well, do any of these\nnodes look identical?In this case, no.We could write a dynamic\nprogramming solutionto the knapsack problem--and we will-- and run\nit on this example,and we'd get the right answer.We would get zero speedup.Because at each\nnode, if you can see,the problems are different.We have different things in the\nknapsack or different thingsto consider.Never do we have the same\ncontents and the same thingsleft to decide.", "start": 2160.0, "heat": 0.42}, {"text": "So \"maybe\" was not a bad\nanswer if that was the answeryou gave to this question.But let's look at\na different menu.This menu happens to\nhave two beers in it.Now, if we look at\nwhat happens, dowe see two nodes that are\nsolving the same problem?The answer is what?Yes or no?I haven't drawn the\nwhole tree here.Well, you'll notice\nthe answer is yes.This node and this node are\nsolving the same problem.Why is it?Well, in this node,\nwe took this beerand still had this\none to consider.But in this node,\nwe took that beerbut it doesn't matter\nwhich beer we took.We still have a beer in\nthe knapsack and a burgerand a slice to consider.So we got there different ways,\nby choosing different beers,but we're in the same place.So in fact, we\nactually, in this case,do have the same problem\nto solve more than once.Now, here I had two\nthings that were the same.That's not really necessary.Here's another\nvery small example.And the point I want to\nmake here is shown by this.So here I have again\ndrawn a search tree.And I'm showing you this\nbecause, in fact, it's exactly", "start": 2280.0, "heat": 0.753}, {"text": "this tree that will be producing\nin our dynamic programmingsolution to the\nknapsack problem.Each node in the tree starts\nwith what you've taken--initially, nothing,\nthe empty set.What's left, the total value,\nand the remaining calories.There's some redundancy\nhere, by the way.If I know what I've taken, I\ncould already always computethe value and what's left.But this is just so\nit's easier to see.And I've numbered the\nnodes here in the orderin which they're get generated.Now, the thing that\nI want you to noticeis, when we ask whether we're\nsolving the same problem,we don't actually\ncare what we've taken.We don't even care\nabout the value.All we care is, how much room\nwe have left in the knapsackand which items we\nhave left to consider.Because what I take next or\nwhat I take remaining reallyhas nothing to do with how\nmuch value I already havebecause I'm trying to maximize\nthe value that's left,independent of\nprevious things done.Similarly, I don't care why\nI have a 100 calories left.Whether I used it up on beers\nor a burger, doesn't matter.All that matters is that\nI just have 100 left.So we see in a large complicated\nproblem it could easilybe a situation where different\nchoices of what to takeand what to not take would\nleave you in a situationwhere you have the same\nnumber of remaining calories.", "start": 2400.0, "heat": 0.404}, {"text": "And therefore you are solving a\nproblem you've already solved.At each node, we're just\ngiven the remaining weight,maximize the value by choosing\namong the remaining items.That's all that matters.And so indeed, you will have\noverlapping subproblems.As we see in this tree, for\nthe example we just saw,the box is around a place\nwhere we're actuallysolving the same problem,\neven though we'vemade different decisions about\nwhat to take, A versus B.And in fact, we have\ndifferent amounts of valuein the knapsack--6 versus 7.What matters is we still\nhave C and D to considerand we have two units left.It's a small and easy step.I'm not going to walk\nyou through the codebecause it's kind\nof boring to do so.How do you modify the maxVal we\nlooked at before to use a memo?First, you have to add the third\nargument, which is initiallygoing to be set to\nthe empty dictionary.The key of the memo\nwill be a tuple--the items left to be considered\nand the available weight.Because the items left to\nbe considered are in a list,we can represent the items\nleft to be consideredby how long the list is.Because we'll start at\nthe front item and justwork our way to the end.And then the function\nworks, essentially,exactly the same\nway fastFib worked.", "start": 2520.0, "heat": 0.378}, {"text": "I'm not going to run it for\nyou because we're running outof time.You might want to\nrun it yourselfbecause it is kind of fun to\nsee how really fast it is.But more interestingly,\nwe can look at this table.This column is what we would\nget with the original recursiveimplementation where\nwe didn't use a memo.And it was therefore 2\nto the length of items.And as you can see,\nit gets really bigor, as we say at the end, huge.But the number of\ncalls grows incrediblyslowly for the dynamic\nprogramming solution.In the beginning\nit's worth Oh, well.But by the time we get to\nthe last number I wrote,we're looking at 43,000\nversus some really big numberI don't know how to pronounce--18 somethings.Incredible improvement\nin performance.And then at the\nend, it's a numberwe couldn't fit on the\nslide, even in tiny font.And yet, only 703,000 calls.How can this be?We know the problem is\ninherently exponential.Have we overturned the\nlaws of the universe?Is dynamic programming a\nmiracle in the liturgical sense?No.But the thing I want\nyou to carry awayis that computational complexity\ncan be a very subtle notion.The running time\nof fastMaxVal isgoverned by the number\nof distinct pairsthat we might be able to\nuse as keys in the memo--", "start": 2640.0, "heat": 0.826}, {"text": "toConsider and available.The number of possible values\nof toConsider is small.It's bounded by the\nlength of the items.If I have a 100 items,\nit's 0, 1, 2, up to a 100.The possible values\nof available weightis harder to characterize.But it's bounded by the number\nof distinct sums of weightsyou can get.If I start with\n750 calories left,what are the possibilities?Well, in fact, in this case,\nmaybe we can take only 750because we're using with units.So it's small.But it's actually smaller\nthan that because ithas to do with the\ncombinations of waysI can add up the units I have.I know this is complicated.It's not worth my going through\nthe details in the lectures.It's covered in considerable\ndetail in the assigned reading.Quickly summarizing\nlectures 1 and 2,here's what I want\nyou to take away.Many problems of\npractical importancecan be formulated as\noptimization problems.Greedy algorithms often provide\nan adequate though often notoptimal solution.Even though finding\nan optimal solutionis, in theory,\nexponentially hard,dynamic programming really\noften yields great results.It always gives you a correct\nresult and it's sometimes,in fact, most of the times\ngives it to you very quickly.Finally, in the\nPowerPoint, you'llfind an interesting\noptimization problemhaving to do with whether or\nnot you should roll over problemthat grades into a quiz.And it's simply a question\nof solving this optimizationproblem.", "start": 2760.0, "heat": 0.828}]