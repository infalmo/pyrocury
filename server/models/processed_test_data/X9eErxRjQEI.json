[{"text": "The following content is\nprovided under a CreativeCommons license.Your support will help\nMIT OpenCourseWarecontinue to offer high quality\neducational resources for free.To make a donation or\nview additional materialsfrom hundreds of MIT courses,\nvisit MIT OpenCourseWareat ocw.mit.edu.PROFESSOR: OK,\nlet's get started.Last time we looked at a\nvariety of ways to analyze sumsand to find closed-form\nexpressions for the sums.And today we're going to\nuse those methods to solvea variety of famous problems,\none of them involving centerof mass and stacking blocks.We saw a version\nof that yesterdayin recitation, where you solved\nthe problem of figuring outhow many L's you need to make\nsomething like this balanceperfectly.Now in this case I didn't\nactually get an integer numberof L's-- which is possible--\nbecause I didn't quite get itstacked right at the bottom.So I got 10 and 1/2 L's here.There's an extra vertical here.Now in theory there are two\ninteger ways of doing it.And you proved that\nyesterday in recitation.So in theory, 10\nand 11 should work,but in practice the\nblocks aren't perfect.I didn't get them\nperfectly lined up.And so 10 wouldn't quite\nwork, and 11 tendedto pitch it the other way.And of course in theory, as\nlong as the center of massis just anywhere over this\nblock, it's going to be stable.In practice there's air moving\naround, and bouncing and stuff.And so if you're close to\nthe edge, it's going over.OK.So now if you want to build\none of these yourself,it's not hard to do.You just start with an\nextra block here, all right,and then you build up.And that's easy.And then you notice\nwhen it's about right.And you can just start\nwiggling this block out.And then it looks pretty\ncool at that point.Actually it was a student\nin the class showed me this", "start": 0.0, "heat": 0.1}, {"text": "a couple of years ago, because\nwe were doing the blocks.The next thing we're going\nto do-- we were doing that--and he said, hey,\nthere's this thing.And yeah, pretty cool.So today we're going to\nlook at a different problem,and that's the problem of\ngetting the blocks stacked upso they go out over the edge of\nthe table-- if that's doable.So the goal is to stack\nthe blocks up like this.We go farther and farther out.And the question\nwe're going to look atis is it possible-- whoa.Almost.Is it possible to get a block\nall the way off the table?That's the question\nwe're going to look at.And here I got close.And you can see it's\ngetting a little tipsy.It's not going to go.It's going to fall over.So I didn't do it this time.You're only allowed\none block per level.So you can't do\nanything like this.That's not allowed.You can go backwards,\nif that helps you.Well it's got to be\nstable on both sides.But you can go back and forth.So the question is, can you\nget out one block totallyout over the table?How many people think\nit can't be done?All right.A few doubters.More doubters.How many think it can be done?Oh, a lot of people\nthink it can be done.OK.Well all right.How many people think\nyou can get a blocktwo blocks out over the table?A few of you.How many think you can\nget it three blocks out?You're believers.OK.How many people think\nI can reach that wall?Well I got to tell you I\ncan't reach the wall because--AUDIENCE: The ceiling\ngets in the way.PROFESSOR: Yeah.That's going to be hard to do.", "start": 120.0, "heat": 0.236}, {"text": "But this is what we're\ngoing to try to figure out.And we're going to do it\nwith a little competition.So we're going to have a team\nof you go up against the TAs.And the winner gets\ncandy to share.The losing team gets the\ninfamous 6042 Nerd Pride pocketprotectors.Very nice.Shiny plastic.Has the MIT logo on them.Very handy.All right.So I need four volunteers.So come on down if\nyou'd like to volunteer.You can win some\ncandy for the class--or at least win yourself\na pocket protector.And we'll put the\nclass over there.And we get the TAs to come down.So come on down.I got a couple of people.Who else wants to join them?All right.Come on down.We've got a fourth\nvolunteer out there?All right.We got some people coming down.All right, come on over.All right.You got all the blocks you want.We could even take\nthis thing down.So here's your supply.All right.Now the TAs have a little\nbit of an advantage,because they've done this\nbefore, some of them.So you can give some advice\nto your colleagues here.So you got to get some blocks\nout of the block supply.Maybe we should take this down.It's about to fall over anyway.So yeah, how do\nwe get this down?I'm not sure.All right, I got this end.Whoa!There we go.Whoa![CRASHING BLOCKS]Oops!All right.There we go.So whoever gets a block\nout over the farthest wins.One block per level.You can't do two\nblocks on a level.Believe me it's a\nlot easier if you cando multiple blocks per level.", "start": 240.0, "heat": 0.12}, {"text": "You can go back and forth.Go ahead and give\nthem some advice.They look like they need it.They're only about half\na block out so far.How are the TAs doing here?AUDIENCE: Three steps\nforward, two steps back?Something like that?[INTERPOSING VOICES]This is an interesting\nidea I thinkis to go out as far as possible\nand then just weight it back.Does that change anything?Like this you're saying?PROFESSOR: All right.The TAs are getting\nscientific here.AUDIENCE: It need\nto be at least half.PROFESSOR: You know it's\nnot looking good for youguys to get the candy today.I got to tell you.Ooh.TAs are close.AUDIENCE: No, that's too far.Too far.Look at the distance\nbetween this and this.[INTERPOSING VOICES]PROFESSOR: All right.Oh, you're about\n2/3 of the way over.We've got one 2/3.You've got an inch to go.Yeah.Maybe it's not doable.It's not the first\ntime we've done thisand the problem has\nnot been solvable.AUDIENCE: The TAs are\ndoing pretty well.PROFESSOR: Oh.TAs are close.they're definitely\nwithin an inch.Maybe an inch and a half.AUDIENCE: Oh, yeah, the top\none should do [INAUDIBLE].PROFESSOR: Yeah.You can't hold it.It's got to stand up by itself.Now the bottom block can go\nout over the edge if you want.Oh, they're getting close.Oh, I think you might have\nthe top block out over.Maybe.", "start": 360.0, "heat": 0.1}, {"text": "How are you guys doing?Not good.This is trouble for the--AUDIENCE: It's out.PROFESSOR: You've got it?AUDIENCE: Yeah.PROFESSOR: Ooh.All right.You've got to work fast now\nif you're going to beat that.TAs got it out over the edge.You see that?They're out over the edge.All right.I think they did it.[INTERPOSING VOICES]We're going to have a hard\ntime analyzing that one.AUDIENCE: Uh, we're-- I\nthink we're actually there.PROFESSOR: No.All right.Well try another block or\ntwo, and then we'll vote.See?AUDIENCE: It's on the edge.Right there.PROFESSOR: All right.AUDIENCE: Looks like\nthe Stata Center.PROFESSOR: Yeah that's it.AUDIENCE: I'm holding it.PROFESSOR: You're close.[INTERPOSING VOICES]PROFESSOR: You're not the most\nefficient, that's for sure.Yeah the TAs are already\nmunching down here.[INTERPOSING VOICES]AUDIENCE: Copy\nthe TAs' solution.PROFESSOR: Now there's an idea.All right.Well I think it's\ntime for a vote.But let the class\nsee what you did.Yeah you got to\ntake your hands off.That's you know.AUDIENCE: We can.We're just choosing not to.PROFESSOR: Get some good\ntop balancing on there.I don't know.", "start": 480.0, "heat": 0.1}, {"text": "All right.Can you let it go?All right.They let it go.Let's see.Did you get one out?AUDIENCE: Yeah.This one right here.PROFESSOR: All right.We're going to do a vote.Who thinks they got\nthe one farthest out?Oh it's close.Ah!Look at that.We need some glasses out there.Who thinks the TAs\ngot it farther out?AUDIENCE: Boo.PROFESSOR: Oh man.All right.All right.So you guys.Here you go.Your very nice\npocket protectors.A good effort.There you are.Well done.And I'm afraid they\nget the candy here.So you can take these out and\nshare them with the class.Oh, leave it that way.Leave it there.I mean, we're going\nto analyze yours,because I can't begin\nto analyze that.All right.Now watching this,\nhow many peoplestill think we can get it\nall the way to the wall?Ah, a few people.In fact, if you stack\nthis high enough--and we're going to analyze\nhow high it has to go--you could reach the wall.Now in fact we're going\nto find that you probablygot to go out to the\nstars to get that highbefore you can reach the wall.So it's not too practical.Now what I want to do is\nanalyze this strategy.And this sort of looks\nlike a nice design.They got out there\nwith just five.And they did a\nparticular approachusing what we could call\nas the greedy algorithm.We've seen greedy\nalgorithms before.And they used another\ngreedy algorithm here.Now what their greedy strategy\ndid-- and I'm going to redo ithere-- is stack all the\nblocks right at the edge.Line it up here and,\nstarting at the top,push it out as\nfar as you can go.Now in this case, we can\nget it out about halfway,because the center of mass of\nthis block is at halfway point.And that better be\nsitting over this block,or it's going to tip.", "start": 600.0, "heat": 0.1}, {"text": "So the top block goes out here.Now I'm going to slide\nthe top two blocks outas far as they go.All right.That's about the tip.Then I slide the top three\nout as far as they go.Whoa!Almost.Oops.Theory is always\neasier than practice.And now we do the\ntop four blocks.And they did a better\njob than I did.But that's the algorithm,\nOK, the greedy algorithm.The top i blocks-- when i\ngoes 1 to n-- push it outas far as you can go.All right.And we're going to\nanalyze that strategyand see how far it goes.So we're given n blocks.And let's say they all have\nlength 1, to make it easy.And we're going to define r\nsub i to be the amount by whichthe i'th block hangs\nout over the edge.and we're going to\ncount from the top.All right.So let's see this on a picture.So I got the table here.And then I'm stacking the blocks\nout in some way like this.", "start": 720.0, "heat": 0.1}, {"text": "And with a greedy strategy,\nyou don't ever go backwards.All right.So I'm defining this distance.This is block one.This distance here is r 1.This distance is r 2.This one is r 3-- and so forth,\nuntil you get down to here.This is r n, because\nthis is the n'th block,and it extends out\nr n from the table.And this is 0 here,\nwhich the table--we'll consider the table to\nbe the n plus first block.So r n plus 1 is 0.OK.And so using the strategy--\nthe greedy strategy--we want to know what's r 1?We want to compute that-- if\nI keep pushing the blocks outin a topward fashion\nas far as they'll go.Now the constraint is\nthe stability constraintso it won't fall over.The stability constraint says\nthat the center of mass--we'll call it C k--\nof the top k blocksmust lie on the k\nplus first block.Otherwise it'll tip over.And of course the table is\nblock n plus 1 in this context.", "start": 840.0, "heat": 0.1}, {"text": "OK.So if at any point\nwe've got k blocks,and their center of\nmass is out here,they'll fall over at that point.Or if you are\nbuilding it this way,they would fall over that way.All right.So for each set of the top\nk blocks, the center of masshas to be on the block below.And if it is, we're fine.It won't fall over.Now for the greedy stacking.Where is the center\nof mass of the top kblocks in the greedy\nstacking, the waywe defined them in terms\nof these variables.What is C k?All right.So I got the top k\nblocks r k plus 1.The center of mass of the top\nk blocks by the greedy strategyis right at the edge\nof the k'th block.So if this is a block k here,\nthen this is r k plus 1.That's where the\ncenter of mass hasto be of all these\nblocks-- the top k blocks.If it's a little bit more,\nit's going to fall over.If it's less, then\nit's not greedy.We didn't push it out\nas far as it could go.All right.So for the greedy stacking,\nC k is equal to r k plus 1.And r n plus 1 of course\nis the edge of the table.That's zero.Any questions so far?What we're doing?OK.All right.So let's figure out where the\ncenter of mass of the top kblocks is-- a formula for\nthat-- a recursive formula.So to do that we look\nat the center of mass", "start": 960.0, "heat": 0.1}, {"text": "of the k'th block by itself,\nand then average it in withthe center of mass of\nthe top k minus 1 blocks.OK.So we're going to set up a\nrecursion to compute C k.Where is the center of mass of\nthe k'th block just by itself?The center of mass\nof the k'th block.This guy.Where is its center of mass?AUDIENCE: [INAUDIBLE]PROFESSOR: Yeah, r\nk plus 1 minus 0.5.Because the center\nof mass of this blockis 1/2 from the right edge.And the right edge\nis-- oh, it's r k.Sorry.All right?The top.Yeah this is.What?What did I do here?Oh, the top k.Sorry.This is the k'th block,\nthe way I had it.Here's the k'th.So it is r k minus a half.That's right.This is r k plus 1 down here.All right.Because the right edge of\nthe k'th block is at r k,the center of mass\nis 1/2 left of that.All right.So we know that the center of\nmass of the k'th block is at rk minus 1/2.All right.Now we can compute another\nexpression for C k.The center of mass\nof the top k blocksis C k equals-- well there's\nk minus 1 block centeredat C k minus 1, because\nthe center of massof the top k minus 1 block's\nby definition is C k minus 1.", "start": 1080.0, "heat": 0.1}, {"text": "And they have weight k minus 1.And then we average that with\na k'th block that has weight 1at position r k minus 1/2.And the total weight of\nthis is k minus 1 here,and one for this block.So this equals KC\nk minus 1 minus--let me write it better here.k minus 1.C k minus 1 plus R k\nminus 1/2 all over k.All right.So now we've got an expression--\na recursive expression--for C k.And to simplify it, we're\ngoing to plug in that-- C kas r k plus 1 for\nthe greedy strategy.Yeah?AUDIENCE: [INAUDIBLE]PROFESSOR: L is 1.The length of the blocks is\n1, here to make it simpler.Otherwise it would\nhave been a half L.So yesterday we talked\nabout length L blocks.Today they're length\n1, to be simple.All right.So now for the\ngreedy strategy, I'mjust going to plug\nin C k as r k plus 1.So let's do that.So I got C k as r k plus\n1 equals zero k minus 1.Well C k minus 1 is just R\nk plus R k minus 1/2 over K.And this simplifies\nto k r k minus r kplus r k-- they cancel--\nminus 1/2 over k.This equals r k minus 1/2.So getting very simple now.And I'm just going\nto rewrite thisto look at the difference\nbetween r k and r k plus 1.", "start": 1200.0, "heat": 0.1}, {"text": "So r k minus r k plus 1 Oops.I made a mistake.That's 1 over 2 k.Half over k is 1 over 2K.Any questions about\nthe math we did?Interesting.This is one of those problems\nwhere the math this wayis easy.There are other ways to\ntry to solve this problemand the math gets pretty hairy.But this one's a\nsimple approach.What's the meaning of this?What's an interpretation\nof r k minus r k plus 1?Yeah.AUDIENCE: [INAUDIBLE]PROFESSOR: Yeah.This is how much further the\nk'th block sticks out overthe k plus first block.So let's see that.All right.So here's r 1.Here's r 2.r 1 minus r 2 is the amount by\nwhich the first block sticksout over the second.Here's r 2 two minus r 3.It's that distance.All right.So we've gotten a formula for\nthe greedy strategy of how muchthe k'th block sticks out\nover the k plus first block.And it's pretty simple.All right.So now we can write\ndown this expressionfor all the values of k.So what's r 1 minus r 2 going\nto be in the greedy strategy?How much is the top\nblock sticking outover the second block\nin the greedy strategy?1/2.Just plug in k equals 1.r 2 minus r 3 equals--AUDIENCE: A quarter.One quarter.r 3 minus r 4 is what?6.All right.So now you can start to\nsee what the TAs did,", "start": 1320.0, "heat": 0.1}, {"text": "how it got smaller\neach step going downall the way to the end here.You get r n-- the n'th block--\nminus the table is 1 over 2 n.All right.Now there's a very\neasy way to figure outwhat r 1 is, which\nis what we're after.How far out is the top block?What do I do?Add them all together.And everything cancels.So I get r 1 minus r n\nplus 1 equals 1/2 plus 1/4plus 1/6 out to 1 over 2 n.All right.So that's just equal to the\nsum i equal 1 to n 1 over 2 1.All right.Now I got r 1 minus r n plus 1.But what's r n plus 1?0.That's the table.The table doesn't\nhang out over itself.So in fact r 1 equals a half\nof the sum of the inversesof the first n integers.OK?And so now all we have to\ndo is to compute this sumto know how far out it is.In fact, this sum\ncomes up so oftenin mathematics and computer\nscience, it has a special name.It's called the harmonic sum.And the numbers are called\nthe harmonic numbers.And in particular, the\nn'th harmonic numberis typically denoted\nH n just equalsthe sum of the n reciprocals.", "start": 1440.0, "heat": 0.1}, {"text": "All right.So for example, the first\nharmonic number is 1.The second is 1\nplus 1/2 equals 3/2.The third is 3/2 plus\n1/3, which is 11/6.The fourth harmonic\nnumber is that plus 1/4.22 plus 3/12 is 25/12.That's sort of an\ninteresting number,because it's bigger than 2.What does that tell us?Why is that interesting\nfrom this perspectiveof what we're doing here?Now you can get a\nblock off the table.Because R1, the distance\nthat the top block hangs outoff the table, is half\nthe harmonic number.Half of H 4 is a little\nbit bigger than 1.Which means with four blocks the\ntop block can be off the table.Now the TAs did it using five.I didn't even get it\nto work with five.In theory it'll work with 12.You can hang one out\nthere just a 24thbeyond the edge of\nthe table in theory.All right.If we kept on going,\nh of a million--the millionth harmonic number,\nif you were to go compute it,is 14.3927 and some other stuff.So if I had a million\nblocks stacked up, in theoryhow far would I get the\ntop block off the table?Seven blocks.All right.So that gives you an idea.You have to do a lot\nof work to get seven.And in fact it's hard,\nbecause the bottom blockwould be hanging out one\ntwo millionth of a block.All right?So you're adding up\na lot of tiny thingsto get to seven out there.Now it turns out that\nthe harmonic numbersgrow to infinity.And we'll see that.But they grow very, very slowly.", "start": 1560.0, "heat": 0.108}, {"text": "And to see that, we need to\nget a closed-form expressionfor this sum.Now does anybody know a\nclosed-form expressionfor the sum of 1 over i?I don't think so,\nbecause I don'tknow anybody who knows that.In fact it's [? probably ?]\nbelieved that it doesn't exist.So what do we do to get a\ngood estimation of that sum?What do we do?AUDIENCE: Integration bounds.PROFESSOR: The\nintegration bounds.Yeah.Because we're not going\nto get a closed form.At least I don't know of\nanybody who knows how to do it.So we'll use the\nintegration bounds.And what kind of\nfunction are we summing?Is it increasing or decreasing?Decreasing.Yep.So we'll use the formula\nwe did last time.All right.And that formula is that the\nsum i equals 1 to n of f of iis, at most, the first\nterm plus the integral.And it's at least the last\nterm plus the integral.All right.In this case we have\nf of i as 1 over i.So the first step is to\ncompute the integral.", "start": 1680.0, "heat": 0.11}, {"text": "And that's pretty easy.That's just the natural log\nof x evaluated at n and 1.And that's easy.That's just the\nnatural log of n.So the integral\nis very easy here.And now we actually\ncan just plug inand get really good bounds.Maybe I'll save\nthat just in case.OK so plugging in\ninto the bounds f of nis 1 over n plus the\nintegral is log of nis less than or equal to\nthe n'th harmonic number.And it's upper\nbounded by f of 1,which is 1 plus the integral.All right.So that's really good.We got very tight bounds.And now you can see that\nthe n'th harmonic number--how fast is it growing?If I were to use tilde\nnotation, what would I write?As log n.Yeah.So this means that h\nof n is tilde log of n.Now this is such an\nimportant functionthat people have gone\nto a lot of extra work--which we can't do in this\nclass-- to really nail downthe value-- get it much closer.And in fact it's now known\nthat it's the natural log of nplus 1 over 2n plus 1 over\n12n squared plus epsilon of nover 120n to the\nfourth where for all nepsilon n is between 0 and 1.", "start": 1800.0, "heat": 0.265}, {"text": "Oop.And I left one piece out.Actually there's a constant\nterm in here-- delta--that's called Euler's constant.Delta is called\nEuler's constant,and equals 0.577215664\nand some other stuff.And in fact to this\nday people don'tknow if this constant is\nrational or irrational.But they know it to a\nlot of decimal places.So basically H n is the log of n\nplus some fixed value between 0and 1-- as we knew\nit had to be--plus even some tail\nterms here thatget very small as n gets large.All right.So say I wanted to using\nthis greedy strategy.How many blocks I would need\nto get a block 100 blocks outover the end of the table.So I want to go 100 blocks out.How many blocks do I need\nusing this strategy, roughly?What is it?I think somebody said it.So I want to get r 1 to be 100.So I need the harmonic\nnumber to be 200.And what does this tell me\nabout n to get this to be 200?e to the 200.All right.So you're going to\nneed an exponentialin 200 number of blocks, which\nnow we're past the stars,all right, to get that many.All right.Now we won't prove it in class,\nbut this strategy-- the TAgreedy strategy-- is optimal.", "start": 1920.0, "heat": 0.323}, {"text": "There is no way to get a block\nfarther out over the edge.That said, there is a\nsecond way to get there.And in the second way, the top\nblock is not the optimal block.In the second way, it's the\nsecond block that goes out.So it looks something like that.So there's a\ncounterweight on it.And in the text, when\nyou read chapter nine,you will see the proof\nthat shows that there'stwo solutions that are optimal.One's a greedy, and\none's this other onethat sort of is mostly the\ngreedy, except the top coupleof blocks are different.And it proves that's optimal.We won't cover that in class.Now actually in the\nliterature today peoplehave been studying how\nfar a block can go outif you're allowed to do more\nthan one block per level,like one of the\nstudents wanted to do.So if you're allowed\nto have multiple blockson the same level, it turns\nout you can get much fartherout with n blocks.And right now it's known\nthat it's something like nto the third is how\nfar you can get out,which is much better\nthan log of n.And so mathematicians have\nbeen studying that problem.Any questions about\nthe block stacking?OK.All right.So that's basically it for sums.I do want to spend a little\ntime talking about products.And that may get us back\ninto sums pretty quick.The most famous product\nout there is n factorial.And once we get to\ncounting and probability,probably every\nlecture we're goingto be looking at n factorial\none way or another.Just comes up all the time.n factorial is the product\nof i equals 1 to n of i.It's the product of the first\nn natural numbers after zero.", "start": 2040.0, "heat": 0.458}, {"text": "Now we'd like to be able to\nget a closed-form expressionfor this, because factorial\nis really not closed form,because it's hiding this thing.And if I ask you how big is\nn factorial, sort of hardto say how big it is,\nhow fast it grows.Any ideas about how we might\ngo about doing a product to geta closed-form expression?AUDIENCE: If you take a\nlogarithm of a product,you get a sum.PROFESSOR: Yeah, good.Take the log of it.Well, let's write that out--\n1 times 2 times 3 to n.That equals the log of\n1 plus the log of 2.Whoops.All right.So I've now got a sum.And now that I've got a sum\nwe can use all the toolswe had for sums.So really, products\nlook hairy, but they'reno different than sums.Because we're going to\nget an approximationor get an answer for\n[? login ?] n factorial.Then we'll exponentiate it,\nand we'll have the answer.All right.So we're looking at this sum.And so how do I get a\nclosed form for that?Turns out nobody\nknows the closed form.But we do know a method that\napproximates it very well,which is the integration bounce.Only in this case, it's\nan increasing function.So let's do that.", "start": 2160.0, "heat": 0.424}, {"text": "OK.So let's do that.And the formula is easy.It's basically the same\nformula we had there--that the sum i equals\n1 to n of f of iis at most the n'th\nterm plus the integral.And it's at least the first\nterm plus the integral.All right.Now in this case f\nof i is the log of i.And so we need to compute\nthe integral of log of x.And that's easy.That's x ln of x minus\nx evaluated at n and 1.And that's just n\nlog of n minus n.If I plug in 1, I get a 0 here,\nand I'm subtracting negative 1there.All right.And so now we'll just plug\nthis into the integraland we'll get our bounce.So f of 1.What is f of 1 in this case?Yeah, 0.Plus n ln n minus\nn plus 1 less thanequal to log of n factorial,\nless than or equal to f of nis log of n.", "start": 2280.0, "heat": 0.607}, {"text": "OK.So to get bounds on\nn factorial, we justexponentiate both sides.So I take e to this,\ngives me-- well, that'sgoing to give n to the n here.And this is negative.That'll be e to the n minus 1.And here I've got n plus\n1 times the log of n.So it's n to the n plus\n1 over the same thing--e to the n minus 1.So we got very close bounds.They're within a factor of\nn-- which sounds like a lot,but compared to how big n\nfactorial is, not so bad.Pretty good bounds there.OK.So n factorial's about n\nover e to the n'th power.Now this is so important\nthat-- even more importantthan harmonic numbers-- people\nhave gone to a lot of effortto get very tight\nbounds on n factorial.So let me tell you\nwhat those are.It's called Stirling's formula.And that says that n\nfactorial equals n over eto the n'th power times the\nsquare root of 2 pi n timese to the epsilon n where\nepsilon n is between 1 over 12nplus 1 and 1 over 12n.", "start": 2400.0, "heat": 0.871}, {"text": "So it's epsilon n is\ngoing to 0 as n gets big.So e to something going\nto 0 is going to 1.All right.So another way of\nlooking at thisis you could put a\ntilde here, all right,and ignore that term.And that's called\nStirling's formula.This is a good thing to\nhave on your crib sheetfor the midterm.So very likely\nthere'll be somethingwhere you've got to have\nsome kind of analysisof n factorial, and to\nknow how fast it's growing.Now these bounds you\nget here are very tight.For example, 100\nfactorial is at least 100over e to 100 times square\nroot 200 pi, times e to the 1over 1,201.This thing is just really tiny.This thing here is\n1.0008329 and something.And 100 factorial\nis lower-boundedby the same things, only here\nit's e to the 1 over 1,200.And that is very close\nto 1-- 1.00083368.So the difference\nin these boundsis a tiny fraction of 1%.So the bound you get\nfrom Stirling's formulais very, very close\nto the right answer.Any questions on\nStirling's formula?We won't derive it.You can derive that in\na graduate math class.They do that sometimes.More typically you'll\nsee it without that eto the error term.And you just see n\nfactorial writtenas tilde, and over e to\nthe n, square root 2 pi n.", "start": 2520.0, "heat": 0.761}, {"text": "All right?Because that e to the epsilon\nn goes to 1 in the limit.So it sort of disappears when\nyou go to the tilde notation.And this in fact is\na lower bound on nfactorial, and very close\nto the right answer.Now this is sort of\nan amazing formula.I mean who would think that\nwhen you look at n factorialthat the expression\nwould have e and piin the expression for it?Maybe e.Maybe.But what's pi doing\nin n factorial?It's sort of a bizarre thing.OK.That's it for products.We're just going to\ndo the one example,because really any product just\nbecomes a sum through the log.And that makes it really easy.Any questions on\nsums and products?Because I'm going to totally\nchange gears now and talkabout more things like tilde.OK.So we're going to talk today\nand tomorrow in recitationabout asymptotic notation.It is used all over the\nplace in computer science.We've already seen one example,\nwhich is the tilde notation.And it turns out there's\nfive more things like thatwhich we're going to learn what\nthey are and how they work.They're used to\nexplain or describe howa function grows in the limit.So for example, we had\nthe tilde notation.And we wrote f of x is tilde\ng of x if the limit as x goes", "start": 2640.0, "heat": 0.754}, {"text": "to infinity of f over g is 1.Now the next one--\nand most commonlyused one in computer\nscience-- iscalled the O notation,\nor the big O.And it's written like this.f of x equals O of g of x.And it means that\nthe limit as x goesto infinity of the\nabsolute value of fof x over g of x\nis convergence--is less than infinity.So it's finite, and\nit can't diverge.The interpretation\nis that this functionis up to constant factors\nupper-bounded by this one,that this grows the same rate\nor slower than this one growsas x gets large.Because if f was growing a lot\nfaster than g in the limit,then the limit would be\nthe ratio is infinity.And we're saying\nthat doesn't happen.All right.I'm not going to do a\nlot of examples for this.In fact, let's go over here.There's several other ways\nyou'll see it written.For example, you'll\nsee people writef of x is less\nthan or equal to Oof g of x, because the\nnatural interpretation is", "start": 2760.0, "heat": 1.0}, {"text": "f is not growing faster than\ng-- sort of upper-bounded by g.You'll see people write\nf of x is O of g of x.And the formal math way\nthat people don't use,but it's the\nformally correct one,is f of x is an\nelement of O of g of x.And the interpretation\nthere is that O of g of xis a set of functions that\ndon't grow any faster than g.And f is one of them.You can use any of\nthese and that's fine.People will know what\nyou mean, and it'llbe fine for the class.All right.Let's see some examples, and see\nhow to prove a big O relation.Let f of x be the\nfunction x, and gof x be the function x squared.Then in this case\nf of x is O of gof x-- because x doesn't\ngrow any faster than xsquared as x gets large.To prove it, we\ntake the limit as xgoes to infinity of\nx over x squared.That is equal to what?What is the limit of x over x\nsquared as x goes to infinity?0.And that is less than infinity.So we proved it.So if you get asked to prove\nf is O of g, what you dois you take the limit of f\nover g as x goes to infinityand show that it\ndoesn't diverge.All right.Let's do another example.In this case we'll show\nthat f is not O of g.", "start": 2880.0, "heat": 0.731}, {"text": "x squared is not O of x.Of course, x squared\ngrows faster than x,but let's see why not.Well we take the limit\nas x goes to infinityof x squared over x.And what is that limit?Infinity.And so it can't be true\nthat it's x squaredis O of x, because it has\nto be less than infinity.Yeah?AUDIENCE: Sorry.I missed it.What's alpha?PROFESSOR: Infinity.Sorry.Infinity.There we go.That's important\nin the definition.Yep.Good.All right.What about this?Is x squared equal O\nof a million times x?Yes?No?What do you think?This looks pretty darn big.AUDIENCE: It's a constant.PROFESSOR: That a constant.So in the limit, as x goes\nto infinity, this over thatis infinite.All right.So no.Because the limit of\nx goes to infinityof x squared over 10 to the\nsixth x, that equals infinity.So the thing with\nthis big O notationis you just ignore\nour constant factors.They don't do anything.Just forget about them.What about this?Is 10 to the sixth x\nequal O of x squared?", "start": 3000.0, "heat": 0.567}, {"text": "Yes.Because you just\nignore the constant.That's what the big\nO is for, and whyit's used all the time\nin computer science.So yes, that's true.The proof is very simple.The limit as x goes to infinity\nof 100 x squared-- whoops.I could even put a square there.10 to the sixth x squared over\nx squared is 10 to the sixth.That's less than infinity.In fact, I could take\nany quadratic polynomial.x squared plus 100x plus 10 to\nthe seventh is O of x squared.Because smaller order\nterms don't matter.The limit of this here over\nthat in that case is 1.So it's less than\ninfinity as x gets big.All right let's do a few more.This really is not so hard.It's a little dull.But you've got to\nknow it for later.OK.I could take classes like\n6046, and you'll neversee any constants, because\neverything is things like big Oand the other notation\nwe'll talk about.What about this?X to the 10th equal\nO of e to the x.Is x to the 10 O of e to the x?Yeah, it is.So this is a theorem.Proof.Limit as x goes to infinity.x to the 10 over e to the x.", "start": 3120.0, "heat": 0.511}, {"text": "That equals 0, which is\ncertainly less than infinity.All right.Now the reason this\nstuff is usefulwhen you're doing the\nanalysis of algorithmsis because when you're\ntalking about thingslike matrix multiplication\nalgorithms or things like that,the actual running time\ndepends on the machine you'redealing with-- the machine\ncharacteristics-- detailsin how you count steps\nof the algorithm.For example, doing\nmatrix multiplication,do you count multiply different\nthan you count plus addition?And if you start getting\ncaught up in all those detailsyou lose the important\nfact of the algorithm.For example, matrix\nmultiplication--the elementary algorithm takes\norder O of n cubed steps.And that's the important fact.And it tells you that if you\ndouble the size of the matrixthe running time will increase\nby at most a factor of eightin the limit as n gets large.And so you might write\nthings like the timeto multiply n by n matrices.You might call that t of n,\nand then state that is O of ncubed.All right.And you don't have to\nworry about what computerit's running on,\nexactly how you'recounting the details of what\na step is or what time is.The important thing\nis that it's growingat most as a cubic of\nthe size of the matrices.And so in 6046 and 6006\nyou will spend lots of timeproving that things\nare the running time,or the size is O of some\nfunction of the input size.All right.Any questions?Yeah.AUDIENCE: [INAUDIBLE]", "start": 3240.0, "heat": 0.257}, {"text": "PROFESSOR: Yeah.It gets all dicey if you\ndo oscillatory things.And it depends\nhow you define it.So we're going to\nstay away from thatand just stick with\nthis definition.So if this guy\noscillates-- like fis a sine of x,\nsine of x is O of x.All right.It doesn't have to converge.But as long as the ratio\nis less than infinity.AUDIENCE: [INAUDIBLE]PROFESSOR: Yeah.Everything you do.Maybe you'll see sine\nfunctions sometimes.But everything you\ndo in algorithmsis going to be\ngrowing monotonically.Yeah.Nothing-- no wacky\nstuff in math usually.Any other questions?Yeah.AUDIENCE: [INAUDIBLE]\nsort of comparingsomething that's the same\nmagnitude that you go offinto infinity.PROFESSOR: Yeah.It's upper bounded.So it's not the same.We'll get to the\nsame in a minute.But it's upper bounded.f is upper bounded by g\nup to a fixed constantas you go to infinity.And all constants get\nwashed away by O. Yeah.AUDIENCE: [INAUDIBLE]PROFESSOR: Ah, why is this true?Well technically we'd have\nto go back to calculusand use L'Hopital's rule\nor something like that,because this function\nexponential grows a lot fasterthan x to the tenth.So L'Hopital's rule is you\ntake the derivative of thisover the derivative of that.Then you'd have x to the\nninth over e to the x.You do it nine more times.And you'd get 10\nfactorial over e to the x.And that limit is zero.So that's how you'd actually\ndo it using L'Hopital's rule.Yep.Any polynomial grows slower\nthan any exponential.All right.Let's now do some examples\nthat can get you screwed up.What about this one?Is 4 to the x O to 2 to the x?", "start": 3360.0, "heat": 0.179}, {"text": "Is that true?No, it's not true.I mean, the mistake\nyou might makeis say, oh, 4 and 2,\n4 is only double 2.Big O wipes out\nconstant factors.So the answer is yes.That would be bad.Better to look at the limit.So we'll state the correct\ntheorem-- 4 to the xis not O of 2 to the x.And the proof is obtained\nby looking at the limitas x goes to infinity of 4\nto the x over 2 to the x.That is just the limit 4\nto the x over 2 to the xis 2 to the x.That's infinity.So the limit is not bounded.All right?So it is not big O there.All right.Here is one.Is 10 O of 1?I've purposely\nwritten it this way.Yes, it is.And in fact the\ninterpretation hereis that you've got\nsome function fof x that's just\nalways equal to 10,and some function g of x\nthat's always equal to 1.And then it is true in this\ncase that f of x is O of g of x.All right.But any constant function is O\nof any other constant function.We're going to revisit\nthis in a nastierscenario in a little bit.OK.Sometimes you'll see\nnotation like this.H of n-- in fact, we\nsaw this earlier--is the log of n plus\ndelta plus O of 1 over n.", "start": 3480.0, "heat": 0.219}, {"text": "When we wrote out the formula\nfor the n'th harmonic number,it was log of n plus\nEuler's constant plussomething like 1 over n,\nconstant times 1 over n.And then some even\nsmaller terms.And so people will\nwrite it like this.And it tells you that the\nerror terms grow no fasterthan a constant times 1 over n.Technically this is the\nwrong way to write it.But everybody does\nit, so you can too.What it means is this.H of n minus ln of n minus\ndelta is O of 1 over n.All right.That's the correct\nway to write it,because you're taking the\nratio of this over that.This is how people will do it.All right.So just make sure you\nunderstand that, what it meanswhen you put it over there.Same thing with tilde notation.People will write this-- H of\nn is tilde ln of n plus Euler'sconstant.The right way to write it\nis Hn minus Euler's constantis tilde ln of n.Now can anybody tell me\nwhy this is really nota good thing to do?And you think of how\nthings get reallyscrewed up if you allow\nto start doing this?Can you think of\nanything that--?What if I did this?Is this true?10.The n'th harmonic\nis harmonic numberis tilde of log of n plus 10.Is that true?Think about that.People are shaking their heads.I mean how can it be true?Because we know this is.We know that's what it is.In fact, this is true.I can even make it a million.10 to the sixth here.", "start": 3600.0, "heat": 0.346}, {"text": "It's true.Because the ratio of this over\nthat in the limit is what?1.And that's all I need for tilde.All right.So when I wrote this,\neverybody knew what I meant.But I could write this and be\njust as true mathematically.And so you've got to be\nsort of careful about this.Really, the right\nway to do it is this,because now we're\ntaking off that term,and then it's-- actually\nI did this wrong.I should've put the [INAUDIBLE].Whoops.I should've done it this way.Let me rewrite that.The right way to do it is\nH of n-- yeah-- is this.You put the small\nterm out over here.That's the right way.Because now it's not true\nthat it's 10 to the sixth outhere-- all right-- for the\nratio of that over this guy.All right.So you can do it.But be careful,\nbecause you mightwrite wrong things\nthat technicallywould fit the definition.Same thing with big\nO. Same problem there.Any questions about that?All right.All right.Now one thing that people do all\nthe time that you cannot do isto use big O as a lower bound.All right.So that's one abuse that we\nwon't-- you'll get marked wrongfor doing that, even though\nfamous researchers will do it,and you'll probably even have\na professor do it sometime.So you may not do this.f of x is bigger than\nor equal to O of g of x.That is meaningless.Because the whole point of big\nO is that it's an upper bound.So you can't use it\nas a lower bound.And the reason\nyou can't do it isbecause there is another symbol\nto do what you want to do.", "start": 3720.0, "heat": 0.32}, {"text": "And that's called\nthe omega symbol.And it's written like this.It's a capital omega.And it's if the limit as x goes\nto infinity of f of x over gof x is greater than zero.OK.So now we're getting\nthe lower bound version.In fact it's just the\nopposite of big O.In fact, we'll state a theorem.Not hard to prove.We won't do it.f of x equals O of g of\nx if and only if g of xequals big omega of f of x.In other words, f\ngrows no faster than gif and only if g grows\nat least as fast as f.One's an upper bound one.One's a lower bound.And you've just got to use\nthe symbol the right way.Now you can do this.You can write f of x bigger\nthan or equal to omega g of x.That's OK.All right?That's all right to do.All right.Let's do some examples.So x squared is omega of x,\nbecause it grows faster than x.2 to the x is\nomega of x squared.All right.x over 100 is omega\nof 100x plus 25,", "start": 3840.0, "heat": 0.537}, {"text": "because constants don't matter.x over 100 grows\nat least as fastas 100x does in terms, because\nwe're measuring the growth.So constants go away.If you want to say the\nrunning time of that algorithmis at least quadratic,\nyou would write T of nis omega n squared.All right.And that says that the running\ntime is at least n squared.Any questions on big omega?Not too hard once you have\nbig O. It's just the opposite.All right the next\nsymbol is the versionof equality, where you're\nbigger-- at least as bigas, and at most as big as.There's a special\nsymbol for that.So in that case we use theta.And we say that f\nof x equals thetaof g of x if the limit\nis both bigger than 0and less than infinity.All right.So it's just a shorthand way\nof saying big O and big omega.That's what theta means.It just both hold true.All right.And that's a theorem which\nis not hard to prove,but we won't do it.f of x equals theta of g\nof x if and only f of the xequals O of g of x and f\nof x equals omega g of x.All right.So let's do some\nexamples of theta.", "start": 3960.0, "heat": 0.357}, {"text": "So for example, 10x cubed\nminus 20x plus 1 is more easilywritten as theta of x cubed--\nbecause the constants don'tmatter.The low order\nterms don't matter.What about this?Is x over log of x,\nis that theta of x?x over log of x.Is that theta of x?People are nodding their heads.Hmm.Let's see.Let's check.The limit as x goes to\ninfinity of x over logof x divided by x.Well, the x's cancel.That's the limit as x goes to\ninfinity of 1 over log of x.What's that?0.Uh-oh.it is not theta.I got to be bigger than zero.In fact, this grows\nmore slowly than that--strictly more slowly.All right.A little more slowly,\nbut strictly more slowly.All right.If I use for an\nalgorithm, if youwant to say the algorithm runs\nin quadratic time-- namelyat least quadratic time, and\nat most quadratic time-- thenyou'd say t of n is\ntheta of n squared.So let me write that.So t of n equals theta\nn squared means t grows", "start": 4080.0, "heat": 0.212}, {"text": "quadratically in n-- both\nupper and lower bound.OK?So for these three guys,\nto summarize-- sort of youcan keep track of them pretty\nsimply-- O means less thanor equal.Omega means greater\nthan or equal.Theta means equal up\nto constant factors.Now there's two\nmore symbols here.And they correspond very\nnaturally to this set-up.What two symbols are missing\nfrom here that would younaturally add to here?Yeah.Less than and greater than.So less than is little o.Greater than is little omega.And less than means it's less\nthan or equal, but not equal.And this means greater\nthan or equal, not equal.And let me put them up\nover here and give youthe formal definitions.Eraser.OK.So little o.", "start": 4200.0, "heat": 0.328}, {"text": "as we have f of x\nequals little o of gx if the limit of f of\nx over g of x equals 0.So f is growing\nstrictly smaller than g,so that when I take the\nratio, the limit goes to 0.And the reverse is little omega.And we say that f of x is\nlittle omega-- whoops--of g of x if this is infinity.Because now f is growing\nstrictly faster than g,so I take the limit of the\nratio, and it goes to infinity.All right so we can do\nsome simple examples.Then we're almost done\nwith all this notation.What about this one?x over ln of x-- we just\nlooked at it-- and x.What symbol do I put there?What symbol's missing here?Little o.This grows strictly\nsmaller than that.If I took the ratio, and I\ntook the limit, we got 0.So that's a little o.OK.Is this true?x over 100-- is\nthat little o of x?No.The limit of the\nratio is 1 over 100.That's bigger than 0.Constants don't matter.All right.So what symbol would go here?Theta goes here.Good.Also big O and big omega.But theta captures everything.", "start": 4320.0, "heat": 0.4}, {"text": "All right.What symbol goes here?x squared equals something x.What symbol goes there?Little omega.It would also be true\nto put big omega,but little omega tells you more.Because the limit of x squared\nover x goes to infinity.OK.Any questions\nabout these things?So a natural thing on the\nmidterm is we do some of that,for example.All right?And you'll certainly see\nsome of that on homework.You might see some\nof that on the test.You'll certainly see all\nthis stuff-- little omeganot very often in 6046 and\nlater algorithms courses.But all the rest\nyou'll see there.Any questions?All right.Now I'm going to\nshow you somethingthat is sort of scary.Yeah.AUDIENCE: Why do\nyou say that it'sequal to zero when\nyou said it's lessthan [INAUDIBLE] equals sign.PROFESSOR: Which equals?AUDIENCE: You said little\nomega is less than.PROFESSOR: Little omega,\nit corresponds to a greaterthan, which means a\ngreater than or equal to,but not an equal to.And the way we can see that\nis looking at the definitionshere in the greater than or\nequal to is the big omega.And that just says\nyou're bigger than 0.Ah.Let's see.All right.So I'm bigger than\nor equal to is omega.But I'm not equal\nto, which is theta.So if I know that I'm\nthis but not that,the only conclusion is that\nI'm infinity in the ratio.All right?So that's another\nway of saying it.That's why.Any other questions?", "start": 4440.0, "heat": 0.385}, {"text": "All right.Now I'm going to\nshow you somethingthat is commonly done, and\nthat many students will attemptto do after seeing\nthis notation,because the notation\nis pretty simple.Take your limits.Everything goes fine.Then you start\ncruising along with it.So now I'm going to show\nyou how to prove somethingthat's false using this notation\nin a way that people often do.And the hope is by showing\nyou, you won't do it.It will confuse you,\nwhich is why sometimes weworry about showing you.But let f of i-- f of n-- equal\nthe sum i equals 1 to n of i.Now we all know\nwhat that is, right?All right.So I'm going to prove to\nyou that f of n is O of n.Now what really-- what\nshould be here instead of n?n squared.So n squared can't be O of n.So this can't be true.All right.Well let's see how we do it.All right.So the false proof\nis by induction on n.My induction hypothesis is p\nof n is going to be that f of nis O of n.All right?That's what we, when we want to\nprove something by induction,typically that's what you do.Becomes the\ninduction hypothesis.Let's look at the base case.Well f of 1 is 1, and\n1 is O of 1 surely.", "start": 4560.0, "heat": 0.414}, {"text": "Right?Even 10 was O of 1.OK.All right.Now we do the inductive step.We assume p n is true to\nprove that p n plus 1 is true.Well p n means that\nf of n is O of n.Now I look at f of n plus 1.That equals the sum of\nthe first n plus 1 number.So that will be f\nof n plus n plus 1.The induction hypothesis\nsays this is O of n.Clearly this is O of n.Well I got O of n plus O of n.That's at most twice O of n.And constants don't matter.So that's O of n.All right.This should begin\nto cause panic.Is induction wrong?What's going on with the big O?You will see this\ndone all the time.People would do this\nkind of an argument.Looks pretty good, right?Can anybody see where\nI got off track?This is a really hard\none to figure outwhere things went wrong.Yeah?AUDIENCE: One of them\nmight be that youmight be applying O of n\nto numbers which really you", "start": 4680.0, "heat": 0.303}, {"text": "really apply asymptotic\nnotation to functions.PROFESSOR: Great.That's a great observation.Asymptotic notation only\nworks for functions.Now here when we\nsay 1 is O of 1,well, you could think of it as\nf of x being 1-- the function--and so forth.So that's OK.That's a great point.Now let's figure out using\nthat how we got in trouble.We're not quite done yet.That's a great observation.But where's the\nstep that's wrong?Oh, no.2 times O of n is O of n.If I have a function that's f\nis O of g, twice f is O of g.Yeah?AUDIENCE: It's the end of\nn equals 1 [INAUDIBLE].PROFESSOR: Is it?So what's the problem now?AUDIENCE: [INAUDIBLE]PROFESSOR: Well f of n plus\n1-- this statement is true,because f of n plus 1 is the sum\nof i equals 1 to n plus 1 of i.That's 1 plus 2 plus\nn plus n plus 1.And this is f of n.So that's OK.Yeah.AUDIENCE: [INAUDIBLE]\nthat function.PROFESSOR: Yeah.You know, you're getting closer.Yeah that's a little\nflaky, because I've justgot a single value\nsaying it's O of one.But we sort of argued\nbefore that 10 was O of 1.Now realize a function\nbehind here that matters.So you're on the right trail.But there's an even\nbigger whopper hiding.Yeah.AUDIENCE: [INAUDIBLE]PROFESSOR: Oh yeah.This is really, really bad.All right.So now explain to me why this\nis really bad what I did here.AUDIENCE: You didn't need\nthe function [INAUDIBLE].PROFESSOR: Yeah.", "start": 4800.0, "heat": 0.305}, {"text": "And why isn't-- this\nlooks like a function.Why isn't it a function?It's not.But it looks like one.f of n sure looks like one.Why is it not a function when\nit's sitting in this thing?This P of n, right?Because I've fixed\nthe value of n here.And so this is\nnow just a scalar.In fact, you know, I could state\nthe following-- f of a million,right, is O of 1, because\nthis is really some function Hof x that always is this value.So the difference between\na scalar and a function.And this is just so nasty\nlooking, because we see f of n.That's a function.But you can never use\nbig O in a predicate,all right, because we've\nlost the function here.This is just f\nvalued at n period.That single instance is\nall that's happened here.It's not a function anymore.All right.If we had f n of x or\nsomething, that might be OK.But there's no function left.All right.So never ever use asymptotic\nnotation with inductive proofs,because you will\njust invariably stickbig O into your predicate.And you could prove all sorts of\nfalse things once you do that.OK?All right.Never use asymptotic notation\nin induction or predicates.Thanks.", "start": 4920.0, "heat": 0.198}]