[{"text": "PATRICK WINSTON: Today\nwe're going to betalking about Search.I know you're going to\nturn blue with yetanother lecture on Search.Those of you who are taking\ncomputer science subjects,you've probably seen in 601.You'll see it again\nas theory course.But we're going to do it for\na little different purpose.I want you to develop some\nintuition about various kindsof Search work.And I want to talk a little bit\nabout Search as a model ofwhat goes on in our heads.And toward the end, if there's\ntime, I'd like to do ademonstration for you of\nsomething never beforedemonstrated to a 603.4 class,\nbecause it was only completedlast spring.And some finishing touches were\nadded by me this morning.Always dangerous, but we'll\nsee what happens.There's Cambridge.You all recognize\nit, of course.You might want to get from some\nstarting position s tosome goal position g.So, you'll hire a cab and\nhope for the best.So, here's what might\nhappen, not too hot.Let's move the starting\nposition over here.I've had cab drivers\nlike this New York.But it's not a very good path.It's the path of a thief.Let's change the way that the\nsearch is done to that of abeginner, an honest beginner.", "start": 0.0, "heat": 0.1}, {"text": "Not too bad.Now, let's have a look at how\nthe Search would happen if thecab driver was a Ph.D.\nin physicsafter his third post-doc.These are not actually\ntraverse.These are just things that the\ndriver is thinking about, andthat is the very best of\nall possible paths.So, the thief does\na horrible job.The beginner does a pretty\ngood job, butnot an optimal job.This is the optimal job as\nproduced by the Ph.D. inphysics after his\nthird post-doc.So, would you like to understand\nhow those all work?The answer, of course, is yes.I'm going to talk to you about\nprocedures that are differentfrom the way that you just\nsolved this problem.I imagine that if I said to you,\nplease find a path for sto g, you would, within\na few seconds, finda pretty good path--not the optimal one, but\na pretty good one--using your eyes.And we're not going to tell\nyou about how that works,because we don't know\nhow that works.But we do know that problem\nsolving with the eyes is animportant part of our\ntotal intelligence.And we'll never have a complete\ntheory of humanintelligence until we can\nunderstand the contributionsof the human visual system to\nsolving everyday problems likefinding a pretty good\npath in that map.But, alas, we can't talk about\nthat, because we don't knowhow to do it.We're working on it.But we don't know\nhow to do it.So, I'm not going to use\nCambridge in my illustrations.There's too much there to\nwork through in an hour.So, we're going to use this map\nover here which has beendesigned to illustrate a\nfew important points.", "start": 120.0, "heat": 0.1}, {"text": "You, too, can find a path\nthrough that graph prettyeasily with your eyes.Our programs don't have eyes,\nand they don't have visuallygrounded algorithms, so they're\ngoing to have to dosomething else.And the very first kind of\nsearch we want to talk aboutis called the British\nMuseum approach.This is a slur against at least\nthe British Museum, ifnot the entire nation, because\nthe way you do a BritishMuseum search is you find\nevery possible path.So, it'll be helpful to have a\ndiagram of all possible pathson the board.We're going to start with\na British Museum search.From the starting position, it's\nclear, you can go from mys to either a or b.And already there's an\nimportant quiz point.Whenever we have these kinds of\nproblems on a quiz, we askyou to develop the tree\nassociated with a search inlexical order.So, the nodes there under s\nare listed alphabetically,just to have an orderly\nway of doing it.So, from a we can go\neither b or d.And another convention of the\nsubject, another thing youhave to keep in mind in quizzes,\nis it we don't havethese searches bite\ntheir own tail.So, I could have said that\nif I'm at a, I canalso go back to s.But no path is ever allowed\nthem to bite itself, to goaround and enter and get\nback to a place that'salready on the path.Now if I go on to b first, that\nmeans that from b I cango to either a or c.This is getting fat\npretty fast.But let's see, s, a, b.The only place I can go\nis c and then to e.", "start": 240.0, "heat": 0.113}, {"text": "s, a, d, without biting my own\ntail and going back to a, theonly place I can go is g.s b, a, I can only go\nto d and then to g.And finally, s, b, c,\nI can only go to e.So, that is a complete set of\npaths as produced by anyprogram that you will feel you'd\nlike to write that findsall possible paths.I haven't been very precise\nabout how to do that, becauseyou don't have to be.You can't save much work by\nbeing clever, because you haveto find everything.So, that's the British Museum\nexpansion of the tree.So, what have I done?I've been playing around\nwith a map.I showed you an example\nof a map.And pretty soon you're\ngoing to think thatSearch is about maps.So, before going even another\ntiny step, I want to emphasizethat Search is not\nequal to maps.Search is about choice.And I happen to illustrate\nthese searches with maps,because they are particularly\ncogent.But Search is not about maps.It's about the choices you make\nwhen you're trying tomake decisions.These things I'm going to be\ntalking to you about today arechoices you make when\nyou explore the map.You can make other kinds of\nchoices when you're exploringother kinds of things.And, in fact, at the end, if\nthere's time, I'll show youhow you do searches when you're\nsolving problems in ahumanities class.That's the British\nMuseum algorithm.Search is not about maps.Our first gold star idea,\nSearch is about choice.But for our illustration,\nSearch is about maps.", "start": 360.0, "heat": 0.113}, {"text": "So, the first kind of Search we\nwant to talk about that'sreal is Depth-first Search.And the idea of Depth-first\nSearch is that you barrelahead in a single-minded way.So, from s, your choices\nare a or b.And you always go down the left\nbranch by convention.So, from s, we go to a.From a we have two choices.We can go to either b or\nd following our lexicalconvention.After that, we can go to c.And after that we can go to e.And too bad for us,\nwe're stuck.What are we going to do.We've got into a dead\nend, all is lost.But of course, all isn't lost.Because we have the choice of\nbacking up to the place wherewe last made a decision and\nchoosing another branch.So, that process is called\nvariously back-up orbacktracking.At this point, we would\nsay, ah, dead end.The first place we find when we\nback up the tree where wemade a choice is when we\nchose b instead of d.So, we go back up there and\ntake the other route.s, a, d now goes to g.And we're done.We're going to make up a little\ntable here of thingsthat we can embellish our\nbasic searches with.And one of the things we can\nembellish our basic searcheswith is this backtracking\nidea.", "start": 480.0, "heat": 0.111}, {"text": "Now, backtrack is not relevant\nto the British Museumalgorithm, because you've\ngot to find everything.You can't quit when you've\nfound one path.But you'd always want to use\nbacktracking with Depth-firstSearch, because you may plunge\non down and miss the path thatgets to the goal.Now, you might ask me, is\nbacktracking, therefore,always part of Depth-first\nSearch?And you can read textbooks\nthat do it either way.Count on it.If we give you a Search problem\non a quiz, we'll tellyou whether or not your Search\nis supposed to usebacktracking.We consider it to be\nan optional thing.You'd be pretty stupid not to\nuse this optional thing whenyou're doing Depth-first\nSearch.But we'll separate these\nideas out and callit an optional add-on.so, that's Depth-first\nSearch, very simple.Now, the natural companion to\nDepth-first Search will beBreadth-first Search,\nBreadth-first.And the way it works is you\nbuild up this tree level bylevel, and at some point, when\nyou scan across a level,you'll find that you've\ncompleted a paththat goes to the goal.So, level by level, s can\ngo to either a or b.a can go either to b or d.And b can go to either a or c.So, you see what we're doing.We're going level by level.And we haven't hit a level\nwith a goal in it yet, sowe've got to keep going.Note that we're building up\nquite a bit of stuff here,quite a lot of growth in the\nsize of the path set thatwe're keeping in mind.At the next level, we have b\ngoing to c, d going to g, agoing to d, and c going to e.", "start": 600.0, "heat": 0.1}, {"text": "And now, when we scan\nacross, we do hit g.So, we found a path with\nBreadth-first Search, just aswe found a path with\nDepth-first Search.Now, you might say, well,\nwhy didn't you just quitwhen you hit g?Implementation detail.We'll talk about a sample\nimplementation.You can write it in\nany way you want.But now that we know what these\nsearches are, let'sspeed things up a little bit\nhere and do a couple searchesthat now have names.The first type will be\nDepth-first, boom.That's the one that produces\nthe thief path.And then we can also do a\nBreadth-first Search, which wehaven't tried yet.What do you suppose is\ngoing to happen?Is it going to be fast, slow,\nproduce a good path,produce a bad path?I don't know, let's try it.I had to speed it up, you see,\nbecause it's doing an awfullot of Search.It's generating an awful\nlot of paths.Finally, you got a path.Is it the best path?I don't think so.But we're not going to talk\nabout optimal paths today.We're just going to talk\nabout pretty goodpaths, heuristic paths.Let's move the starting position\nhere in the middle.Do you think Breadth-first\nSearch is going to be stupid?I think it's going to\nbe pretty stupid.Let's see what happens.This Search is a lot to the\nleft, which you would never dowith you eye.Let me slow that down just\nto demonstrate it.It finds a shorter path, because\nit's right there inthe middle.But it spends a lot of its time\nlooking off to the left.It's pretty stupid.But that's how it works.So, now that we've got two\nexamples of searches on thetable, I'd like to just write\na little flow chart for howthe search might work.Because if I do that, then it'll\nbe easier for us to seewhat kind of small differences\nthere are between the", "start": 720.0, "heat": 0.1}, {"text": "implementations of these\nvarious searches.So, what we're going to do is\nwe're going to develop awaiting list, a queue, a\nline, whatever you'dlike to call it.Let's call if a queue.We're going to develop a queue\nof paths that are underconsideration.So, the first step in our\nalgorithm will be toinitialize our queue.And I think what I'll do is\nI'll simulate Depth-firstSearch on this problem\nup there on theleft using this algorithm.I need to have some way of\nrepresenting my paths.And what I want to do is I'm\ngoing to betray my heritage asa list programmer, because I'm\njust going to put these up asif there were lisp\ns-expressions.To begin with, I just\nhave one path.And it has only one\nnode in it, s.That's the whole path.The next thing I do after I\ninitialize the queue is Iextend first path\non the queue.OK, when I extend s,\nI get two paths.I get s goes to a, and\nI get s goes to b.I take the first one off\nthe front of the queue.And I put back the two\nthat are produced byextending that path.Now, after I've extended the\nfirst path on the queue, Ihave to but those extended\npaths on to the queue.In here there's an explicit step\nwhere I've checked to seeif that first path\nis a winner.", "start": 840.0, "heat": 0.1}, {"text": "If it's not, I extend it.And I have to put those\npaths onto the queue.So, I'll say that what\nI do is I end queue.Now, I've done one step.And let's let me do\nanother step.I'm going to take this\nfirst path off.I'm going to extend that path.And where do I put these new\npaths on the queue if I'mdoing Depth-first Search?Well, I want to work with the\npath that I've just generated.I'm taking this plunge down\ndeep into the search tree.So, since I want to keep going\ndown into the stuff that Ijust generated, where then do I\nwant to put these two paths?At the end of the queue?I don't think so, because\nit'll be a longtime getting there.I want to put them on the\nfront of the queue.For Depth-first Search, I\nwant to put them on thefront of the queue.And that's why s, a, b goes\nhere, and s, a, d, and thenthat's s, b.So, s, b is still there.That's still a valid\npossibility.But now I've stuck two paths\nin front of it, both of theones I generated by taking a\npath off the front of thequeue, discovering that it\ndoesn't go to the goal,extending it and putting those\nback on the queue.I might as well complete\nthis illustration here.While I'm at it, I take the s,\na, b off, s, a, b, and I cango only there to c.But, of course, I keep s, a,\nd and s, b on the queue.", "start": 960.0, "heat": 0.1}, {"text": "Now, I take the front off the\nqueue again, and I get s, a,b, c, e, and not to forget\ns, a, d and s, b.I take the first one\noff the queue.It doesn't go to the goal.I try to extend it, but\nthere's nothing there.I've reached a dead end.So, in this operation, all I'm\ndoing is taking the front oneoff the queue and shortening\nthe queue.We're almost home.I take s, a,d off of queue.And I get s, a, d, c.And, of course, I\nstill have s, b.Now, the next time I visit the\nsituation, buried in thatfirst step, I discover a path\nthat actually does get togoal, and I'm done.So, each time around I\nvisualize the queue.I check to see if I'm done.If not, I take the extensions\nand put themsomewhere on the queue.And then I go back in.And then here there's a varied\ntest which checks to see ifwe're done.That's how the Depth-first\nSearch algorithm works.And now, would we have to start\nall over again if we didBreadth-first Search?Nope.Same algorithm.All the code we've got\nneeds one linereplaced, one line changed.What do I have to do different\nin order to get aBreadth-first Search out\nof this instead ofa Depth-first Search?Tanya?TANYA: Change [INAUDIBLE]\non the queue.PATRICK WINSTON: And where\ndo I put it on the queue?She says to change it.TANYA: On the back?PATRICK WINSTON: Put\nit on the back.", "start": 1080.0, "heat": 0.102}, {"text": "So, with Breadth-first Search\nall I have to dois put on the back.Now, if we were content with a\ninefficient search, and didn'tcare much about how good our\npath was, we'd be done.And we could go home.But we are a little concerned\nabout theefficiency of our search.And we would like a\npretty good path.So, we're going to have\nto stick aroundfor a little while.Now, you may have noticed, up\nthere in that the developmentof the Breadth-first Search,\nthat the algorithm isincredibly stupid.Why is the algorithm\nincredibly stupid?Ty, what do you think?TY: It can't tell whether it's\ngetting closer or further awayfrom the goal.PATRICK WINSTON: It certainly\ncan't tell whether it'sgetting closer or further\naway from the goal.And we're going to deal\nwith that in a minute.But it's even stupider\nthan that.Why is it stupid?What's your name?DYLAN: Dylan.It [? hits ?] the same\nnodes twice.PATRICK WINSTON: Dylan said it's\nextending paths that goto the same node\nmore than once.Let's see what Dylan's\ntalking about.Down here, it extends a.But it's already extended\na up there.Down here, it extends a\npath that goes to b.And it's already extended\na path that goes to d.Over here, it could extend a\npath that went through c, but", "start": 1200.0, "heat": 0.113}, {"text": "it's already got a path\nthat goes through c.So, all of these paths\nare duplicated.And we're still going\nthrough them.That's incredibly stupid.What we're going to do is\nwe're going to amend ouralgorithm just a little bit.And we're not going to extend\nthe first path on the queueunless final node never\nbefore extended.What we're going to do is we're\ngoing to look to see ifthere-- we've got this path.And we're going to extend it.And it's got a final note.If we've ever extended a path\nthat goes to that final node,and it was a final node on\nthat path, then we're notgoing to do it again.We got to keep a list of places\nthat have already beenthe last piece of a path\nthat was extended.Everybody got that?It's a little awkward to say it,\nbecause it's the last nodewe care about.If a path terminates in a node,\nand if some other pathpreviously terminated in that\nnode and got extended--we're not going to\ndo it again.Because it's a waste of time.Now, let's see if this\nactually helps.Now, use the extended list.Let's see, well, gee,\nwe got that place", "start": 1320.0, "heat": 0.104}, {"text": "in the center there.Let's just repeat the\nprevious search.Wow, it's taking a long time.But notice it put 103 paths\nback on the queue.Now, let's add a filter\nand try again.A lot less.So, let's speed this up, and\nwe'll start way over here.You remember how tedious\nthat search was.And now we'll repeat it with\nthis list, boom, there it is.That's all because we didn't do\nthat silly thing of goingback through the final\nnode that'salready been gone through.So, you would never not\nwant to do this.We better list this\nas another option.It doesn't help with a British\nMuseum algorithm, becausenothing helps with the British\nMuseum algorithm.Does it help with Depth-first?Yes.Does it help with\nBreadth-first?Yes.Do we do backtracking\nwith Breadth-first?No, because backtracking\ncan't do us any good.OK, we're almost, except that\nsearch that's starting in themiddle is still pretty stupid.Both the Breadth-first version\nand the Depth-first versionare going off to the left.And we would never do that with\nour eyes in any case.The next thing we want to do is\nwe want to have ourselves a", "start": 1440.0, "heat": 0.1}, {"text": "slightly more informed search\nby taking into considerationwhether we seem to be\ngetting anywhere.So, in general, it's a good\nthing to get closer to wherewe want to go.In general, if we've got a\nchoice of going to a nodethat's close to the goal or a\nnode that's not so close tothe goal, we'll always want\nto go to the one that'sclose to the goal.And as soon as we add that to\nwhat we're doing, we haveanother kind of Search,\nwhich goes by thename of Hill Climbing.And it's just like Depth-first\nSearch, except instead ofusing lexical order to break\nties, we're going to breakties according to which node\nis closer to the goal.I went to some trouble\nto talk to you aboutthis enqueued list.And having gone to that\ntrouble, I'm nowgoing to ignore it.Not because it isn't a good\nidea, but because trying tokeep track of everything\nin the example isconfusing the example.It won't work out right in the\nsmall example and all that.Put the queueing thing aside,\nqueued list aside, and thinkinstead just about the value\nof going in the directionthat's getting us closer\nto the goal.In Hill Climbing Search, just\nlike a Depth-first Search, wehave a and b.And we're still going to list\nthem lexically on underneaththe parent node.But now which one is so\ncloser to the goal?Now, this time b is closer\nto the goal than a.So, instead of following the\nDepth-first course, whichwould take us down through a,\nwe're going to go to the one", "start": 1560.0, "heat": 0.1}, {"text": "that's closest which\ngoes through b.And b can either go to a or c.b is six units away from the\ngoal. a is about seven plus,not drawn exactly to scale.Use the numbers not your eyes.Now where are we?It's symmetric, so a and\nc are both equallyfar from the goal.Now we're going to use\nthe lexical orderto break the tie.Now from s, b, a,\nwe'll go to d.And now, which is closest\nto the goal?That's the only choice\nwe have.So, now we have no choice but\nto go down to the goal.That's the Hill Climbing way\nof doing the search.And notice that this time\nthere's no backtracking.It's not the optimal path.It's not the best path.But at least there's\nno backtracking.That's not always true.That's just an artifact of\nthis particular example.Do you think Hill Climbing would\nproduce a faster search?I think so.Let's see what happens\nwhen we add thesethings at one at a time.First, let's turn off\nour extended list.We turned off our\nextended list.And we're going to do\nDepth-first again just for thesake of comparison.It produces a very roundabout\npath with 48 enqueueings.Now, let's switch over\nto Hill Climbing.And what do think?Do you think it will produce\na straighter path, fewerenqueueings?Boom.You wouldn't not want to\ndo that, would you?If you've got some kind of\nheuristic that tells you thatyou're getting close to the\ngoal, you should use it.Now, it's easy to modify my\nexample over there so that", "start": 1680.0, "heat": 0.106}, {"text": "getting close to the goal\ngets you trapped in ablind alley on e.That's easy to do.But that's just an artifact\nof the example.In general, you want to go along\na path that gets youcloser to the goal.So, that's 23.I don't know, let's see if using\nthe extended list filterdoes any good.Yeah, still 23.So, in that particular case\nthe extension list didn'tactually do us any good, because\nwe're driving sodirectly toward the goal.OK, that's that.Now, let's see, is there\nany analog to--well, we might say that this\nis yet another way ofdistinguishing the searches.And that is, is it an\ninformed search?Is it making use of any kind\nof heuristic information?Certainly, a British Museum\nis not, Depth isnot, Breadth is not.And now let's consider what\nwe got for Hill Climbing.Do we want to use\nbacktracking?Sure.Do we want to use an\nenqueued list?Sure.And it is informed, because it's\ntaking advantage of thisextra information.It may not be in your problem.It's not often the case you've\ngot this information in a map.Your problem may not have any\nheuristic measurement ofdistance to the goal.In which case, you\ncan't do it.But if you've got it,\nyou should use it.Oh, yeah, there's one more.And I've already given it away\nby having it on my chart.It's called Beam Search.And just as Hill Climbing is\nan analog of Depth-firstSearch, Beam Search is a\ncomplement or addition of aninforming heuristic to\nBreadth-first Search.What you do is you start\noff just likeBreadth-first Search.", "start": 1800.0, "heat": 0.119}, {"text": "But you say I'm going to limit\nthe number of paths I'm goingto consider at any level to\nsome small, fixed number,like, in this case,\nhow about two.So, I'm going to say that\nI have a Beam oftwo for my Beam Search.Otherwise, I proceed just\nlike Breadth-firstSearch, b, d, a, g.And now I've got that stupid\nthing where I'm duplicating mynodes, because I'm forgetting\nabout the enqueued list.But to illustrate Beam Search,\nwhat about I'm going to do nowis I'm going to take all these\npaths I've got at the secondlevel, and I'm only going\nto keep the best two.That's my beam width.And the best two are the two\nthat get closest to the goal.So, those four, b, c, a,\nand d, which two getclosest to the goal?Now, b and d.These guys are trimmed off.I'm only keeping two\nat every level.Now, going down from b and\nd, I have, at the nextlevel, c and g.And now I've found the goal.So, I'm done.We could do that here, too.We could choose a Beam\nSearch, not bad.Let's see, let's try this\nthing from the middle.Let's slow my speed\ndown a little bit.Now, are we going to see\nanything going off to the leftlike we did with ordinary\nBreadth-first Search?No, because it's smart.It doesn't say, I want to go to\na place that's further awayfrom my goal.Now, let's see, maybe we can go\nback to our algorithm nowand talk about that enqueueing\nmechanism and", "start": 1920.0, "heat": 0.139}, {"text": "talk about Hill Climbing.Can I use the same basic search\nmechanism, just changethat one line again?Yes.How do I add new paths to\nthe queue this time?Well, it's very much like\nHill Climbing, right?I want to add them\nto the front butwith one little flourish.What's the flourish?[? Krishna, ?] what\ndo you think?Remember, I want to use my\nheuristic information.So, I not only add them to the\nfront, but amongst the onesI'm adding to the front,\nwhat do I do?AUDIENCE:Check the distance?PATRICK WINSTON: Check\nthe distance.And how do you arrange them?AUDIENCE:[? You ?][? keep the ?] minimum\n[? first. ?]PATRICK WINSTON: Yeah, you\ncan put the minimumfirst if you like.But let's sort them.We'll sort them, that will\nkeep everything straight.So Hill Climbing is\nfront-sorted.And, finally, how about Beam?What do we do with Beam Search\nto add them to the queue?Well, it doesn't matter where we\nadd them, because all we'regoing to do is we're going\nto keep the w best.So, with Beam, we'll just\nabbreviate that bysaying keep w best.Now, you have some of the basicsearches in you're toolkit.There's one more that's\nsometimes talked about.We've got Depth, Breadth, Best,\nand Beam, one more isBest, Best-first Search.It's a variant where you say,\nI've got this tree.", "start": 2040.0, "heat": 0.174}, {"text": "It's got a bunch of paths that\nterminate in leaves.Let me just always work on\nthe leaf node that'sclosest to the goal.It can skip around a little bit\nfrom one place to another.Because as it pursues one path,\nit may not do very wellin some other path\nquite distant.And the tree will become\nthe best one.We've actually seen an instance\nof that in thenintegration program.It's capable of skipping all\nover the place, because it'salways taking the easiest\nproblem in the search tree, inthe and/or tree, working\non that.That's Best-first Search.You can do these sorts\nof things incontinuous spaces, too.And you've done the\nmathematics ofthat in 1802 or something.But in continuous spaces, the\nHill Climbing sometimes leadsto problems or doesn't\ndo very well.What kind of a problem can you\nencounter in a continuousspace with Hill Climbing?Well, how would you do\nHill Climbing ina continuous space?Let's say we're in the\nmountains, and a bigfog has come up.We're trying to get to the\ntop of the hill beforewe freeze to death.And we take a few steps north,\na few steps east, west, andsouth using our compass.And we check to see which\ndirection seems to be doingthe best job of getting\nus moving upward.And that's our Hill Climbing\napproach, right?We have explored four directions\nwe can go and pickthe best one.And from there, we pick four,\ntry all those, pick the bestone, and away we go.We've got ourselves a Hill\nClimbing algorithm.What's wrong with it?Or what can be wrong with it?Sometimes it works just fine.Yes.SPEAKER 1: You might get stuck\nin a local maximum.PATRICK WINSTON: We might get\nstuck in a local maximum.", "start": 2160.0, "heat": 0.209}, {"text": "So, problem letter a is that if\nthis is your space, it maylook like that.And you may get stuck\non a local maximum.Is there any other kind of\nproblem that can come up?Well, it all depends on what\nthe space is like.Here's a problem where the\nspace has local maxima.Now, a lot of people have\nbeen killed on Mt.Washington when the\nfog comes up.And they do freeze\nto death, why?The reason they freeze to death\nis the Hill Climbingfails them, and they can't\nget to the topto the ranger station.And the reason is that there\nare large lawns on theshoulders of Mt.Washington.It's quite flat.So, it's the telephone\npole problem.That space looks like this.Well, this isn't what Mt.Washington looks like.But it's the telephone\npole problem.So, when you're wandering\naround here, the idea oftrying a few directions and\npicking the one that's bestdoesn't help any, because\nit's flat.That can be a problem\nwith Hill Climbing.Now, there's one more problem\nwith Hill Climbing that mostpeople don't know about.But it works like this.This is a particularly\nacute problem inhigh dimensional spaces.I'll illustrate it\nhere just in two.And I'm going to switch from\na regular kind of view to acontour map.So, my contour map is going to\nbetray the presence of a sharpbridge along the\n45 degree line.", "start": 2280.0, "heat": 0.194}, {"text": "Now you see how you can\nget in trouble there.You get in trouble, because\nif you take a step in eachdirection, every direction\ntakes you downhill.And you think you're\nat the top.So, suppose you're right\nhere and you go north.That takes you down over\na contour line.If you go south, that\nalso takes you downover contour lines.Likewise, going west and east\nall appear to be taking youdown, whereas, in fact, you're\nclimbing a ridge.And that contour line is the\nhighest that I've shown.So, sometimes you\ncan get fooled--not stuck, but fooled-- into\nthinking you're at the topwhen you're actually not.Now, this is a model\nsomething.This subject is about modeling\nintelligence.And this is a kind of algorithm\nyou frequently needin order to build an\nintelligent system.But do we have any kind of\nSearch happening in our heads?If we're going to model what\ngoes on inside our heads, dowe have to model any kind of\nsearching in order to do thekinds of things that\nwe humans do?I suppose so.Anytime we make a plan, we're\nactually evaluating a bunch ofchoices and seeing\nhow they work.Let me see if I can illustrate\nit another way.This is a system that I showed\nyou a little bit of last time.And, shoot, I might as well\nreview one or two things here.I showed you a Macbeth story.This is the story\nI showed you.And if you had this in a\nhumanities class, the simplestquestions that might be asked\nis why did Macduff kill", "start": 2400.0, "heat": 0.211}, {"text": "Macbeth down there\nat the bottom?Did I demonstrate the answering\nof questions lasttime, or just the development\nof the graph?I can't remember.But we'll do it again, anyway.This is somewhat stylized\nEnglish.Just so you'll know,\nit doesn't haveto be stylized English.This is English that's made\navailable to the Genesissystem by way of something\ncalled Story Workbench.There's no free lunch.Either you can use your human\nresources to rewrite the plotin third grade English.Or you can use your human\nresources to take a morenatural, adult-type version of\nthe story and decorate it withannotations that make it\npossible to absorb it.Just this summer, in a miracle\nof summer [? Europe, ?][? Brit ?][? van ?][? Zijp-- ?]one of you--connected these two\nsystems together.So, we can now work with stories\nthat are expressed inpretty natural English.Everything in our system is\nexpressed in English,including common sense\nknowledge--like if somebody kills\nyou, you're dead--but more importantly, for\ntoday's illustration, thatreflective level knowledge,\nthat knowledge about whatrevenge is.Here you are.You're in the humanities class,\nand someone says,what's really going\non in the story?Not the details of who\nkills whom, but isthere a Pyrrhic victory?Does somebody have a success?Is there an act of revenge?These are all kinds of things\nyou might be asked about insome kind of humanities class.So, let me fire up the\ngenesis system.Pray for internet\nconnectivity.Launch the system on a read of\nthat Macbeth story that I", "start": 2520.0, "heat": 1.0}, {"text": "showed you just a moment ago.At the moment, it's absorbing\ninformation about backgroundknowledge, and about reflective\nlevel knowledge,and all that sort of thing.It's building itself\nthis thing we callan elaboration graph.It's not quite there yet.It's still reading background\nknowledge.Now it's reading Macbeth.It's building it's elaboration\ngraph, the same thing you sawlast time, except not quite.Do you see that stuff\ndown at the bottom?Those are higher level concepts\nthat it's managed tofind in the Macbeth story.So, its found a revenge.How did it do that?It searched.It had a description of what a\nrevenge is, and it looked tosee if that pattern\nwas exhibited inthe elaboration graph.So, in a combination of things\nthat were said explicitly andthings that were produced by\nknee-jerk if/then rules, theelaboration graph was\nsufficiently instantiated thatthe revenge pattern\ncould be found.That's interesting, Pyrrhic\nvictory is a little harder.You'd probably get an a if you\nsaid, oh, there's a Pyrrhicvictory in here.There it is.So, I'll blow that up a\nlittle bit so you cansee what that is.You know what a Pyrrhic\nvictory is.It's a situation where\neverything seems to be goinggood at first, and\nthen not so hot.So, Macbeth wants to\nbe King down here.And eventually that leads\nto becoming King.But too bad for Macbeth, because\neventually he getskilled in consequence.So, it's a Pyrrhic victory.All that produced by Search\nprograms who are lookingthrough this graph.Now once you've got the\ncapability of doing that, of", "start": 2640.0, "heat": 0.125}, {"text": "course, then you can find\nall sorts of things.And you can report\nthem in English.But, more interestingly, you\ncan answer questions.Why did Macbeth--it cares not a hoot about\ncapitalization.ARTIFICIAL INTELLIGENCE: On a\ncommon sense level, it lookslike Dr. Jekyll thinks Macduff\nkilled Macbeth because Macbethangered Macduff on a\nreflective level.It looks like Dr. Jekyll thinks\nMacduff killed Macbethas part of acts of mistake,\nPyrrhic victory, and revenge.PATRICK WINSTON: Pretty\ncorny speech output.But you see the point.How did it get the stuff on\nthe common sense level?The same way all those programs\nthat build goal treesreport, answers the questions.It's just looking locally around\nin the connections inthe goal tree.How did it get the stuff on\nthe reflective level?By reporting on the searches\nthat produced information--it does that by looking for\nhigher level thoughts aboutits own thoughts and reporting\nin which of those higher levelthoughts the incident we asked\nabout actually occurs.So, let's see, just for fun, we\nmight be interested in whyMacbeth murdered Duncan.Wouldn't this be handy if you\nhadn't actually read the play,and here it is, you've got\nto write that paper?ARTIFICIAL INTELLIGENCE:\nOn a common senselevel, it looks like--PATRICK WINSTON: I'll pull the\nplug on that, because that'sjust annoying.Yeah, pretty good, Macbeth wants\nto be King, and Duncanis the King.Let's see, why did Macbeth\nbecome King?Oh, it won't answer\nthe questionunless I spell it right.", "start": 2760.0, "heat": 0.145}, {"text": "I wouldn't be able to show that\nto you until last spring.In fact, I wouldn't have been\nable to show you this todayuntil last week with a\ntweak this morning.Because we've just now connected\nthe language outputto, of course, [? Cass's ?]parser system, which is running\nin reverse, in orderto generate that English.So, that's something that has\nnever before been seen by anyeyes but me.So, that will conclude what\nwe have to do today.", "start": 2880.0, "heat": 0.203}]