[{"text": "The following content is\nprovided under a CreativeCommons license.Your support will help\nMIT OpenCourseWarecontinue to offer high quality\neducational resources for free.To make a donation or to\nview additional materialsfrom hundreds of\nMIT courses, visitMITOpenCourseWare@OCW.MIT.eduPHILIPPE RIGOLLET: So today\nWE'LL actually just do a briefchapter on Bayesian statistics.And there's entire courses\non Bayesian statistics,there's entire books\non Bayesian statistics,there's entire careers\nin Bayesian statistics.So admittedly, I'm\nnot going to beable to do it\njustice and tell youall the interesting\nthings that are happeningin Bayesian statistics.But I think it's important\nas a statisticianto know what it\nis, how it works,because it's actually\na weapon of choicefor many practitioners.And because it allows them to\nincorporate their knowledgeabout a problem in a\nfairly systematic manner.So if you look at like, say the\nBayesian statistics literature,it's huge.And so here I give\nyou sort of a rangeof what you can expect to\nsee in Bayesian statisticsfrom your second edition of\na traditional book, somethingthat involves computation,\nsome things thatinvolve risk thinking.And there's a lot of\nBayesian thinking.There's a lot of\nthings that you knowtalking about sort of like\nphilosophy of thinkingBayesian.This book, for example,\nseems to be one of them.This book is\ndefinitely one of them.This one represents sort of\na wide, a broad literatureon Bayesian statistics, for\napplications for example,in social sciences.But even in large\nscale machine learning,there's a lot of Bayesian\nstatistics happening,particular using something\ncalled Bayesian parametrics,or hierarchical\nBayesian modeling.So we do have some experts\nat MIT in the c-cell.Tamara Broderick for\nexample, is a person", "start": 0.0, "heat": 0.1}, {"text": "who does quite a bit\nof interesting workon Bayesian parametrics.And if that's something you\nwant to know more about,I urge you to go\nand talk to her.So before we go into\nmore advanced things,we need to start with what\nis the Bayesian approach.What do Bayesians\ndo, and how is itdifferent from what\nwe've been doing so far?So to understand the\ndifference between Bayesiansand what we've been\ndoing so far is,we need to first put a name on\nwhat we've been doing so far.It's called\nfrequentist statistics.Which usually Bayesian versus\nfrequentist statistics,by versus I don't mean\nthat there is naturallyin opposition to them.Actually, often you will\nsee the same method thatcomes out of both approaches.So let's see how\nwe did it, right.The first thing, we had data.We observed some data.And we assumed that this\ndata was generated randomly.The reason we did\nthat is because thiswould allow us to leverage\ntools from probability.So let's say by nature,\nmeasurements, you do a survey,you get some data.Then we made some assumptions\non the data generating process.For example, we\nassumed they were iid.That was one of the\nrecurring things.Sometimes we assume\nit was Gaussian.If you wanted to\nuse say, T-test.Maybe we did some\nnonparametric statistics.We assume it was a\nsmooth function or maybelinear regression function.So those are our modeling.And this was basically\na way to say, well,we're not going to allow for\nany distributions for the datathat we have.But maybe a small\nset of distributionsthat indexed by some small\nparameters, for example.Or at least remove some\nof the possibilities.Otherwise, there's\nnothing we can learn.And so for example,\nthis was associatedto some parameter of\ninterest, say data or betain the regression model.Then we had this unknown\nproblem and this unknown thing,a known parameter.And we wanted to find it.We wanted to either\nestimate it or test it,or maybe find a confidence\ninterval for the subject.", "start": 120.0, "heat": 0.245}, {"text": "So, so far I should not have\nsaid anything that's new.But this last\nsentence is actuallywhat's going to be different\nfrom the Bayesian part.And particular, this\nunknown but fixed thingsis what's going to be changing.In the Bayesian\napproach, we stillassume that we observe\nsome random data.But the generating process\nis slightly different.It's sort of a\ntwo later process.And there's one\nprocess that generatesthe parameter and\nthen one processthat, given this parameter\ngenerates the data.So what the first layer\ndoes, nobody reallybelieves that there's\nsome random process that'shappening, about\ngenerating what is goingto be the true expected\nnumber of peoplewho turn their head to\nthe right when they kiss.But this is actually going to\nbe something that brings ussome easiness for\nus to incorporatewhat we call prior belief.We'll see an\nexample in a second.But often, you actually\nhave prior beliefof what this\nparameter should be.When we, say least\nsquares, we lookedover all of the vectors\nin all of R to the p,including the ones that\nhave coefficients equalto 50 million.Those are things that we\nmight be able to rule out.We might be able to rule out\nthat on a much smaller scale.For example, well\nI'm not an experton turning your head to\nthe right or to the left.But maybe you can\nrule out the factthat almost everybody\nis turning their headin the same direction, or almost\neverybody is turning their headto another direction.So we have this prior belief.And this belief is going\nto play say, hopefullyless and less important role as\nwe collect more and more data.But if we have a\nsmaller amount of data,we might want to be able\nto use this information,rather than just\nshooting in the dark.And so the idea is to\nhave this prior belief.And then, we want to\nupdate this prior belief", "start": 240.0, "heat": 0.143}, {"text": "into what's called the\nposterior belief after we'veseen some data.Maybe I believe that\nthere's somethingthat should be in some range.But maybe after I see data, it's\ncomforting me in my beliefs.So I'm actually having\nmaybe a belief that's more.So belief encompasses\nbasically what you thinkand how strongly\nyou think about it.That's what I call belief.So for example, if I have a\nbelief about some parametertheta, maybe my\nbelief is telling mewhere theta should\nbe and how strongly Ibelieve in it, in the sense\nthat I have a very narrow regionwhere theta could be.The posterior beliefs, as\nwell, you see some data.And maybe you're more confident\nor less confident about whatyou've seen.Maybe you've shifted\nyour belief a little bit.And so that's what we're\ngoing to try to see,and how to do this in\na principal manner.To understand this\nbetter, there'snothing better than an example.So let's talk about another\nstupid statistical question.Which is, let's try\nto understand p.Of course, I'm not going to\ntalk about politics from now on.So let's talk about p,\nthe proportion of womenin the population.And so what I could do is\nto collect some data, X1, Xnand assume that\nthey're Bernoulliwith some parameter, p unknown.So p is in 0, 1.OK, let's assume that\nthose guys are iid.So this is just an indicator\nfor each of my collected data,whether the person I randomly\nsample is a woman, I get a one.If it's a man, I get a zero.Now the question is, I\nsample these people randomly.I do you know their gender.And the frequentist\napproach was just saying,OK, let's just estimate\np hat being Xn bar.And then we could do some tests.", "start": 360.0, "heat": 0.365}, {"text": "So here, there's a test.I want to test maybe if\np is equal to 0.5 or not.That sounds like a pretty\nreasonable thing to test.But we want to also\nmaybe estimate p.But here, this is a case where\nwe definitely prior beliefof what p should be.We are pretty confident that\np is not going to be 0.7.We actually believe\nthat we shouldbe extremely close to one\nhalf, but maybe not exactly.Maybe this population is not\nthe population in the world.But maybe this is the\npopulation of, say some collegeand we want to understand if\nthis college has half womenor not.Maybe we know it's going\nto be close to one half,but maybe we're not quite sure.We're going to want to\nintegrate that knowledge.So I could integrate it in\na blunt manner by saying,discard the data and say\nthat p is equal to one half.But maybe that's just\na little too much.So how do I do this trade\noff between adding the dataand combining it with\nthis prior knowledge?In many instances, essentially\nwhat's going to happenis this one half is going to\nact like one new observation.So if you have\nfive observations,this is just the\nsixth observation,which will play a role.If you have a\nmillion observations,you're going to have\na million and one.It's not going to play\nso much of a role.That's basically how it goes.But, definitely not\nalways because we'llsee that if I take my prior to\nbe a point minus one half here,it's basically as if I\nwas discarding my data.So essentially, there's\nalso your abilityto encompass how strongly\nyou believe in this prior.And if you believe\ninfinitely more in the priorthan you believe in\nthe data you collected,then it's not going to act\nlike one more observation.The Bayesian approach\nis a tool to one,include mathematically\nour prior.And our prior belief into\nstatistical procedures.", "start": 480.0, "heat": 0.431}, {"text": "Maybe I have this\nprior knowledge.But if I'm a medical\ndoctor, it's not clear to mehow I'm going to turn this into\nsome principal way of buildingestimators.And the second\ngoal is going to beto update this prior belief\ninto a posterior beliefby using the data.How do I do this?And at some point,\nI sort of suggestedthat there's two layers.One is where you draw\nthe parameter at random.And two, once you\nhave the parameter,conditionless parameter,\nyou draw your data.Nobody believed this actually is\nhappening, that nature is justrolling dice for us and\nchoosing parameters at random.But what's happening\nis that, this ideathat the parameter comes\nfrom some random distributionactually captures, very\nwell, this idea that howyou would encompass your prior.How would you say, my\nbelief is as follows?Well here's an example about p.I'm 90% sure that p is\nbetween 0.4 and 0.6.And I'm 95% sure that p\nis between 0.3 and 0.8.So essentially, I have\nthis possible value of p.And what I know is that, there's\n90% here between 0.4 and 0.6.And then I have 0.3 and 0.8.And I know that I'm 95%\nsure that I'm in here.If you remember, this sort of\nlooks like the kind of picturesthat I made when I had\nsome Gaussian, for example.And I said, oh here we have\n90% of the observations.And here, we have 95%\nof the observations.", "start": 600.0, "heat": 0.782}, {"text": "So in a way, if I\nwere able to tell youall those ranges for\nall possible values,then I would essentially\ndescribe a probabilitydistribution for p.And what I'm saying\nis that, p is goingto have this kind of shape.So of course, if I tell you\nonly two twice this informationthat there's 90% I'm here,\nand I'm between here and here.And 95%, I'm between here\nand here, then there'smany ways I can\naccomplish that, right.I could have something that\nlooks like this, maybe.It could be like this.There's many ways\nI can have this.Some of them are\ndefinitely goingto be mathematically more\nconvenient than others.And hopefully, we're\ngoing to have thingsthat I can\nparameterize very well.Because if I tell\nyou this is this guy,then there's basically one,\ntwo three, four, five, six,seven parameters.So I probably don't\nwant somethingthat has seven parameters.But maybe I can say, oh,\nit's a Gaussian and I allI have to do is to tell\nyou where it's centeredand what the standard\ndeviation is.So the idea of using\nthis two layer thing,where we think of\nthe parameter pas being drawn from\nsome distribution,is really just a way for us\nto capture this information.Our prior belief\nbeing, well there'sthis percentage of\nchances that it's there.But the percentage of\nthis chance, I'm not I'mdeliberately not using\nprobability here.So it's really a way\nto get close to this.That's why I say, the true\nparameter is not random.But the Bayesian approach\ndoes as if it was random.And then, just spits\nout a procedureout of this thought process,\nthis thought experiment.So when you practice\nBayesian statistics a lot,you start getting automatisms.You start getting some things\nthat you do without really", "start": 720.0, "heat": 0.195}, {"text": "thinking about\nit. just like whenyou you're a statistician,\nthe first thing you do is,can I think of this data as\nbeing Gaussian for example?When you're Bayesian\nyou're thinking about,OK I have a set of parameters.So here, I can\ndescribe my parameteras being theta in\ngeneral, in some big spaceparameter of theta.But what spaces\ndid we encounter?Well, we encountered\nthe real line.We encountered the interval\n0, 1 for Bernoulli's And weencountered some of\nthe positive real linefor exponential\ndistributions, etc.And so what I'm\ngoing to need to do,if I want to put some\nprior on those spaces,I'm going to have to\nhave a usual set of toolsfor this guy, usual set\nof tools for this guy,usual sort of\ntools for this guy.And by usual set\nof tools, I meanI'm going to have to have a\nfamily of distributions that'ssupported on this.So in particular,\nthis is the speedin which my parameter\nthat I usually denoteby p for Bernoulli lives.And so what I need is to find a\ndistribution on the interval 0,1 just like this guy.The problem with the\nGaussian is that it'snot on the interval 0, 1.It's going to spill\nout in the end.And it's not going to be\nsomething that works for me.And so the question is, I need\nto think about distributionsthat are probably continuous.Why would I restrict myself\nto discrete distributions thatare actually convenient and for\nBernoulli, one that's actuallybasically the main tool\nthat everybody is usingis the so-called\nbeta distribution.So the beta distribution\nhas two parameters.So x follows a beta\nwith parametersa and b if it has\na density, f of x", "start": 840.0, "heat": 0.167}, {"text": "is equal to x to the a minus 1.1 minus x to the b minus 1,\nif x is in the interval 0,1 and 0 for all other x's.OK?Why is that a good thing?Well, it's a density that's\non the interval 0, 1 for sure.But now I have these two\nparameters and a set of shapesthat I can get by tweaking those\ntwo parameters is incredible.It's going to be a\nunimodal distribution.It's still fairly nice.It's not going to be something\nthat goes like this and this.Because if you think\nabout this, whatwould it mean if your prior\ndistribution of the interval 0,1 had this shape?It would mean that, maybe\nyou think that p is hereor maybe you think\nthat p is here,or maybe you think\nthat p is here.Which essentially\nmeans that you thinkthat p can come from\nthree different phenomena.And there's other models\nthat are called mixersfor that, that directly\naccount for the factthat maybe there are several\nphenomena that are aggregatedin your data set.But if you think that your\ndata set is sort of pure,and that everything comes\nfrom the same phenomenon,you want something\nthat looks like this,or maybe looks like this, or\nmaybe is sort of symmetric.You want to get all this stuff.Maybe you want something\nthat says, wellif I'm talking about p being the\nprobability of the proportionof women in the whole world, you\nwant something that's probablyreally spiked around one half.Almost the point\nmath, because you knowlet's agree that 0.5\nis the actual number.So you want something that\nsays, OK maybe I'm wrong.But I'm sure I'm not going\nto be really that way off.", "start": 960.0, "heat": 0.111}, {"text": "So you want something\nthat's really pointy.But if it's something\nyou've never checked,and again I can not make\nreferences at this point,but something where you might\nhave some uncertainty thatshould be around one half.Maybe you want something\nthat a little more allowsyou to say, well, I think\nthere's more around one half.But there's still some\nfluctuations that are possible.And in particular\nhere, I talk about p,where the two parameters a\nand b are actually the same.I call them a.One is called scale.The other one is called shape.Oh sorry, this is not a density.So it actually has\nto be normalized.When you integrate\nthis guy, it'sgoing to be some function\nthat depends on aand b, actually depends\non this functionthrough the beta function.Which is this combination\nof gamma function,so that's why it's\ncalled beta distribution.That's the definition of\nthe beta function when youintegrate this thing anyway.You just have to normalize it.That's just a number that\ndepends on the a and b.So here, if you\ntake a equal to b,you have something\nthat essentiallyis symmetric around one half.Because what does it look like?Well, so my density f of\nx, is going to be what?It's going to be my constant\ntimes x, times one minus xto a minus one.And this function, x times\n1 minus x looks like this.We've drawn it before.That was something\nthat showed upas being the variance\nof my Bernoulli.So we know it's something that\ntakes its maximum at one half.And now I'm just taking\na power of this guy.So I'm really just\ndistorting this thinginto some fairly\nsymmetric manner.This distribution that\nwe actually take for p.", "start": 1080.0, "heat": 0.307}, {"text": "I assume that p, the\nparameter, noticethat this is kind of weird.First of all, this is\nprobably the first timein this entire\ncourse that somethinghas a distribution when it's\nactually a lower case letter.That's something you\nhave to deal with,because we've been using lower\ncase letters for parameters.And now we want them\nto have a distribution.So that's what's\ngoing to happen.This is called the\nprior distribution.So really, I should write\nsomething like f of pis equal to a constant times\np, 1 minus p, to the n minus 1.Well no, actually I should not\nbecause then it's confusing.One thing in terms\nof notation that I'mgoing to write, when\nI have a constant hereand I don't want to\nmake it explicit.And we'll see in a second why I\ndon't need to make it explicit.I'm going to write\nthis as f of xis proportional to x 1\nminus x to the n minus 1.That's just to say, equal to\nsome constant that does notdepend on x times this thing.So if we continue\nwith our experimentwhere I'm drawing\nthis data, X1 to Xn,which is Bernoulli p, if\np has some distributionit's not clear what it\nmeans to have a Bernoulliwith some random parameter.So what I'm going to do is, then\nI'm going to first draw my p.Let's say I get a number, 0.52.And then, I'm going to draw\nmy data conditionally on p.So here comes the first and\nlast flowchart of this class.So nature first draws p.p follows some data on a, a.Then I condition on p.", "start": 1200.0, "heat": 0.326}, {"text": "And then I draw X1, Xn\nthat are iid, Bernoulli p.Everybody understand the\nprocess of generating this data?So you first draw a\nparameter, and then you justflip those independent biased\ncoins with this particular p.There's this layered thing.Now conditionally p, right so\nhere I have this prior about pwhich was the thing.So this is just the\nthought process again,it's not anything that\nactually happens in practice.This is my way of thinking about\nhow the data was generated.And from this, I'm going to try\nto come up with some procedure.Just like, if your estimator\nis the average of the data,you don't have to\nunderstand probabilityto say that my estimator\nis the average of the data.Anyone outside this\nroom understandsthat the average\nis a good estimatorfor some average behavior.And they don't need\nto think of the dataas being a random\nvariable, et cetera.So same thing, basically.In this case, you can see that\nthe posterior distributionis still a beta.What it means is that,\nI had this thing.Then, I observed my data.And then, I continue\nand here I'mgoing to update my prior\ninto some posteriordistribution, pi.And here, this guy is\nactually also a beta.My posterior\ndistribution, p, is alsoa beta distribution\nwith the parametersthat are on this slide.And I'll have the space\nto reproduce them.So I start the beginning\nof this flowchartas having p, which is a prior.I'm going to get\nsome observationsand then, I'm going to\nupdate what my posterior is.", "start": 1320.0, "heat": 0.307}, {"text": "This posterior is\nbasically somethingthat's, in business\nstatistics wasbeautiful is as soon as\nyou have this distribution,it's essentially capturing all\nthe information about the datathat you want for p.And it's not just the point.It's not just an average.It's actually an\nentire distributionfor the possible\nvalues of theta.And it's not the same\nthing as saying, wellif theta hat is equal to Xn\nbar, in the Gaussian case I knowthat this is some mean, mu.And then maybe it has\nvarying sigma squared over n.That's not what I mean by, this\nis my posterior distribution.This is not what I mean.This is going to come from\nthis guy, the Gaussian thingand the central limit theorem.But what I mean is this guy.And this came exclusively\nfrom the prior distribution.If I had another prior,\nI would not necessarilyhave a beta distribution\non the output.So when I have the same\nfamily of distributionsat the beginning and at\nthe end of this flowchart,I say that beta is\na conjugate prior.Meaning I put in beta as a prior\nand I get beta as [INAUDIBLE]And that's why betas\nare so popular.Conjugate priors\nare really nice,because you know that whatever\nyou put in, what you're goingto get in the end is a beta.So all you have to think\nabout is the parameters.You don't have to check\nagain what the posterior isgoing to look like, what the\nPDF of this guy is going to be.You don't have to\nthink about it.You just have to check\nwhat the parameters are.And there's families\nof conjugate priors.Gaussian gives\nGaussian, for example.There's a bunch of them.And this is what drives people\ninto using specific priors asopposed to others.It has nice\nmathematical properties.", "start": 1440.0, "heat": 0.431}, {"text": "Nobody believes that p is really\ndistributed according to beta.But it's flexible enough\nand super convenientmathematically.Now let's see for one\nsecond, before we actuallygo any further.I didn't mention A and\nB are both in here,A and B are both\npositive numbers.They can be anything positive.So here what I did\nis that, I updated Ainto a plus the sum\nof my data, and binto b plus n minus\nthe sum of my data.So that's essentially, a becomes\na plus the number of ones.Well, that's only\nwhen I have a and a.So the first parameters become\nitself plus the number of ones.And the second\none becomes itselfplus the number of zeros.And so just as a sanity\ncheck, what does this mean?If a it goes to zero, what\nis the beta when a goes to 0?We can actually\nread this from here.Actually, let's take a goes to--no.Sorry, let's just do this.I'll do it when we talk\nabout non-informative prior,because it's a little too messy.How do we do this?How did I get this posterior\ndistribution, given the prior?How do I update This well this\nis called Bayesian statistics.And you've heard this\nword, Bayes before.And the way you've heard\nit is in the Bayes formula.", "start": 1560.0, "heat": 0.364}, {"text": "What was the Bayes formula?The Bayes formula\nwas telling youthat the probability of A, given\nB was equal to something thatdepended on the probability of\nB, given A. That's what it was.You can actually either\nremember the formulaor you can remember\nthe definition.And this is what p of A\nand B divided by p of B.So this is p of B, given A\ntimes p of A divided by p of B.That's what Bayes\nformula is telling you.Agree?So now what I want is to have\nsomething that's telling mehow this is going to work.What is going to play the\nrole of those events, A and B?Well one is going\nto be, this is goingto be the distribution\nof my parameter of theta,given that I see the data.And this is going\nto tell me, whatis the distribution of the\ndata, given that I know whatmy parameter if theta is.But that part, if\nthis is theta and thisis the parameter of\ntheta, this is whatwe've been doing all along.The distribution of the data,\ngiven the parameter herewas n iid Bernoulli p.I knew exactly what their joint\nprobability mass function is.Then, that was what?So we said that this\nis going to be my dataand this is going\nto be my parameter.So that means that, this is\nthe probability of my data,given the parameter.This is the probability\nof the parameter.What is this?What did we call this?This is the prior.It's just the distribution\nof my parameter.Now what is this?Well, this is just\nthe distributionof the data, itself.", "start": 1680.0, "heat": 0.138}, {"text": "This is essentially the\ndistribution of this,if this was indeed\nnot conditioned on p.So if I don't condition\non p, this datais going to be a bunch of iid,\nBernoulli with some parameter.But the perimeter\nis random, right.So for different realization\nof this data set,I'm going to get different\nparameters for the Bernoulli.And so that leads to\nsome sort of convolution.It's not really a\nconvolution in this case,but it's like some sort of\ncomposition of distributions.I have the randomness that\ncomes from here and then,the randomness that comes\nfrom realizing the Bernoulli.That's just the\nmarginal distribution.It actually might be painful to\nunderstand what this is, right.In a way, it's sort of a\nmixture and it's not super nice.But we'll see that this\nactually won't matter for us.This is going to be some number.It's going to be there.But it will matter\nfor us, what it is.Because it actually does\nnot depend on the parameter.And that's all\nthat matters to us.Let's put some names\non those things.This was very informal.So let's put some actual\nnames on what we call prior.So what is the formal\ndefinition of a prior,what is the formal\ndefinition of a posterior,and what are the\nrules to update it?So I'm going to have my data,\nwhich is going to be X1, Xn.Let's say they are iid, but\nthey don't actually have to.And so I'm going to\nhave given, theta.And when I say\ngiven, it's eithergiven like I did in the\nfirst part of this coursein all previous chapters,\nor conditionally on.If you're thinking like a\nBayesian, what I really meanis conditionally on\nthis random parameter.", "start": 1800.0, "heat": 0.1}, {"text": "It's as if it was\na fixed number.They're going to\nhave a distribution,X1, Xn is going to\nhave some distribution.Let's assume for now\nit's a PDF, pn of X1, Xn.I'm going to write\ntheta like this.So for example, what is this?Let's say this is a PDF.It could be a PMF.Everything I say, I'm going to\nthink of them as being PDF's.I'm going to combine\nPDF's with PDF's, but Icould combine PDF it PMF, PMF\nwith PDF's or PMF with PMF.So everywhere you see\na D could be an M.Now I have those things.So what does it mean?So here is an example.X1, Xn or iid, and theta 1.Now I know exactly what the\njoint PDF of this thing is.It means that pn of X1, Xn\ngiven theta is equal to what?Well it's 1 over\n2pi to the power ne, to the minus sum\nfrom i equal 1 to nof xi minus theta\nsquared divided by 2.So that's just the joint\ndistribution of n iidand theta 1, random variables.That's my pn given theta.Now this is what we denoted\nby f sub theta before.We had the subscript before, but\nnow we just put a bar in thetabecause we want to remember\nthat this is actuallyconditioned on theta.But this is just notation.You should just think of this\nas being, just the usual thingthat you get from some\nstatistical model.Now, that's going to be pn.", "start": 1920.0, "heat": 0.205}, {"text": "Theta has prior\ndistribution, pi.For example, so think of it\nas either PDF or PMF again.For example, pi\nof theta was what?Well it was some constant\ntimes theta to the a minus 1,1 minus theta to a minus 1.So it has some\nprior distribution,and that's another PMF.So now I'm given the\ndistribution of my,x is given theta and given\nthe distribution of my theta.I'm given this guy.That's this guy.I'm given that guy,\nwhich is my pi.So that's my pn of\nX1, Xn given theta.That's my pi of theta.Well, this is just\nthe integral of pnof X1, Xn times pi\nof theta, d theta,over all possible sets of theta.That's just when I\nintegrate out my theta,or I compute the\nmarginal distribution,I did this by integrating.That's just basic probability,\nconditional probabilities.Then if I had the\nPMF, I would justsum over the values of thetas.Now what I want is to\nfind what's called,so that's the\nprior distribution,and I want to find the\nposterior distribution.", "start": 2040.0, "heat": 0.415}, {"text": "It's pi of theta, given X1, Xn.If I use Bayes' rule\nI know that thisis pn of X1, Xn, given\ntheta times pi of theta.And then it's divided\nby the distributionof those guys, which I will\nwrite as integral over thetaof pn, X1, Xn, given theta\ntimes pi of theta, d theta.Everybody's with me, still?If you're not\ncomfortable with this,it means that you probably need\nto go read your couple of pageson conditional densities\nand conditionalPMF's from your probably class.There's really not much there.It's just a matter of being able\nto define those quantities, fdensity of x, given y.This is just what's called\na conditional density.You need to understand\nwhat this object isand how it relates to the\njoint distribution of x and y,or maybe the distribution of\nx or the distribution of y.But it's the same rules.One way to actually\nremember thisis, this is exactly\nthe same rules as this.When you see a bar, it's the\nsame thing as the probabilityof this and this guy.So for densities,\nit's just a commadivided by the second the\nprobably the second guy.That's it.So if you remember this, you can\njust do some pattern matchingand see what I just wrote here.Now, I can compute every\nsingle one of these guys.This something I get\nfrom my modeling.", "start": 2160.0, "heat": 0.323}, {"text": "So I did not write this.It's not written in the slides.But I give a name to this guy\nthat was my prior distribution.And that was my\nposterior distribution.In chapter three, maybe\nwhat did we call this guy?The one that does not have a\nname and that's in the box.What did we call it?AUDIENCE: [INAUDIBLE]PHILLIPE RIGOLLET: It is the\njoint distribution of the Xi's.And we gave it a name.AUDIENCE: [INAUDIBLE]PHILLIPE RIGOLLET: It's\nthe likelihood, right?This is exactly the likelihood.This was the\nlikelihood of theta.And this is something that's\nvery important to remember,and that really reminds you\nthat these things are really notthat different.Maximum likelihood estimation\nand Bayesian estimation,because your posterior is really\njust your likelihood timessomething that's just putting\nsome weights on the thetas,depending on where you\nthink theta should be.If I had, say a maximum\nlikelihood estimate,and my likelihood and\ntheta looked like this,but my prior and theta\nlooked like this.I said, oh I really want\nthetas that are like this.So what's going to\nhappen is that, I'mgoing to turn this into some\nposterior that looks like this.So I'm just really\nwaiting, this posterior,this is a constant that does\nnot depend on theta right?Agreed?I integrated over\ntheta, so theta is gone.So forget about this guy.I have basically, that the\nposterior distribution upto scaling, because it has to\nbe a probability density and not", "start": 2280.0, "heat": 0.32}, {"text": "just anything any\nfunction that's positive,is the product of this guy.It's a weighted version\nof my likelihood.That's all it is.I'm just weighing\nthe likelihood,using my prior belief on theta.And so given this guy\na natural estimator,if you follow the maximum\nlikelihood principle,would be the maximum\nof this posterior.Agreed?That would basically be doing\nexactly what maximum likelihoodestimation is telling you.So it turns out that you can.It's called Maximum\nA Posteriori,and I won't talk much\nabout this, or MAP.That's Maximum a Posteriori.So it's just the\ntheta hat is the arcmax of pi theta, given X1, Xn.And it sounds like it's OK.I'll give you a\ndensity and you say, OKI have a density for all\nvalues of my parameters.You're asking me to\nsummarize it into one number.I'm just going to take the most\nlikely number of those guys.But you could summarize\nit, otherwise.You could take the average.You could take the median.You could take a\nbunch of numbers.And the beauty of\nBayesian statisticsis that, you don't have to\ntake any number in particular.You have an entire\nposterior distribution.This is not only telling\nyou where theta is,but it's actually telling\nyou the differenceif you actually\ngive as somethingthat gives you the posterior.Now, let's say the theta\nis p between 0 and 1.If my posterior distribution\nlooks like this,or my posterior distribution\nlooks like this,then those two guys\nhave one, the same mode.This is the same value.And their symmetric, so they'll\nalso have the same mean.So these two posterior\ndistributionsgive me the same\nsummary into one number.However clearly, one\nis much more confidentthan the other one.So I might as well just\nspit it out as a solution.", "start": 2400.0, "heat": 0.342}, {"text": "You can do even better.People actually do things,\nsuch as drawing a random numberfrom this distribution.Say, this is my number.That's kind of\ndangerous, but youcan imagine you could do this.This is what works.That's what we went through.So here, as you notice I don't\ncare so much about this parthere.Because it does not\ndepend on theta.So I know that given the\nproduct of those two things,this thing is only the\nconstant that I need to divideso that when I integrate\nthis thing over theta,it integrates to one.Because this has to be a\nprobability density on theta.I can write this and just\nforget about that part.And that's what's written\non the top of this slide.This notation, this sort of\nweird alpha, or I don't know.Infinity sign\npropped to the right.Whatever you want\nto call this thingis actually just really\nemphasizing the factthat I don't care.I write it because I can,\nbut you know what it is.In some instances, you have\nto compute the integral.In some instances, you don't\nhave to compute the integral.And a lot of\nBayesian computationis about saying,\nOK it's actuallyreally hard to\ncompute this integral,so I'd rather not doing it.So let me try to find some\nmethods that will allow meto sample from the\nposterior distribution,without having to compute this.And that's what's called\nMonte-Carlo Markovchains, or MCMC, and that's\nexactly what they're doing.They're just using\nonly ratios of things,like that for different thetas.And which means that\nif you take ratios,the normalizing constant\nis gone and you don'tneed to find this integral.So we won't go into\nthose details at all.That would be the purpose\nof an entire courseon Bayesian inference.Actually, even\nBayesian computationswould be an entire\ncourse on its own.", "start": 2520.0, "heat": 0.214}, {"text": "And there's some very\ninteresting thingsthat are going on there,\nthe interface of statsand computation.So let's go back to our example\nand see if we can actuallycompute any of those things.Because it's very nice to give\nyou some data, some formulas.Let's see if we\ncan actually do it.In particular, can I\nactually recover this claimthat the posterior associated\nto a beta prior with a Bernoullilikelihood is actually\ngiving me a beta again?What was my prior?So p was following\na beta AA, whichmeans that p, the density.That was pi of theta.Well I'm going to\nwrite this as pi of p--was proportional to p to the\nA minus 1 times 1 minus pto the A minus 1.So that's the first ingredient\nI need to complete my posterior.I really need only two, if I\nwanted to bound up to constant.The second one was p hat.We've computed that many times.And we had even a nice\ncompact way of writing it,which was that pn of X1,\nXn, given the parameter p.So the joint density of my data,\ngiven p, that's my likelihood.The likelihood of p was what?Well it was p to\nthe sum of Xi's.1 minus p to the n\nminus some of the Xi's.Anybody wants me\nto parse this more?Or do you remember seeing\nthat from maximum likelihoodestimation?Yeah?AUDIENCE: [INAUDIBLE]", "start": 2640.0, "heat": 0.1}, {"text": "PHILLIPE RIGOLLET: That's\nwhat conditioning does.AUDIENCE: [INAUDIBLE]\nprevious slide.[INAUDIBLE] bottom\nthere, it says D pi of t.Shouldn't it be dt pi of t?PHILLIPE RIGOLLET:\nSo D pi of T isa measure theoretic notation,\nwhich I used without thinking.And I should not because\nI can see it upsets you.D pi of T is just a\nnatural way to saythat I integrate\nagainst whatever I'mgiven for the prior of theta.In particular, if theta is just\nthe mix of a PDF and a pointmass, maybe I say\nthat my p takesvalue 0.5 with probability 0.5.And then is uniform on the\ninterval with probability 0.5.For this, I neither\nhave a PDF nor a PMF.But I can still talk about\nintegrating with respectto this, right?It's going to look like, if\nI take a function f of T,D pi of T is going to be\none half of f of one half.That's the point mass\nwith probability one half,at one half.Plus one half of the integral\nbetween 0 and 1, of f of TDT.This is just the notation, which\nis actually funnily enough,interchangeable with pi of DT.But if you have a\ndensity, it's reallyjust the density pi of TDT.If pi is really a\ndensity, but that'swhen it's when pi is and\nmeasure and not a density.Everybody else,\nforget about this.This is not something\nyou should reallyworry about at this point.This is more graduate\nlevel probability classes.But yeah, it's called\nmeasure theory.And that's when you think\nof pi as being a measurein an abstract fashion.You don't have to worry\nwhether it's a density", "start": 2760.0, "heat": 0.217}, {"text": "or not, or whether\nit has a density.So everybody is OK with this?Now I need to\ncompute my posterior.And as I said, my\nposterior is reallyjust the product of\nthe likelihood weightedby the prior.Hopefully, at this stage\nof your application,you can multiply two functions.So what's happening is,\nif I multiply this guywith this guy, p gets\nthis guy to the powerthis guy plus this guy.And then 1 minus p gets the\npower n minus some of Xi's.So this is always\nfrom I equal 1 to n.And then plus A minus 1 as well.This is up to constant, because\nI still need to solve this.And I could try to do it.But I really don't\nhave to, because Iknow that if my density\nhas this form, thenit's a beta distribution.And then I can just\ngo on Wikipediaand see what should be\nthe normalization factor.But I know it's going to\nbe a beta distribution.It's actually the\nbeta with parameter.So this is really my beta\nwith parameter, sum of Xi,i equal 1 to n plus A minus 1.And then the second\nparameter is n minus sumof the Xi's plus A minus 1.I just wrote what was here.What happened to my one?", "start": 2880.0, "heat": 0.286}, {"text": "Oh no, sorry.Beta has the power minus 1.So that's the\nparameter of the beta.And this is the\nparameter of the beta.Beta is over there, right?So I just replace\nA by what I see.A is just becoming\nthis guy plus this guyand this guy plus this guy.Everybody is comfortable\nwith this computation?We just agreed that beta priors\nfor Bernoulli observationsare certainly convenient.Because they are just\nconjugate, and we knowthat's what is going\nto come out in the end.That's going to\nbe a beta as well.I just claim it was convenient.It was certainly convenient\nto compute this, right?There was certainly\nsome compatibilitywhen I had to multiply this\nfunction by that function.And you can imagine that things\ncould go much more wrong,than just having p to some power\nand p to some power, 1 minus pto some power, when it might\njust be some other power.Things were nice.Now this is nice, but I can also\nquestion the following things.Why beta, for one?The beta tells me something.That's convenient, but\nthen how do I pick A?I know that A should definitely\ncapture the fact that whereI want to have my p\nmost likely located.But it also actually\nalso capturesthe variance of my beta.And so choosing\ndifferent As is goingto have different functions.If I have A and B, If I started\nwith the beta with parameter.If I started with a B here, I\nwould just pick up the B here.Agreed?And that would just\nbe a symmetric.But they're going to\ncapture mean and varianceof this thing.And so how do I pick those guys?If I'm a doctor and\nyou're asking me,what do you think the\nchances of this drug working", "start": 3000.0, "heat": 0.197}, {"text": "in this kind of patients is?And I have to spit out the\nparameters of a beta for you,it might be a bit of a\ncomplicated thing to do.So how do you do this,\nespecially for problems?So by now, people\nhave actually masteredthe art of coming up with how\nto formulate those numbers.But in new problems that\ncome up, how do you do this?What happens if you want\nto use Bayesian methods,but you actually do not\nknow what you expect to see?To be fair, before we started\nthis class, I hope all of youhad no idea whether people tend\nto bend their head to the rightor to the left before kissing.Because if you did, well\nyou have too much timeon your hands and I should\ndouble your homework.So in this case,\nmaybe you still wantto use the Bayesian machinery.Maybe you just want\nto do something nice.It's nice right, I mean\nit worked out pretty well.What if you want to do?Well you actually want\nto use some priors thatcarry no information, that\nbasically do not preferany theta to another theta.Now, you could read\nthis slide or youcould look at this formula.We just said that this\npi here was just hereto weigh some thetas more\nthan others, dependingon their prior belief.If our prior belief\ndoes not wantto put any preference towards\nsome thetas than to others,what do I do?AUDIENCE: [INAUDIBLE]PHILLIPE RIGOLLET:\nYeah, I remove it.And the way to remove\nsomething we multiply by,is just replace it by one.That's really what we're doing.If this was a constant\nnot depending on theta,then that would mean that\nwe're not preferring any theta.And we're looking\nat the likelihood.But not as a function that\nwe're trying to maximize,but it is a function that\nwe normalize in such a waythat it's actually\na distribution.So if I have pi,\nwhich is not here,this is really just taking\nthe like likelihood,which is a positive function.It may not integrate\nto 1, so I normalize itso that it integrates to 1.", "start": 3120.0, "heat": 0.262}, {"text": "And then I just say, well this\nis my posterior distribution.Now I could just\nmaximize this thingand spit out my maximum\nlikelihood estimator.But I can also\nintegrate and findwhat the expectation\nof this guy is.I can find what the\nmedian of this guy is.I can sample data from this guy.I can build, understand what\nthe variance of this guy is.Which is something we did\nnot do when we just didmaximum likelihood estimation\nbecause given a function, allwe cared about was the\narc max of this function.These priors are\ncalled uninformative.This is just replacing this\nnumber by one or by a constant.Because it still\nhas to be a density.If I have a bounded\nset, I'm justlooking for the\nuniform distributionon this bounded set, the\none that puts constant oneover the size of this thing.But if I have an\ninvalid set, whatis the density that\ntakes a constant valueon the entire real\nline, for example?What is this density?AUDIENCE: [INAUDIBLE]PHILLIPE RIGOLLET:\nDoesn't exist, right?It just doesn't exist.The way you can think\nof it is a Gaussianwith the variance going\nto infinity, maybe,or something like this.But you can think\nof it in many ways.You can think of the limit of\nthe uniform between minus Tand T, with T going to infinity.But this thing is actually zero.There's nothing there.You can actually\nstill talk about this.You could always talk\nabout this thing, whereyou think of this guy\nas being a constant,remove this thing from this\nequation, and just say,well my posterior is\njust the likelihooddivided by the integral of\nthe likelihood over theta.And if theta is the entire\nreal line, so be it.As long as this\nintegral converges,", "start": 3240.0, "heat": 0.581}, {"text": "you can still talk\nabout this stuff.This is what's called\nan improper prior.An improper prior is just a\nnon-negative function definedin theta, but it does not have\nto integrate neither to one,nor to anything.If I integrate the\nfunction equal to 1on the entire real\nline, what do I get?Infinity.It's not a proper prior, and\nit's called and improper prior.And those improper\npriors are usuallywhat you see when you start\nto want non-informative priorson infinite sets of datas.That's just the nature of it.You should think of them as\nbeing the uniform distributionof some infinite set, if\nthat thing were to exist.Let's see some examples\nabout non-informative priors.If I'm in the interval 0,\n1 this is a finite set.So I can talk about\nthe uniform prioron the interval 0, 1 for a\nparameter, p of a Bernoulli.If I want to talk\nabout this, then itmeans that my prior is p follows\nsome uniform on the interval0, 1.So that means that f of\nx is 1 if x is in 0, 1.Otherwise, there is actually\nnot even a normalization.This thing integrates to 1.And so now if I look\nat my likelihood,it's still the same thing.So my posterior\nbecomes theta X1, Xn.", "start": 3360.0, "heat": 0.637}, {"text": "That's my posterior.I don't write the\nlikelihood again,because we still have it--well we don't have\nit here anymore.The likelihood is given here.Copy, paste over there.The posterior is just\nthis thing times 1.So you will see it in a second.So it's p to the power sum\nof the Xi's, one minus pto the power, n minus\nsum of the Xi's.And then it's multiplied by\n1, and then divided by thisintegral between 0 and\n1 of p, sum of the Xi's.1 minus p, n minus\nsum of the Xi's.Dp, which does not depend on p.And I really don't care\nwhat the thing actually is.That's posterior of p.And now I can see,\nwell what is this?It's actually just the\nbeta with parameters.This guy plus 1.And this guy plus 1.I didn't tell you what the\nexpectation of a beta was.We don't know what the\nexpectation of a betais, agreed?If I wanted to find say, the\nexpectation of this thing thatwould be some good\nestimator, we knowthat the maximum\nof this guy-- whatis the maximum of this thing?Well, it's just this thing,\nit's the average of the Xi's.That's just the maximum\nlikelihood estimatorfor Bernoulli.", "start": 3480.0, "heat": 0.44}, {"text": "We know it's the average.Do you think if I take the\nexpectation of this thing,I'm going to get the average?So actually, I'm not\ngoing to get the average.I'm going to get this guy plus\nthis guy, divided by n plus 1.Let's look at what\nthis thing is doing.It's looking at the number\nof ones and it's adding one.And this guy is looking\nat the number of zerosand it's adding one.Why is it adding this one?What's going on here?This is going to matter\nmostly when the number of onesis actually zero, or the\nnumber of zeros is zero.Because what it does is just\npushes the zero from non-zero.And why is that something that\nthis Bayesian method actuallydoes for you automatically?It's because when we\nput this non-informativeprior on p, which was\nuniform on the interval 0, 1.In particular, we know\nthat the probabilitythat p is equal to 0 is zero.And the probability p\nis equal to 1 is zero.And so the problem\nis that if I did notadd this 1 with some\npositive probability,I wouldn't be allowed to spit\nout something that actually hadp hat, which was equal to 0.If by chance, let's say\nI have n is equal to 3,and I get only 0, 0, 0, that\ncould happen with probability.1 over pq, one over 1 minus pq.That's not something\nthat I want.And I'm using my priors.My prior is not informative,\nbut somehow it captures the factthat I don't want to\nbelieve p is goingto be either equal to 0 or 1.So that's sort of\ntaken care of here.So let's move away a little\nbit from the Bernoulli example,", "start": 3600.0, "heat": 0.395}, {"text": "shall we?I think we've seen enough of it.And so let's talk about\nthe Gaussian model.Let's say I want to\ndo Gaussian inference.I want to do inference\nin a Gaussian model,using Bayesian methods.What I want is that Xi,\nX1, Xn, or say 0, 1 iid.Sorry, theta 1, iid\nconditionally on theta.That means that pn of\nX1, Xn, given thetais equal to exactly\nwhat I wrote before.So 1 square root to pi, to the\nn exponential minus one halfsum of Xi minus theta squared.So that's just the\njoint distributionof my Gaussian with mean data.And the another\nquestion is, whatis the posterior distribution?Well here I said, let's use\nthe uninformative prior,which is an improper prior.It puts weight on everyone.That's the so-called uniform\non the entire real line.So that's certainly\nnot a density.But it can still just use this.So all I need to do\nis get this dividedby normalizing this thing.But if you look at\nthis, essentially Iwant to understand.So this is proportional\nto the exponentialminus one half\nsum from I equal 1to n of Xi minus theta squared.And now I want to see\nthis thing as a density,", "start": 3720.0, "heat": 0.38}, {"text": "not on the Xi's but on theta.What I want is a\ndensity on theta.So it looks like I have\nchances of getting somethingthat looks like a Gaussian.To have a Gaussian, I would\nneed to see minus one half.And then I would need to\nsee theta minus somethinghere, not just the sum of\nsomething minus thetas.So I need to work\na little bit more,to expand the square here.So this thing here\nis going to beequal to exponential minus\none half sum from I equal 1to n of Xi squared minus 2Xi\ntheta plus theta squared.Now what I'm going to do\nis, everything rememberis up to this little sign.So every time I see a term\nthat does not depend on theta,I can just push it in there\nand just make it disappear.Agreed?This term here, exponential\nminus one half sum of Xisquared, does it\ndepend on theta?No.So I'm just pushing it here.This guy, yes.And the other one, yes.So this is proportional to\nexponential sum of the Xi.And then I'm going to pull out\nmy theta, the minus one halfcanceled with the minus 2.And then I have minus\none half sum from Iequal 1 to n of theta squared.", "start": 3840.0, "heat": 0.382}, {"text": "Agreed?So now what this\nthing looks like,this looks very much like some\ntheta minus something squared.This thing here is really\njust n over 2 times theta.Sorry, times theta squared.So now what I need to do is to\nwrite this of the form, thetaminus something.Let's call it mu, squared,\ndivided by 2 sigma squared.I want to turn this into\nthat, maybe up to termsthat do not depend on theta.That's what I'm\ngoing to try to do.So that's called\ncompleting the squaring.That's some exercises you do.You've done it probably,\nalready in the homework.And that's something\nyou do a lot whenyou do Bayesian\nstatistics, in particular.So let's do this.What is it going to\nbe the leading term?Theta squared is going to\nbe multiplied by this thing.So I'm going to pull\nout my n over 2.And then I'm going to write\nthis as minus theta over 2.And then I'm going to write\ntheta minus something squared.And this something is going\nto be one half of whatI see in the cross-product.I need to actually\npull this thing out.So let me write it\nlike that first.So that's theta squared.And then I'm going to write it\nas minus 2 times 1 over n sumfrom I equal 1 to n\nof Xi's times theta.That's exactly just a rewriting\nof what we had before.And that should look\nmuch more familiar.A squared minus 2 blap A,\nand then I missed something.So this thing, I'm going\nto be able to rewriteas theta minus Xn bar squared.But then I need to remove\nthe square of Xn bar.", "start": 3960.0, "heat": 0.128}, {"text": "Because it's not here.So I just complete the square.And then I actually really don't\ncare with this thing actuallywas, because it's going to go\nagain in the little Alpha'ssign over there.So this thing\neventually is goingto be proportional\nto exponentialof minus n over 2 times theta\nof minus Xn bar squared.And so we know that if\nthis is a density that'sproportional to this guy, it has\nto be some n with mean, Xn bar.And variance, this is supposed\nto be 1 over sigma squared.This guy over here, this n.So that's really just 1 over n.So the posterior\ndistribution is a Gaussiancentered at the average\nof my observations.And with variance, 1 over n.Everybody's with me?Why I'm saying this, this was\nthe output of some computation.But it sort of\nmakes sense, right?It's really telling me that\nthe more observations I have,the more concentrated\nthis posterior is.Concentrated around what?Well around this Xn bar.That looks like something\nwe've sort of seen before.But it does not have the\nsame meaning, somehow.This is really just the\nposterior distribution.It's sort of a sanity check,\nthat I have this 1 over nwhen I have Xn bar.But it's not the\nsame thing as sayingthat the variance of Xn bar was\n1 over n, like we had before.As an exercise,\nI would recommendif you don't get it,\njust try pi of theta", "start": 4080.0, "heat": 0.122}, {"text": "to be equal to some n mu 1.Here, the prior that we used\nwas completely non-informative.What happens if I take my prior\nto be some Gaussian, whichis centered at mu and\nit has the same varianceas the other guys?So what's going to\nhappen here is that we'regoing to put a weight.And everything\nthat's away from muis going to actually\nget less weight.I want to know how I'm\ngoing to be updatingthis prior into a posterior.Everybody sees what\nI'm saying here?So that means that pi of theta\nhas the density proportionalto exponential minus one\nhalf theta minus mu squared.So I need to multiply\nmy posterior with this,and then see.It's actually going\nto be a Gaussian.This is also a conjugate prior.It's going to spit\nout another Gaussian.You're going to have to complete\na square again, and just checkwhat it's actually giving you.And so spoiler alert,\nit's going to looklike you get an extra\nobservation, which is actuallyequal to mu.It's going to be the average\nof n plus 1 observations.The first n1's being X1 to Xn.And then, the last one being mu.And it sort of makes sense.That's actually a\nfairly simple exercise.Rather than going\ninto more computation,this is something\nyou can definitelydo when you're in the\ncomfort of your room.I want to talk about\nother types of priors.The first thing I said is,\nthere's this beta priorthat I just pulled out of my hat\nand that was just convenient.Then there was this\nnon-informative prior.It was convenient.It was non-informative, so\nif you don't know anythingelse maybe that's\nwhat you want to do.The question is, are there\nany other priors that", "start": 4200.0, "heat": 0.138}, {"text": "are sort of principled\nand generic, in the sensethat the uninformative\nprior was generic, right?It was equal to 1, that's\nas generic as it gets.So is there anything\nthat's generic as well?Well, there's this priors that\nare called Jeffrey's priors.And Jeffrey's prior, which is\nproportional to square rootof the determinant of the\nFisher information of theta.This is actually a\nweird thing to do.It says, look at your model.Your model is going to\nhave a Fisher information.Let's say it exists.Because we know it\ndoes not always exist.For example, in the\nmultinomial model,we didn't have a\nFisher information.The determinant of\na matrix is somehowmeasuring the size of a matrix.If you don't trust\nme, just thinkabout the matrix being\nof size one by one,then the determinant is just\nthe number that you have there.And so this is really something\nthat looks like the Fisherinformation.It's proportional to the\namount of informationthat you have at\na certain point.And so what my prior\nis saying well,I want to put more weights\non those thetas thatare going to just extract more\ninformation from the data.You can actually\ncompute those things.In the first example,\nJeffrey's prioris something that\nlooks like this.In one dimension,\nFisher informationis essentially one\nthe word variance.That's just 1 over the\nsquare root of the variance,because I have the square root.And when I have the Jeffrey's\nprior, when I have the Gaussiancase, this is the\nidentity matrixthat I would have in\nthe Gaussian case.The determinant of\nthe identities is 1.So square root of 1 is 1, and\nso I would basically get 1.And that gives me my improper\nprior, my uninformative priorthat I had.", "start": 4320.0, "heat": 0.473}, {"text": "So the uninformative\nprior 1 is fine.Clearly, all the thetas\ncarry the same informationin the Gaussian model.Whether I translate\nit here or here,it's pretty clear none\nof them is actuallybetter than the other.But clearly for\nthe Bernoulli case,the p's that are closer\nto the boundary carrymore information.I sort of like those\nguys, because they justcarry more information.So what I do is, I\ntake this function.So p1 minus p.Remember, it's something\nthat looks like this.On the interval 0, 1.This guy, 1 over square\nroot of p1 minus pis something that\nlooks like this.AgreedWhat it's doing is\nsort of wants to pushtowards the piece that actually\ncarry more information.Whether you want to\nbias your data thatway or not, is something\nyou need to think about.When you put a prior on your\ndata, on your parameter,you're sort of biasing\ntowards this idea your data.That's maybe not\nsuch a good idea,when you have some p that's\nactually close to one half,for example.You're actually\nsaying, no I don'twant to see a p that's\nclose to one half.Just make a decision,\none way or another.But just make a decision.So it's forcing you to do that.Jeffrey's prior, I'm\nrunning out of timeso I don't want to go\ninto too much detail.We'll probably stop\nhere, actually.So Jeffrey's priors have\nthis very nice property.It's that they actually do not\ncare about the parameterizationof your space.If you actually have\np and you suddenlydecide that p is not the\nright parameter for Bernoulli,but it's p squared.", "start": 4440.0, "heat": 1.0}, {"text": "You could decide to\nparameterize this by p squared.Maybe your doctor is\nactually much more ableto formulate some prior\nassumption on p squared,rather than p.You never know.And so what happens is\nthat Jeffrey's priorsare an invariant in this.And the reason is because\nthe information carried by pis the same as the information\ncarried by p squared, somehow.They're essentially\nthe same thing.You need to have one to one map.Where you basically for\neach parameter, beforeyou have another parameter.Let's call Eta the\nnew parameters.The PDF of the new prior\nindexed by Eta this timeis actually also\nJeffrey's prior.But this time, the\nnew Fisher informationis not the Fisher information\nwith respect to theta.But it's this Fisher\ninformation associatedto this statistical\nmodel indexed by Eta.So essentially, when you\nchange the parameterizationof your model, you still\nget Jeffrey's priorfor the new parameterization.Which is, in a way,\na desirable property.Jeffrey's prior is just\nan uninformative priors,or priors you want\nto use when youwant a systematic way without\nreally thinking about whatto pick for your mile.I'll finish this next time.And we'll talk about\nBayesian confidence regions.We'll talk about\nBayesian estimation.Once I have a posterior,\nwhat do I get?And basically, the\nonly message isgoing to be that you\nmight want to integrateagainst the posterior.Find the posterior, the\nexpectation of your posteriordistribution.That's a good point\nestimator for theta.We'll just do a\ncouple of computation.", "start": 4560.0, "heat": 0.481}]