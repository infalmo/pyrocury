[{"text": "PROFESSOR: Hi, everyone.Welcome back.So today, I'd like to tackle\na problem in Markov matrices.Specifically, we're going to\nstart with this problem whichalmost has a physics origin.If we have a particle that\njumps between positions A and Bwith the following\nprobabilities--I'll just state it-- if\nit starts at A and jumpsto B with probability\n0.4 or starts at Aand stays at A with probability\n0.6, or if it starts at Bthen it goes to A\nwith probability 0.2or stays at B with\nprobability 0.8,we'd like to know the\nevolution of the probabilityof this particle over\na long period of time.So specifically\nthe problem we'reinterested today is:\nif we have a particleand we know that it\nstarts at position A,what is the\nprobability that it isat position A and\nthe probabilitythat it's at position B after\none step, after n steps,and then finally after an\ninfinite number of steps?So I'll let you think about\nthis problem for a momentand I'll be back.Hi everyone.Welcome back.So the main difficulty\nwith this problemis that it's phrased\nas a physics problem.And we need to convert it into\nsome mathematical languageto get a handle on it.So specifically,\nwhat we'd like to dois to convert this into\na matrix formalism.So what we can do is we can\nwrite this little graph downand describe everything in\nthis graph using a matrix.So I'm going to\ncall this matrix A,and I'm going to associate\nthe first row of Awith particle position A\nand particle position B.And I'll associate the\nfirst and second columns", "start": 0.0, "heat": 0.1}, {"text": "with particles\npositions A and B.And then what I'm\ngoing to do is I'mgoing to fill in this\nmatrix with the probabilitydistributions.So, specifically what's going\nto go in this top left corner?Well, the number 0.6, which\nrepresents the probabilitythat I stay at position\nA, given that Istart at position A.\nWhat's going to go herein the bottom left-hand corner?Well, we're going to put 0.4,\nbecause this is the probabilitythat I wind up at B, given that\nI start at A. And then lastly,we'll fill in these other two\ncolumns or the second columnwith 0.8 and 0.2.So I'll just state\nbriefly this iswhat's called a Markov matrix.And it's called Markov, because\nfirst off, every elementis positive or 0.And secondly, the sum of the\nelements in each column is 1.So if we note 0.4 plus 0.6\nis 1, 0.8 plus 0.2 is 1.And these matrices\ncome up all the timewhen we're talking about\nprobabilities and the evolutionof probability distributions.OK.So now, once we've encoded\nthis graph using this matrix A,we now want to\ntackle this problem.So I'm going to\nintroduce the vector p,and I'm going to\nuse a subscript 0is to denote the probability\nthat the particle is at time 0.So we're told that the\nparticle starts at position A.So at time 0, I'm going\nto use the vector [1, 0].Again, I'm going to match the\ntop component of this vector", "start": 120.0, "heat": 0.1}, {"text": "with the top component\nof this matrixand the first column\nof this matrix.And then likewise, the second\ncomponent of this vectorwith the second row and\nsecond column of this matrix.And we're interested\nin: how doesthis probability evolve as\nthe particle takes many steps?So for one step, what's the\nprobability of the particlegoing to be?Well, this is the beauty of\nintroducing matrix notation.I'm going to denote p_1\nto be the probabilityof the particle after one step.And we see that we can write\nthis as the matrix A multipliedby p_0.So the answer is 0.6 and 0.4.And I achieve this just\nby multiplying this matrixby this vector.OK?So this concludes part one.Now part two is a\nlittle trickier.So part two is n steps.And to tackle this\nproblem, we needto use a little more machinery.So first off, I'm going to\nnote that p_1 is A times p_0.Likewise, p_2-- so\nthis is the positionof the-- the probability\ndistribution of the particleafter two steps.This is A times p_0, which\nis A squared times p_0.And we note that\nthere's a general trend.After n steps-- so\nP_n-- the general trend", "start": 240.0, "heat": 0.1}, {"text": "is, it's going to be this matrix\nA raised to the n-th power,multiply the vector P0.So how do we take the\nn-th power of a matrix?Well, this is where we use\neigenvectors and eigenvalues.So recall, that we can take any\nmatrix A that's diagonalizableand write it as U D U inverse,\nwhere D is a diagonal matrixand this matrix U is a matrix\nwhose columns correspondto the eigenvectors of A.So for this problem,\nI'm just goingto state what the eigenvalues\nand eigenvectors are.And I'll let you work them out.So because it's a\nMarkov matrix, we alwayshave an eigenvalue which is 1.And in this case, we have an\neigenvector u which is 1 and 2.In addition, the second\neigenvalue is 0.4.And the eigenvector\ncorresponding to this oneis [1, -1].And I'll just call these\nu_1 and u_2, like that.OK, we can now write this\nbig matrix U as 1, 2; 1, -1.D is going to be-- now I\nhave to match things up.If I'm going to put\nthe first eigenvectorin the first column, we have\nto stick 1 in the first columnas well and then 0.4 like this.And then lastly, we also have\nU inverse which I can just", "start": 360.0, "heat": 0.1}, {"text": "work out to be minus 1/3,\none over the determinant,times -1, -1; -2, and 1,\nwhich simplifies to this.OK, so now if we take A and\nraise it to the power of n,we have this nice identity\nthat all the U and U inversescollapse in the middle.And we're left with U, D\nto the n, U inverse, p_0.Now raising the a diagonal\nmatrix to the power of nis a relatively\nsimple thing to do.We just take the eigenvalues and\nraise them to the power of n.So when we compute this\nproduct, there's a questionof what order do we do things?Now these are 2 by 2\nmatrices, so in theory wecould just multiply\nout, 2 by 2 matrix, 2by 2 matrix, 2 by 2 matrix, and\nthen on a vector which is a 2by 1 matrix.But if you're in a test and\nyou're cramped for time,you want to do as little\ncomputations as possible.So what you want\nto do is you wantto start on the right-hand\nside and then work backwards.So if we do this, we\nend up obtaining 1, 2,this is going to be to the\npower of n, 1/3, [1, 2].OK, so for this\nlast part, I'm justgoing to write down\nthe final answer.And I'll let you work out the\nmultiplication of matrices.So we have for p_n: 1/3, 2 times\n0.4 to the n plus 1, -2 0.4", "start": 480.0, "heat": 0.1}, {"text": "to the n plus 2.And this is the final\nvector for p of n.So this finishes up Part 2.And then lastly,\nfor Part 3, whathappens when n goes to infinity?Well, we have the\nanswer for any n.So we can just take the\nlimit as n goes to infinity.Now, specifically as\nn goes to infinity,0.4 raised to some very\nlarge power vanishes.So these two terms drop off.And at the end of the day,\nwe're left with p_infinityis 1/3 [1, 2].OK?So just to recap, we started off\nwith a particle starting at A,and then after a very\nlong time, the particlewinds up with a\nprobability distributionwhich is 1/3, 1 and 2.And this is quite characteristic\nof Markov matrix chains.Specifically, we note\nthat 1/3 * [1, 2]is a multiple of the eigenvector\ncorresponding to eigenvalue 1.So even though the particle\nstarted at position A,after a long period\nof time, it tendedto forget where it started\nand approached, diffusedinto this uniform distribution.OK.I'd like to finish up here.And I'll see you next time.", "start": 600.0, "heat": 0.1}]