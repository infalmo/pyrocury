[{"text": "The following content is\nprovided under a CreativeCommons license.Your support will help\nMIT OpenCourseWarecontinue to offer high quality\neducational resources for free.To make a donation or to\nview additional materialsfrom hundreds of MIT courses,\nvisit MIT OpenCourseWareat ocw.mit.edu.JOHN GUTTAG: Welcome\nto Lecture 6.As usual, I want to start by\nposting some relevant reading.For those who don't\nknow, this lovely pictureis of the Casino at Monte\nCarlo, and shortly you'llsee why we're talking about\ncasinos and gambling today.Not because I want to encourage\nyou to gamble your lifesavings away.A little history about\nMonte Carlo simulation,which is the topic\nof today's lecture.The concept was invented by the\nPolish American mathematician,Stanislaw Ulam.Probably more well known for his\nwork on thermonuclear weaponsthan on mathematics,\nbut he did doa lot of very\nimportant mathematicsearlier in his life.The story here starts\nthat he was ill,recovering from some\nserious illness,and was home and\nwas bored and wasplaying a lot of games\nof solitaire, a game Isuspect you've all played.Being a mathematician,\nhe naturally wondered,what's the probability of my\nwinning this stupid game whichI keep losing?And so he actually spent\nquite a lot of timetrying to work out\nthe combinatorics,so that he could actually\ncompute the probability.And despite being a really\namazing mathematician,he failed.The combinatorics were\njust too complicated.So he thought, well suppose\nI just play lots of hands", "start": 0.0, "heat": 0.102}, {"text": "and count the number I\nwin, divide by the numberof hands I played.Well then he thought\nabout it and said,well, I've already played a lot\nof hands and I haven't won yet.So it probably\nwill take me yearsto play enough hands to\nactually get a good estimate,and I don't want to do that.So he said, well, suppose\ninstead of playing the game,I just simulate the\ngame on a computer.He had no idea how\nto use a computer,but he had friends\nin high places.And actually talked\nto John von Neumann,who is often viewed as the\ninventor of the stored programcomputer.And said, John, could you do\nthis on your fancy new ENIACmachine?And on the lower\nright here, you'llsee a picture of the ENIAC.It was a very large machine.It filled a room.And von Neumann said,\nsure, we could probablydo it in only a few\nhours of computation.Today we would think\nof a few microseconds,but those machines were slow.Hence was born Monte\nCarlo simulation,and then they actually used it\nin the design of the hydrogenbomb.So it turned out to be\nnot just useful for cards.So what is Monte\nCarlo simulation?It's a method of\nestimating the valuesof an unknown\nquantity using what iscalled inferential statistics.And we've been using\ninferential statisticsfor the last several lectures.The key concepts-- and I want\nto be careful about these thingswill be coming back to them--are the population.So think of the\npopulation as the universeof possible examples.So in the case of\nsolitaire, it'sa universe of all possible\ngames of solitairethat you could possibly play.", "start": 120.0, "heat": 0.242}, {"text": "I have no idea how big that\nis, but it's really big,Then we take that\nuniverse, that population,and we sample it by\ndrawing a proper subset.Proper means not\nthe whole thing.Usually more than one\nsample to be useful.Certainly more than 0.And then we make an inference\nabout the populationbased upon some set of\nstatistics we do on the sample.So the population is typically\na very large set of examples,and the sample is a\nsmaller set of examples.And the key fact\nthat makes them workis that if we choose\nthe sample at random,the sample will tend to\nexhibit the same propertiesas the population from\nwhich it is drawn.And that's exactly what we did\nwith the random walk, right?There were a very large number\nof different random walksyou could take of\nsay, 10,000 steps.We didn't look at all possible\nrandom walks of 10,000 steps.We drew a small sample\nof, say 100 such walks,computed the mean of\nthose 100, and said,we think that's probably\na good expectationof what the mean would be of\nall the possible walks of 10,000steps.So we were depending\nupon this principle.And of course the key fact\nhere is that the samplehas to be random.If you start drawing the\nsample and it's not random,then there's no\nreason to expect itto have the same properties\nas that of the population.And we'll go on\nthroughout the term,and talk about the various ways\nyou can get fooled and thinkof a random sample\nwhen exactly you don't.", "start": 240.0, "heat": 0.323}, {"text": "All right, let's look at\na very simple example.People like to use flipping\ncoins because coins are easy.So let's assume\nwe have some coin.All right, so I bought\ntwo coins slightly largerthan the usual coin.And I can flip it.Flip it once, and let's\nconsider one flip,and let's assume\nit came out heads.I have to say the coin I flipped\nis not actually a $20 goldpiece, in case any of you\nwere thinking of stealing it.All right, so we've got one\nflip, and it came up heads.And now I can ask\nyou the question--if I were to flip the same coin\nan infinite number of times,how confident would\nyou be about answeringthat all infinite\nflips would be heads?Or even if I were to\nflip it once more,how confident would you be that\nthe next flip would be heads?And the answer is not very.Well, suppose I\nflip the coin twice,and both times it came up heads.And I'll ask you\nthe same question--do you think that the next\nflip is likely to be heads?Well, maybe you would be\nmore inclined to say yesand having only seen one\nflip, but you wouldn't reallyjump to say, sure.On the other hand, if I flipped\nit 100 times and all 100 flipscame up heads, well,\nyou might be suspiciousthat my coin only has a head\non both sides, for example.Or is weighted in some funny way\nthat it mostly comes up heads.And so a lot of people,\nmaybe even me, if you said,I flipped it 100 times\nand it came up heads.", "start": 360.0, "heat": 0.197}, {"text": "What do you think\nthe next one will be?My best guess would\nbe probably heads.How about this one?So here I've\nsimulated 100 flips,and we have 50 heads here,\ntwo heads here, And 48 tails.And now if I said, do you\nthink that the probabilityof the next flip\ncoming up heads--is it 52 out of 100?Well, if you had to guess, that\nshould be the guess you make.Based upon the\navailable evidence,that's the best guess\nyou should probably make.You have no reason to\nbelieve it's a fair coin.It could well be weighted.We don't see it with coins,\nbut we see weighted diceall the time.We shouldn't, but they exist.You can buy them\non the internet.So typically our best\nguess is what we've seen,but we really shouldn't\nhave very much confidencein that guess.Because well, could've\njust been an accident.Highly unlikely even\nif the coin is fairthat you'd get 50-50, right?So why when we see 100 samples\nand they all come up headsdo we feel better about\nguessing heads for the 101stthan we did when\nwe saw two samples?And why don't we feel so good\nabout guessing 52 out of 100when we've seen a hundred\nflips that came out 52 and 48?", "start": 480.0, "heat": 0.119}, {"text": "And the answer is\nsomething called variance.When I had all heads, there was\nno variability in my answer.I got the same\nanswer all the time.And so there was no variability,\nand that intuitively--and in fact, mathematically--\nshould make us feel confidentthat, OK, maybe that's\nreally the way the world is.On the other hand, when almost\nhalf are heads and almost halfare tails, there's\na lot of variance.Right, it's hard to predict\nwhat the next one will be.And so we should have\nvery little confidencethat it isn't an\naccident that it happenedto be 52-48 in one direction.So as the variance grows,\nwe need larger samplesto have the same\namount of confidence.All right, let's look at\nthat with a detailed example.We'll look at roulette in\nkeeping with the theme of MonteCarlo simulation.This is a roulette wheel that\ncould well be at Monte Carlo.There's no need to simulate\nroulette, by the way.It's a very simple\ngame, but as we'veseen with our earlier\nexamples, it'snice when we're learning about\nsimulations to simulate thingswhere we actually can know\nwhat the actual answer isso that we can then understand\nour simulation better.For those of you who don't\nknow how roulette is played--is there anyone here who doesn't\nknow how roulette is played?Good for you.You grew up virtuous.All right, so-- well all right.Maybe I won't go there.So you have a wheel\nthat spins around,and in the middle are\na bunch of pockets.Each pocket has a\nnumber and a color.", "start": 600.0, "heat": 0.104}, {"text": "You bet in advance\non what numberyou think is going to\ncome up, or what color youthink is going to come up.Then somebody drops a ball in\nthat wheel, gives it a spin.And through centrifugal\nforce, the ballstays on the\noutside for a while.But as the wheel slows down\nand heads towards the middle,and eventually settles\nin one of those pockets.And you win or you lose.Now you can bet on\nit, and so let's lookat an example of that.So here is a roulette game.I've called it fair\nroulette, because it'sset up in such a way that\nin principle, if you bet,your expected value should be 0.You'll win some,\nyou'll lose some,but it's fair in the\nsense that it's not eithera negative or positive sum game.So as always, we have an\nunderbar underbar in it.Well we're setting up the\nwheel with 36 pockets on it,so you can bet on the\nnumbers 1 through 36.That's way range\nwork, you'll recall.Initially, we don't\nknow where the ball is,so we'll say it's none.And here's the key thing\nis, if you make a bet,this tells you\nwhat your odds are.That if you bet on a\npocket and you win,you get len of pockets minus 1.So This is why it's\na fair game, right?You bet $1.If you win, you get $36,\nyour dollar plus $35 back.If you lose, you lose.All right, self dot\nspin will be random dotchoice among the pockets.And then there is simply\nbet, where you justcan choose an amount to bet and\nthe pocket you want to bet on.", "start": 720.0, "heat": 0.206}, {"text": "I've simplified it.I'm not allowing you\nto bet here on colors.All right, so then\nwe can play it.So here is play roulette.I've made game the\nclass a parameter,because later we'll look at\nother kinds of roulette games.You tell it how many spins.What pocket you want to bet on.For simplicity, I'm going\nto bet on this same pocketall the time.Pick your favorite lucky number\nand how much you want to bet,and then we'll have a\nsimulation just like the oneswe've already looked at.So the number you get\nright starts at 0.For I and range number of\nspins, we'll do a spin.And then tote pocket plus\nequal game dot that pocket.And it will come back\neither 0 if you've lost,or 35 if you've won.And then we'll just\nprint the results.So we can do it.In fact, let's run it.So here it is.I guess I'm doing a million\ngames here, so quite a few.Actually I'm going to do two.What happens when you\nspin it 100 times?What happens when you\nspin it a million times?And we'll see what we get.So what we see here is\nthat we do 100 spins.The first time I did it my\nexpected return was minus 100%.", "start": 840.0, "heat": 0.348}, {"text": "I lost everything I bet.Not so unlikely,\ngiven that the oddsare pretty long that you could\ndo 100 times without winning.Next time I did a 100, my return\nwas a positive 44%, and thena positive 28%.So you can see, for 100 spins\nit's highly variable whatthe expected return is.That's one of the\nthings that makesgambling attractive to people.If you go to a casino, 100 spins\nwould be a pretty long nightat the table.And maybe you'd\nwon 44%, and you'dfeel pretty good about it.What about a million spins?Well people aren't interested in\nthat, but the casino is, right?They don't really care what\nhappens with 100 spins.They care what happens\nwith a million spins.What happens when everybody\ncomes every night to play.And there what we see is--you'll notice much\nless variance.Happens to be minus\n0.04 plus 0.6 plus 0.79.So it's still not 0,\nbut it's certainly,these are all closer to\n0 than any of these are.We know it should\nbe 0, but it doesn'thappen to be in these examples.But not only are they closer\nto 0, they're closer together.There is much less variance\nin the results, right?So here I show you\nthese three numbers,and ask what do you\nexpect to happen?You have no clue, right?So I don't know,\nmaybe I'll win a lot.Maybe I'll lose everything.I show you these three numbers,\nyou're going to look at itand say, well you\nknow, I'm goingto be somewhere between\naround 0 and maybe 1%.But you're never\ngoing to guess it'sgoing to be radically\ndifferent from that.", "start": 960.0, "heat": 0.259}, {"text": "And if I were to change this\nnumber to be even higher,it would go even closer to 0.But we won't bother.OK, so these are\nthe numbers we justlooked at, because I said\nthe seed to be the same.So what's going on\nhere is somethingcalled the law of large numbers,\nor sometimes Bernoulli's law.This is a picture of\nBernoulli on the stamp.It's one of the two most\nimportant theorems in allof statistics, and we'll come\nto the second most importanttheorem in the next lecture.Here it says, \"in\nrepeated independent testswith the same actual\nprobability, the chancethat the fraction of\ntimes the outcome differsfrom p converges to 0\nas the number of trialsgoes to infinity.\"So this says if I were to\nspin this fair roulettewheel an infinite\nnumber of times,the expected-- the\nreturn would be 0.The real true probability\nfrom the mathematics.Well, infinite is a\nlot, but a millionis getting closer to infinite.And what this says is the\ncloser I get to infinite,the closer it will be\nto the true probability.So that's why we did better with\na million than with a hundred.And if I did a 100\nmillion, we'd do way betterthan I did with a million.I want to take a minute to\ntalk about a way this law isoften misunderstood.This is something called\nthe gambler's fallacy.And all you have\nto do is say, let's", "start": 1080.0, "heat": 0.335}, {"text": "go watch a sporting event.And you'll watch a\nbatter strike outfor the sixth consecutive time.The next time they\ncome to the plate,the idiot announcer says,\nwell he struck out six timesin a row.He's due for a hit this\ntime, because he's usuallya pretty good hitter.Well that's nonsense.It says, people somehow\nbelieve that if deviationsfrom expected occur, they'll\nbe evened out in the future.And we'll see something\nsimilar to this that is true,but this is not true.And there is a great\nstory about it.This is told in a\nbook by Huff and Geis.And this truly happened in\nMonte Carlo, with Roulette.And you could either\nbet on black or red.Black came up 26 times in a row.Highly unlikely, right?2 to the 26th is a giant number.And what happened is, word\ngot out on the casino floorthat black had kept\ncoming up way too often.And people more or less\npanicked to rush to the tableto bet on red, saying, well\nit can't keep coming up black.Surely the next one will be red.And as it happened when the\ncasino totaled up its winnings,it was a record\nnight for the casino.Millions of francs got\nbet, because people weresure it would have to even out.Well if we think\nabout it, probabilityof 26 consecutive reds is that.A pretty small number.But the probability\nof 26 consecutive redswhen the previous 25\nrolls were red is what?No, that.AUDIENCE: Oh, I\nthought you meantit had been 26 times again.JOHN GUTTAG: No, if you\nhad 25 reds and then", "start": 1200.0, "heat": 0.14}, {"text": "you spun the wheel once\nmore, the probabilityof it having 26 reds is\nnow 0.5, because theseare independent events.Unless of course the wheel\nis rigged, and we're assumingit's not.People have a hard\ntime accepting this,and I know it seems funny.But I guarantee there will be\nsome point in the next monthor so when you will find\nyourself thinking this way,that something has to even out.I did so badly on\nthe midterm, I willhave to do better on the final.That was mean, I'm sorry.All right, speaking of means--see?Professor Grimson not the only\none who can make bad jokes.There is something-- it's\nnot the gambler's fallacy--that's often confused\nwith it, and that'scalled regression to the mean.This term was coined in\n1885 by Francis Galtonin a paper, of which I've\nshown you a page from it here.And the basic\nconclusion here was--what this table says is\nif somebody's parents areboth taller than\naverage, it's likelythat the child will be\nsmaller than the parents.Conversely, if the parents\nare shorter than average,it's likely that the child\nwill be taller than average.Now you can think about this\nin terms of genetics and stuff.That's not what he did.He just looked at\na bunch of data,and the data actually\nsupported this.And this led him to this notion\nof regression to the mean.And here's what\nit is, and here'sthe way in which it is subtly\ndifferent from the gambler's", "start": 1320.0, "heat": 0.104}, {"text": "fallacy.What he said here is,\nfollowing an extreme event--parents being unusually tall--the next random event is\nlikely to be less extreme.He didn't know much\nabout genetics,and he kind of assumed the\nheight of people were random.But we'll ignore that.OK, but the idea is here\nthat it will be less extreme.So let's look at it in roulette.If I spin a fair roulette\nwheel 10 times and get 10 reds,that's an extreme event.Right, here's a probability\nof basically 1.1024.Now the gambler's\nfallacy says, if Iwere to spin it\nanother 10 times,it would need to even out.As in I should get more\nblacks than you would usuallyget to make up for\nthese excess reds.What regression to the\nmean says is different.It says, it's likely that\nin the next 10 spins,you will get fewer than 10 reds.You will get a\nless extreme event.Now it doesn't have to be 10.If I'd gotten 7 reds instead of\n5, you'd consider that extreme,and you would bet that the next\n10 would have fewer than 7.But you wouldn't bet that\nit would have fewer than 5.Because of this, if you now look\nat the average of the 20 spins,it will be closer to\nthe mean of 50% redsthan you got from the\nextreme first spins.So that's why it's called\nregression to the mean.The more samples you\ntake, the more likelyyou'll get to the mean.", "start": 1440.0, "heat": 0.1}, {"text": "Yes?AUDIENCE: So,\nroulette wheel spinsare supposed to be independent.JOHN GUTTAG: Yes.AUDIENCE: So it seems\nlike the second 10--JOHN GUTTAG: Pardon?AUDIENCE: It seems like\nthe second 10 timesthat you spin it.Like that shouldn't\nhave to [INAUDIBLE]..JOHN GUTTAG: Has nothing\nto do with the first one.AUDIENCE: But you said\nit's likely [INAUDIBLE]..JOHN GUTTAG: Right, because you\nhave an extreme event, whichwas unlikely.And now if you\nhave another event,it's likely to be\ncloser to the averagethan the extreme\nwas to the average.Precisely because\nit is independent.That makes sense to everybody?Yeah?AUDIENCE: Isn't that the same\nas the gambler's fallacy, then?By saying that, because\nthis was super unlikely,the next one [INAUDIBLE].JOHN GUTTAG: No, the\ngambler's fallacy here--and it's a good question,\nand indeed people oftendo get these things confused.The gambler's fallacy would\nsay that the second 10spins would--we would expect to\nhave fewer than 5 reds,because you're trying to even\nout the unusual number of redsin the first SpinWhereas here we're not saying\nwe would have fewer than 5.We're saying we'd probably\nhave fewer than 10.That it'll be\ncloser to the mean,not that it would\nbe below the mean.Whereas the gambler's\nfallacy would sayit should be below that mean to\nquote, even out, the first 10.Does that makes sense?OK, great questions.Thank you.All right, now you\nmay not know this,but casinos are not in the\nbusiness of being fair.And the way they don't\ndo that is in Europe,they're not all red and black.They sneak in one green.", "start": 1560.0, "heat": 0.1}, {"text": "And so now if you bet\nred, well sometimesit isn't always red or black.And furthermore,\nthere is this 0.They index from 0 rather\nthan from one, and soyou don't get a full payoff.In American roulette, they\nmanage to sneak in two greens.They have a 0 in a double 0.Tilting the odds even more\nin favor of the casino.So we can do that\nin our simulation.We'll look at European roulette\nas a subclass of fair roulette.I've just added this\nextra pocket, 0.And notice I have\nnot changed the odds.So what you get if you get\nyour number is no higher,but you're a little bit\nless likely to get itbecause we snuck in that 0.Than American roulette is a\nsubclass of European roulettein which I add yet\nanother pocket.All right, we can\nsimulate those.Again, nice thing\nabout simulations,we can play these games.So I've simulated 20 trials\nof 1,000 spins, 10,000 spins,100,000, and a million.And what do we see\nas we look at this?Well, right away we can see\nthat fair roulette is usuallya much better bet than\neither of the other two.That even with only 1,000\nspins the return is negative.And as we get more and\nmore as I got to a million,it starts to look much\nmore like closer to 0.And these, we have reason\nto believe at least,are much closer to\ntrue expectationsaying that, while you\nbreak even in fair roulette,", "start": 1680.0, "heat": 0.1}, {"text": "you'll lose 2.7% in Europe\nand over 5% in Las Vegas,or soon in Massachusetts.All right, we're\nsampling, right?That's why the\nresults will change,and if I ran a\ndifferent simulationwith a different seed I'd\nget different numbers.Whenever you're sampling,\nyou can't be guaranteedto get perfect accuracy.It's always possible\nyou get a weird sample.That's not to say that you won't\nget exactly the right answer.I might have spun\nthe wheel twiceand happened to get the exact\nright answer of the return.Actually not twice,\nbecause the mathdoesn't work out, but\n35 times and gottenexactly the right answer.But that's not the point.We need to be able\nto differentiatebetween what happens to be\ntrue and what we actually know,in a rigorous sense, is true.Or maybe don't know it,\nbut have real good reasonto believe it's true.So it's not just a\nquestion of faith.And that gets us to\nwhat's in some sensethe fundamental question of\nall computational statistics,is how many samples\ndo we need to lookat before we can have real,\njustifiable confidencein our answer?As we've just seen--not just, a few minutes\nago-- with the coins,our intuition tells\nus that it dependsupon the variability in the\nunderlying possibilities.So let's look at\nthat more carefully.We have to look at the\nvariation in the data.", "start": 1800.0, "heat": 0.1}, {"text": "So let's look at first\nsomething called variance.So this is variance of x.Think of x as just a list of\ndata examples, data items.And the variance is we\nfirst compute the averageof value, that's mu.So mu is for the mean.For each little x and big\nX, we compare the differenceof that and the mean.How far is it from the mean?And square of the difference,\nand then we just sum them.So this takes, how far is\neverything from the mean?We just add them all up.And then we end up dividing\nby the size of the set,the number of examples.Why do we have to\ndo this division?Well, because we don't want to\nsay something has high variancejust because it has\nmany members, right?So this sort of normalizes\nis by the number of members,and this just sums how different\nthe members are from the mean.So if everything\nis the same value,what's the variance going to be?If I have a set of 1,000\n6's, what's the variance?Yes?AUDIENCE: 0.JOHN GUTTAG: 0.You think this is going to\nbe hard, but I came prepared.I was hoping this would happen.Look out, I don't know\nwhere this is going to go.[FIRES SLINGSHOT]AUDIENCE: [LAUGHTER]JOHN GUTTAG: All right, maybe\nit isn't the best technology.I'll go home and practice.", "start": 1920.0, "heat": 0.1}, {"text": "And then the thing\nyou're more familiarwith is the standard deviation.And if you look at the\nstandard deviation is,it's simply the square\nroot of the variance.Now, let's understand\nthis a little bitand first ask, why am\nI squaring this here,especially because\nlater on I'm just goingto take a square root anyway?Well squaring it has\none virtue, whichis that it means I don't care\nwhether the difference ispositive or negative.And I shouldn't, right?I don't care which side\nof the mean it's on,I just care it's\nnot near the mean.But if that's all\nI wanted to do Icould take the absolute value.The other thing we\nsee with squaringis it gives the outliers\nextra emphasis, because I'msquaring that distance.Now you can think\nthat's good or bad,but it's worth\nknowing it's a fact.The more important\nthing to think aboutis standard deviation all by\nitself is a meaningless number.You always have to think about\nit in the context of the mean.If I tell you the\nstandard deviation is 100,you then say, well-- and I ask\nyou whether it's big or small,you have no idea.If the mean is 100 and the\nstandard deviation is 100,it's pretty big.If the mean is a billion and\nthe standard deviation is 100,it's pretty small.So you should never want to look\nat just the standard deviation.All right, here\nis just some codeto compute those, easy enough.Why am I doing this?Because we're now getting\nto the punch line.", "start": 2040.0, "heat": 0.115}, {"text": "We often try and estimate\nvalues just by giving the mean.So we might report on an exam\nthat the mean grade was 80.It's better instead\nof trying to describean unknown value by it--an unknown parameter\nby a single value,say the expected return on\nbetting a roulette wheel,to provide a\nconfidence interval.So what a confidence\ninterval is isa range that's likely to\ncontain the unknown value,and a confidence that\nthe unknown value iswithin that range.So I might say on\na fair roulettewheel I expect that your\nreturn will be between minus 1%and plus 1%, and I expect that\nto be true 95% of the timeyou play the game if you\nplay 100 rolls, spins.If you take 100 spins\nof the roulette wheel,I expect that 95% of\nthe time your returnwill be between this and that.So here, we're saying the return\non betting a pocket 10 times,10,000 times in European\nroulette is minus 3.3%.I think that was the\nnumber we just saw.And now I'm going to add to\nthat this margin of error,which is plus or minus 3.5%\nwith a 95% level of confidence.What does this mean?If I were to conduct an\ninfinite number of trialsof 10,000 bets each, my\nexpected average return", "start": 2160.0, "heat": 0.1}, {"text": "would indeed be\nminus 3.3%, and itwould be between these\nvalues 95% of the time.I've just subtracted\nand added this 3.5,saying nothing about\nwhat would happenin the other 5% of the time.How far away I\nmight be from this,this is totally silent\non that subject.Yes?AUDIENCE: I think\nyou want 0.2 not 9.2.JOHN GUTTAG: Oh, let's see.Yep, I do.Thank you.We'll fix it on the spot.This is why you have\nto come to lecturerather than just\nreading the slides,because I make mistakes.Thank you, Eric.All right, so it's telling me\nthat, and that's all it means.And it's amazing how\noften people don't quiteknow what this means.For example, when they\nlook at a political poleand they see how many votes\nsomebody is expected to get.And they see this\nconfidence interval and say,what does that really mean?Most people don't know.But it does have a very precise\nmeaning, and this is it.How do we compute\nconfidence intervals?Most of the time we compute\nthem using somethingcalled the empirical rule.Under some assumptions, which\nI'll get to a little bit later,the empirical rule says that if\nI take the data, find the mean,compute the standard\ndeviation as we've just seen,68% of the data will be within\none standard deviation in frontof or behind the mean.", "start": 2280.0, "heat": 0.174}, {"text": "Within one standard\ndeviation of the mean.95% will be within 1.96\nstandard deviations.And that's what\npeople usually use.Usually when people talk\nabout confidence intervals,they're talking about the\n95% confidence interval.And they use this 1.6 number.And 99.7% of the data\nwill be within threestandard deviations.So you can see if you are\noutside the third standarddeviation, you are\na pretty rare bird,for better or worse\ndepending upon which side.All right, so let's\napply the empirical ruleto our roulette game.So I've got my three\nroulette games as before.I'm going to run a\nsimple simulation.And the key thing\nto notice is reallythis print statement here.Right, that I'll print the\nmean, which I'm rounding.And then I'm going to give\nthe confidence intervals,plus or minus, and I'll just\ntake the standard deviationtimes 1.6 times\n100, y times 100,because I'm showing\nyou percentages.All right so again, very\nstraightforward code.Just simulation, just like the\nones we've been looking at.And well, I'm just going--I don't think I'll\nbother running it for youin the interest of time.You can run it yourself.But here's what I\ngot when I ran it.So when I simulated betting\na pocket for 20 trials,we see that the--of 1,000 spins each,\nfor 1,000 spins", "start": 2400.0, "heat": 0.3}, {"text": "the expected return for fair\nroulette happened to be 3.68%.A bit high.But you'll notice the confidence\ninterval plus or minus27 includes the actual\nanswer, which is 0.And we have very large\nconfidence intervalsfor the other two games.If you go way down to the bottom\nwhere I've spun, spun the wheelmany more times,\nwhat we'll see isthat my expected return for fair\nroulette is much closer to 0than it was here.But more importantly,\nmy confidence intervalis much smaller, 0.8.So now I really have\nconstrained it pretty well.Similarly, for the other\ntwo games you will see--maybe it's more accurate,\nmaybe it's less accurate,but importantly the confidence\ninterval is smaller.So I have good reason to believe\nthat the mean I'm computingis close to the true mean,\nbecause my confidenceinterval has shrunk.So that's the really\nimportant concept here,is that we don't just guess--compute the value\nin the simulation.We use, in this case,\nthe empirical ruleto tell us how much faith we\nshould have in that value.All right, the empirical\nrule doesn't always work.There are a couple\nof assumptions.One is that the mean\nestimation error is 0.What is that saying?That I'm just as likely\nto guess high as gas low.In most experiments of this\nsort, most simulations,", "start": 2520.0, "heat": 0.253}, {"text": "that's a very fair assumption.There's no reason to guess\nI'd be systematically offin one direction or another.It's different when you use\nthis in a laboratory experiment,where in fact, depending upon\nyour laboratory technique,there may be a bias in your\nresults in one direction.So we have to assume that\nthere's no bias in our errors.And we have to assume that\nthe distribution of errorsis normal.And we'll come back to\nthis in just a second.But this is a\nnormal distribution,called the Gaussian.Under those two assumptions\nthe empirical rulewill always hold.All right, let's talk\nabout distributions,since I just introduced one.We've been using a\nprobability distribution.And this captures the notion\nof the relative frequencywith which some random variable\ntakes on different values.There are two kinds. , Discrete\nand these when the values aredrawn from a finite\nset of values.So when I flip\nthese coins, thereare only two possible\nvalues, head or tails.And so if we look at the\ndistribution of headsand tails, it's pretty simple.We just list the\nprobability of heads.We list the\nprobability of tails.We know that those two\nprobabilities must add up to 1,and that fully describes\nour distribution.Continuous random variables\nare a bit trickier.They're drawn from a set of\nreals between two numbers.For the sake of\nargument, let's saythose two numbers are 0 and 1.Well, we can't just\nenumerate the probability", "start": 2640.0, "heat": 0.213}, {"text": "for each number.How many real numbers are\nthere between 0 and 1?An infinite number, right?And so I can't say, for each of\nthese infinite numbers, what'sthe probability of it occurring?Actually the probability is\nclose to 0 for each of them.Is 0, if they're truly infinite.So I need to do\nsomething else, and whatI do that is what's called the\nprobability density function.This is a different kind of\nPDF than the one Adobe sells.So there, we don't\ngive the probabilityof the random variable\ntaking on a specific value.We give the\nprobability of it lyingsomewhere between two values.And then we define a curve,\nwhich shows how it works.So let's look at an example.So we'll go back to\nnormal distributions.This is-- for the continuous\nnormal distribution,it's described by this function.And for those of you who don't\nknow about the magic number e,this is one of many\nways to define it.But I really don't care\nwhether you remember this.I don't care whether\nyou know what e is.I don't care if you\nknow what this is.What we really want to say\nis, it looks like this.In this case, the mean is 0.It doesn't have to be 0.I've shown a mean of 0 and\na standard deviation of 1.This is called the so-called\nstandard normal distribution.But it's symmetric\naround the mean.And that gets back to,\nit's equally likelythat our errors are in\neither direction, right?So it peaks at the mean.The peak is always at the mean.That's the most\nprobable value, and it's", "start": 2760.0, "heat": 0.156}, {"text": "symmetric about the mean.So if we look at it,\nfor example, and I say,what's the probability of the\nnumber being between 0 and 1?I can look at it here\nand say, all right,let's draw a line\nhere, and a line here.And then I can integrate\nthe curve under here.And that tells me\nthe probabilityof this random variable\nbeing between 0 and 1.If I want to know\nbetween minus 1 and 1.I just do this and then I\nintegrate over that area.All right, so the area\nunder the curve in this casedefines the likelihood.Now I have to divide and\nnormalize to actually getthe answer between 0 and 1.So the question\nis, what fractionof the area under the curve\nis between minus 1 and 1?And that will tell\nme the probability.So what does the\nempirical rule tell us?What fraction is between\nminus 1 and 1, roughly?Yeah?68%, right?So that tells me 68% of\nthe area under this curveis between minus 1 and 1,\nbecause my standard deviationis 1, roughly 68%.And maybe your eyes\nwill convince youthat's a reasonable guess.OK, we'll come back and look\nat this in a bit more detailon Monday of next week.And also look at\nthe question of,why does this work\nin so many caseswhere we don't actually\nhave a normal distributionto start with?", "start": 2880.0, "heat": 0.134}]