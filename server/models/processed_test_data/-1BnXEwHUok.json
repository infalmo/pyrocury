[{"text": "The following content is\nprovided under a CreativeCommons license.Your support will help\nMIT OpenCourseWarecontinue to offer high quality\neducational resources for free.To make a donation or to\nview additional materialsfrom hundreds of MIT courses,\nvisit MIT OpenCourseWareat ocw.mit.edu.JOHN GUTTAG: So\ntoday, we're goingto move on to a fairly\ndifferent world than the worldwe've been living in.And this will be a\nworld we'll be living infor quite a few lectures.But before I do that,\nI want to get backto just finish up something\nthat Professor Grimson started.You may recall he talked\nabout family treesand raised the question,\nwas it actuallypossible to represent all\nancestral relationshipsas a tree?Well, as a counterexample,\nI'm sure some of youare familiar with Oedipus Rex.For those of you\nwho are not, I'mhappy give you a plot summary\nat the end of the lecture.It's a rather bizarre plot.But it was captured in a\nwonderful song by Tom Lehrer.The short story is Oedipus\nended up marrying his motherand having four children.And Tom Lehrer, if you've\nnever heard of Tom Lehrer,you're missing one of the\nworld's funniest songwriters.And he had a wonderful\nsong called \"Oedipus Rex,\"and I recommend this YouTube as\na way to go and listen to it.And you can gather from the\nquote what the story is about.I also recommend the\nplay, by the way.It's really kind of\nappalling what goes on,but it's beautiful.Back to the main topic,\nhere's the relevant reading--a small bit from later in\nthe book and then chapter 14.", "start": 0.0, "heat": 0.1}, {"text": "You may notice that\nwe're not actually goingthrough the book in order.And the reason we're not\ndoing that is because we'retrying to get you\ninformation you need in timeto do problem sets.So the topic of today is\nreally uncertainty and the factthat the world is really\nannoyingly hard to understand.This is a signpost\nrelated to 6.0002,but we won't go into too\nmuch detail about it.We'd rather things were certain.But in fact, they\nusually are not.And this is a place\nwhere 6.0002 divergesfrom the typical\nintroductory computer sciencecourse, which focuses on\nthings that are functional--given an input, you always\nget the same output.It's predictable.And we like to do that,\nbecause that's easier to teach.But in fact, for reasons\nwe'll be talking about,it's not nearly as\nuseful if you'retrying to actually\nwrite computations thathelp you understand the world.You have to face\nuncertainty head on.An analogy is for many\nyears people, believedin Newtonian mechanics--I guess they still\ndo in 8.01 maybe--that every effect has a cause.An apple falls from the\ntree because of gravity,and you know where\nit's going to land.And the world can be\nunderstood causally.And people believed this\nreally for quite a long time,most of history,\nuntil the early partof the 20th century, when\nthe so-called Copenhagendoctrine was put forth.", "start": 120.0, "heat": 0.356}, {"text": "The doctrine there from\nBohr and Heisenberg,two very famous\nphysicists, was oneof what they called\ncausal nondeterminism.And their assertion was that\nthe world at its very mostfundamental level behaves in\na way that you cannot predict.It's OK to make a statement that\nx is highly likely to occur,almost certain to occur,\nbut for no case canyou make a statement\nx will occur.Nothing has a\nprobability of one.This was hard for us to\nimagine today, when we allknow quantum mechanics.But at the turn of the century,\nthis was a shocking statement.And two other very\nwell-known physicists,Albert Einstein and\nSchrodinger, basicallysaid, no, this is wrong.Bohr, Heisenberg,\nyou guys are idiots.It's just not true.They probably didn't\ncall them idiots.And this is most exemplified\nby Einstein's famous quotethat \"God does not play dice,\"\nwhich is indicative of the factthat this was actually a\ndiscussion that permeatednot just the world of physics,\nbut society in general peoplereally turned it into\nliterally a religious issue,as did Einstein.Well, so now we should\nask the question,does it really matter?And to illustrate\nthat, I need two coins.I forgot to bring\nany coins with me.Does anyone got a\ncoin they can lend me?AUDIENCE: I have some coins.JOHN GUTTAG: All right.Now, this is where I see how\nmuch the students trust me.Do I get a penny?Do I get a silver dollar?So what do we got here?This is someone who's entrusting\nme with quarters, not so bad.So we'll take these quarters,\nand we'll shake them up,", "start": 240.0, "heat": 0.796}, {"text": "and we'll put them\ndown on the table.And now, we'll ask a question--do we have two heads, two\ntails, or one head and one tail?So who thinks we have two heads?Who thinks we have two tails?Who thinks we have one of each?Well, clearly, everyone except\na few people-- for example,the Indians fan, who clearly\nbelieve in the counterfactual--made the most\nprobabilistic decision.But in fact, there is\nno nondeterminism here.I know the answer.And so in some sense,\nit doesn't matterwhether it's deterministic,\nbecause in fact, it'snot causally nondeterministic.The answer is quite clear,\nbut you don't know the answer.And so whether or not the world\nis inherently unpredictable,the fact that we never have\ncomplete knowledge of the worldsuggests that we\nmight as well treatit as inherently unpredictable.And so this is called\npredictive nondeterminism.And this really is\nwhat's going to underlinepretty much everything else\nwe're going to be doing here.No comments about that?I wouldn't do that to you.Thank you.I know you are wishing to\nget interest on the money,but you don't get any.AUDIENCE: Was it heads or tails?JOHN GUTTAG: What was that?So when we think about\nnondeterminism in computation,", "start": 360.0, "heat": 0.456}, {"text": "we use the word\nstochastic process.And that's any\nprocess that's ongoingin which the next state depends\nupon the previous statesin some random element.So typically up till now\nwhen we've written code,one line of code\ndid depended onlyon what the previous\nlines of code did.There was no randomness.Here, we're going\nto have randomness.And we can see the\ndifference if welook at these two\nspecifications of rolling a die.The first one, returns\nan int between 1 and 6,is what I'll call\nunderdetermined.By that I mean you can't tell\nwhat it's going to return.Maybe it will return a different\nnumber each time you call it,but it's not required to.Maybe it will return three\nevery time you call it.The second specification\nrequires randomness.It says, it returns are\nrandomly chosen int.So it requires a\nstochastic implementation.Let's look at how we implement\na random process in Python.We start by importing\nthe library random.This is not to\nsay you can importany random library you want.It's to say you import\nthe library called random.Let me get my pen out of here.And we'll use that a lot.And then we're going to use\nthe function in random calledrandom.choice.It takes as an argument a\nsequence, in this case a list,and randomly chooses\none member of the list.And it chooses it uniformly.It's a uniform distribution.And what that means is\nthat it's equally probablethat it will choose any\nnumber in that list each timeyou call it.", "start": 480.0, "heat": 0.1}, {"text": "We'll later look\nat distributionsthat are not uniform,\nnot equally probable,where things are weighted.But here, it's quite\nsimple, it's just uniform.And then we can test\nit using testRoll--take some number of n and\nrolls the die that many timesand creates a string\ntelling us what we got.So let's consider running this\non, say, testRoll of five.And we'll ask the\nquestion, if we run it,how probable is it that it's\ngoing to return a stringof five 1's?How do we do that?Now, how many people\nhere are either in 6.041or would have taken 6.041?Raise your hand.Oh, good.So very few of you\nknow probability.That helps.So how do we think\nabout that question?Well, probability, to me at\nleast, is all about counting,especially discrete\nprobability, whichis what we're looking at here.What you do is you start by\ncounting the number of eventsthat have the\nproperty of interestand the number of\npossible eventsand divide one by the other.So if we think about\nrolling a die five times,we can enumerate all of\nthe possible outcomesof five rolls.So if we look at that,\nwhat are the outcomes?Well, I could get five 1's.I could get four 1's and a 2\nor four 1's and 3, skip a few.", "start": 600.0, "heat": 0.147}, {"text": "The next one would be three 1's,\na 2 and a 1, then a 2 and 2,and finally, at\nthe end, all 6's.So remember, we\nlooked before at whenwe're looking at optimization\nproblems about binary numbers.And we said we can look at all\nthe possible choices of itemsin the knapsack by a\nvector of 0's and 1's.We said, how many possible\nchoices are there?Well, it depended on how\nmany binary numbers you couldget in that number of digits.Well, here we're doing the same\nthing, but instead of base 2,it's base 6.And so the number of possible\noutcomes of five rollsis quite high.How many of those are five 1's?Only one of them, right?So in order to get the\nprobability of a five 1's, Idivide 1 by 6 to the fifth.Does that makes\nsense to everybody?So in fact, we see\nit's highly unlikely.The probability of a\nfive 1's is quite small.Now, suppose we were to\nask about the probabilityof something else--instead of five 1's, say 53421.It kind of looks more likely\nthan that than five 1'sin a row, but of\ncourse, it isn't, right?Any specific combination\nis equally probable.And there are a lot of them.So this is all the probability\nwe're going to think about wecould think about this way, as\nsimply a matter of counting--the number of possible events,\nthe number of events that havethe property of interest--\nin this case being all 1's--and then simple division.Given that framework, there\nwere three basic facts", "start": 720.0, "heat": 0.144}, {"text": "about probability we're\ngoing to be using a lot of.So one, probabilities\nalways range from 0 to 1.How do we know that?Well, we've got a\nfraction, right?And the denominator is\nall possible events.The numerator is the subset\nof that that's of interest.So it has to range from\n0 to the denominator.And that tells us\nthat the fractionhas to range from 0 to 1.So 1 says it's always\ngoing to happen, 0 never.So if the probability of\nan event occurring is p,what's the probability\nof it not occurring?This follows from\nthe first bullet.It's simply going\nto be 1 minus p.This is a trick that we'll\nfind we'll use a lot.Because it's often\nthe case when youwant to compute the probability\nof something happening,it's easier to compute the\nprobability of it not happeningand subtract it from 1.And we'll see an example\nof that later today.Now, here's the biggie.When events are\nindependent of each other,the probability of all\nof the events occurringis equal to the product of\nthe probabilities of eachof the events occurring.So if the probability of A is\n0.5 and the probability of Bis 0.4, the probability\nof A and B is what?", "start": 840.0, "heat": 0.225}, {"text": "0.5 times 0.4.You guys can figure that out.I think that's 0.2.So you'd expect\nthat, that it shouldbe much smaller than either of\nthe first two probabilities.This is the most\ncommon rule, it'ssomething we use all the\ntime in probabilities,the so-called\nmultiplicative law.We have to be careful\nabout it, however,in that it only holds if\nthe events are actuallyindependent.Two events are independent\nif the outcome of onehas no influence on the\noutcome of the other.So when we roll\nthe die, we assumethat the first\nroll, the outcome,was independent of the--or the second roll was\nindependent of the first roll,independent of the fourth roll.When we looked at\nthe two coins, weassume that heads and\ntails of each coinwas independent\nof the other coin.I didn't, for example,\nlook at one coinand make sure that the\nother one was different.The danger here is\nthat people oftencompute probabilities assuming\nindependence when you don'tactually have independence.So let's look at an example.For those of you familiar\nwith American football,the New England Patriots\nand the Denver Broncosare two prominent teams.And let's look at\ncomputing the probabilityof whether one of them will\nlose on a given Sunday.So the Patriots have a\nwinning percentage of 7 of 8--they've won 7 of\ntheir 8 games so far--and the Broncos 6 of 8.The probability of both\nwinning next Sunday,assuming that this is\nindicative of how good they are,", "start": 960.0, "heat": 0.509}, {"text": "we can get with the\nmultiplicative rule.So it's 7/8 times 6/8, or 42/64.We could simplify that\nfraction, I suppose.Does that makes sense?So this is probably a pretty\ngood estimate of both of themwinning next Sunday.So the probability of at\nleast one of them losingis 1 minus that.So here's an example\nof why we often usethe 1 minus rule,\nbecause we couldcompute the probability\nof both of themwinning by simply multiplying.And we subtract that from 1.However, what about\nSunday, December 18?What's the probability?Well, as it happens,\nthat day the Patriotsare playing the Broncos.So now suddenly, the\noutcomes are not independent.The probability of\none of them losingis influenced by the probability\nof the other winning.So you would expect\nthe probability of oneof them losing is much\ncloser to 1 than 22/64,which is about 1/3.So in this case, it's easy.But as we'll see, as we\nget through the term,there are lots of\ncases where youhave to work pretty hard to\nunderstand whether or not twoevents really are independent.And if you get it wrong, you\nget a totally bogus answer.1/3 versus 1 is a\npretty big difference.By the way, as it happens,\nthe probability of the Broncoslosing is about 1.Let's go look at some code.", "start": 1080.0, "heat": 0.482}, {"text": "And we'll go back to\nour dice, because it'smuch easier to\nsimulate dice gamesthan it is to simulate\nfootball games.So here it is.And we're going to talk\na lot about simulations.So here, rather than\nrolling the die,I've written a program to do it.We've already seen the\ncode for rolling a die.And so to run this simulation,\ntypically what we're doing hereis I'm giving you the goal--for example, are we\ngoing to get five 1's--the number of trials--each trial, in this case,\nwill be say of length 5--so I'm going to\nroll the same diefive times say 1,000 different\ntimes, and then just some textas to what I'm going to print.Almost all the\nsimulations we look atare going to start with lines\nthat look a lot like that.We're going to\ninitialize some variable.And then we're going to\nrun some number of trials.So in this case,\nwe're going to getfrom the length of the goal--so if the goal is\nfive 1's, then we'regoing to roll the dice five\ntimes; if it's 10 runs,we'll roll it 10 times.So this is essentially\none trial, one attempt.And then we'll check\nthe result. And if ithas the property we want--in this case, it's\nequal to the goal--then we're going to\nincrement the total, whichwe initialized up here by 1.So we'll keep track\nwith just the counting--the number of trials that\nactually meet the goal.", "start": 1200.0, "heat": 0.219}, {"text": "And then when we're done,\nwhat we're going to dois divide the number\nthat met the goalby the number of trials--exactly the counting\nargument we just looked at.And then we'll print the result.Almost every\nsimulation we look atis going to have this structure.There'll be an outer loop,\nwhich is the number of trials.And then inside-- maybe\nit'll have a loop,or maybe it won't--\nwill be a single trial.We'll sum up the results.And then we'll divide\nby the number of trials.Let's run it.So a couple of things\nare going to go on here.If you look at the code as\nwe've looked at it before,what you're seeing is I'm\ncomputing the estimatedprobability by the simulation.And I'm comparing it to the\nactual probability, which we'vealready seen how to compute.So if you look at it, there are\na couple of things to look at.The estimated\nprobability is prettyclose to the actual\nprobability but not the same.So let's go back\nto the PowerPoint.Here are the results.And there are at least\ntwo questions raisedby this result.\nFirst of all, howdid I know that this is\nwhat would get printed?Remember, this is random.How did I know that the\nestimate-- well, there'snothing random about\nthe actual probability.But how did I know that\nthe estimated probabilitywould be 0?And why did it print it twice?Because I messed\nup the PowerPoint.", "start": 1320.0, "heat": 0.1}, {"text": "Any rate, so how do I know\nwhat would get printed?Well a confession--\nrandom.choiceis not actually random.In fact, nothing we can do in\na computer is actually random.You can prove that it's\nimpossible to builda computer that actually\ngenerates truly random numbers.What they do instead\nis generate numbersthat called pseudorandom.How do they do that?They have an algorithm that\ngiven one number generatesthe next number in a sequence.And they start that\nalgorithm with a seed.Now, typically,\nthey get that seedby reading the clock\nof the computer.So most computers have\na clock that, say,keeps track of the number of\nmicroseconds since January 1,1978.I don't know if\nthat's still true.That's what Unix used to do.So the notion is, you\nstart your program,there's no way of knowing how\nmany microseconds have elapsed.And so you're getting a random\nnumber to start the process.Since you don't know\nwhere it starts,you don't know what\nthe second numberis, you don't know what the\nthird number is, you don'tknow what the fourth number is.And so it's predictably\nnondeterministic,because you don't know what\nthe seed is going to be.Now, you can imagine\nthat this makesprograms really hard to debug.Every time you run it, something\ndifferent could happen.Now, we'll see often you want\nthem to be unpredictable.But for now, we want them to\nbe predictable, makes it easier", "start": 1440.0, "heat": 0.415}, {"text": "prepare PowerPoint.So what you have is a command.You can call random.seed\nand give it a valueand say, I don't want you to\njust choose some random seed,I want you to use 0 as the seed.For the same seed, you\nalways get the same sequenceof random values.And so what I've done is I\nset the seed to be, I think, 0in this case, not because\nthere's anything magic about 0,it's just sort of habit.But it made it predictable.As you write programs\nwith randomnessin and when you're debugging\nit, you will almost surelywant to start by setting\nrandom.seed to a valueso you get the same answer.But make sure you debug it with\nmore than one value of this,so you didn't just get\nlucky with your seed.So that's how I knew\nwhat would get printed.The next question is,\nwhy did the simulationgive me the wrong answer?The actual probability\nis three 0's and 1286.But it's estimated\na probability of 0.Why is it wrong?Well, let's think about this.I ran 1,000 trials.What does it mean to say\nthe probability is zero?It means that I tried it 1,000\ntimes and didn't ever geta sequence of five 1's.So the numerator of the\ndivision at the bottom was 0.Hence, the answer is 0.Is this surprising?Well, no.Because if that's the actual\nprobability of getting five1's, it's not very shocking\nthat in 1,000 trialsit never happened.", "start": 1560.0, "heat": 0.663}, {"text": "It's not a surprising\nresult. And so wehave to be careful when we\nrun these things to understandthe difference between what's in\nthis case an actual probabilityand what statisticians\ncall a sample probability.So what we got with\nthe sample was 0.So what's the\nobvious thing to do?If you're doing a\nsimulation of an eventand the event is\npretty rare, youwant to try it on a very\nlarge number of trials.So let's go back to our code.And we'll change it to\ninstead of 1,000, 1,000,000.You can see up here, by the\nway, where I set the seed.And now, let's run it.We did a lot better.If we look at here our\nestimated probability,it's three 0's 128,\nstill not quitethe actual probability\nbut darn close.And maybe if I had\ndone 10 million,it would have been even closer.So if you're\nwriting a simulationto compute the\nprobability of an eventand the event is\nmoderately rare,then you better\nrun a lot of trialsbefore you believe your\nestimated probability.In a week or so, we'll\nactually look at that moremathematically and\nsay, what is a lot,how do we know what is enough.", "start": 1680.0, "heat": 0.703}, {"text": "What are the morals here?Moral one, I've just told you--takes a lot of trials to get a\ngood estimate of the frequencyof a rare event.Moral two, we should always,\nif we're getting an estimatedprobability, know\nthat, and probablysay that, and not confuse it\nwith the actual probability.The third moral here\nis, it was kind ofstupid to do a simulation.Since it was a very\nsimple closed-form answerthat we could compute\nthat would really tell uswhat the actual\nprobability is, why evenbother with the simulation?Well, we're going\nto see why now,because simulations\ncan be very useful.Let's look at another problem.This is the famous\nbirthday problem.Some of you have seen it.What's the probability of at\nleast two people in a grouphaving the same birthday?There's a URL at the bottom.That's pointing\nto a Google form.I'd like please all of you\nwho have a computing deviceto go to it and fill\nout your birthday.It's anonymous, so we won't know\nhow old you are, don't worry.Actually, it's only the date.It's not the year.So suppose there were 367\npeople in the group, roughlythe number of people who\ntook the 6.0001 600 midterm.If they are 367 people, what's\nthe probability of at least twoof them sharing a birthday?One, by something called\nthe pigeonhole principle.You got some number of holes.And if you have more\npigeons than holes,two pigeons have\nto share a whole.", "start": 1800.0, "heat": 0.607}, {"text": "What about smaller numbers?Well, if we make a\nsimplifying assumptionthat each birthdate\nis equally likely,then there's actually a nice\nclosed-form solution for it.Again, this is a question\nwhere it's easierto compute the opposite\nof what you're tryingto do and subtract it from 1.And so this fraction is giving\nthe probability of two peoplenot sharing a birthday.The proof that this is right,\nit's a little bit elaborate.But you can trust\nme, it's accurate.But it's a formula, and it's\nnot that complicated a formula.So numbers like 366\nfactorial are big.So let's approximate a solution.We'll right a simulation and\nsee if we get the same answerthat that formula gave us.So here's the code for that--two arguments-- the\nnumber of peoplein the group and the\nnumber that we asking dothey have the same birthday.So since I'm assuming for now\nthat every birthday is equallylikely, the possible\ndates range from 1 to 366,because some years\nhave a February 29.I'll keep track of the number\nof people born in each dateby starting with none.And then for p in the\nrange of number of people,I'll make a random choice\nof the possible datesand increment that\nelement of the list by 1.And then at the end,\nwe can say, lookat the maximum\nnumber of birthdaysand see if it's greater than\nor equal to the number of same.So that tells us that.", "start": 1920.0, "heat": 0.89}, {"text": "And then we can actually look\nat the birthday problem--number of people, the number\nof same, and, as usual,the number of trials.So the number of hits is 0 for\nt in range number of trials.If sameDate is true, then\nwe'll increment the numberof hits by 1 and then as usual\ndivide by the number of trials.And we'll try it for 10,\n20, 40, and 100 people.And then just, we'll print\nthe estimated probabilityand the actual\nprobability computed usingthat formula I showed you.I have not shown you,\nbut I've importeda library called\nmath, because itis a factorial implementation.It's way faster than\nthe recursive onethat we've seen before.Let's run it.And we'll see what we get.So for 10, the estimated\nprobability is 0.11 now.So you can see, the estimates\nare really pretty good.Once again, we have this\nbusiness that for 100,we're estimating 1, when the\nreal answer is point many,many 9's.But again, this is\nsample probability.It just means in the number\nof trials we did, every 1for 100 people, there\nwas a shared birthday.This is a number that\nusually surprises people,as to why with 100 people\nthe probability is so high.", "start": 2040.0, "heat": 0.579}, {"text": "But we could work out\nthe formula and see it.And as you can\nsee, the estimatesare pretty good\nfrom my simulation.Now, we're going to see\nwhy we did a simulationin the first place.Suppose we want the probability\nof three people sharinga birthday instead of two.It's pretty easy to see how\nwe changed the simulation.I even made a parameter.I just changed the\nnumber 2 to number 3.The math, on the\nother hand, is ugly.Why is the math so much\nuglier for 3 than for 2?Because for 2, the\ncomplementary problem--the number we're\nsubtracting from 1--is simply the question of,\nare all birthdays different?So did two people share a\nbirthday is 1 minus or alldoes everybody have\na different birthday.On the other hand, for 3 people,\nthe complementary problem isa complicated disjunct--\na bunch of ors--either all birthdays\nare distinct,or two people share a birthday\nand the rest are distinct,or there are two groups of\ntwo people sharing a birthdayand everything is distinct.So you can see here, there's\na lot of possibilities.And so it's 1 minus now a\nvery complicated formula.And in fact, if you try\nand look how to do this,most people will tell\nyou don't bother.Here's kind of a\ngood approximation.But the math gets very hairy.In contrast, changing the\nsimulation is dead easy.We can do that.", "start": 2160.0, "heat": 0.47}, {"text": "Whoops.So if we come over here for\nthe code, all I have to dois change this to 2 or 3.And I'm going to leave\nin this code, whichis the wrong code, computing\nthe actual probability nowfor 2 people sharing rather\nthan 3, because I wantto make it easy for you to see\nthe difference between whathappens when we look at 3\nshared rather than 2 shared.And I get invalid syntax.That's not good.That's what happens when\nI type in real time.Why do I have invalid syntax?AUDIENCE: Line 56.JOHN GUTTAG: Pardon.AUDIENCE: Line 56.JOHN GUTTAG: One person, Anna.AUDIENCE: Line 56,\nthere's a comma.JOHN GUTTAG: Oh.That's not a good line.So now, we see that if we get,\nsay, to n equals 100, for 2,you'll remember, it was 0.99.But for 3, it's only 0.63.So we see going from two\nsharing to three sharinggets us a radically different\nanswer, not surprisingly.But we also-- and the real\nthing I wanted you to see--is how easy it was to\nanswer this questionwith the simulation.", "start": 2280.0, "heat": 0.224}, {"text": "And that's a primary\nreason we use simulationsto get probabilistic\nquestions ratherthan sitting down and\nthe pencil and paperand doing fancy\nprobability calculations,because it's often way\neasier to do a simulation.We can see that in spades if\nwe look at the next question.Let's think about\nthis assumptionthat all birthdays\nare equally likely.Well, as you can\nsee, this is a chartof how common birthdates\nare in the US, a heat map.And you'll see, for\nexample, that February 29is quite an uncommon birthday.So we should probably\ntreat that differently.Somewhat surprisingly,\nyou'll seethat July 4 is a very\nuncommon birthday as well.It's easy to understand\nwhy February 29.The only thing I can\nfigure out for July 4is obstetricians don't\nlike working on holidays.And so they induce\nlabor sometimearound the 2nd or\nthe 3rd, so theydon't have to come to work\non the 4th or the 5th.Sounds a horrible thought.But I can't think of any other\nexplanation for this anomaly.You'll probably,\nif you look at it,see Christmas day is\nnot so common either.So now, the question,\nwhich we cananswer, since you've\nall fill out this form,is how exceptional\nare MIT students?We like to think that you're\ndifferent in every respect.So are your birthdays\ndistributed differentlythan other dates?Have we got that data?So now we'll go look at that.We should have a heat\nmap for you guys.This one?AUDIENCE: Yep.I removed all the February 31.Thank you for those submissions.", "start": 2400.0, "heat": 0.424}, {"text": "[LAUGHTER]JOHN GUTTAG: So here it is.And we can see that,\nwell, they don'tseem to be banded quite as\nmuch in the summer months,probably says more about your\nparents than it does about you.But you can see that,\nindeed, we do have--wow, we have a day\nwhere there arefive birthdays, that look like?Or no?AUDIENCE: February 12.JOHN GUTTAG: Wow.You want to raise your hand\nif you're born on February 12?[LAUGHTER]So you are exceptional in that\nyou lie about when you're born.But if you hadn't lied, I\nthink we would have still seenthe probabilities would hold.How many people were\nthere, do we know?AUDIENCE: 146 with\n112 unique birthdays.JOHN GUTTAG: 146 people,\n112 unique birthdays.So indeed, the\nprobability does work.So we know you're\nexceptional in a funny way.Well, you can\nimagine how hard itwould be to adjust the\nanalytic model to accountfor a weird distribution\nof birthdates.But again, adjusting the\nsimulation model is easy.I could have gone\nback to that heatmap I showed you of\nbirthdays in the USand gotten a separate\nprobability for each day,but I was too lazy.And instead, what I observed\nwas that we had a few days,", "start": 2520.0, "heat": 0.526}, {"text": "like February 29, highly\nunlikely, and this bandin the middle of people\nwho were conceivedin the late fall\nand early winter.So what I did is I\nduplicated some dates.So the 58th day of the year,\nFebruary 29, occurs only once.The dates before\nthat, I said, let'spretend they occur four times.What only matters\nhere is not how oftenthey occur but the\nrelative frequency.And then the dates after\nthat occur four timesexcept for the dates in\nthat band, which is goingto have occur yet more often.So now-- and don't worry\nabout the exact details here--but what I'm doing is simply\nadjusting the simulationto change the probability\nof each date gettingchosen by same date.And then I can run\nthe simulation model.And, again, with a very\nsmall change to code,I've modeled something\nthat's mathematicallyenormously complex.I have no idea how to\nactually do this probabilitymathematically.But the code is, as you can\nsee, quite straightforward.So let's go to that here.So what I'm going to do\nis comment this one outand uncomment this more\ncomplicated set of dates", "start": 2640.0, "heat": 0.291}, {"text": "and see what we get.And again, it changes\nquite dramatically.You might remember, before\nit was around I think0.6-something for 100,\nand now, it's 0.75.So getting away from the notion\nthat birthdays are uniformlydistributed to saying\nsome birthdays aremore common than others,\nagain, dramatically changesthe answer.And we can easily look at that.So that gets us to the big\ntopic of simulation models.It's a program that\ndescribes a computation thatprovides information about the\npossible behaviors of a system.I say possible\nbehaviors, because I'mparticularly interested\nin stochastic systems.They're descriptive not\nprescriptive in the sensethat they describe\nthe possible outcomes.They don't tell you how to\nachieve possible outcomes.This is different\nfrom what we'velooked at earlier in\nthe course, where welooked at optimization models.So an optimization\nmodel is prescriptive.It tells you how to\nachieve an effect,how to get the most value\nout of your knapsack,how to find the shortest\npath from A to B in a graph.In contrast, a\nsimulation model says,if I do this,\nhere's what happens.It doesn't tell you how to\nmake something happened.So it's very\ndifferent, and it's whywe need both, why we\nneed optimization modelsand we need simulation models.", "start": 2760.0, "heat": 0.133}, {"text": "We have to remember that\na simulation model is onlyan approximation to reality.I put in an approximation to\nthe distribution of birthdates,but it wasn't quite right.And as the very famous\nstatistician George Box said,\"all models are wrong, but\nsome are actually very useful.\"In the next lecture, we'll look\nat a useful class of models.When do we use simulations?Typically, as we've just\nshown, to model systems thatare mathematically intractable,\nlike the birthday problemwe just looked at.In other situations, to\nextract intermediate results--something happens along\nthe way to the answer.And as I hope you've\nseen that simulationsare used because we can play\nwhat if games by successivelyrefining it.We started with a\nsimple simulationthat assumed that we only\nasked the question of, dotwo people share a birthday.We showed how we could change\nit to ask do three people sharea birthday.We then saw that\nwe could change itto assume a different\ndistribution of birthdatesin the group.And so we can start\nwith something simple.And we get it ever\nmore complexedto answer questions what if.We're going to start\nin the next lectureby producing a simulation\nof a random walk.And with that, I'll stop.And see you guys soon.", "start": 2880.0, "heat": 0.224}]