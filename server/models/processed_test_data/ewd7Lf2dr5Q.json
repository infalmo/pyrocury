[{"text": "ANNOUNCER: Open content is\nprovided under a creativecommons license.Your support will help MIT\nOpenCourseWare continue tooffer high-quality educational\nresources for free.To make a donation, or view\nadditional materials fromhundreds of MIT courses, visit\nMIT OpenCourseWare atocw.mit.edu .PROFESSOR ERIC GRIMSON: Last\ntime, we ended up, we sort ofdid this tag team thing,\nProfessor Guttag did the firsthalf, I did the second half of\nthe lecture, and the secondhalf of the lecture, we\nstarted talking aboutcomplexity.Efficiency.Orders of growth.And that's what we're going to\nspend today on, is talkingabout that topic.I'm going to use it\nto build over thenext couple of lectures.I want to remind you that we\nwere talking at a fairly highlevel about complexity.We're going to get down into\nthe weeds in a second here.But the things we were trying\nto stress were that it's animportant design decision, when\nyou are coming up with apiece of code, as to what kind\nof efficiency your code has.And the second thing that we\ntalked about is this idea thatwe want you to in fact learn\nhow to relate a choice youmake about a piece of\ncode to what theefficiency is going to be.So in fact, over the next thirty\nor forty minutes, we'regoing to show you a set of\nexamples of sort of canonicalalgorithms, and the different\nclasses of complexity.Because one of the things that\nyou want to do as a gooddesigner is to basically\nmap a new probleminto a known domain.You want to take a new problem\nand say, what doesthis most look like?What is the class of algorithm\nthat's-- that probably appliesto this, and how do I pull\nsomething out of that, if youlike, a briefcase of possible\nalgorithms to solve?All right, having said that,\nlet's do some examples.I'm going to show you a sequence\nof algorithms,they're mostly simple\nalgorithms, that's OK.But I want you to take away from\nthis how we reason aboutthe complexity of these\nalgorithms. And I'll remindyou, we said we're going to\nmostly talk about time.We're going to be counting the\nnumber of basic steps it takesto solve the problem.So here's the first example\nI want to do.I'm going to write a function\nto compute integer powerexponents. a to the b where\nb is an integer.", "start": 0.0, "heat": 1.0}, {"text": "And I'm going to do it only\nusing multiplication andaddition and some simple tests.All right?And yeah, I know it comes built\nin, that's OK, what wewant to do is use it as an\nexample to look at it.So I'm going to build something\nthat's going to doiterative exponentiation.OK?And in fact, if you look at the\ncode up here, and it's onyour handout, the very first\none, x 1, right here-- if Icould ask you to look at it--\nis a piece of code to do it.And I'm less interested in the\ncode than how we're going toanalyze it, but let's look\nat it for a second.All right, you can see that\nthis little piece of code,it's got a loop in there,\nand what's it doing?It's basically cycling\nthrough the loop,multiplying by a each time.So first time through the\nloop, the answer is 1.Second time it-- sorry, as it\nenters the loop, at the timeit enter-- exits,\nthe answer is a.Next time through the loop\nit goes to a squared.Next time through the loop\nit goes to a cubed.And it's just gathering together\nthe multiplicationswhile counting down\nthe exponent.And you can see it when we get\ndown to the end test here,we're going to pop out of\nthere and we're going toreturn the answer.I could run it, it'll\ndo the right thing.What I want to think about\nthough, is, how muchtime does this take?How many steps does it take\nfor this function to run?Well, you can kind of\nlook at it, right?The key part of that\nis that WHILE loop.And what are the steps\nI want to count?They're inside that loop--I've got the wrong glasses so\nI'm going to have to squint--and we've got one test which\nis a comparison, we've gotanother test which is a\nmultiplication-- sorry, not atest, we've got another step\nwhich is a multiplication--and another step that\nis a subtraction.So each time through the loop,\nI'm doing three steps.Three basic operations.How many times do I go\nthrough the loop?Somebody help me out.Hand up?Sorry. b times.You're right.Because I keep counting down\neach time around-- mostly I'vegot to unload this candy, which\nis driving me nuts, so--thank you. b times.", "start": 120.0, "heat": 0.1}, {"text": "So I've got to go 3 b steps.All right, I've got to go\nthrough the loop b times, I'vegot three steps each time, and\nthen when I pop out of theloop, I've got two more steps.All right, I've got the\ninitiation of answer and thereturn of it.So I take 2 plus 3 b steps\nto go through this loop.OK.So if b is 300, it takes 902\nsteps. b is 3000, it takes9002 steps. b is 30,000\nyou get the point, ittakes 90,002 steps.OK.So the point here is, first of\nall, I can count these things,but the second thing you can\nsee is, as the size of theproblems get larger, that\nadditive constant, that 2,really doesn't matter.All right?The difference between 90,000\nsteps and 90,002 steps, whocares about the 2, right?So, and typically, we're not\ngoing to worry about thoseadditive constants.The second one is, this\nmultiplicative constant hereis 3, in some sense also\nisn't all that crucial.Does it really matter to you\nwhether your code is going totake 300 years or 900\nyears to run?Problem is, how big\nis that number?So we're going to typically\nalso not worry about themultiplicative constants.This factor here.What we really want to worry\nabout is, as the size of theproblem gets larger, how\ndoes this thing grow?How does the cost go up?And so what we're going to\nprimarily talk about as aconsequence is the rate of\ngrowth as the size of theproblem grows.If it was, how much bigger does\nthis get as I make theproblem bigger?And what that really says is,\nthat we're going to use thisusing something we're\ngoing to justcall asymptotic notation--", "start": 240.0, "heat": 0.1}, {"text": "I love spelling this word--\nmeaning, as in the limit asthe size of the problem gets\nbigger, how do I characterizethis growth?All right?You'll find out, if you go on\nto some of the other classesin course 6, there are a lot of\ndifferent ways that you canmeasure this.The most common one, and the\none we're going to use, iswhat's often called\nbig Oh notation.This isn't big Oh as in, oh my\nGod I'm shocked the marketsare collapsing, This is called\nbig Oh because we use theGreek letter, capital letter,\nomicron to represent it.And the way we're going to do\nthis, or what this represents,let me write this carefully for\nyou, big Oh notation isbasically going to be an upper\nlimit to the growth of afunction as the input grow--\nas the input gets large.Now we're going to see a bunch\nof examples, and I know thoseare words, let me give\nyou an example.I would write f of x is in\nbig Oh of n squared.And what does it say?It says that function, f of x,\nis bounded above, there's anupper limit on it, that this\ngrows no faster than quadraticin n, n squared.OK.And first of all, you say,\nwait a minute, x and n?Well, one of the things we're\ngoing to see is x is the inputto this particular problem, n is\na measure of the size of x.And we're going to talk about\nhow we come up with that. nmeasures the size of x.OK.In this example I'd use b.All right, as b get-- b is the\nthing that's changing as I goalong here, but it could be\nthings like, how many elementsare there in a list if the input\nis a list, could be howmany digits are there in a\nstring if the input's astring, it could be the size of\nthe integer as we go along.", "start": 360.0, "heat": 0.1}, {"text": "All right.?And what we want to do then, is\nwe want to basically comeup with, how do we characterize\nthe growth--God bless you-- of this problem\nin terms of thisquadra-- sorry, terms of\nthis exponential growthNow, one last piece of math.I could cheat.I said I just want\nan upper bound.I could get a really big upper\nbound, this thing growsexponentially.That doesn't help me much.Usually what I want to talk\nabout is what's the smallestsize class in which this\nfunction grows?With all of that, what that\nsays, is that this we wouldwrite is order b.That algorithm is linear.You can see it.I've said the product\nwas is 2 plus 3 b.As I make b really large, how\ndoes this thing grow?It grows as b.The 3 doesn't matter, it's\njust a constant,it's growing linearly.Another way of saying it is,\nif I, for example, increasethe size of the input by\n10, the amount of timeincreases by 10.And that's a sign that\nit's linear.OK.So there's one quick example.Let's look at another example.If you look at x 2, this one\nright here in your handout.OK.This is another way of doing\nexponentiation, but this one'sa recursive function.All right?So again, let's look at it.What does it say to do?Well, it's basically saying\na similar thing.It says, if I am in the base\ncase, if b is equal to 1, theanswer is just a.I could have used if b is equal\nto 0, the answer is 1,that would have also worked.Otherwise, what do I say?I say, ah, I'm in a nice\nrecursive way, a to the b isthe same as a times a\nto the b minus 1.And I've just reduced that\nproblem to a simpler versionof the same problem.OK, and you can see that this\nthing ought to unwrap, it'sgoing to keep extending out\nthose multiplications untilgets down to the base\ncase, going tocollapse them all together.OK.Now I want to know what's the\norder of growth here?What's the complexity of this?", "start": 480.0, "heat": 0.123}, {"text": "Well, gee.It looks like it's pretty\nstraightforward, right?I've got one test there, and\nthen I've just got one thingto do here, which has got\na subtraction and amultiplication.Oh, but how do I know how\nlong it takes to do x 2?All right, we were counting\nbasic steps.We don't know how long\nit takes to do x 2.So I'm going to show you\na little trick forfiguring that out.And in particular, I'm going to\ncheat slightly, I'm goingto use a little bit of abusive\nmathematics, but I'm going toshow you a trick to\nfigure it out.In the case of a recursive\nexponentiator, I'm going to dothe following trick.I'm going to let t of b be the\nnumber of steps it takes tosolve the problem of size b.OK, and I can figure this out.I've got one test, I've got\na subtraction, I've got amultiplication, that's three\nsteps, plus whatever number ofsteps it takes to solve a\nproblem of size b minus 1.All right, this is what's called\na recurrence relation,there are actually cool\nways to solve them.We can kind of eyeball it.In particular, how would I\nwrite an expression fort of b minus 1?Well the same way.This is 3 plus 3 plus\nt of b minus 2.Right?I'm using exactly the same\nform to reduce this.You know, you can see what's\ngoing to happen.If I reduce that, it would be\n3 plus t of b minus 3, so ingeneral, this is 3 k plus\nt of b minus k.OK.I'm just expanding it out.When am I done?How do I stop this?Any suggestions?Don't you hate it when\nprofessors ask questions?Yeah.Actually, I think I want\nb minus k equal to 1.Right?When this gets down to t of\n1, I'm in the base case.So I'm done when b minus\nk equals 1, or k", "start": 600.0, "heat": 0.152}, {"text": "equals b minus 1.Right, that gets me down to the\nbase case, I'm solving aproblem with size 1, and in that\ncase, I've got two moreoperations to do, so I plug this\nall back in, I-- t of bis I'm going to put k for b\nminus 1 I get 3 b minus 1 plust of 1, so t of 1 is 2, so this\nis 3 b minus 1 plus 2, or3 b minus 1.OK.A whole lot of work\nto basically say,again, order b is linear.But that's also nice, it lets\nyou see how the recursivething is simply unwrapping but\nthe complexity in terms of theamount of time it takes is\ngoing to be the same.I owe you a candy.Thank you.OK.At this point, if we stop,\nyou'll think all algorithmsare linear.This is really boring.But they're not.OK?So let me show you another way\nI could do exponentiation.Taking an advantage\nof a trick.I want to solve a to the b.Here's another way\nI could do that.OK.If b is even, then a to the b\nis the same as a squared allto the b over 2.All right, just move\nthe 2's around.It's the same thing.You're saying, OK, so what?Well gee, notice.This is a primitive operation.That's a primitive operation.But in one step, I've reduced\nthis problem in half.I didn't just make\nit one smaller, Imade it a half smaller.That's a nice deal.OK.But I'm not always going\nto have b as even.If b is odd, what do I do?Well, go back to what\nI did before.Multiply a by a to\nthe b minus 1.You know, that's nice, right?", "start": 720.0, "heat": 0.206}, {"text": "Because if b was odd, then b\nminus one is even, which meanson the next step, I can cut\nthe problem in half again.OK?All right. x 3, as you can see\nright here, does exactly that.OK?You can take a quick look at\nit, even with the wrongglasses on, it says if a--\nsorry, b is equal to 1, I'mjust going to return a.Otherwise there's that funky\nlittle test. I'll do theremainder multiplied by 2,\nbecause these are integers,that gives me back an integer,\nI just check to see if it'sequal to b, that tells me\nwhether it's even or odd.And in the even case, I'd\nsquare, divide by half, callthis again: in the odd case,\nI go b minus 1 andthen multiply by a.I'll let you chase it through,\nit does work.What I want to look\nat is, what's theorder of growth here?This is a little different,\nright?It's going to take a little bit\nmore work, so let's see ifwe can do it.In the b even case, again I'm\ngoing to let t of b be thenumber of steps I want\nto go through.And we can kind of eyeball\nthis thing, right?If b is even, I've got a test to\nsee if b is equal to 1, andthen I've got to do the\nremainder, the multiplication,and the test, I'm up to four.And then in the even case, I've\ngot to do a square andthe divide.So I've got six steps, plus\nwhatever it takes to solve theproblem size b over 2, right?Because that's the recursive\ncall. b as odd, well I can gothrough the same\nkind of thing.I've got the same first four\nsteps, I've got a check to seeis it 1, I got a check to see if\nit's even, and then in theodd case, I've got to subtract 1\nfrom b, that's a fifth step,I've got to go off and solve\nthe recursive problem, andthen I'm going to do one more\nmultiplication, so it's 6plus, in this case,\nt of b minus 1.Because it's now solving\na one-smaller problem.On the next step though, this,\nwe get substituted by that.", "start": 840.0, "heat": 0.293}, {"text": "Right, on the next step, I'm\nback in the even case, it'sgoing to take six more steps,\nplus t of b minus 1.Oops, sorry about\nthat, over 2.Because b minus 1 is now even.Don't sweat the details here,\nI just want you to see thereason it goes through it.What I now have, though,\nis a nice thing.It says, in either case, in\ngeneral, t of b-- and this iswhere I'm going to abuse\nnotation a little bit-- but Ican basically bound it by t, 12\nsteps plus t of b over 2.And the abuse is, you know,\nit's not quite right, itdepends upon whether it's all\nready, but you can see ineither case, after 12 steps, 2\nruns through this and down toa problem size b over 2.Why's that nice?Well, that then says after\nanother 12 steps, we're downto a problem with size\nt of b over 4.And if I pull it out one more\nlevel, it's 12 plus 12 plus tof b over 8, which in general is\ngoing to be, after k steps,12 k because I'll have 12 of\nthose to add up, plus t of bover 2 to the k.When am I done?When do I get down\nto the base case?Somebody help me out.What am I looking for?Yeah.You're jumping slightly ahead of\nme, but basically, I'm donewhen this is equal\nto 1, right?Because I get down to the base\ncase, so I'm done when b u isover 2 to the k is equal to 1,\nand you're absolutely right,that's when k is log\nbase 2 of b.You're sitting a long ways back,\nI have no idea if I'llmake it this far or not.Thank you.OK.There's some constants\nin there, but thisis order log b.Logarithmic.This matters.", "start": 960.0, "heat": 0.273}, {"text": "This matters a lot.And I'm going to show you an\nexample in a second, just todrive this home, but notice\nthe characteristics.In the first two cases,\nthe problem reducedby 1 at each step.Whether it was recursive\nor iterative.That's a sign that it's\nprobably linear.This case, I reduced the size\nof the problem in half.It's a good sign that this is\nlogarithmic, and I'm going tocome back in a second to why\nlogs are a great thing.Let me show you one more class,\nthough, about-- sorry,let me show you two more classes\nof algorithms. Let'slook at the next one g-- and\nthere's a bug in your handout,it should be g of n and m, I\napologize for that, I changedit partway through and\ndidn't catch it.OK.Order of growth here.Anybody want to volunteer\na guess?Other than the TAs, who know?OK.Let's think it through.I've got two loops.All right?We already saw with one of the\nloops, you know, it lookedlike it might be linear,\ndepending on what's inside ofit, but let's think\nabout this.I got two loops with g.What's g do?I've got an initialization of\nx, and then I say, for i inthe range, so that's basically\nfrom 0 up to n minus1, what do I do?Well, inside of there, I've got\nanother loop, for j in therange from 0 up to m minus 1.What's the complexity\nof that inner loop?Sorry?OK.You're doing the whole\nthing for me.What's the complexity just\nof this inner loop here?Just this piece.How many times do I go\nthrough that loop? m.Right?I'm going to get back to your\nanswer in a second, becauseyou're heading in the\nright direction.The inner loop, this part\nhere, I do m times.There's one step inside of it.Right?How many times do I go\nthrough that loop?Ah, n times, because for each\nvalue of i, I'm going to dothat m thing, so that is, close\nto what you said, right?The order complexity here, if\nI actually write it, wouldbe-- sorry, order n times m, and\nif m was equal to n, that", "start": 1080.0, "heat": 0.109}, {"text": "would be order n squared,\nand this is quadratic.And that's a different\nbehavior.OK.What am I doing?Building up examples of\nalgorithms. Again, I want youto start seeing how to map the\ncharacteristics of the code--the characteristics of the\nalgorithm, let's not call itthe code-- to the complexity.I'm going to come back to that\nin a second with that, but Ineed to do one more example,\nand I've got to use myhigh-tech really expensive\nprops.Right.So here's the fourth or fifth,\nwhatever we're up to, I guessfifth example.This is an example of a problemcalled Towers of Hanoi.Anybody heard about\nthis problem?A few tentative hands.OK.Here's the story as\nI am told it.There's a temple in the\nmiddle of Hanoi.In that temple, there\nare three very largediamond-encrusted posts, and on\nthose posts are sixty-fourdisks, all of a different\nsize.And they're, you know, covered\nwith jewels and all sorts ofother really neat stuff.There are a set of priests in\nthat temple, and their task isto move the entire stack of\nsixty-four disks from one postto a second post. When they do\nthis, you know, the universeends or they solve the financial\ncrisis in Washingtonor something like that actually\ngood happens, right?Boy, none of you have 401k's,\nyou're not even wincing atthat thing.All right.The rules, though, are, they\ncan only move one disk at atime, and they can never cover\nup a smaller disk with alarger disk.OK.Otherwise you'd just move the\nwhole darn stack, OK?So we want to solve\nthat problem.We want to write a piece of\ncode that helps these guysout, so I'm going to show\nyou an example.Let's see if we can figure\nout how to do this.So, we'll start with\nthe easy one.Moving a disk of size 1.OK, that's not so bad.Moving a stack of size 2, if I\nwant to go there, I need toput this one temporarily over\nhere so I can move the bottomone before I move it over.", "start": 1200.0, "heat": 0.112}, {"text": "Moving a stack of size 3, again,\nif I want to go overthere, I need to make sure I\ncan put the spare one overhere before I move the bottom\none, I can't cover up any ofthe smaller ones with\nthe larger one, butI can get it there.Stack of size 4, again I'm going\nthere, so I'm going todo this initially, no I'm not,\nI'm going to start again.I'm going to go there initially,\nso I can move thisover here, so I can get the base\npart of that over there,I want to put that one there\nbefore I put this over here,finally I get to the point where\nI can move the bottomone over, now I've got to be\nreally careful to make surethat I don't cover up the bottom\none in the wrong waybefore I get to the stage where\nI wish they were postsand there you go.All right?[APPLAUSE]I mean, I can make money at\nHarvard Square doing thisstuff, right?All right, you ready\nto do five?Got the solution?Not so easy to see.All right, but this is actually\na great one of thoseeducational moments.This is a great example\nto think recursively.If I wanted to think about this\nproblem recursively--what do I mean by thinking\nrecursively?How do I reduce this to a\nsmaller-size problem in thesame instant?And so, if I do that, this\nnow becomes really easy.If I want to move this stack\nhere, I'm going to take astack of size n minus 1, move\nit to the spare spot, now Ican move the base disk over,\nand then I'm going to movethat stack of size n\nminus 1 to there.That's literally\nwhat I did, OK?So there's the code.Called towers.I'm just going to have you--\nlet you take a look at it.I'm giving it an argument,\nwhich is the size of thestack, and then just labels\nfor the three posts.A from, a to, and a spare.And in fact, if we look at\nthis-- let me just pop it overto the other side--OK, I can move a tower, I'll say\nof size 2, from, to, andspare, and that was\nwhat I did.And if I want to move towers,\nlet's say, size 5, from, to,and spare, there are\nthe instructions", "start": 1320.0, "heat": 0.168}, {"text": "for how to move it.We ain't going to\ndo sixty-four.OK.All right.So it's fun, and I got a little\nbit of applause out ofit, which is always nice for me,\nbut I also showed you howto think about it recursively.Once you hear that description,\nit's easy towrite the code, in fact.This is a place where the\nrecursive version of it ismuch easier to think about\nthan the iterative one.But what I really want to talk\nabout is, what's the order ofgrowth here?What's the complexity\nof this algorithm?And again, I'm going to do it\nwith a little bit of abusivenotation, and it's a little more\ncomplicated, but we cankind of look at.All right?Given the code up there, if I\nwant to move a tower of sizen, what do I have to do?I've got to test to see if I'm\nin the base case, and if I'mnot, then I need to move a tower\nof size n minus 1, Ineed to move a tower of size\n1, and I need to move asecond-- sorry about that--\na second tower ofsize n minus 1.OK. t of 1 I can also reduce.In the case of a tower of size\n1, basically there are twothings to do, right?I've got to do the test, and\nthen I just do the move.So the general formula is that.Now.You might look at that and say,\nwell that's just a lotlike what we had over here.Right?We had some additive constant\nplus a simpler version of thesame problem reduced\nin size by 1.But that two matters.So let's look at it.How do I rea-- replace the\nexpression FOR t of n minus 1?Substitute it in again. t\nof n minus 1 is 3 plus 2t of n minus 2.So this is 3, plus 2 times\n3, plus 4 t minus 2.OK.And if I substitute it again, I\nget 3 plus 2 times 3 plus 4times 3 plus 8 t n minus 3.", "start": 1440.0, "heat": 0.19}, {"text": "This is going by a little\nfast. I'm justsubstituting in.I'm going to skip some steps.But basically if I do this, I\nend up with 3 times 1 plus 2plus 4 to 2 to the k\nminus 1 for all ofthose terms, plus 2--I want to do this right, 2 to\nthe k, sorry-- t of n minus k.OK.Don't sweat the details, I'm\njust expanding it out.What I want you to see is,\nbecause I've got two versionsof that problem.The next time down I've\ngot four versions.Next time down I've got\neight versions.And in fact, if I substitute, I\ncan solve for this, I'm donewhen this is equal to 1.If you substitute it all\nin, you get basicallyorder 2 to the n.Exponential.That's a problem.Now, it's also the case that\nthis is fundamentally whatclass this algorithm falls\ninto, it is going to takeexponential amount of time.But it grows pretty rapidly, as\nn goes up, and I'm going toshow you an example\nin a second.Again, what I want you\nto see is, notice thecharacteristic of that.That this recursive call had two\nsub-problems of a smallersize, not one.And that makes a\nbig difference.So just to show you how big a\ndifference it makes, let's runa couple of numbers.Let's suppose n is 1000,\nand we're runningat nanosecond speed.We have seen log, linear,\nquadratic, and exponential.So, again, there could be\nconstants in here, but just togive you a sense of this.If I'm running at nanosecond\nspeed, n, the size of theproblem, whatever it is, is\n1000, and I've got a log", "start": 1560.0, "heat": 0.171}, {"text": "algorithm, it takes 10\nnanoseconds to complete.If you blink, you miss it.If I'm running a linear\nalgorithm, it'll take onemicrosecond to complete.If I'm running a quadratic\nalgorithm, it'll take onemillisecond to complete.And if I'm running\nan exponentialalgorithm, any guesses?I hope Washington doesn't take\nthis long to fix my 401k plan.All right?10 to the 284 years.As Emeril would say, pow!That's a some spicy whatever.All right.Bad jokes aside, what's\nthe point?You see, these classes have\nreally different performance.Now this is a little\nmisleading.These are all really fast, so\njust to give you another setof examples, I'm not\ngoing to do the--If I had a problem where the log\none took ten milliseconds,then the linear one would take\na second, the quadratic onewould take 16 minutes.So you can see, even the\nquadratic ones canblow up in a hurry.And this goes back to\nthe point I triedto make last time.Yes, the computers are really\nfast. But the problems cangrow much faster than you can\nget a performance boost out ofthe computer.And you really, wherever\npossible, want to avoid thatexponential algorithm, because\nthat's really deadly.Yes.All right.The question is, is there a\npoint where it'll quit.Yeah, when the power goes out,\nor-- so let me not answer itquite so facetiously.We'd be mostly talking\nabout time.In fact, if I ran one of these\nthings, it would just keep", "start": 1680.0, "heat": 0.254}, {"text": "crunching away.It will probably quit at some\npoint because of space issues,unless I'm writing an algorithm\nthat is using noadditional space.Right.Those things are going to stack\nup, and eventually it'sgoing to run out of space.And that's more likely to\nhappen, but, you know.The algorithm doesn't know that\nit's going to take thislong to compute, it's just busy\ncrunching away, trying tosee if it can make it happen.OK.Good question, thank you.All right.I want to do one more extended\nexample here., because we'vegot another piece to do, but I\nwant to capture this, becauseit's important, so let me\nagain try and say it thefollowing way.I want you to recognize classes\nof algorithms andmatch what you see in the\nperformance of the algorithmto the complexity of\nthat algorithm.All right?Linear algorithms tend to\nbe things where, at onepass-through, you reduce\nthe problem by aconstant amount, by one.If you reduce it by two, it's\ngoing to be the same thing.Where you go from problem of\nsize n to a problem ofsize n minus 1.A log algorithm typically is one\nwhere you cut the size ofthe problem down by some\nmultiplicative factor.You reduce it in half.You reduce it in third.All right?Quadratic algorithms\ntend to have this--I was about to say additive,\nwrong term-- butdoubly-nested, triply-nested\nthings are likely to bequadratic or cubic algorithms,\nall right, because you know--let me not confuse things--\ndouble-loop quadraticalgorithm, because you're doing\none set of things andyou're doing it some other\nnumber of times, and that's atypical signal that that's\nwhat you have there.OK.And then the exponentials, as\nyou saw is when typically Ireduce the problem of one size\ninto two or more sub-problemsof a smaller size.And you can imagine this gets\ncomplex and there's lots ofinteresting things to do to\nlook to the real form, butthose are the things that\nyou should see.Now.Two other things, before we\ndo this last example.One is, I'll remind you, what\nwe're interested in isasymptotic growth.How does this thing grow as I\nmake the problem size big?And I'll also remind you, and\nwe're going to see this in thenext example, we talked\nabout looking atthe worst case behavior.", "start": 1800.0, "heat": 0.201}, {"text": "In these cases there's no best\ncase worst case, it's justdoing one computation.We're going to see an example\nof that in a second.What we really want to worry\nabout, what's the worst casethat happens.And the third thing I want you\nto keep in mind is, rememberthese are orders of growth.It is certainly possible, for\nexample, that a quadraticalgorithm could run faster\nthan a linear algorithm.It depends on what the input is,\nit depends on, you know,what the particular cases are.So it is not the case that,\non every input, a linearalgorithm is always\ngoing to be betterthan a quadratic algorithm.It is just in general that's\ngoing to hold true, and that'swhat I want you to see.OK.I want to do one last example.I'm going to take a little bit\nmore time on it, because it'sgoing to both reinforce these\nideas, but it's also going toshow us how we have to think\nabout what's a primitivestep., and in a particular,\nhow do data structuresinteract with this analysis?Here I've just been running\nintegers, it's pretty simple,but if I have a data structure,\nI'm going to haveto worry about that\na little bit more.So let's look at that.And the example I want to look\nat is, suppose I want tosearch a list that I know is\nsorted, to see if an element'sin the list. OK?So the example I'm going to\ndo, I'm going to search asorted list. All right.If you flip to the second side\nof your handout, you'll seethat I have a piece of code\nthere, that does this-- letme, ah, I didn't want to\ndo that, let me back upslightly-- this is the algorithm\ncalled search.And let's take a look at it.OK?Basic idea, before I even look\nat the code, is pretty simple.If I've got a list that is\nsorted, in let's call it, justin increasing order, and I\nhaven't said what's in thelist, could be numbers, could\nbe other things, for now,we're going to just assume\nthey're integers.The easy thing to do would be\nthe following: start at thefront end of the list, check\nthe first element.If it's the thing I'm looking\nfor, I'm done.It's there.If not, move on to\nthe next element.And keep doing that.But if, at any point, I get to\na place in the list where the", "start": 1920.0, "heat": 0.163}, {"text": "thing I'm looking for is smaller\nthan the element inthe list, I know everything else\nin the rest of the listhas to be bigger than that,\nI don't have tobother looking anymore.It says the element's\nnot there.I can just stop.OK.So that's what this piece\nof code does here.Right.?I'm going to set up a variable\nto say, what's the answer Iwant to return, is\nit there or not.Initially it's got that\nfunny value none.I'm going to set up an index,\nwhich is going to tell mewhere to look, starting at the\nfirst part of the list, right?And then, when I got--I'm also going to count how many\ncomparisons I do, just soI can see how much work\nI do here, and thennotice what it does.It says while the index is\nsmaller than the size of thelist, I'm not at the end of the\nlist, and I don't have ananswer yet, check.So I'm going to check to see\nif-- really can't read thatthing, let me do it this way--\nright, I'm going to increasethe number of compares, and I'm\ngoing to check to say, isthe thing I'm looking for at\nthe i'th spot in the list?Right, so s of i saying, given\nthe list, look at the i'thelement, is it the same thing?If it is, OK.Set the answer to true.Which means, next time through\nthe loop, that's going to popout and return an answer.If it's not, then check to see,\nis it smaller than thatelement in the current\nspot of the list?And if that's true, it says\nagain, everything else in thelist has to be bigger than this,\nthing can't possibly bein the list, I'm taking\nadvantage of the ordering, Ican set the answer to false,\nchange i to go to the nextone, and next time through the\nloop, I'm going to pop out andprint it out.OK?Right.Order of growth here.What do you think?Even with these glasses on,\nI can see no hands up, anysuggestions?Somebody help me out.What do you think the order\nof growth is here?I've got a list, walk you\nthrough it an element at atime, do I look at each\nelement of the", "start": 2040.0, "heat": 0.148}, {"text": "list more than once?Don't think so, right?So, what does this suggest?Sorry?Constant.Ooh, constant says, no matter\nwhat the length of the listis, I'm going to take the\nsame amount of time.And I don't think that's\ntrue, right?If I have a list ten times\nlonger, it's going to take memore time, so-- not a\nbad guess, I'm stillreward you, thank you.Somebody else.Yeah.Linear.Why?You're right, by the\nway, but why?Yeah.All right, so the answer was\nit's linear, which isabsolutely right.Although for a reason\nwe're going tocome back in a second.Oh, thank you, I hope your\nfriends help you out withthat, thank you.Right?You can see that this\nought to be linear,because what am I doing?I'm walking down the list. So\none of the things I didn'tsay, it's sort of implicit here,\nis what is the thing Imeasuring the size of\nthe problem in?What's the size of the list?And if I'm walking down the\nlist, this is probably orderof the length of the list s,\nbecause I'm looking at eachelement once.Now you might say,\nwait a minute.Thing's ordered, if I stop part\nway through and I throwaway half the list, doesn't\nthat help me?And the answer is yes, but it\ndoesn't change the complexity.Because what did we say?We're measuring the\nworst case.The worst case here is, the\nthings not in the list, inwhich case I've got to go all\nthe way through the list toget to the end.OK.Now, having said that, and I've\nactually got a subtletyI'm going to come back to in a\nsecond, there ought to be abetter way to do this.OK?And here's the better\nway to think about.I'll just draw out sort of a\nfunny representation of alist. These are sort of the\ncells, if you like, in memorythat are holding the elements\nof the list. What we've beensaying is, I start\nhere and look.", "start": 2160.0, "heat": 0.191}, {"text": "If it's there, I'm done.If not, I go there.If it's there, I'm done, if not,\nI keep walking down, andI only stop when I get to a\nplace where the element I'mlooking for is smaller than\nthe value in the list., inwhich case I know the\nrest of this is toobig and I can stop.But I still have to go\nthrough the list.There's a better way to think\nabout this, and in factProfessor Guttag has already\nhinted at this in the lastcouple of lectures.The better way to think about\nthis is, suppose, rather thanstarting at the beginning, I\njust grabbed some spot atrandom, like this one.And I look at that value.If it's the value I'm looking\nfor, boy, I ought to go toVegas, I'm really lucky.And I'm done, right?If not, what could I do?Well, I could look at the value\nhere, and compare it tothe value I'm trying to find,\nand say the following; if thevalue I'm looking for is bigger\nthan this value, wheredo I need to look?Just here.All right?Can't possibly be there,\nbecause I knowthis thing is over.On the other hand, if the value\nI'm looking for here--sorry, the value I'm looking for\nis smaller than the valueI see here, I just need\nto look here.All right?Having done that, I could do the\nsame thing, so I suppose Itake this branch, I can pick a\nspot like, say, this one, andlook there.Because there, I'm done,\nif not, I'm eitherlooking here or there.And I keep cutting\nthe problem down.OK.Now, having said that, where\nshould I pick tolook in this list?I'm sorry?Halfway.Why?You're right, but why?Yeah.So the answer, in case you\ndidn't hear it, was, again, ifI'm a gambling person, I could\nstart like a way down here.All right?If I'm gambling, I'm saying,\ngee, if I'm really lucky,it'll be only on this side, and\nI've got a little bit of", "start": 2280.0, "heat": 0.233}, {"text": "work to do, but if I'm unlucky,\nI'm scrawed, the pastpluperfect of screwed, OK.,\nor a Boston fish.I'll look at the rest of that\nbig chunk of the list, andthat's a pain.So halfway is the right thing\nto do, because at each step,I'm guaranteed to throw away at\nleast half the list. Right?And that's nice.OK.What would you guess the order\nof growth here is?Yeah.Why?Good.Exactly.Right?Again, if you didn't hear it,\nthe answer was it's log.Because I'm cutting down the\nproblem in half at each time.You're right, but there's\nsomething we have to do to addto that, and that's the last\nthing I want to pick up on.OK.Let's look at the code--\nactually, let's test this outfirst before we do it.So I've added, as Professor\nGuttag did-- ah, should havesaid it this way, let's write\nthe code for it first, sorryabout that--OK, I'm going to write a little\nthing called b search.I'm going to call it down here\nwith search, which is simplygoing to call it, and then\nprint an answer out.In binary search-- ah, there's\nthat wonderful phrase, this iscalled a version of binary\nsearch, just like you sawbin-- or bi-section methods,\nwhen we were doing numericalthings-- in binary search, I\nneed to keep track of thestarting point and the\nending point of thelist I'm looking at.Initially, it's the beginning\nand the end of it.And when I do this test, what I\nwant to do, is say I'm goingto pick the middle spot, and\ndepending on the test, if Iknow it's in the upper half, I'm\ngoing to set my start atthe mid point and the end stays\nthe same, if it's in thefront half I'm going to keep\nthe front the same and I'mgoing to change the endpoint.And you can see that\nin this code here.Right?What does it say to do?It says, well I'm going to print\nout first and last, justso you can see it, and then I\nsay, gee, if last minus firstis less than 2, that is, if\nthere's no more than twoelements left in the list, then\nI can just check thosetwo elements, and return\nthe answer.Otherwise, we find\nthe midpoint, andnotice what it does.First, it's pointing to the\nbeginning of the list, whichinitially might be down here at\n0 but after a while, mightbe part way through.And to that, I simply\nadd a halfway", "start": 2400.0, "heat": 0.212}, {"text": "point, and then I check.If it's at that point, I'm done,\nif not, if it's greaterthan the value I'm looking\nfor, I either takeone half or the other.OK.You can see that thing is\ncutting down the problem inhalf each time, which is good,\nbut there's one more thing Ineed to deal with.So let's step through this\nwith a little more care.And I keep saying, before\nwe do it, let's justactually try it out.So I'm going to go over\nhere, and I'm goingto type test search--I can type-- and if you look at\nyour handout, it's just asequence of tests that\nI'm going to do.OK.So initially, I'm going to set\nup the list to be the firstmillion integers.Yeah, it's kind of simple, but\nit gives me an ordered list ofthese things, And let's run it.OK.So I'm first going to look for\nsomething that's not in thelist, I'm going to see, is minus\n1 in this list, so it'sgoing to be at the far end,\nand if I do that inthe basic case, bam.Done.All right?The basic, that primary search,\nbecause it looks atthe first element, says\nit's smaller thaneverything else, I'm done.If I look in the binary case,\ntakes a little longer.Notice the printout here.The printout is simply telling\nme, what are theranges of the search.And you can see it wrapping its\nway down, cutting in halfat each time until it\ngets there, but ittakes a while to find.All right.Let's search to see though now\nif a million is in this list,or 10 million, whichever way\nI did this, it must be amillion, right?In the basic case, oh,\ntook a little while.Right, in the binary\ncase, bam.In fact, it took the same number\nof steps as it did inthe other case, because\neach time I'm cuttingit down by a half.OK.That's nice.Now, let's do the following;\nif you look right here, I'mgoing to set this now to--I'm going to change my range\nto 10 million, I'm going tofirst say, gee, is a\nmillion in there,using the basic search.It is.Now, I'm going to say, is 10\nmillion in this, using thebasic search.", "start": 2520.0, "heat": 0.419}, {"text": "We may test your hypothesis,\nabout how long does it take,if I time this really well, I\nought to be able to end whenit finds it, which should\nbe right about now.That was pure luck.But notice how much\nlonger it took.On the other hand, watch what\nhappens with binary.Is the partway one there?Yeah.Is the last one there?Wow.I think it took one more step.Man, that's exactly what\nlogs should do, right?I make the problem ten times\nbigger, it takes onemore step to do it.Whereas in the linear case, I\nmake it ten times bigger, ittakes ten times longer to run.OK.So I keep saying I've got one\nthing hanging, it's the lastthing I want to do, but I wanted\nyou see how much of adifference this makes.But let's look a little more\ncarefully at the code forbinary search-- for search 1.What's the complexity\nof search 1?Well, you might say it's\nconstant, right?It's only got two things to do,\nexcept what it really saysis, that the complexity of\nsearch 1 is the same as thecomplexity of b search,\nbecause that'sthe call it's doing.So let's look at b search.All right?We've got the code for\nb search up there.First step, constant, right?Nothing to do.Second step, hm.That also looks constant,\nyou think?Oh but wait a minute.I'm accessing s.I'm accessing a list. How long\ndoes it take for me to get thenth element of a list?That might not be a\nprimitive step.And in fact, it depends\non how I store a list.So, for example, in this case,\nI had lists that I knew weremade out of integers.As a consequence, I have\na list of ints.I might know, for example,\nthat it takes four memorychunks to represent one\nint, just for example.And to find the i'th element,\nI'm simply going to take the", "start": 2640.0, "heat": 0.283}, {"text": "starting point, that point at\nthe beginning of memory wherethe list is, plus 4 times i,\nthat would tell me how manyunits over to go, and that's the\nmemory location I want tolook for the i'th element\nof the list.And remember, we said we're\ngoing to assume a randomaccess model, which says, as\nlong as I know the location,it takes a constant amount of\ntime to get to that point.So if the-- if I knew the\nlists were made of justintegers, it'd be really\neasy to figure it out.Another way of saying it is,\nthis takes constant amount oftime to figure out where to\nlook, it takes constant amountof time to get there, so in fact\nI could treat indexinginto a list as being\na basic operation.But we know lists can be\ncomposed of anything.Could be ints, could be floats,\ncould be a combinationof things, some ints, some\nfloats, some lists, somestrings, some lists of\nlists, whatever.And in that case, in general\nlists, I need to figure outwhat's the access time.And here I've got a choice.OK, one of the ways I could\ndo would be the following.I could have a pointer to the\nbeginning of the list wherethe first element here is the\nactual value, and this wouldpoint to the next element in\nthe list. Or another way ofsaying it is, the first part\nof the cell could be someencoding of how many cells do\nI need to have to store thevalue, and then I've got some\nway of telling me where to getthe next element of the list.\nAnd this would point to value,and this would point off\nsomeplace in memory.Here's the problem with that\ntechnique, and by the way, anumber of programming\nlanguages usethis, including Lisp.The problem with that technique,\nwhile it's verygeneral, is how long does it\ntake me to find the i'thelement of the list?Oh fudge knuckle.OK.I've got to go to the first\nplace, figure out how far overto skip, go to the next place,\nfigure out how far over to", "start": 2760.0, "heat": 0.243}, {"text": "skip, eventually I'll\nbe out the door.I've got to count my way down,\nwhich means that the accesswould be linear in the length\nof the list to find the i'thelement of the list, and that's\ngoing to increase thecomplexity.There's an alternative, which\nis the last point I want tomake, which is instead what I\ncould do, I should have saidthese things are called linked\nlists, we'll come back tothose, another way to do it,\nis to have the start of thelist be at some point in memory,\nand to have each oneof the successive cells\nin memory point offto the actual value.Which may take up some arbitrary\namount of memory.In that case, I'm back\nto this problem.And as a consequence, access\ntime in the list is constant,which is what I want.Now, to my knowledge, most\nimplementations of Python usethis way of storing lists,\nwhereas Lispand Scheme do not.The message I'm trying to get\nto here, because I'm runningyou right up against time, is\nI have to be careful aboutwhat's a primitive step.With this, if I can assume\nthat accessing the i'thelement of a list is constant,\nthen you can't see that therest of that analysis looks just\nlike the log analysis Idid before, and each step, no\nmatter which branch I'mtaking, I'm cutting the\nproblem down in half.And as a consequence,\nit is log.And the last piece of this, is\nas said, I have to make sure Iknow what my primitive elements\nare, in terms ofoperations.Summary: I want you to recognize\ndifferent classes ofalgorithms. I'm not going\nto repeat them.We've seen log, we've seen\nlinear, we've seen quadratic,we've seen exponential.One of the things you should\nbegin to do, is to recognizewhat identifies those classes of\nalgorithms, so you can mapyour problems into\nthose ranges.And with that, good\nluck on Thursday.", "start": 2880.0, "heat": 0.332}]