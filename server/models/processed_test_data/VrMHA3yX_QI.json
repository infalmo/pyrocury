[{"text": "The following content is\nprovided under a CreativeCommons license.Your support will help\nMIT OpenCourseWarecontinue to offer high-quality\neducational resources for free.To make a donation or to\nview additional materialsfrom hundreds of MIT courses,\nvisit MIT OpenCourseWareat ocw.mit.edu.[MUSIC PLAYING]PATRICK H. WINSTON: Well,\nwhat we're going to do todayis climb a pretty big\nmountain because we'regoing to go from a\nneural net with twoparameters to discussing\nthe kind of neural netsin which people end up dealing\nwith 60 million parameters.So it's going to be\na pretty big jump.Along the way are\na couple thingsI wanted to underscore from\nour previous discussion.Last time, I tried to\ndevelop some intuitionfor the kinds of formulas\nthat you use to actually dothe calculations in a\nsmall neural net about howthe weights are going to change.And the main thing\nI tried to emphasizeis that when you have a\nneural net like this one,everything is sort of\ndivided in each column.You can't have the performance\nbased on this outputaffect some weight\nchange back herewithout going through this\nfinite number of outputvariables, the y1s.And by the way, there's no y2\nand y4-- there's no y2 and y3.Dealing with this is really\na notational nightmare,", "start": 0.0, "heat": 0.1}, {"text": "and I spent a lot\nof time yesterdaytrying to clean it\nup a little bit.But basically, what\nI'm trying to sayhas nothing to do with\nthe notation I have usedbut rather with the\nfact that there'sa limited number of ways in\nwhich that can influence this,even though the number of\npaths through this networkcan be growing exponential.So those equations\nunderneath areequations that derive\nfrom trying to figure outhow the output performance\ndepends on someof these weights back here.And what I've calculated\nis I've calculatedthe dependence of\nthe performance on w1going that way, and\nI've also calculatedthe dependence of performance\non w1 going that way.So that's one of the\nequations I've got down there.And another one\ndeals with w3, and itinvolves going both\nthis way and this way.And all I've done in both\ncases, in all four cases,is just take the partial\nderivative of performancewith respect to those weights\nand use the chain ruleto expand it.And when I do that,\nthis is the stuff I get.And that's just a whole\nbunch of partial derivatives.But if you look at it and let\nit sing a little bit to you,what you see is that\nthere's a lot of redundancyin the computation.So for example, this\nguy here, partialof performance\nwith respect to w1,depends on both\npaths, of course.But look at the first elements\nhere, these guys right here.And look at the first\nelements in the expressionfor calculating the partial\nderivative of performancewith respect to w3, these guys.", "start": 120.0, "heat": 0.349}, {"text": "They're the same.And not only that, if you\nlook inside these expressionsand look at this\nparticular piece here,you see that that is\nan expression thatwas needed in order\nto calculate oneof the downstream weights,\nthe changes in oneof the downstream weights.But it happens to be the same\nthing as you see over here.And likewise, this piece is the\nsame thing you see over here.So each time you move\nfurther and further backfrom the outputs\ntoward the inputs,you're reusing a\nlot of computationthat you've already done.So I'm trying to find a\nway to sloganize this,and what I've come up with is\nwhat's done is done and cannotbe-- no, no.That's not quite right, is it?It's what's computed is computed\nand need not be recomputed.OK?So that's what's going on here.And that's why this is\na calculation that'slinear in the depths of the\nneural net, not exponential.There's another thing I wanted\nto point out in connectionwith these neural nets.And that has to do\nwith what happenswhen we look at a single neuron\nand note that what we've gotis we've got a bunch of\nweights that you multiply timesa bunch of inputs like so.And then those are all\nsummed up in a summing boxbefore they enter some kind\nof non-linearity, in our casea sigmoid function.", "start": 240.0, "heat": 0.138}, {"text": "But if I ask you to write down\nthe expression for the valuewe've got there, what is it?Well, it's just the sum\nof the w's times the x's.What's that?That's the dot product.Remember a few lectures\nago I said that some of usbelieve that the dot product is\na fundamental calculation thattakes place in our heads?So this is why we think so.If neural nets are doing\nanything like this,then there's a dot product\nbetween some weightsand some input values.Now, it's a funny\nkind of dot productbecause in the models\nthat we've been using,these input variables are\nall or none, or 0 or 1.But that's OK.I have it on good\nauthority that thereare neurons in our head\nfor which the values thatare produced are not\nexactly all or nonebut rather have a kind of\nproportionality to them.So you get a real dot product\ntype of operation out of that.So that's by way of\na couple of asidesthat I wanted to\nunderscore before weget into the center\nof today's discussion,which will be to talk about\nthe so-called deep nets.Now, let's see,\nwhat's a deep net do?Well, from last time, you\nknow that a deep net doesthat sort of thing, and\nit's interesting to lookat some of the offerings here.By the way, how good was\nthis performance in 2012?Well, it turned out\nthat the fractionof the time that the\nsystem had the right answerin its top five\nchoices was about 15%.And the fraction of the time\nthat it got exactly the rightanswer as its top pick\nwas about 37%-- error,15% error if you count it as\nan error if it's-- what am I", "start": 360.0, "heat": 0.2}, {"text": "saying?You got it right if you\ngot it in the top five.An error rate on that\ncalculation, about 15%.If you say you only get it right\nif it was your top choice, thenthe error rate was about 37%.So pretty good, especially\nsince some of these thingsare highly ambiguous even to us.And what kind of\na system did that?Well, it wasn't one\nthat looked exactlylike that, although that\nis the essence of it.The system actually\nlooked like that.There's quite a lot\nof stuff in there.And what I'm going to talk about\nis not exactly this system,but I'm going to talk about the\nstuff of which such systems aremade because there's\nnothing particularlyspecial about this.It just happens to be\na particular assemblyof components that tend to\nreappear when anyone doesthis sort of neural net stuff.So let me explain that this way.First thing I need to talk\nabout is the concept of-- well,I don't like the term.It's called convolution.I don't like the term because\nin the second-best courseat the Institute,\nSignals and Systems,you learn about impulse\nresponses and convolutionintegrals and stuff like that.And this hints at that,\nbut it's not the same thingbecause there's no memory\ninvolved in what's going onas these signals are processed.But they call it convolutional\nneural nets anyway.So here you are.You got some kind of image.And even with lots of computing\npower and GPUs and allthat sort of stuff, we're\nnot talking about imageswith 4 million pixels.We're talking about images\nthat might be 256 on a side.As I say, we're not\ntalking about imagesthat are 1,000 by 1,000 or 4,000\nby 4,000 or anything like that.They tend to be\nkind of compressed", "start": 480.0, "heat": 0.109}, {"text": "into a 256-by-256 image.And now what we do\nis we run over thiswith a neuron that\nis looking onlyat a 10-by-10 square like so,\nand that produces an output.And next, we went\nover that again havingshifted this neuron\na little bit like so.And then the next thing we do\nis we shift it again, so weget that output right there.So each of those deployments\nof a neuron produces an output,and that output is associated\nwith a particular placein the image.This is the process that\nis called convolutionas a term of art.Now, this guy, or this\nconvolution operation,results in a bunch\nof points over here.And the next thing that\nwe do with those pointsis we look in\nlocal neighborhoodsand see what the\nmaximum value is.And then we take\nthat maximum valueand construct yet another\nmapping of the imageover here using\nthat maximum value.Then we slide that over like so,\nand we produce another value.And then we slide\nthat over one moretime with a different\ncolor, and now we'vegot yet another value.So this process\nis called pooling.And because we're\ntaking the maximum,this particular kind of\npooling is called max pooling.", "start": 600.0, "heat": 0.1}, {"text": "So now let's see what's next.This is taking a\nparticular neuronand running it across the image.We call that a kernel, again\nsucking some terminology outof Signals and Systems.But now what we're\ngoing to do iswe're going to say we could\nuse a whole bunch of kernels.So the thing that I\nproduce with one kernelcan now be repeated\nmany times like so.In fact, a typical\nnumber is 100 times.So now what we've got is\nwe've got a 256-by-256 image.We've gone over it\nwith a 10-by-10 kernel.We have taken the\nmaximum values thatare in the vicinity\nof each other,and then we repeated\nthat 100 times.So now we can take that, and\nwe can feed all those resultsinto some kind of neural net.And then we can, through\nperhaps a fully-connected jobon the final layers of this, and\nthen in the ultimate output weget some sort of\nindication of how likely itis that the thing that's\nbeing seen is, say, a mite.So that's roughly how\nthese things work.So what have we\ntalked about so far?We've talked about pooling, and\nwe've talked about convolution.And now we can talk about\nsome of the good stuff.But before I get into that,\nthis is what we can do now,and you can compare this with\nwhat was done in the old days.It was done in the old\ndays before massive amountsof computing became available\nis a kind of neural net activitythat's a little easier to see.You might, in the old days,\nonly have enough computing power", "start": 720.0, "heat": 0.1}, {"text": "to deal with a small\ngrid of picture elements,or so-called pixels.And then each of these might be\na value that is fed as an inputinto some kind of neuron.And so you might have a column\nof neurons that are lookingat these pixels in your image.And then there might be\na small number of columnsthat follow from that.And finally, something\nthat says this neuronis looking for things that are\na number 1, that is to say,something that looks like\na number 1 in the image.So this stuff up\nhere is what youcan do when you have a\nmassive amount of computationrelative to the\nkind of thing youused to see in the old days.So what's different?Well, what's\ndifferent is insteadof a few hundred parameters,\nwe've got a lot more.Instead of 10 digits,\nwe have 1,000 classes.Instead of a few\nhundred samples,we have maybe 1,000\nexamples of each class.So that makes a million samples.And we got 60 million\nparameters to play with.And the surprising thing\nis that the net resultis we've got a function\napproximator thatastonishes everybody.And no one quite\nknows why it works,except that when you throw an\nimmense amount of computationinto this kind of\narrangement, it'spossible to get a performance\nthat no one expected wouldbe possible.So that's sort of\nthe bottom line.But now there are a couple of\nideas beyond that that I thinkare especially interesting,\nand I want to talk about those.First idea that's\nespecially interestingis the idea of\nautocoding, and here's", "start": 840.0, "heat": 0.1}, {"text": "how the idea of\nautocoding works.I'm going to run\nout of board space,so I think I'll\ndo it right here.You have some input values.They go into a layer of\nneurons, the input layer.Then there is a so-called hidden\nlayer that's much smaller.So maybe in the example,\nthere will be 10 neurons hereand just a couple here.And then these expand to\nan output layer like so.Now we can take the output\nlayer, z1 through zn,and compare it with the\ndesired values, d1 through dn.You following me so far?Now, the trick is to say, well,\nwhat are the desired values?Let's let the desired\nvalues be the input values.So what we're going\nto do is we'regoing to train this net\nup so that the output'sthe same as the input.What's the good of that?Well, we're going to\nforce it down through this[? neck-down ?]\npiece of network.So if this network\nis going to succeedin taking all the possibilities\nhere and cramming theminto this smaller inner layer,\nthe so-called hidden layer,such that it can reproduce\nthe input [? at ?] the output,it must be doing some\nkind of generalizationof the kinds of things\nit sees on its input.And that's a very clever idea,\nand it's seen in various formsin a large fraction\nof the papers that", "start": 960.0, "heat": 0.1}, {"text": "appear on deep neural nets.But now I want to\ntalk about an exampleso I can show you\na demonstration.OK?So we don't have GPUs, and\nwe don't have three daysto do this.So I'm going to make up a\nvery simple example that'sreminiscent of what goes\non here but involveshardly any computation.What I'm going to\nimagine is we'retrying to recognize\nanimals from how tall theyare from the shadows\nthat they cast.So we're going to recognize\nthree animals, a cheetah,a zebra, and a giraffe, and\nthey will each cast a shadowon the blackboard like me.No vampire involved here.And what we're\ngoing to do is we'regoing to use the shadow as\nan input to a neural net.All right?So let's see how\nthat would work.So there is our network.And if I just clicked into\none of these test samples,that's the height of the shadow\nthat a cheetah casts on a wall.And there are 10 input\nneurons correspondingto each level of the shadow.They're rammed through\nthree inner layer neurons,and from that it spreads out and\nbecomes the outer layer values.And we're going to\ncompare those outer layervalues to the desired values,\nbut the desired valuesare the same as\nthe input values.So this column is a\ncolumn of input values.On the far right, we have\nour column of desired values.And we haven't trained\nthis neural net yet.", "start": 1080.0, "heat": 0.1}, {"text": "All we've got is\nrandom values in there.So if we run the test samples\nthrough, we get that and that.Yeah, cheetahs are short,\nzebras are medium height,and giraffes are tall.But our output is just pretty\nmuch 0.5 for all of them,for all of those shadow\nheights, all right,[? with ?] no training so far.So let's run this thing.We're just using simple\n[? backdrop, ?] just like onour world's simplest neural net.And it's interesting\nto see what happens.You see all those\nvalues changing?Now, I need to mention that\nwhen you see a green connection,that means it's a\npositive weight,and the density of the green\nindicates how positive it is.And the red ones are\nnegative weights,and the intensity of the\nred indicates how red it is.So here you can\nsee that we stillhave from our random\ninputs a varietyof red and green values.We haven't really\ndone much training,so everything correctly\nlooks pretty much random.So let's run this thing.And after only 1,000 iterations\ngoing through these examplesand trying to make the\noutput the same as the input,we reached a point where\nthe error rate has dropped.In fact, it's\ndropped so much it'sinteresting to relook\nat the test cases.So here's a test case\nwhere we have a cheetah.And now the output\nvalue is, in fact,very close to the desired value\nin all the output neurons.So if we look at\nanother one, once again,there's a correspondence\nin the right two columns.And if we look at the\nfinal one, yeah, there'sa correspondence in\nthe right two columns.Now, you back up from\nthis and say, well,what's going on here?It turns out that you're\nnot training this thing", "start": 1200.0, "heat": 0.111}, {"text": "to classify animals.You're training it to understand\nthe nature of the thingsthat it sees in the\nenvironment because all it seesis the height of a shadow.It doesn't know anything\nabout the classificationsyou're going to try\nto get out of that.All it sees is that there's\na kind of consistencyin the kind of data that it\nsees on the input values.Right?Now, you might say,\nOK, oh, that's cool,because what must\nbe happening isthat that hidden layer,\nbecause everything is forcedthrough that narrow\npipe, must be doingsome kind of generalization.So it ought to be the\ncase that if we clickon each of those\nneurons, we oughtto see it specialize\nto a particular height,because that's the sort of stuff\nthat's presented on the input.Well, let's go see\nwhat, in fact, isthe maximum\nstimulation to be seenon the neurons in\nthat hidden layer.So when I click on these\nguys, what we're going to seeis the input values\nthat maximallystimulate that neuron.And by the way, I\nhave no idea howthis is going to turn out\nbecause the initialization'sall random.Well, that's good.That one looks like\nit's generalizedthe notion of short.Ugh, that doesn't\nlook like medium.And in fact, the\nmaximum stimulationdoesn't involve any stimulation\nfrom that lower neuron.Here, look at this one.That doesn't look like tall.So we got one that looks\nlike short and two thatjust look completely random.So in fact, maybe we\nbetter back off the ideathat what's going on\nin that hidden layeris generalization\nand say that whatis going on in there\nis maybe the encodingof a generalization.It doesn't look like\nan encoding we can see,but there is a generalization\nthat's-- let me start that", "start": 1320.0, "heat": 0.163}, {"text": "over.We don't see the generalization\nin the stimulating values.What we have instead\nis we have some kindof encoded generalization.And because we got\nthis stuff encoded,it's what makes these neural\nnets so extraordinarilydifficult to understand.We don't understand\nwhat they're doing.We don't understand why they\ncan recognize a cheetah.We don't understand why\nit can recognize a schoolbus in some cases,\nbut not in others,because we don't\nreally understandwhat these neurons\nare responding to.Well, that's not quite true.There's been a lot\nof work recentlyon trying to sort that\nout, but it's stilla lot of mystery in this world.In any event, that's\nthe autocoding idea.It comes in various guises.Sometimes people talk about\nBoltzmann machines and thingsof that sort.But it's basically all\nthe same sort of idea.And so what you can\ndo is layer by layer.Once you've trained\nthe input layer,then you can use that layer\nto train the next layer,and then that can train\nthe next layer after that.And it's only at the very, very\nend that you say to yourself,well, now I've accumulated\na lot of knowledgeabout the environment and what\ncan be seen in the environment.Maybe it's time to\nget around to usingsome samples of particular\nclasses and train on classes.So that's the story\non autocoding.Now, the next thing to talk\nabout is that final layer.So let's see what the final\nlayer might look like.Let's see, it might\nlook like this.There's a [? summer. ?]\nThere's a minus 1 up here.No.Let's see, there's a\nminus 1 up-- [INAUDIBLE].There's a minus 1 up there.There's a multiplier here.And there's a\nthreshold value there.Now, likewise, there's some\nother input values here.", "start": 1440.0, "heat": 0.29}, {"text": "Let me call this one x, and it\ngets multiplied by some weight.And then that goes into\nthe [? summer ?] as well.And that, in turn, goes into\na sigmoid that looks like so.And finally, you get an\noutput, which we'll z.So it's clear that if you\njust write out the value of zas it depends on those inputs\nusing the formula that weworked with last\ntime, then what yousee is that z is\nequal to 1 over 1plus e to the minus w times\nx minus T-- plus T, I guess.Right?So that's a sigmoid\nfunction thatdepends on the\nvalue of that weightand on the value\nof that threshold.So let's look at how those\nvalues might change things.So here we have an\nordinary sigmoid.And what happens if we shift\nit with a threshold value?If we change that\nthreshold value,then it's going\nto shift the placewhere that sigmoid comes down.So a change in T\ncould cause this thingto shift over that way.And if we change\nthe value of w, thatcould change how\nsteep this guy is.So we might think that the\nperformance, since it depends", "start": 1560.0, "heat": 0.298}, {"text": "on w and T, should be\nadjusted in such a wayas to make the classification\ndo the right thing.But what's the right thing?Well, that depends on the\nsamples that we've seen.Suppose, for example, that\nthis is our sigmoid function.And we see some examples of a\nclass, some positive examplesof a class, that\nhave values thatlie at that point and\nthat point and that point.And we have some values that\ncorrespond to situations wherethe class is not one of the\nthings that are associatedwith this neuron.And in that case, what\nwe see is examples thatare over in this vicinity here.So the probability that we\nwould see this particular guyin this world is associated with\nthe value on the sigmoid curve.So you could think of\nthis as the probabilityof that positive\nexample, and thisis the probability of\nthat positive example,and this is the probability\nof that positive example.What's the probability\nof this negative example?Well, it's 1 minus the\nvalue on that curve.And this one's 1 minus\nthe value on that curve.So we could go through\nthe calculations.And what we would determine\nis that to maximizethe probability of seeing this\ndata, this particular stuffin a set of experiments, to\nmaximize that probability,we would have to adjust T and\nw so as to get this curve doingthe optimal thing.And there's nothing\nmysterious about it.It's just more\npartial derivatives", "start": 1680.0, "heat": 0.2}, {"text": "and that sort of thing.But the bottom line is that the\nprobability of seeing this datais dependent on the\nshape of this curve,and the shape of this curve is\ndependent on those parameters.And if we wanted to maximize\nthe probability that we'veseen this data, then we have\nto adjust those parametersaccordingly.Let's have a look\nat a demonstration.OK.So there's an ordinary\nsigmoid curve.Here are a couple of\npositive examples.Here's a negative example.Let's put in some more\npositive examples over here.And now let's run the good,\nold gradient ascent algorithmon that.And this is what happens.You've seen how the\nprobability, as we adjustthe shape of the curve,\nthe probability of seeingthose examples of\nthe class goes up,and the probability of seeing\nthe non-example goes down.So what if we put\nsome more examples in?If we put a negative\nexample there,not much is going to happen.What would happen if we put a\npositive example right there?Then we're going to start\nseeing some dramatic shiftsin the shape of the curve.So that's probably\na noise point.But we can put some more\nnegative examples in thereand see how that\nadjusts the curve.All right.", "start": 1800.0, "heat": 0.195}, {"text": "So that's what we're doing.We're viewing this\noutput value as somethingthat's related to the\nprobability of seeing a class.And we're adjusting the\nparameters on that output layerso as to maximize the\nprobability of the sample datathat we've got at hand.Right?Now, there's one more thing.Because see what\nwe've got here iswe've got the basic idea\nof back propagation, whichhas layers and layers\nof additional--let me be flattering and call\nthem ideas layered on top.So here's the next idea\nthat's layered on top.So we've got an\noutput value here.And it's a function after\nall, and it's got a value.And if we have\n1,000 classes, we'regoing to have 1,000\noutput neurons,and each is going to be\nproducing some kind of value.And we can think of that\nvalue as a probability.But I didn't want to\nwrite a probability yet.I just want to say\nthat what we'vegot for this output neuron\nis a function of class 1.And then there will be\nanother output neuron,which is a function of class 2.And these values will\nbe presumably higher--this will be higher if we are,\nin fact, looking at class 1.And this one down here\nwill be, in fact, higherif we're looking at class m.So what we would like to do\nis we'd like to not just pickone of these outputs\nand say, well, you'vegot the highest\nvalue, so you win.What we want to do\ninstead is we wantto associate some\nkind of probabilitywith each of the classes.Because, after all,\nwe want to do thingslike find the most\nprobable five.So what we do is\nwe say, all right,so the actual\nprobability of class 1is equal to the output of\nthat sigmoid function divided", "start": 1920.0, "heat": 0.204}, {"text": "by the sum over all functions.So that takes all of\nthat entire output vectorand converts each output\nvalue into a probability.So when we used that\nsigmoid function,we did it with the\nview toward thinkingabout that as a probability.And in fact, we assumed\nit was a probability whenwe made this argument.But in the end,\nthere's an outputfor each of those classes.And so what we get is, in the\nend, not exactly a probabilityuntil we divide by a\nnormalizing factor.So this, by the way, is called--\nnot on my list of things,but it soon will be.Since we're not talking\nabout taking the maximumand using that to classify the\npicture, what we're going to dois we're going to use\nwhat's called softmax.So we're going to give a\nrange of classifications,and we're going to associate\na probability with each.And that's what you saw\nin all of those samples.You saw, yes, this is\n[? containership, ?]but maybe it's also this,\nthat, or a third, or fourth,and fifth thing.So that is a pretty good\nsummary of the kindsof things that are involved.But now we've got one more\nstep, because what we can do nowis we can take this output\nlayer idea, this softmax idea,and we can put them together\nwith the autocoding idea.So we've trained\njust a layer up.And now we're going to detach\nit from the output layerbut retain those\nweights that connectthe input to the hidden layer.And when we do that,\nwhat we're going to see", "start": 2040.0, "heat": 0.296}, {"text": "is something that\nlooks like this.And now we've got a\ntrained first layerbut an untrained output layer.We're going to freeze\nthe input layerand train the output layer\nusing the sigmoid curveand see what happens\nwhen we do that.Oh, by the way, let's run\nour test samples through.You can see it's\nnot doing anything,and the output is half\nfor each of the categorieseven though we've got\na trained middle layer.So we have to train\nthe outer layer.Let's see how long it takes.Whoa, that was pretty fast.Now there's an extraordinarily\ngood match between the outputsand the desired outputs.So that's the combination\nof the autocodingidea and the softmax idea.[? There's ?] just one more\nidea that's worthy of mention,and that's the idea of dropout.The plague of any neural\nnet is that it gets stuckin some kind of local maximum.So it was discovered\nthat these things trainbetter if, on every\niteration, youflip a coin for each neuron.And if the coin\nends up tails, youassume it's just died and has\nno influence on the output.It's called dropping\nout those neurons.And in our next iteration,\nyou drop out a different set.So what this seems\nto do is it seemsto prevent this thing from going\ninto a frozen local maximumstate.So that's deep nets.They should be called, by the\nway, wide nets because theytend to be enormously\nwide but rarelymore than 10 columns deep.", "start": 2160.0, "heat": 0.42}, {"text": "Now, let's see, where\nto go from here?Maybe what we should do is talk\nabout the awesome curiosityin the current state of the art.And that is that\nall of [? this ?]sophistication with output\nlayers that are probabilitiesand training using autocoding\nor Boltzmann machines,it doesn't seem to help much\nrelative to plain, old backpropagation.So back propagation\nwith a convolutional netseems to do just about\nas good as anything.And while we're on the subject\nof an ordinary deep net,I'd like to examine\na situation herewhere we have a deep net--\nwell, it's a classroom deep net.And we'll will put\nfive layers in there,and its job is still\nto do the same thing.It's to classify an animal as a\ncheetah, a zebra, or a giraffebased on the height of\nthe shadow it casts.And as before, if it's\ngreen, that means positive.If it's red, that\nmeans negative.And right at the moment,\nwe have no training.So if we run our\ntest samples through,the output is always a 1/2\nno matter what the animal is.All right?So what we're\ngoing to do is justgoing to use ordinary back\nprop on this, same thingas in that sample that's\nunderneath the blackboard.Only now we've got a\nlot more parameters.We've got five columns,\nand each one of themhas 9 or 10 neurons in it.So let's let this one run.Now, look at that\nstuff on the right.It's all turned red.At first I thought this\nwas a bug in my program.", "start": 2280.0, "heat": 0.429}, {"text": "But that makes absolute sense.If you don't know what the\nactual animal is going to beand there are a whole\nbunch of possibilities,you better just say\nno for everybody.It's like when a biologist\nsays, we don't know.It's the most probable answer.Well, but eventually, after\nabout 160,000 iterations,it seems to have got it.Let's run the test\nsamples through.Now it's doing great.Let's do it again just to\nsee if this is a fluke.And all red on the right\nside, and finally, youstart seeing some changes go\nin the final layers there.And if you look at the error\nrate down at the bottom,you'll see that it kind\nof falls off a cliff.So nothing happens\nfor a real long time,and then it falls off a cliff.Now, what would happen if\nthis neural net were notquite so wide?Good question.But before we get to that\nquestion, what I'm going to dois I'm going to do a\nfunny kind of variationon the theme of dropout.What I'm going to\ndo is I'm goingto kill off one\nneuron in each column,and then see if I can\nretrain the networkto do the right thing.So I'm going to reassign\nthose to some other purpose.So now there's one fewer\nneuron in the network.If we rerun that, we see that\nit trains itself up very fast.So we seem to be\nstill close enoughto a solution we\ncan do without oneof the neurons in each column.Let's do it again.Now it goes up a little\nbit, but it quicklyfalls down to a solution.Try again.", "start": 2400.0, "heat": 0.714}, {"text": "Quickly falls down\nto a solution.Oh, my god, how much of\nthis am I going to do?Each time I knock\nsomething out and retrain,it finds its solution very fast.Whoa, I got it all the way down\nto two neurons in each column,and it still has a solution.It's interesting,\ndon't you think?But let's repeat the\nexperiment, but this time we'regoing to do it a\nlittle differently.We're going to take\nour five layers,and before we do\nany training I'mgoing to knock out all but\ntwo neurons in each column.Now, I know that with two\nneurons in each column,I've got a solution.I just showed it.I just showed one.But let's run it this way.It looks like\nincreasingly bad news.What's happened is that\nthis sucker's got itselfinto a local maximum.So now you can see\nwhy there's beena breakthrough in this\nneural net learning stuff.And it's because when\nyou widen the net,you turn local maxima\ninto saddle points.So now it's got a way\nof crawling its waythrough this vast\nspace without gettingstuck on a local maximum,\nas suggested by this.All right.So those are some, I\nthink, interesting thingsto look at by way of\nthese demonstrations.", "start": 2520.0, "heat": 0.933}, {"text": "But now I'd like to go\nback to my slide setand show you some\nexamples that will addressthe question of whether these\nthings are seeing like we see.So you can try these\nexamples online.There are a variety\nof websites that allowyou to put in your own picture.And there's a cottage industry\nof producing papers in journalsthat fool neural nets.So in this case, a very\nsmall number of pixelshave been changed.You don't see the\ndifference, but it'senough to take this\nparticular neural netfrom a high confidence that\nit's looking at a school busto thinking that it's\nnot a school bus.Those are some things that\nit thinks are a school bus.So it appears to be\nthe case that whatis triggering this\nschool bus resultis that it's seeing enough\nlocal evidence that this is notone of the other 999 classes\nand enough positive evidencefrom these local\nlooks to concludethat it's a school bus.So do you see any\nof those things?I don't.And here you can say, OK, well,\nlook at that baseball one.Yeah, that looks like it's got\na little bit of baseball texturein it.So maybe what it's doing\nis looking at texture.These are some examples from\na recent and very famouspaper by Google using\nessentially the same ideasto put captions on pictures.So this, by the way,\nis what has stimulatedall this enormous concern\nabout artificial intelligence.Because a naive viewer looks\nat that picture and says,oh, my god, this\nthing knows what", "start": 2640.0, "heat": 1.0}, {"text": "it's like to play, or be young,\nor move, or what a Frisbee is.And of course, it\nknows none of that.It just knows how to\nlabel this picture.And to the credit of the\npeople who wrote this paper,they show examples\nthat don't do so well.So yeah, it's a cat,\nbut it's not lying.Oh, it's a little girl, but\nshe's not blowing bubbles.What about this one?[LAUGHTER]So we've been doing our\nown work in my laboratoryon some of this.And the way the following set of\npictures was produced was this.You take an image,\nand you separate itinto a bunch of slices,\neach representinga particular frequency band.And then you go into one\nof those frequency bandsand you knock out a\nrectangle from the picture,and then you\nreassemble the thing.And if you hadn't\nknocked that piece out,when you reassemble it,\nit would look exactlylike it did when you started.So what we're doing is we\nknock out as much as we canand still retain the\nneural net's impressionthat it's the thing that it\nstarted out thinking it was.So what do you think this is?It's identified by a neural\nnet as a railroad carbecause this is the image\nthat it started with.How about this one?That's easy, right?That's a guitar.We weren't able to mutilate that\none very much and still retainthe guitar-ness of it.How about this one?AUDIENCE: A lamp?PATRICK H. WINSTON: What's that?AUDIENCE: Lamp.PATRICK H. WINSTON: What?AUDIENCE: Lamp.PATRICK H. WINSTON: A lamp.Any other ideas?AUDIENCE: [INAUDIBLE].AUDIENCE: [INAUDIBLE].PATRICK H. WINSTON: Ken,\nwhat do you think it is?AUDIENCE: A toilet.PATRICK H. WINSTON: See, he's\nan expert on this subject.[LAUGHTER]It was identified as a barbell.What's that?AUDIENCE: [INAUDIBLE].PATRICK H. WINSTON: A what?AUDIENCE: Cello.PATRICK H. WINSTON: Cello.You didn't see the little\ngirl or the instructor.How about this one?", "start": 2760.0, "heat": 0.812}, {"text": "AUDIENCE: [INAUDIBLE].PATRICK H. WINSTON: What?AUDIENCE: [INAUDIBLE].PATRICK H. WINSTON: No.AUDIENCE: [INAUDIBLE].PATRICK H. WINSTON:\nIt's a grasshopper.What's this?AUDIENCE: A wolf.PATRICK H. WINSTON:\nWow, you're good.It's actually not\na two-headed wolf.[LAUGHTER]It's two wolves that\nare close together.AUDIENCE: [INAUDIBLE].PATRICK H. WINSTON:\nThat's a bird, right?AUDIENCE: [INAUDIBLE].PATRICK H. WINSTON:\nGood for you.It's a rabbit.[LAUGHTER]How about that?[? AUDIENCE: Giraffe. ?]PATRICK H. WINSTON:\nRussian wolfhound.AUDIENCE: [INAUDIBLE].PATRICK H. WINSTON: If\nyou've been to Venice,you recognize this.AUDIENCE: [INAUDIBLE].PATRICK H. WINSTON:\nSo bottom lineis that these things\nare an engineeringmarvel and do great things,\nbut they don't see like we see.", "start": 2880.0, "heat": 0.946}]