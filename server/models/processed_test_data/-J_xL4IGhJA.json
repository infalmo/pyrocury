[{"text": "[MUSIC PLAYING]PROFESSOR: I'd like to\nwelcome you to thiscourse on computer science.Actually, that's a terrible\nway to start.Computer science is a terrible\nname for this business.First of all, it's\nnot a science.It might be engineering or it\nmight be art, but we'llactually see that computer\nso-called science actually hasa lot in common with magic,\nand we'll seethat in this course.So it's not a science.It's also not really very\nmuch about computers.And it's not about computers in\nthe same sense that physicsis not really about particle\naccelerators, and biology isnot really about microscopes\nand petri dishes.And it's not about computers\nin the same sense thatgeometry is not really about\nusing surveying instruments.In fact, there's a lot of\ncommonality between computerscience and geometry.Geometry, first of all,\nis another subjectwith a lousy name.The name comes from Gaia,\nmeaning the Earth, and metron,meaning to measure.Geometry originally\nmeant measuringthe Earth or surveying.And the reason for that was\nthat, thousands of years ago,the Egyptian priesthood\ndeveloped the rudiments ofgeometry in order to figure\nout how to restore theboundaries of fields that were\ndestroyed in the annualflooding of the Nile.And to the Egyptians who did\nthat, geometry really was theuse of surveying instruments.Now, the reason that we think\ncomputer science is aboutcomputers is pretty much the\nsame reason that the Egyptians", "start": 0.0, "heat": 0.447}, {"text": "thought geometry was about\nsurveying instruments.And that is, when some field\nis just getting started andyou don't really understand it\nvery well, it's very easy toconfuse the essence of what\nyou're doing with the toolsthat you use.And indeed, on some absolute\nscale of things, we probablyknow less about the essence of\ncomputer science than theancient Egyptians really\nknew about geometry.Well, what do I mean by the\nessence of computer science?What do I mean by the\nessence of geometry?See, it's certainly true that\nthese Egyptians went off andused surveying instruments, but\nwhen we look back on themafter a couple of thousand\nyears, we say, gee, what theywere doing, the important stuff\nthey were doing, was tobegin to formalize notions about\nspace and time, to starta way of talking about\nmathematical truths formally.That led to the axiomatic\nmethod.That led to sort of all of\nmodern mathematics, figuringout a way to talk precisely\nabout so-called declarativeknowledge, what is true.Well, similarly, I think in the\nfuture people will lookback and say, yes, those\nprimitives in the 20th centurywere fiddling around with\nthese gadgets calledcomputers, but really what they\nwere doing is starting tolearn how to formalize\nintuitions about process, howto do things, starting to\ndevelop a way to talkprecisely about how-to\nknowledge, as opposed togeometry that talks about\nwhat is true.Let me give you an\nexample of that.", "start": 120.0, "heat": 0.47}, {"text": "Let's take a look.Here is a piece of mathematics\nthat says whata square root is.The square root of X is the\nnumber Y, such that Y squaredis equal to X and Y\nis greater than 0.Now, that's a fine piece of\nmathematics, but just tellingyou what a square root is\ndoesn't really say anythingabout how you might go\nout and find one.So let's contrast that with a\npiece of imperative knowledge,how you might go out and\nfind a square root.This, in fact, also comes\nfrom Egypt, notancient, ancient Egypt.This is an algorithm due to\nHeron of Alexandria, calledhow to find a square root\nby successive averaging.And what it says is that, in\norder to find a square root,you make a guess, you\nimprove that guess--and the way you improve the\nguess is to average the guessand X over the guess, and we'll\ntalk a little bit laterabout why that's a reasonable\nthing--and you keep improving the guess\nuntil it's good enough.That's a method.That's how to do something\nas opposed to declarativeknowledge that says what\nyou're looking for.That's a process.Well, what's a process\nin general?It's kind of hard to say.You can think of it as like a\nmagical spirit that sort oflives in the computer\nand does something.And the thing that directs a\nprocess is a pattern of rulescalled a procedure.", "start": 240.0, "heat": 0.363}, {"text": "So procedures are the spells,\nif you like, that controlthese magical spirits that\nare the processes.I guess you know everyone needs\na magical language, andsorcerers, real sorcerers, use\nancient Arcadian or Sumerianor Babylonian or whatever.We're going to conjure our\nspirits in a magical languagecalled Lisp, which is a language\ndesigned for talkingabout, for casting the spells\nthat are procedures to directthe processes.Now, it's very easy\nto learn Lisp.In fact, in a few minutes,\nI'm going to teach you,essentially, all of Lisp.I'm going to teach you,\nessentially, all of the rules.And you shouldn't find that\nparticularly surprising.That's sort of like saying it's\nvery easy to learn therules of chess.And indeed, in a few minutes,\nyou can tell somebody therules of chess.But of course, that's very\ndifferent from saying youunderstand the implications of\nthose rules and how to usethose rules to become a\nmasterful chess player.Well, Lisp is the same way.We're going to state the rules\nin a few minutes, and it'll bevery easy to see.But what's really hard is going\nto be the implicationsof those rules, how you exploit\nthose rules to be amaster programmer.And the implications of those\nrules are going to take usthe, well, the whole rest of\nthe subject and, of course,way beyond.OK, so in computer science,\nwe're in the business offormalizing this sort of how-to\nimperative knowledge,how to do stuff.And the real issues of computer\nscience are, ofcourse, not telling people\nhow to do square roots.Because if that was\nall it was, therewouldn't be no big deal.The real problems come when we\ntry to build very, very largesystems, computer programs that\nare thousands of pageslong, so long that nobody can\nreally hold them in theirheads all at once.And the only reason that that's\npossible is becausethere are techniques for\ncontrolling the complexity of", "start": 360.0, "heat": 0.356}, {"text": "these large systems. And these\ntechniques that arecontrolling complexity\nare what thiscourse is really about.And in some sense, that's\nreally whatcomputer science is about.Now, that may seem like a very\nstrange thing to say.Because after all, a lot of\npeople besides computerscientists deal with controlling\ncomplexity.A large airliner is an extremely\ncomplex system, andthe aeronautical engineers who\ndesign that are dealing withimmense complexity.But there's a difference\nbetween that kind ofcomplexity and what we deal\nwith in computer science.And that is that computer\nscience, in somesense, isn't real.You see, when an engineer is\ndesigning a physical system,that's made out of real parts.The engineers who worry about\nthat have to address problemsof tolerance and approximation\nand noise in the system.So for example, as an electrical\nengineer, I can gooff and easily build a one-stage\namplifier or atwo-stage amplifier, and I can\nimagine cascading a lot ofthem to build a million-stage\namplifier.But it's ridiculous to build\nsuch a thing, because longbefore the millionth stage,\nthe thermal noise in thosecomponents way at the beginning\nis going to getamplified and make the whole\nthing meaningless.Computer science deals with\nidealized components.We know as much as we want about\nthese little program anddata pieces that we're fitting\nthings together.We don't have to worry\nabout tolerance.And that means that, in building\na large program,there's not all that much\ndifference between what I can", "start": 480.0, "heat": 0.441}, {"text": "build and what I can imagine,\nbecause the parts are theseabstract entities that I\nknow as much as I want.I know about them as precisely\nas I'd like.So as opposed to other kinds\nof engineering, where theconstraints on what you can\nbuild are the constraints ofphysical systems, the\nconstraints of physics andnoise and approximation, the\nconstraints imposed inbuilding large software systems\nare the limitations ofour own minds.So in that sense, computer\nscience is like an abstractform of engineering.It's the kind of engineering\nwhere you ignore theconstraints that are\nimposed by reality.Well, what are some of\nthese techniques?They're not special to\ncomputer science.First technique, which is used\nin all of engineering, is akind of abstraction called\nblack-box abstraction.Take something and build\na box about it.Let's see, for example, if we\nlooked at that square rootmethod, I might want to take\nthat and build a box.That sort of says, to find the\nsquare root of X. And thatmight be a whole complicated\nset of rules.And that might end up being a\nkind of thing where I can putin, say, 36 and say, what's\nthe square root of 36?And out comes six.And the important thing is that\nI'd like to design thatso that if George comes along\nand would like to compute,", "start": 600.0, "heat": 0.39}, {"text": "say, the square root of A plus\nthe square root of B, he cantake this thing and use it as\na module without having tolook inside and build something\nthat looks likethis, like an A and a B and a\nsquare root box and anothersquare root box and then\nsomething that adds that wouldput out the answer.And you can see, just from the\nfact that I want to do that,is from George's point of view,\nthe internals of what'sin here should not\nbe important.So for instance, it shouldn't\nmatter that, when I wrotethis, I said I want to find the\nsquare root of X. I couldhave said the square root of Y,\nor the square root of A, oranything at all.That's the fundamental notion of\nputting something in a boxusing black-box abstraction\nto suppress detail.And the reason for that is you\nwant to go off and buildbigger boxes.Now, there's another reason\nfor doing black-boxabstraction other than you want\nto suppress detail forbuilding bigger boxes.Sometimes you want to say that\nyour way of doing something,your how-to method, is an\ninstance of a more generalthing, and you'd like your\nlanguage to be able to expressthat generality.Let me show you another examplesticking with square roots.Let's go back and take another\nlook at that slide with thesquare root algorithm on it.Remember what that says.That says, in order to do\nsomething, I make a guess, andI improve that guess,\nand I sort of keepimproving that guess.So there's the general strategy\nof, I'm looking forsomething, and the way\nI find it is that I", "start": 720.0, "heat": 0.435}, {"text": "keep improving it.Now, that's a particular case\nof another kind of strategyfor finding a fixed point\nof something.So you have a fixed point\nof a function.A fixed point of a function\nis something, is a value.A fixed point of a function F is\na value Y, such that F of Yequals Y. And the way I might do\nthat is start with a guess.And then if I want something\nthat doesn't change when Ikeep applying F, is I'll keep\napplying F over and over untilthat result doesn't\nchange very much.So there's a general strategy.And then, for example, to\ncompute the square root of X,I can try and find a fixed point\nof the function whichtakes Y to the average of X/Y.\nAnd the idea that is that if Ireally had Y equal to the square\nroot of X, then Y andX/Y would be the same value.They'd both be the square root\nof X, because X over thesquare root of X is the\nsquare root of X.And so the average if Y were\nequal to the square of X, thenthe average wouldn't change.So the square root of X\nis a fixed point ofthat particular function.Now, what I'd like to have,\nI'd like to express thegeneral strategy for finding\nfixed points.So what I might imagine doing,\nis to find, is to be able touse my language to define a box\nthat says \"fixed point,\"just like I could make a box\nthat says \"square root.\" AndI'd like to be able to express\nthis in my language.So I'd like to express not only\nthe imperative how-to", "start": 840.0, "heat": 0.562}, {"text": "knowledge of a particular thing\nlike square root, butI'd like to be able to express\nthe imperative knowledge ofhow to do a general thing like\nhow to find fixed point.And in fact, let's go back and\nlook at that slide again.See, not only is this a piece\nof imperative knowledge, howto find a fixed point, but\nover here on the bottom,there's another piece of\nimperative knowledge whichsays, one way to compute square\nroot is to apply thisgeneral fixed point method.So I'd like to also\nbe able to expressthat imperative knowledge.What would that look like?That would say, this fixed point\nbox is such that if Iinput to it the function that\ntakes Y to the average of Yand X/Y, then what should come\nout of that fixed point box isa method for finding\nsquare roots.So in these boxes we're\nbuilding, we're not onlybuilding boxes that you input\nnumbers and output numbers,we're going to be building in\nboxes that, in effect, computemethods like finding\nsquare root.And my take is their inputs\nfunctions, like Y goes to theaverage of Y and X/Y. The reason\nwe want to do that, thereason this is a procedure, will\nend up being a procedure,as we'll see, whose value is\nanother procedure, the reasonwe want to do that is because\nprocedures are going to be ourways of talking about imperative\nknowledge.And the way to make that very\npowerful is to be able to talkabout other kinds\nof knowledge.So here is a procedure that, in\neffect, talks about anotherprocedure, a general strategy\nthat itself talks aboutgeneral strategies.", "start": 960.0, "heat": 0.703}, {"text": "Well, our first topic in this\ncourse-- there'll be threemajor topics-- will be black-box\nabstraction.Let's look at that in a little\nbit more detail.What we're going to do is we\nwill start out talking abouthow Lisp is built up out\nof primitive objects.What does the language\nsupply with us?And we'll see that there are\nprimitive procedures andprimitive data.Then we're going to see, how do\nyou take those primitivesand combine them to make more\ncomplicated things, means ofcombination?And what we'll see is that\nthere are ways of puttingthings together, putting\nprimitive procedures togetherto make more complicated\nprocedures.And we'll see how to put\nprimitive data together tomake compound data.Then we'll say, well, having\nmade those compounds things,how do you abstract them?How do you put those black boxes\naround them so you canuse them as components in\nmore complex things?And we'll see that's done by\ndefining procedures and atechnique for dealing with\ncompound data called dataabstraction.And then, what's maybe the most\nimportant thing, is goingfrom just the rules to how\ndoes an expert work?How do you express common\npatterns of doing things, likesaying, well, there's a general\nmethod of fixed pointand square root is a particular\ncase of that?And we're going to use--I've already hinted at it--\nsomething called higher-orderprocedures, namely procedures\nwhose inputs and outputs arethemselves procedures.And then we'll also see\nsomething very interesting.We'll see, as we go further and\nfurther on and become moreabstract, there'll be very--well, the line between what we\nconsider to be data and whatwe consider to be procedures\nis going to blur at anincredible rate.", "start": 1080.0, "heat": 0.356}, {"text": "Well, that's our first\nsubject, black-boxabstraction.Let's look at the\nsecond topic.I can introduce it like this.See, suppose I want to\nexpress the idea--remember, we're talking\nabout ideas--suppose I want to express the\nidea that I can take somethingand multiply it by the sum\nof two other things.So for example, I might say,\nif I had one and three andmultiply that by two,\nI get eight.But I'm talking about the\ngeneral idea of what's calledlinear combination, that you\ncan add two things andmultiply them by\nsomething else.It's very easy when I think\nabout it for numbers, butsuppose I also want to use that\nsame idea to think about,I could add two vectors, a1 and\na2, and then scale them bysome factor x and get\nanother vector.Or I might say, I want to think\nabout a1 and a2 as beingpolynomials, and I might want\nto add those two polynomialsand then multiply them by two to\nget a more complicated one.Or a1 and a2 might be electrical\nsignals, and Imight want to think about\nsumming those two electricalsignals and then putting the\nwhole thing through anamplifier, multiplying\nit by somefactor of two or something.The idea is I want to\nthink about thegeneral notion of that.Now, if our language is going\nto be good language forexpressing those kind of general\nideas, if I really,really can do that, I'd like to\nbe able to say I'm going tomultiply by x the sum of a1 and\na2, and I'd like that to", "start": 1200.0, "heat": 0.372}, {"text": "express the general idea of all\ndifferent kinds of thingsthat a1 and a2 could be.Now, if you think about that,\nthere's a problem, becauseafter all, the actual primitive\noperations that goon in the machine are obviously\ngoing to bedifferent if I'm adding two\nnumbers than if I'm adding twopolynomials, or if I'm adding\nthe representation of twoelectrical signals\nor wave forms.Somewhere, there has to be the\nknowledge of the kinds ofvarious things that you\ncan add and theways of adding them.Now, to construct such a system,\nthe question is, wheredo I put that knowledge?How do I think about\nthe different kindsof choices I have?And if tomorrow George comes up\nwith a new kind of objectthat might be added and\nmultiplied, how do I addGeorge's new object to the\nsystem without screwing upeverything that was\nalready there?Well, that's going to be the\nsecond big topic, the way ofcontrolling that kind\nof complexity.And the way you do that is by\nestablishing conventionalinterfaces, agreed upon ways of\nplugging things together.Just like in electrical\nengineering, people havestandard impedances for\nconnectors, and then you knowif you build something with\none of those standardimpedances, you can plug it\ntogether with something else.So that's going to be our\nsecond large topic,conventional interfaces.What we're going to see is,\nfirst, we're going to talkabout the problem of generic\noperations, which is the one Ialluded to, things like \"plus\"\nthat have to work with alldifferent kinds of data.So we talk about generic\noperations.Then we're going to talk about\nreally large-scale structures.How do you put together very\nlarge programs that model the", "start": 1320.0, "heat": 0.42}, {"text": "kinds of complex systems\nin the real world thatyou'd like to model?And what we're going to see\nis that there are two veryimportant metaphors for putting\ntogether such systems.One is called object-oriented\nprogramming, where you sort ofthink of your system as a kind\nof society full of littlethings that interact by sendinginformation between them.And then the second one is\noperations on aggregates,called streams, where you think\nof a large system puttogether kind of like a signal\nprocessing engineer putstogether a large electrical\nsystem.That's going to be\nour second topic.Now, the third thing we're going\nto come to, the thirdbasic technique for controlling\ncomplexity, ismaking new languages.Because sometimes, when you're\nsort of overwhelmed by thecomplexity of a design, the\nway that you control thatcomplexity is to pick a\nnew design language.And the purpose of the new\ndesign language will be tohighlight different aspects\nof the system.It will suppress some kinds of\ndetails and emphasize otherkinds of details.This is going to be the most\nmagical part of the course.We're going to start out by\nactually looking at thetechnology for building new\ncomputer languages.The first thing we're going to\ndo is actually build in Lisp.We're going to express in Lisp\nthe process of interpretingLisp itself.And that's going to be a very\nsort of self-circular thing.There's a little mystical\nsymbol thathas to do with that.The process of interpreting Lisp\nis sort of a giant wheelof two processes, apply and\neval, which sort of constantlyreduce expressions\nto each other.Then we're going to see all\nsorts of other magical things.Here's another magical symbol.This is sort of the Y operator,\nwhich is, in some", "start": 1440.0, "heat": 0.331}, {"text": "sense, the expression\nof infinity insideour procedural language.We'll take a look at that.In any case, this section\nof the course is calledMetalinguistic Abstraction,\nabstracting by talking abouthow you construct\nnew languages.As I said, we're going to start\nout by looking at theprocess of interpretation.We're going to look\nat this apply-evalloop, and build Lisp.Then, just to show you that this\nis very general, we'regoing to use exactly the same\ntechnology to build a verydifferent kind of language, a\nso-called logic programminglanguage, where you don't really\ntalk about proceduresat all that have inputs\nand outputs.What you do is talk about\nrelations between things.And then finally, we're going\nto talk about how youimplement these things very\nconcretely on the verysimplest kind of machines.We'll see something like this.This is a picture of a chip,\nwhich is the Lisp interpreterthat we will be talking about\nthen in hardware.Well, there's an outline of the\ncourse, three big topics.Black-box abstraction,\nconventional interfaces,metalinguistic abstraction.Now, let's take a break now and\nthen we'll get started.[MUSIC PLAYING]", "start": 1560.0, "heat": 0.448}, {"text": "Let's actually start in\nlearning Lisp now.Actually, we'll start out by\nlearning something much moreimportant, maybe the very most\nimportant thing in thiscourse, which is not Lisp, in\nparticular, of course, butrather a general framework for\nthinking about languages thatI already alluded to.When somebody tells you they're\ngoing to show you alanguage, what you should say\nis, what I'd like you to tellme is what are the primitive\nelements?What does the language\ncome with?Then, what are the ways you\nput those together?What are the means\nof combination?What are the things that allow\nyou to take these primitiveelements and build bigger\nthings out of them?What are the ways of putting\nthings together?And then, what are the\nmeans of abstraction?How do we take those complicated\nthings and drawthose boxes around them?How do we name them so that we\ncan now use them as if theywere primitive elements\nin making stillmore complex things?And so on, and so\non, and so on.So when someone says to you,\ngee, I have a great newcomputer language, you don't\nsay, how many characters doesit take to invert a matrix?It's irrelevant.What you say is, if the language\ndid not come withmatrices built in or with\nsomething else built in, howcould I then build that thing?What are the means of\ncombination which would allowme to do that?And then, what are the means of\nabstraction which allow methen to use those as elements\nin making more complicatedthings yet?Well, we're going to see that\nLisp has some primitive data", "start": 1680.0, "heat": 0.414}, {"text": "and some primitive procedures.In fact, let's really start.And here's a piece of\nprimitive data inLisp, number three.Actually, if I'm being very\npedantic, that's not thenumber three.That's some symbol that\nrepresents Plato's concept ofthe number three.And here's another.Here's some more primitive\ndata in Lisp, 17.4.Or actually, some representation\nof 17.4.And here's another one, five.Here's another primitive\nobject that'sbuilt in Lisp, addition.Actually, to use the same kind\nof pedantic-- this is a namefor the primitive method\nof adding things.Just like this is a name for\nPlato's number three, this isa name for Plato's concept\nof how you add things.So those are some primitive\nelements.I can put them together.I can say, gee, what's the sum\nof three and 17.4 and five?And the way I do that is to\nsay, let's apply the sumoperator to these\nthree numbers.And I should get,\nwhat? eight, 17.25.4.So I should be able to ask Lisp\nwhat the value of thisis, and it will return 25.4.Let's introduce some names.This thing that I typed is\ncalled a combination.And a combination consists,\nin general,of applying an operator--", "start": 1800.0, "heat": 0.3}, {"text": "so this is an operator--to some operands.These are the operands.And of course, I can make\nmore complex things.The reason I can get complexity\nout of this isbecause the operands themselves,\nin general, can becombinations.So for instance, I could say,\nwhat is the sum of three andthe product of five and\nsix and eight and two?And I should get-- let's see--30, 40, 43.So Lisp should tell\nme that that's 43.Forming combinations is the\nbasic needs of combinationthat we'll be looking at.And then, well, you see\nsome syntax here.Lisp uses what's called prefix\nnotation, which means that theoperator is written to the\nleft of the operands.It's just a convention.And notice, it's fully\nparenthesized.And the parentheses make it\ncompletely unambiguous.So by looking at this, I can see\nthat there's the operator,and there are one, two,\nthree, four operands.And I can see that the second\noperand here is itself somecombination that has one\noperator and two operands.Parentheses in Lisp are a little\nbit, or are very unlikeparentheses in conventional\nmathematics.In mathematics, we sort of use\nthem to mean grouping, and it", "start": 1920.0, "heat": 0.223}, {"text": "sort of doesn't hurt if\nsometimes you leave outparentheses if people\nunderstandthat that's a group.And in general, it doesn't\nhurt if you put in extraparentheses, because that\nmaybe makes thegrouping more distinct.Lisp is not like that.In Lisp, you cannot leave out\nparentheses, and you cannotput in extra parentheses,\nbecause putting in parenthesesalways means, exactly and\nprecisely, this is acombination which has\nmeaning, applyingoperators to operands.And if I left this out, if I\nleft those parentheses out, itwould mean something else.In fact, the way to think about\nthis, is really what I'mdoing when I write something\nlike this is writing a tree.So this combination is a tree\nthat has a plus and then athee and then a something else\nand an eight and a two.And then this something else\nhere is itself a littlesubtree that has a star\nand a five and a six.And the way to think of that\nis, really, what's going onare we're writing these trees,\nand parentheses are just a wayto write this two-dimensional\nstructure as a linearcharacter string.Because at least when Lisp first\nstarted and people hadteletypes or punch cards or\nwhatever, this was moreconvenient.Maybe if Lisp started today,\nthe syntax of Lispwould look like that.Well, let's look at\nwhat that actuallylooks like on the computer.Here I have a Lisp interaction\nset up.There's a editor.And on the top, I'm going to\ntype some values and ask Lispwhat they are.So for instance, I can say\nto Lisp, what's thevalue of that symbol?That's three.And I ask Lisp to evaluate it.And there you see Lisp has\nreturned on the bottom, andsaid, oh yeah, that's three.Or I can say, what's the sum of\nthree and four and eight?", "start": 2040.0, "heat": 0.285}, {"text": "What's that combination?And ask Lisp to evaluate it.That's 15.Or I can type in something\nmore complicated.I can say, what's the sum of the\nproduct of three and thesum of seven and 19.5?And you'll notice here that Lisp\nhas something built inthat helps me keep track of\nall these parentheses.Watch as I type the next closed\nparentheses, which isgoing to close the combination\nstarting with the star.The opening one will flash.Here, I'll rub those out\nand do it again.Type close, and you see\nthat closes the plus.Close again, that\ncloses the star.Now I'm back to the sum, and\nmaybe I'm going to add thatall to four.That closes the plus.Now I have a complete\ncombination, and I can askLisp for the value of that.That kind of paren balancing is\nsomething that's built intoa lot of Lisp systems to help\nyou keep track, because it iskind of hard just by hand doing\nall these parentheses.There's another kind of\nconvention for keeping trackof parentheses.Let me write another complicated\ncombination.Let's take the sum of the\nproduct of three and five andadd that to something.And now what I'm going to do is\nI'm going to indent so thatthe operands are written\nvertically.Which the sum of that and\nthe product of 47 and--let's say the product\nof 47 with adifference of 20 and 6.8.That means subtract\n6.8 from 20.And then you see the\nparentheses close.", "start": 2160.0, "heat": 0.467}, {"text": "Close the minus.Close the star.And now let's get another\noperator.You see the Lisp editor here\nis indenting to the rightposition automatically to\nhelp me keep track.I'll do that again.I'll close that last\nparentheses again.You see it balances the plus.Now I can say, what's\nthe value of that?So those two things, indenting\nto the right level, which iscalled pretty printing, and\nflashing parentheses, are twothings that a lot of Lisp\nsystems have built in to helpyou keep track.And you should learn\nhow to use them.Well, those are the\nprimitives.There's a means of\ncombination.Now let's go up to the\nmeans of abstraction.I'd like to be able to take\nthe idea that I do somecombination like this, and\nabstract it and give it asimple name, so I can use\nthat as an element.And I do that in Lisp with\n\"define.\" So I can say, forexample, define A to be the\nproduct of five and five.And now I could say, for\nexample, to Lisp, what is theproduct of A and A?And this should be 25, and\nthis should be 625.And then, crucial thing,\nI can now use A--here I've used it in\na combination--but I could use that in other\nmore complicated things that Iname in turn.So I could say, define B to be\nthe sum of, we'll say, A andthe product of five and A.\nAnd then close the plus.", "start": 2280.0, "heat": 0.591}, {"text": "Let's take a look at that\non the computer andsee how that looks.So I'll just type what\nI wrote on the board.I could say, define A to be the\nproduct of five and five.And I'll tell that to Lisp.And notice what Lisp responded\nthere withwas an A in the bottom.In general, when you type in\na definition in Lisp, itresponds with the symbol\nbeing defined.Now I could say to Lisp, what\nis the product of A and A?And it says that's 625.I can define B to be the sum of\nA and the product of fiveand A. Close a paren\ncloses the star.Close the plus.Close the \"define.\" Lisp says,\nOK, B, there on the bottom.And now I can say to Lisp,\nwhat's the value of B?And I can say something more\ncomplicated, like what's thesum of A and the quotient\nof B and five?That slash is divide, another\nprimitive operator.I've divided B by five,\nadded it to A. Lispsays, OK, that's 55.So there's what it looks like.There's the basic means\nof defining something.It's the simplest kind of\nnaming, but it's not reallyvery powerful.See, what I'd really\nlike to name--remember, we're talking about\ngeneral methods--I'd like to name, oh, the\ngeneral idea that, forexample, I could multiply five\nby five, or six by six, or", "start": 2400.0, "heat": 0.65}, {"text": "1,001 by 1,001, 1,001.7\nby 1,001.7.I'd like to be able to name\nthe general idea ofmultiplying something\nby itself.Well, you know what that is.That's called squaring.And the way I can do that in\nLisp is I can say, define tosquare something x, multiply\nx by itself.And then having done that,\nI could say to Lisp, forexample, what's the\nsquare of 10?And Lisp will say 100.So now let's actually look at\nthat a little more closely.Right, there's the definition\nof square.To square something, multiply\nit by itself.You see this x here.That x is kind of a pronoun,\nwhich is the something thatI'm going to square.And what I do with it\nis I multiply x, Imultiply it by itself.OK.So there's the notation for\ndefining a procedure.Actually, this is a little bit\nconfusing, because this issort of how I might\nuse square.And I say square root of x or\nsquare root of 10, but it'snot making it very clear that\nI'm actually naming something.", "start": 2520.0, "heat": 0.497}, {"text": "So let me write this definition\nin another way thatmakes it a little\nbit more clearthat I'm naming something.I'll say, \"define\" square to\nbe lambda of x times xx.Here, I'm naming something\nsquare, just like over here,I'm naming something A. The\nthing that I'm naming square--here, the thing I named A was\nthe value of this combination.Here, the thing that I'm naming\nsquare is this thingthat begins with lambda, and\nlambda is Lisp's way of sayingmake a procedure.Let's look at that more\nclosely on the slide.The way I read that definition\nis to say, I define square tobe make a procedure--that's what the lambda is--make a procedure with\nan argument named x.And what it does is return\nthe results ofmultiplying x by itself.Now, in general, we're going to\nbe using this top form ofdefining, just because it's a\nlittle bit more convenient.But don't lose sight of the fact\nthat it's really this.In fact, as far as the Lisp\ninterpreter's concerned,there's no difference between\ntyping this to it and typingthis to it.And there's a word for that,\nsort of syntactic sugar.What syntactic sugar means,\nit's having somewhat moreconvenient surface forms\nfor typing something.", "start": 2640.0, "heat": 0.332}, {"text": "So this is just really syntactic\nsugar for thisunderlying Greek thing\nwith the lambda.And the reason you should\nremember that is don't forgetthat, when I write something\nlike this, I'mreally naming something.I'm naming something square,\nand the something that I'mnaming square is a procedure\nthat's getting constructed.Well, let's look at that\non the computer, too.So I'll come and I'll say,\ndefine square ofx to be times xx.Now I'll tell Lisp that.It says \"square.\" See, I've\nnamed something \"square.\" Now,having done that, I can\nask Lisp for, what'sthe square of 1,001?Or in general, I could say,\nwhat's the square of the sumof five and seven?The square of 12's 144.Or I can use square itself\nas an element in somecombination.I can say, what's the sum of\nthe square of three and thesquare of four?nine and 16 is 25.Or I can use square as an\nelement in some much morecomplicated thing.I can say, what's the square\nof, the sqare of,the square of 1,001?", "start": 2760.0, "heat": 0.472}, {"text": "And there's the square of the\nsquare of the square of 1,001.Or I can say to Lisp, what\nis square itself?What's the value of that?And Lisp returns some\nconventional way of telling methat that's a procedure.It says, \"compound procedure\nsquare.\" Remember, the valueof square is this procedure, and\nthe thing with the starsand the brackets are just Lisp's\nconventional way ofdescribing that.Let's look at two more\nexamples of defining.Here are two more procedures.I can define the average of x\nand y to be the sum of x and ydivided by two.Or having had average and mean\nsquare, having had average andsquare, I can use that to talk\nabout the mean square ofsomething, which is the average\nof the square of x andthe square of y.So for example, having done\nthat, I could say, what's themean square of two and three?And I should get the\naverage of four andnine, which is 6.5.The key thing here is that,\nhaving defined square, I canuse it as if it were\nprimitive.So if we look here on the\nslide, if I look at meansquare, the person defining mean\nsquare doesn't have toknow, at this point, whether\nsquare was something builtinto the language or\nwhether it was aprocedure that was defined.And that's a key thing in Lisp,\nthat you do not make", "start": 2880.0, "heat": 0.54}, {"text": "arbitrary distinctions between\nthings that happen to beprimitive in the language\nand things thathappen to be built in.A person using that shouldn't\neven have to know.So the things you construct get\nused with all the powerand flexibility as if they\nwere primitives.In fact, you can drive that\nhome by looking on thecomputer one more time.We talked about plus.And in fact, if I come here on\nthe computer screen and say,what is the value of plus?Notice what Lisp types out.On the bottom there, it typed\nout, \"compound procedureplus.\" Because, in this system,\nit turns out that theaddition operator is itself\na compound procedure.And if I didn't just type that\nin, you'd never know that, andit wouldn't make any\ndifference anyway.We don't care.It's below the level of\nthe abstraction thatwe're dealing with.So the key thing is you cannot\ntell, should not be able totell, in general, the difference\nbetween things thatare built in and things\nthat are compound.Why is that?Because the things that are\ncompound have an abstractionwrapper wrapped around them.We've seen almost all the\nelements of Lisp now.There's only one more we have to\nlook at, and that is how tomake a case analysis.Let me show you what I mean.We might want to think about the\nmathematical definition ofthe absolute value functions.I might say the absolute value\nof x is the function which hasthe property that it's\nnegative of x.For x less than zero, it's\nzero for x equal to zero.And it's x for x greater\nthan zero.And Lisp has a way of making\ncase analyses.Let me define for you\nabsolute value.Say define the absolute value\nof x is conditional.", "start": 3000.0, "heat": 0.502}, {"text": "This means case analysis,\nCOND.If x is less than zero, the\nanswer is negate x.What I've written here\nis a clause.This whole thing is a\nconditional clause,and it has two parts.This part here is a predicate\nor a condition.That's a condition.And the condition is expressed\nby something called apredicate, and a predicate in\nLisp is some sort of thingthat returns either\ntrue or false.And you see Lisp has a\nprimitive procedure,less-than, that tests whether\nsomething is true or false.And the other part of a clause\nis an action or a thing to do,in the case where that's true.And here, what I'm doing\nis negating x.The negation operator, the\nminus sign in Lisp isa little bit funny.If there's two or more\narguments, if there's twoarguments it subtracts the\nsecond one from the first, andwe saw that.And if there's one argument,\nit negates it.So this corresponds to that.And then there's another\nCOND clause.It says, in the case where\nx is equal to zero,the answer is zero.And in the case where x\nis greater than zero,the answer is x.Close that clause.Close the COND.Close the definition.And there's the definition\nof absolute value.And you see it's the case\nanalysis that looks very muchlike the case analysis you\nuse in mathematics.There's a somewhat different\nway of writing a restricted", "start": 3120.0, "heat": 0.5}, {"text": "case analysis.Often, you have a case analysis\nwhere you only haveone case, where you test\nsomething, and then dependingon whether it's true or false,\nyou do something.And here's another definition of\nabsolute value which looksalmost the same, which says,\nif x is less than zero, theresult is negate x.Otherwise, the answer is x.And we'll be using \"if\" a lot.But again, the thing to remember\nis that this form ofabsolute value that you're\nlooking at here, and then thisone over here that I wrote\non the board, areessentially the same.And \"if\" and COND are--well, whichever way\nyou like it.You can think of COND as\nsyntactic sugar for \"if,\" oryou can think of \"if\" as\nsyntactic sugar for COND, andit doesn't make any\ndifference.The person implementing a Lisp\nsystem will pick one andimplement the other\nin terms of that.And it doesn't matter\nwhich one you pick.Why don't we break now, and\nthen take some questions.How come sometimes when I write\ndefine, I put an openparen here and say, define open\nparen something or other,and sometimes when\nI write this, Idon't put an open paren?The answer is, this particular\nform of \"define,\" where yousay define some expression, is\nthis very special thing fordefining procedures.But again, what it really means\nis I'm defining thissymbol, square, to be that.So the way you should think\nabout it is what \"define\" doesis you write \"define,\" and the\nsecond thing you write is thesymbol here-- no open paren--the symbol you're defining and\nwhat you're defining it to be.That's like here\nand like here.That's sort of the basic way\nyou use \"define.\" And then,", "start": 3240.0, "heat": 0.633}, {"text": "there's this special syntactic\ntrick which allows you todefine procedures that\nlook like this.So the difference is, it's\nwhether or not you're defininga procedure.[MUSIC PLAYING]Well, believe it or not, you\nactually now know enough Lispto write essentially any\nnumerical procedure that you'dwrite in a language like FORTRAN\nor Basic or whatever,or, essentially, any\nother language.And you're probably saying,\nthat's not believable, becauseyou know that these languages\nhave things like \"forstatements,\" and \"do until\nwhile\" or something.But we don't really\nneed any of that.In fact, we're not going\nto use any ofthat in this course.Let me show you.Again, looking back at square\nroot, let's go back to thissquare root algorithm of\nHeron of Alexandria.Remember what that said.It said, to find an\napproximation to the squareroot of X, you make a guess,\nyou improve that guess byaveraging the guess and\nX over the guess.You keep improving that until\nthe guess is good enough.I already alluded to the idea.The idea is that, if the initial\nguess that you tookwas actually equal to the square\nroot of X, then G herewould be equal to X/G.So if you hit the square\nroot, averaging themwouldn't change it.If the G that you picked was\nlarger than the square root ofX, then X/G will be smaller than\nthe square root of X, so", "start": 3360.0, "heat": 0.527}, {"text": "that when you average\nG and X/G, you getsomething in between.So if you pick a G that's\ntoo small, youranswer will be too large.If you pick a G that's too\nlarge, if your G is largerthan the square root of X and\nX/G will be smaller than thesquare root of X.So averaging always gives you\nsomething in between.And then, it's not quite\ntrivial, but it's possible toshow that, in fact, if G misses\nthe square root of X bya little bit, the average of G\nand X/G will actually keepgetting closer to the square\nroot of X. So if you keepdoing this enough, you'll\neventually get asclose as you want.And then there's another fact,\nthat you can always start outthis process by using 1\nas an initial guess.And it'll always converge to\nthe square root of X. Sothat's this method of successive\naveraging due toHeron of Alexandria.Let's write it in Lisp.Well, the central idea is, what\ndoes it mean to try aguess for the square\nroot of X?Let's write that.So we'll say, define to try a\nguess for the square root ofX, what do we do?We'll say, if the guess is good\nenough to be a guess forthe square root of X,\nthen, as an answer,we'll take the guess.Otherwise, we will try\nthe improved guess.We'll improve that guess for\nthe square root of X, and", "start": 3480.0, "heat": 0.338}, {"text": "we'll try that as a guess for\nthe square root of X. Closethe \"try.\" Close the \"if.\" Close\nthe \"define.\" So that'show we try a guess.And then, the next part of the\nprocess said, in order tocompute square roots, we'll\nsay, define to compute thesquare root of X, we will try\none as a guess for the squareroot of X. Well, we have to\ndefine a couple more things.We have to say, how is\na guess good enough?And how do we improve a guess?So let's look at that.The algorithm to improve a guess\nfor the square root ofX, we average--that was the algorithm--we average the guess with\nthe quotient ofdividing X by the guess.That's how we improve a guess.And to tell whether a guess is\ngood enough, well, we have todecide something.This is supposed to be a guess\nfor the square root of X, soone possible thing you can do\nis say, when you take thatguess and square it, do you get\nsomething very close to X?So one way to say that is to\nsay, I square the guess,subtract X from that, and see if\nthe absolute value of thatwhole thing is less than some\nsmall number, which depends onmy purposes.So there's a complete procedure\nfor how to computethe square root of X. Let's look\nat the structure of thata little bit.I have the whole thing.I have the notion of how to\ncompute a square root.That's some kind of module.That's some kind of black box.It's defined in terms of how to\ntry a guess for the square", "start": 3600.0, "heat": 0.409}, {"text": "root of X.\"Try\" is defined in terms of,\nwell, telling whethersomething is good enough\nand tellinghow to improve something.So good enough.\"Try\" is defined in terms of\n\"good enough\" and \"improve.\"And let's see what\nelse I fill in.Well, I'll go down this tree.\"Good enough\" was defined\nin terms ofabsolute value, and square.And improve was defined in\nterms of something calledaveraging and then some other\nprimitive operator.Square root's defined in terms\nof \"try.\" \"Try\" is defined interms of \"good enough\"\nand \"improve,\"but also \"try\" itself.So \"try\" is also defined in\nterms of how to try itself.Well, that may give you some\nproblems. Your high schoolgeometry teacher probably told\nyou that it's naughty to tryand define things in terms of\nthemselves, because it doesn'tmake sense.But that's false.Sometimes it makes perfect\nsense to define things interms of themselves.And this is the case.And we can look at that.We could write down what this\nmeans, and say, suppose Iasked Lisp what the square\nroot of two is.What's the square root\nof two mean?Well, that means I try one\nas a guess for thesquare root of two.Now I look.I say, gee, is one a good enough\nguess for the squareroot of two?And that depends on the test\nthat \"good enough\" does.And in this case, \"good enough\"\nwill say, no, one isnot a good enough guess for\nthe square root of two.So that will reduce to saying,\nI have to try an improved--", "start": 3720.0, "heat": 0.509}, {"text": "improve one as a guess for the\nsquare root of two, and trythat as a guess for the\nsquare root of two.Improving one as a guess for the\nsquare root of two means Iaverage one and two\ndivided by one.So this is going\nto be average.This piece here will be the\naverage of one and thequotient of two by one.That's this piece here.And this is 1.5.So this square root of two\nreduces to trying one for thesquare root of two, which\nreduces to trying 1.5 as aguess for the square\nroot of two.So that makes sense.Let's look at the rest\nof the process.If I try 1.5, that reduces.1.5 turns out to be not good\nenough as a guess for thesquare root of two.So that reduces to trying the\naverage of 1.5 and two dividedby 1.5 as a guess for the\nsquare root of two.That average turns\nout to be 1.333.So this whole thing reduces to\ntrying 1.333 as a guess forthe square root of two.And then so on.That reduces to another called\na \"good enough,\" 1.4something or other.And then it keeps going until\nthe process finally stops withsomething that \"good enough\"\nthinks is good enough, which,in this case, is 1.4142\nsomething or other.So the process makes\nperfect sense.This, by the way, is called\na recursive definition.", "start": 3840.0, "heat": 0.621}, {"text": "And the ability to make\nrecursive definitions is asource of incredible power.And as you can already see I've\nhinted at, it's the thingthat effectively allows you to\ndo these infinite computationsthat go on until something is\ntrue, without having any otherconstricts other than the\nability to call a procedure.Well, let's see, there's\none more thing.Let me show you a variant of\nthis definition of square roothere on the slide.Here's sort of the same thing.What I've done here is packaged\nthe definitions of\"improve\" and \"good enough\"\nand \"try\" inside \"squareroot.\" So, in effect, what\nI've done is I've built asquare root box.So I've built a box that's the\nsquare root procedure thatsomeone can use.They might put in 36\nand get out six.And then, packaged inside this\nbox are the definitions of\"try\" and \"good enough\"\nand \"improve.\"So they're hidden\ninside this box.And the reason for doing that\nis that, if someone's usingthis square root, if George is\nusing this square root, Georgeprobably doesn't care very much\nthat, when I implementedsquare root, I had things inside\nthere called \"try\" and\"good enough\" and \"improve.\" And\nin fact, Harry might havea cube root procedure that has\n\"try\" and \"good enough\" and\"improve.\" And in order to not\nget the whole system confused,it'd be good for Harry to\npackage his internalprocedures inside his\ncube root procedure.Well, this is called block\nstructure, this particular way", "start": 3960.0, "heat": 0.766}, {"text": "of packaging internals inside\nof a definition.And let's go back and look\nat the slide again.The way to read this kind of\nprocedure is to say, to define\"square root,\" well, inside that\ndefinition, I'll have thedefinition of an \"improve\" and\nthe definition of \"goodenough\" and the definition of\n\"try.\" And then, subject tothose definitions, the way I do\nsquare root is to try one.And notice here, I don't have to\nsay one as a guess for thesquare root of X, because since\nit's all inside thesquare root, it sort of\nhas this X known.Let me summarize.We started out with the idea\nthat what we're going to bedoing is expressing imperative\nknowledge.And in fact, here's a slide\nthat summarizes the way welooked at Lisp.We started out by looking at\nsome primitive elements inaddition and multiplication,\nsome predicates for testingwhether something is less-than\nor something's equal.And in fact, we saw really\nsneakily in the system we'reactually using, these aren't\nactually primitives, but itdoesn't matter.What matters is we're going\nto use them as if they'reprimitives.We're not going to\nlook inside.We also have some primitive\ndata and some numbers.We saw some means of\ncomposition, means ofcombination, the basic one being\ncomposing functions andbuilding combinations with\noperators and operands.And there were some other\nthings, like COND and \"if\" and\"define.\" But the main thing\nabout \"define,\" in particular,was that it was the means\nof abstraction.It was the way that\nwe name things.You can also see from this slide\nnot only where we'vebeen, but holes we\nhave to fill in.", "start": 4080.0, "heat": 0.539}, {"text": "At some point, we'll have to\ntalk about how you combineprimitive data to get compound\ndata, and how you abstractdata so you can use large\nglobs of data asif they were primitive.So that's where we're going.But before we do that, for the\nnext couple of lectures we'regoing to be talking about, first\nof all, how it is thatyou make a link between these\nprocedures we write and theprocesses that happen\nin the machine.And then, how it is that you\nstart using the power of Lispto talk not only about these\nindividual littlecomputations, but about general\nconventional methodsof doing things.OK, are there any questions?AUDIENCE: Yes.If we defined A using\nparentheses instead of as wedid, what would be\nthe difference?PROFESSOR: If I wrote this, if\nI wrote that, what I would bedoing is defining a procedure\nnamed A. In this case, aprocedure of no arguments,\nwhich, when I ran it, wouldgive me back five times five.AUDIENCE: Right.I mean, you come up with the\nsame thing, except for youreally got a different--PROFESSOR: Right.And the difference would\nbe, in the old one--Let me be a little\nbit clearer here.Let's call this A, like here.And pretend here, just for\ncontrast, I wrote, define D tobe the product of\nfive and five.And the difference between\nthose, let's think aboutinteractions with the\nLisp interpreter.I could type in A and Lisp\nwould return 25.I could type in D, if I just\ntyped in D, Lisp would return", "start": 4200.0, "heat": 0.521}, {"text": "compound procedure D, because\nthat's what it is.It's a procedure.I could run D. I could say,\nwhat's the value of running D?Here is a combination\nwith no operands.I see there are no operands.I didn't put any after D. And\nit would say, oh, that's 25.Or I could say, just for\ncompleteness, if I typed in,what's the value of running A?I get an error.The error would be the same\none as over there.It'd be the error would say,\nsorry, 25, which is the valueof A, is not an operator that\nI can apply to something.", "start": 4320.0, "heat": 0.512}]