[{"text": "The following content is\nprovided under a CreativeCommons license.Your support will help\nMIT OpenCourseWarecontinue to offer high quality\neducational resources for free.To make a donation or to\nview additional materialsfrom hundreds of MIT courses,\nvisit MIT OpenCourseWareat ocw.mit.edu.PHILIPPE RIGOLLET: --of\nour limiting distribution,which happen to be Gaussian.But if the central\nlimit theorem toldus that the limiting\ndistribution of some averagewas something that\nlooked like a Poissonor an [? exponential, ?]\nthen we would justhave in the same way\ntaken the quintilesof the exponential distribution.So let's go back to what we had.So generically if you have a\nset of observations X1 to Xn.So remember for the kiss example\nthey were denoted by R1 to Rn,because they were turning\nthe head to the right,but let's just go back.We say X1 to Xn,\nand in this caseI'm going to assume\nthey're IID, and I'mgoing to make them Bernoulli\nwith [INAUDIBLE] p,and p is unknown, right?So what did we do from here?Well, we said p is\nthe expectation of Xi,and actually we didn't even\nthink about it too much.We said, well, if\nI need to estimatethe proportion of people who\nturn their head to the rightwhen they kiss, I\njust basically I'mgoing to compute the average.So our p hat was just\nXn bar, which was just 1over n sum from i\nover 1 2n of the Xi.The average of the observations\nwas their estimate.And then we wanted to build\nsome confidence intervalsaround this.So what we wanted to understand\nis, how much that this p hatfluctuates.This is a random variable.It's an average of\nrandom variables.It's a random\nvariable, so we wantto know what the\ndistribution is.And if we know what\nthe distribution is,then we actually know,\nwell, where it fluctuates.What the expectation is.Around which value it tends\nto fluctuate et cetera.And so what the\ncentral limit theoremtold us was if I take square\nroot of n times Xn bar minus p,", "start": 0.0, "heat": 0.763}, {"text": "which is its average.And then I divide it by\nthe standard deviation.Then this thing here converges\nas n goes to infinity,and we will say\na little bit moreabout what it means\nin distributionto some standard\nnormal random variable.So that was the\ncentral limit theorem.So what it means is\nthat when I thinkof this as a random variable,\nwhen n is large enoughit's going to look like this.And so I understand\nperfectly its fluctuations.I know that this\nthing here has--I know the probability\nof being in this zone.I know that this\nnumber here is 0.I know a bunch of things.And then, in\nparticular, what I wasinterested in was that\nthe probability, that'sthe absolute value of a\nGaussian random variable,exceeds q alpha over\n2, q alpha over 2.We said that this\nwas equal to what?Anybody?What was that?AUDIENCE: [INAUDIBLE]PHILIPPE RIGOLLET: Alpha, right?So that's the probability.That's my random variable.So this is by definition q\nalpha over 2 is the number.So that to the right\nof it is alpha over 2.And this is a negative q\nalpha over 2 by symmetry.And so the probability\nthat i exceeds-- well,it's not very symmetric,\nbut the probabilitythat i exceeds this\nvalue, q alpha over 2,is just the sum of\nthe two gray areas.All right?So now I said that this thing\nwas approximately equal,due to the central\nlimit theorem,to the probability,\nthat square root of n.Xn bar minus p divided by\nsquare root p 1 minus p.", "start": 120.0, "heat": 0.484}, {"text": "Well, absolute value was\nlarger than q alpha over 2.Well, then this thing by default\nis actually approximately equalto alpha, just because of virtue\nof the central limit theorem.And then we just said,\nwell, I'll solve for p.Has anyone attempted to solve\nthe degree two equation for pin the homework?Everybody has tried it?So essentially, this is\ngoing to be an equation in p.Sometimes we don't\nwant to solve it.Some of the p's we will replace\nby their worst possible value.For example, we said one\nof the tricks we had wasthat this value here,\nsquare root of p 1 minus p,was always less than one half.Until we could actually get\nthe confidence interval thatwas larger than all\npossible confidenceintervals for all\npossible values of p,but we could solve for p.Do we all agree on the\nprinciple of what we did?So that's how you build\nconfidence intervals.Now let's step\nback for a second,and see what was important in\nthe building of this confidenceinterval.The really key thing is\nthat I didn't tell youwhy I formed this thing, right?We started from\nx bar, and then Itook some weird function of x\nbar that depended on p and n.And the reason is, because\nwhen I take this function,the central limit\ntheorem tells methat it converges to\nsomething that I know.But this very important thing\nabout the something that I knowis that it does not depend on\nanything that I don't know.For example, if I\nforgot to divideby square root of p 1 minus\np, then this thing would havehad a variance, which\nis the p 1 minus p.If I didn't remove this\np here, the mean herewould have been affected by p.And there's no table\nfor normal p 1.Yes?AUDIENCE: [INAUDIBLE]PHILIPPE RIGOLLET: Oh, so\nthe square root of n termscome from.So really you should view this.", "start": 240.0, "heat": 1.0}, {"text": "So there's a rule and sort\nof a quiet rule in maththat you don't write a\ndivided by b over c, right?You write c times a divided\nby b, because it looks nicer.But the way you want\nto think about thisis that this is x bar minus p\ndivided by the square root of p1 minus p divided by n.And the reason is,\nbecause this is actuallythe standard deviation of this--oh sorry, x bar n.This is actually the standard\ndeviation of this guy,and the square root of n comes\nfrom the [INAUDIBLE] average.So the key thing\nwas that this thing,this limiting distribution\ndid not depend on anythingI don't know.And this is actually called\na pivotal distribution.It's pivotal.I don't need anything.I don't need to know anything,\nand I can read it in a table.Sometimes there's going\nto be complicated things,but now we have computers.The beauty about Gaussian is\nthat people have studied themto death, and you can\nopen any stats textbook,and you will see a table\nagain that will tell youfor each value of alpha\nyou're interested in,it will tell you what\nq alpha over 2 is.But there might be some\ncrazy distributions,but as long as they\ndon't depend on anything,we might actually\nbe able to simulatefrom them, and in particular\ncompute what q alpha over 2is for any possible\nvalue [INAUDIBLE]..And so that's what we're\ngoing to be trying to do.Finding pivotal distributions.How do we take this Xn bar,\nwhich is a good estimate,and turn it into something\nwhich may be exactlyor asymptotically\ndoes not dependon any unknown parameter.So here is one way\nwe can actually--so that's what we did for\nthe kiss example, right?And here I mentioned,\nfor example,in the extreme case,\nwhen n was equal to 3we would get a different\nthing, but here the CLTwould not be valid.And what that means is that\nmy pivotal distributionis actually not the\nnormal distribution,but it might be something else.And I said we can make\ntake exact computations.Well, let's see\nwhat it is, right?If I have three observations,\nso I'm going to have X1, X2, X3.", "start": 360.0, "heat": 0.946}, {"text": "So now I take the\naverage of those guys.OK, so that's my estimate.How many values\ncan this guy take?It's a little bit of counting.Four values.How did you get to that number?OK, so each of these guys\ncan take value 0, 1, right?So the number of values\nthat it can take,I mean, it's a little\nannoying, because then Ihave to sum them, right?So basically, I have to\ncount the number of 1's.So how many 1's\ncan I get, right?Sorry I have to-- yeah, so this\nis the number of 1's that I--OK, so let's look at that.So we get 0, 0, 0.0, 0, 1.And then I get\nbasically three of themthat have just the\none in there, right?So there's three of them.How many of them\nhave exactly two 1's?2.Sorry, 3, right?So it's just this guy where\nI replaced the 0's and the 1.OK, so now I get--so here I get three\nthat take the value 1,and one that gets the value 0.And then I get three\nthat take the value 2,and then one that\ntakes the value 1.The value [? 0 ?] 1's, right?OK, so everybody knows what I'm\nmissing here is just the oneshere where I replaced\nthe 0's by 1's.So the number of values\nthat this thing can takeis 1, 2, 3, 4.So someone is counting\nmuch faster than me.And so those numbers, you've\nprobably seen them before,right?1, 3, 3, 1, remember?And so essentially\nthose guys, ittakes only three values,\nwhich are either 1/3, 1.Sorry, 1/3.", "start": 480.0, "heat": 0.554}, {"text": "Oh OK, so it's 0, sorry.1/3, 2/3, and 1.Those are the four possible\nvalues you can take.And so now-- which is\nprobably much easierto count like that--\nand so now allI have to tell you\nif I want to describethe distribution\nof this probabilityof this random variable,\nis just the probabilitythat it takes each\nof these values.So X bar 3 takes the\nvalue 0 probabilitythat X bar 3 takes the\nvalue 1/3, et cetera.If I give you each of\nthese possible values,then you will be able to know\nexactly what the distributionis, and hopefully maybe\nto turn it into somethingyou can compute.Now the thing is that\nthose values will actuallydepend on the unknown p.What is the unknown p here?What is the\nprobability that X bar3 is equal to 0 for example?I'm sorry?AUDIENCE: [INAUDIBLE]PHILIPPE RIGOLLET: Yeah, OK.So let's write it without\nmaking the computation So 1/8 isprobably not the\nright answer, right?For example, if p is equal to\n0, what is this probability?1.If p is 1, what is\nthis probability?0.So it will depend on p.So the probability that\nthis thing is equal to 0,is just the probability\nthat all three of those guysare equal to 0.The probability that X1 is equal\nto 0, and X2 is equal to 0,and X3 is equal to 0.Now my things are\nindependent, so Ido what I actually\nwant to do, whichsay the probability\nof the intersectionis the product of the\nprobabilities, right?So it's just the probability\nthat each of them is equal to 0to the power of 3.And the probability that each\nof them, or say one of themis equal to 0, is\njust 1 minus p.And then for this guy I just\nget the probability-- well,it's more complicated, because I\nhave to decide which one it is.But those things are\njust the probabilityof some binomial random\nvariables, right?This is just a\nbinomial, X bar 3.", "start": 600.0, "heat": 0.29}, {"text": "So if I look at X bar 3,\nand then I multiply it by 3,it's just this sum of\nindependent Bernoulli'swith parameter p.So this is actually a binomial\nwith parameter 3 and p.And there's tables\nfor binomials,and they tell you all this.Now the thing is I want\nto invert this guy, right?Somehow.This thing depends on p.I don't like it, so\nI'm going to haveto find ways to get this\nthings depending on p,and I could make all\nthese nasty computations,and spend hours doing this.But there's tricks\nto go around this.There's upper bounds.Just like we just\nsaid, well, maybe Idon't want to solve the\nsecond degree equation in p,because it's just going to\ncapture maybe smaller orderterms, right?Things that maybe won't make\na huge difference numerically.You can check that in\nyour problem set one.Does it make a huge\ndifference numericallyto solve the second\ndegree equation,or to just use the\n[INAUDIBLE] p 1minus p or even to plug\nin p hat instead of p.Those are going to\nbe the-- problemset one is to make sure that you\nsee what magnitude of changesyou get by changing from\none method to the other.So what I wanted to\ngo to is somethingwhere we can use\nsomething, which is justa little more brute force.So the probability\nthat-- so hereis this Hoeffding's inequality.We saw that.That's what we've\nfinished on last time.So Hoeffding's\ninequality is actuallyone of the most\nuseful inequalities.If any one of you is doing\nanything really to algorithms,you've seen that\ninequality before.It's extremely convenient\nthat it tells yousomething about bounded\nrandom variables,and if you do algorithms\ntypically with things bounded.And that's the case of\nBernoulli's random variables,right?They're bounded between 0 and 1.And so when I do\nthis thing, whenI do Hoeffding's inequality,\nwhat this thing is tellingme is for any given epsilon\nhere, for any given epsilon,what is the probability\nthat Xn bar goes awayfrom its expectation?All right, then we saw that it\ndecreases somewhat similarly", "start": 720.0, "heat": 0.314}, {"text": "to the way a Gaussian\nwould look like.So essentially what Hoeffding's\ninequality is telling me, isthat I have this picture, when\nI have a Gaussian with mean u,I know it looks\nlike this, right?What Hoeffding's\ninequality is tellingme is that if I actually\ntake the averageof some bounded\nrandom variables,then their probability\ndistribution function or maybemath function-- this thing\nmight not even have [INAUDIBLE]the density, but let's think\nof it as being a density justfor simplicity-- it's\ngoing to be somethingthat's going to look like this.It's going to be\nsomewhat-- well,sometimes it's going\nto have to escape justfor the sake of\nhaving integral 1.But it's essentially\ntelling me that those guysstay below those guys.The probability that\nXn bar exceeds muis bounded by\nsomething that decayslike to tail of Gaussian.So really that's the picture\nyou should have in mind.When I average bounded\nrandom variables,I actually have something\nthat might be really rugged.It might not be smooth\nlike a Gaussian,but I know that it's always\nbounded by a Gaussian.And what's nice about it\nis that when I actuallystart computing probability\nthat exceeds some number,say alpha over 2, then I\nknow that this I can actuallyget a number, which is just--sorry, the probability\nthat it exceeds, yeah.So this number that I\nget here is actuallygoing to be somewhat\nsmaller, right?So that's going to be the q\nalpha over 2 for the Gaussian,and that's going to be the--I don't know, r alpha over\n2 for this [? Bernoulli ?]random variable.Like q prime or different q.So I can actually do\nthis without actuallytaking any limits, right?This is valid for any n.I don't need to\nactually go to infinity.Now this seems a\nbit magical, right?I mean, I just said\nwe need n to be,we discussed that we\nwanted n to be larger", "start": 840.0, "heat": 0.222}, {"text": "than 30 last time for\nthe central limit theoremto kick in, and this\none seems to tell meI can do it for any n.Now there will be a price to pay\nis that I pick up this 2 over bminus alpha squared.So that's the variance of the\nGaussian that I have, right?Sort of.That's telling me what\nthe variance should be,and this is actually\nnot as nice.I pick factor 4\ncompared to the Gaussianthat I would get for that.So let's try to solve\nit for our case.So I just told you try it.Did anybody try to do it?So we started from\nthis last time, right?And the reason was\nthat we could saythat the probability that this\nthing exceeds q alpha over 2is alpha.So that was using CLT, so let's\njust keep it here, and seewhat we would do differently.What Hoeffding tells me is\nthat the probability that Xnbar minus--well, what is mu in this case?It's p, right?It's just notation here.Mu was the average,\nbut we call itp in the case of\nBernoulli's, exceeds--let's just call it\nepsilon for a second.So we said that this\nwas bounded by what?So Hoeffding tells me\nthat this is boundedby 2 times exponential minus 2.Now the nice thing is that\nI pick up a factor n here,epsilon squared.And what is b minus a\nsquared for the Bernoulli's?1.So I don't have a\ndenominator here.And I'm going to do\nexactly what I did here.I'm going to set this\nguy to be equal to alpha.So that if I get\nalpha here, then thatmeans that just\nsolving for epsilon,I'm going to have some number,\nwhich will play the role of qalpha over 2, and\nthen I'm going to beable to just say that p\nis between X bar and minusepsilon, and X bar\nn plus epsilon.", "start": 960.0, "heat": 0.326}, {"text": "OK, so let's do it.So we have to\nsolve the equation.2 exponential minus 2n\nepsilon squared equals alpha,which means that--so here I'm going to get,\nthere's a 2 right here.So that means that I\nget alpha over 2 here.Then I take the\nlogs on both sides,and now let me just write it.And then I want to\nsolve for epsilon.So that means that epsilon\nis equal to square root logq over alpha divided by 2n.Yes?AUDIENCE: [INAUDIBLE]PHILIPPE RIGOLLET:\nWhy is b minus a 1?Well, let's just look, right?X lives in the\ninterval b minus a.So I can take b to be 25,\nand a to be my negative 42.But I'm going to try to\nbe as sharp as I can.All right, so what\nis the smallest valueyou can think of such that\na Bernoulli random variableis larger than or\nequal to this value?What values does a Bernoulli\nrandom variable take?0 and 1.So it takes values\nbetween 0 and 1.It just maxes the value.Actually, this is the\nworst possible casefor the Hoeffding inequality.So now I just get this\none, and so now youtell me that I have this thing.So when I solve\nthis guy over there.So combining this\nthing and this thingimplies that the probability\nthat p lives between Xnbar minus square root log 2\nover alpha divided by 2n and X", "start": 1080.0, "heat": 0.53}, {"text": "bar plus the square root log\n2 over alpha divided by 2nis equal to?I mean, is at least.What is it at least equal to?Here this controls the\nprobability of them outsideof this interval, right?It tells me the probability\nthat Xn bar is far from pby more than epsilon.So there's a probability\nthat they're actuallyoutside of the interval\nthat I just wrote.So it's 1 minus the probability\nof being in the interval.So this is at least\n1 minus alpha.So I just use the fact that a\nprobability of the complementis 1 minus the\nprobability of the set.And since I have an upper bound\non the probability of the set,I have a lower bound on the\nprobability of the complement.So now it's a bit different.Before, we actually wrote\nsomething that was--so let me get it back.So if we go back to the example\nwhere we took the [INAUDIBLE]over p, we got this guy.q alpha over square root of--over 2 square root n.So we had Xn bar plus minus\nq alpha over 2 square root n.Actually, that was q alpha\nover 2n, I'm sorry about that.And so now we have something\nthat replaces this q alpha,and it's essentially square\nroot of 2 log 2 over alpha.Because if I replace\nq alpha by square rootof 2 log 2 over\nalpha, I actuallyget exactly this thing here.And so the question is,\nwhat would you guess?Is this number, this margin,\nsquare root of log 2 over alpha", "start": 1200.0, "heat": 0.644}, {"text": "divided by 2n, is it smaller\nor larger than this guy?q alpha all over 2/3n.Yes?Larger.Everybody agrees with this?Just qualitatively?Right, because we just made a\nvery conservative statement.We do not use anything.This is true always.So it can only be better.The reason in statistics where\nyou use those assumptionsthat n is large enough, that you\nhave this independence that youlike so much, and so you can\nactually have the central limittheorem kick in,\nall these thingsare for you to have\nenough assumptionsso that you can actually make\nsharper and sharper decisions.More and more\nconfident statement.And that's why there's all\nthis junk science out there,because people make too much\nassumptions for their own good.They're saying,\nwell, let's assumethat everything is the way I\nlove it, so that I can for sureany minor change, I\nwill be able to saythat's because I made an\nimportant scientific discoveryrather than, well, that\nwas just [INAUDIBLE] OK?So now here's the fun moment.And actually let me tell you\nwhy we look at this thing.So there's actually--\nwho has seendifferent types of convergence\nin the probability statisticclass?[INAUDIBLE] students.And so there's\ndifferent types of--in the real numbers\nthere's very simple.There's one\nconvergence, Xn turnsto X. To start thinking\nabout functions,well, maybe you have\nuniform convergence,you have pointwise convergence.So if you've done\nsome real analysis,you know there's different\ntypes of convergenceyou can think of.And in the convergence\nof random variables,there's also different types,\nbut for different reasons.It's just because the\nquestion is, what do youdo with the randomness?When you see that something\nconverges to something,it probably means that\nyou're willing to toleratelow probability things happening\nor where it doesn't happen,and on how you\nhandle those, createsdifferent types of convergence.So to be fair, in statistics the\nonly convergence we care about", "start": 1320.0, "heat": 0.1}, {"text": "is the convergence\nin distribution.That's this one.The one that comes from\nthe central limit theorem.That's actually the weakest\npossible you could make.Which is good, because\nthat means it'sgoing to happen more often.And so why do we\nneed this thing?Because the only\nthing we really needto do is to say that\nwhen I start computingprobabilities on\nthis random variable,they're going to look\nlike probabilitieson that random variable.All right, so for example,\nthink of the followingtwo random variables,\nx and minus x.So this is the same\nrandom variable,and this one is negative.When I look at those\ntwo random variables,think of them as a sequence,\na constant sequence.These two constant sequences\ndo not go to the same number,right?One is plus-- one is x,\nthe other one is minus x.So unless x is the random\nvariable always equal to 0,those two things are different.However, when I compute\nprobabilities on this guy,and when I compute probabilities\non that guy, they're the same.Because x and minus x\nhave the same distributionjust by symmetry of the\ngaps in random variables.And so you can see\nthis is very weak.I'm not saying anything about\nthe two random variables beingclose to each other\nevery time I'mgoing to flip my coin, right?Maybe I'm going to press my\ncomputer and say, what is x?Well, it's 1.2.Negative x is going\nto be negative 1.2.Those things are\nfar apart, and itdoesn't matter, because\nin average those thingsare going to have the same\nprobabilities that's happening.And that's all we care\nabout in statistics.You need to realize that\nthis is what's important,and why you need to know.Because you have it really good.If your problem is you really\ncare more about convergencealmost surely, which is probably\nthe strongest you can think of.So what we're going to do is\ntalk about different typesof convergence not to\njust reflect on the facton how our life is good.It's just that the problem\nis that when the convergencein distribution is so weak that\nit cannot do anything I want", "start": 1440.0, "heat": 0.11}, {"text": "with it.In particular, I cannot\nsay that if X converges,Xn converges in distribution,\nand Yn convergesin distribution, then Xn plus\nYn converge in distributionto the sum of their limits.I cannot do that.It's just too weak.Think of this example\nand it's preventing youto do quite a lot of things.So this is converge in\ndistribution to sum n 0, 1.This is converge in\ndistribution to sum n 0, 1.But their sum is 0, and\nit's certainly not--it doesn't look\nlike the sum of twoindependent Gaussian\nrandom variables, right?And so what we need is to\nhave stronger conditions hereand there, so that we can\nactually put things together.And we're going to have\nmore complicated formulas.One of the formulas,\nfor example,is if I replace p by p\nhat in this denominator.We mentioned doing\nthis at some point.So I would need that\np hat goes to p,but I need stronger\nthan n distributionsso that this happens.I actually need this to\nhappen in a stronger sense.So here are the first two\nstrongest sense in whichrandom variables can converge.The first one is almost surely.And who has already seen\nthis notation little omegawhen they're talking\nabout random variables?All right, so very few.So this little omega is-- so\nwhat is a random variable?A random variable is\nsomething that you measureon something that's random.So the example I\nlike to think ofis, if you take a ball\nof snow, and put itin the sun for some time.You come back.It's going to have a\nrandom shape, right?It's going to be a random\nblurb of something.But there's still a bunch of\nthings you can measure on it.You can measure its volume.You can measure its\ninner temperature.You can measure\nits surface area.All these things are\nrandom variables,but the ball itself is omega.That's the thing on which\nyou make your measurement.And so a random variable is\njust a function of those omegas.", "start": 1560.0, "heat": 0.174}, {"text": "Now why do we make all\nthese things fancy?Because you cannot\ntake any function.This function has to be\nwhat's called measurable,and there's entire\ncourses on measure theory,and not everything\nis measurable.And so that's why you have\nto be a little carefulwhy not everything\nis measurable,because you need some\nsort of nice property.So that the measure\nof something,the union of two things, is less\nthan the sum of the measures,things like that.And so almost surely is telling\nyou that for most of the balls,for most of the omegas,\nthat's the right-hand side.The probability of omega is\nsuch that those things convergeto each other is\nactually equal to 1.So it tells me that for almost\nall omegas, all the omegas,if I put them together,\nI get somethingthat has probability of 1.It might be that there are other\nones that have probability 0,but what it's telling\nis that this thinghappens for all possible\nrealization of the underlyingthing.That's very strong.It essentially says\nrandomness does not matter,because it's happening always.Now convergence in\nprobability allowsyou to squeeze a little bit\nof probability under the rock.It tells you I want the\nconvergence to hold,but I'm willing to let go\nof some little epsilon.So I'm willing to allow Tn\nto be less than epsilon.Tn minus T to be-- sorry,\nto be larger than epsilon.But the problem is they\nwant this to go to 0as well as n goes to\ninfinity, but for eachn this thing does not\nhave to be 0, whichis different from here, right?So this probability\nhere is fine.So it's a little weaker, but\nit's a slightly different one.I'm not going to ask you\nto learn and show that oneis weaker than the other one.But just know that these\nare two different types.This one is actually much\neasier to check than this one.", "start": 1680.0, "heat": 0.222}, {"text": "Then there's something\ncalled convergence in Lp.So this one is the fact that\nit embodies the following fact.If I give you a random\nvariable with mean 0,and I tell you that its\nvariance is going to 0, right?You have a sequence of random\nvariables, their mean is 0,their expectation is 0, but\ntheir variance is going to 0.So think of Gaussian random\nvariables with mean 0,and a variance\nthat shrinks to 0.And this random variable\nconverges to a spike at 0,so it converges to 0, right?And so what I mean by that is\nthat to have this convergence,all I had to tell you was that\nthe variance was going to 0.And so in L2 this is really\nwhat it's telling you.It's telling you, well, if\nthe variance is going to 0--well, it's for any\nrandom variable T,so here what I describe\nwas for a deterministic.So Tn goes to a random variable\nT. If you look at the square--the expectation of the square\ndistance, and it goes to 0.But you don't have to limit\nyourself to the square.You can take power of three.You can take power\n67.6, power of 9 pi.You take whatever power you\nwant, it can be fractional.It has to be lower than 1, and\nthat's the convergence in Lp.But we mostly care\nabout integer p.And then here's our star, the\nconvergence in distribution,and that's just the\none that tells youthat when I start computing\nprobabilities on the Tn,they're going to look very close\nto the probabilities on the T.So that was our Tn with\nthis guy, for example,and T was this standard\nGaussian distribution.Now here, this is\nnot any probability.This is just the probability\nthen less than or equal to x.But if you remember\nyour probability class,if you can compute\nthose probabilities,you can compute\nany probabilitiesjust by subtracting and just\nbuilding things together.Well, I need this for all x's,\nso I want this for each x,So you fix x, and then you\nmake the limit go to infinity.", "start": 1800.0, "heat": 0.316}, {"text": "You make n go to\ninfinity, and I wantthis for the point x's at which\nthe cumulative distributionfunction of T is continuous.There might be jumps, and that\nI don't actually care for those.All right, so here I mentioned\nit for random variables.If you're interested,\nthere's also random vectors.A random vector is just a\ntable of random variables.You can talk about\nrandom matrices.And you can talk about\nrandom whatever you want.Every time you have\nan object that'sjust collecting real\nnumbers, you can justplug random variables in there.And so there's all these\ndefinitions that [? extend. ?]So where I see you\nsee an absolute value,we'll see a norm.Things like this.So I'm sure this might\nlook scary a little bit,but really what we are going to\nuse is only the last one, whichas you can see is\njust telling youthat the probabilities\nconverge to the probabilities.But I'm going to need the other\nones every once in a while.And the reason is,\nwell, OK, so here I'mactually going to the\nimportant characterizationsof the convergence\nin distribution,which is R convergence style.So i converge in\ndistribution if and onlyif for any function that's\ncontinuous and bounded,when I look at the\nexpectation of f of Tn,this converges to the\nexpectation of f of T. OK,so this is just those two\nthings are actually equivalent.Sometimes it's easier to check\none, easier to check the other,but in this class you won't\nhave to prove that somethingconverges in distribution\nother than just combiningour existing\nconvergence results.And then the last one which\nis equivalent to the above twois, anybody knows what the\nname of this quantity is?This expectation here?What is it called?The characteristic\nfunction, right?And so this i is the complex\ni, and is the complex number.And so it's\nessentially telling methat, well, rather\nthan actually lookingat all bounded and continuous\nbut real functions,I can actually look\nat one specific family", "start": 1920.0, "heat": 0.179}, {"text": "of complex functions, which\nare the functions that mapsT to E to the ixT\nfor x and R. That'sa much smaller\nfamily of functions.All possible continuous\nembedded functionshas many more elements\nthan just the real element.And so now I can show that\nif I limit myself to do it,it's actually sufficient.So those three things are used\nall over the literature justto show things.In particular, if you're\ninterested in deep digginga little more mathematically,\nthe central limit theoremis going to be so important.Maybe you want to read\nabout how to prove it.We're not going to\nprove it in this class.There's probably at least five\ndifferent ways of proving it,but the most canonical one, the\none that you find in textbooks,is the one that actually\nuses the third element.So you just look at the\ncharacteristic functionof the square root of\nn Xn bar minus say mu,and you just expand the thing,\nand this is what you get.And you will see\nthat in the end,you will get the characteristic\nfunction of a Gaussian.Why a Gaussian?Why does it kick in?Well, because what is the\ncharacteristic functionof a Gaussian?Does anybody remember the\ncharacteristic functionof a standard Gaussian?AUDIENCE: [INAUDIBLE]PHILIPPE RIGOLLET:\nYeah, well, I meanthere's two pi's and stuff\nthat goes away, right?A Gaussian is a random variable.A characteristic\nfunction is a function,and so it's not really itself.It looks like itself.Anybody knows what\nthe actual formula is?Yeah.AUDIENCE: [INAUDIBLE]PHILIPPE RIGOLLET:\nE to the minus?AUDIENCE: E to the\nminus x squared over 2.PHILIPPE RIGOLLET: Exactly.E to the minus x squared over 2.But this x squared\nover 2 is actuallyjust the second order expansion\nin the Taylor expansion.And that's why the\nGaussian is so important.It's just the second\norder Taylor expansion.And so you can check it out.I think Terry Tao has\nsome stuff on his blog,and there's a bunch\nof different proofs.", "start": 2040.0, "heat": 0.517}, {"text": "But if you want to prove\nconvergence in distribution,you very likely are going to\nuse one this three right here.So let's move on.This is when I said\nthat this convergence isweaker than that convergence.This is what I meant.If you have convergence\nin one style,it implies convergence\nin the other stuff.So the first [INAUDIBLE] is that\nif Tn converges almost surely,this a dot s dot\nmeans almost surely,then it also converges\nin probabilityand actually the\ntwo limits, whichare this random variable\nT, are equal almost surely.Basically what it means is\nthat whatever you measure oneis going to be the same that\nyou measure on the other one.So that's very strong.So that means that\nconvergence almost surelyis stronger than\nconvergence in probability.If you're converge in Lp\nthen you also convergein Lq for sum q less than p.So if you converge in L2,\nyou'll also converge in L1.If you converge in L67,\nyou converge in L2.If you're converge\nin L infinity,you converge in Lp for anything.And so, again, limits are equal.And then when you\nconverge in distribution,when you converge\nin probability,you also converge\nin distribution.OK, so almost surely\nimplies probability.Lp implies probability.Probability implies\ndistribution.And here note that\nI did not write,and the limits are\nequal almost surely.Why?Because the convergence\nin distributionis actually not telling you\nthat your random variableis converging to\nanother random variable.It's telling you\nthat the distributionof your random variable is\nconverging to a distribution.And think of this, guys.x and minus x.The central limit\ntheorem tells methat I'm converging to some\nstandard Gaussian distribution,but am I converging to x or\nam I converging to minus x?It's not well identified.It's any random variable\nthat has this distribution.", "start": 2160.0, "heat": 0.521}, {"text": "So there's no way\nthe limits are equal.Their distributions are\ngoing to be the same,but they're not the same limit.Is that clear for everyone?So in a way, convergence\nin distributionis really not a convergence\nof a random variabletowards another random variable.It's just telling you\nthe limiting distributionof your random\nvariable [INAUDIBLE]which is enough for us.And one thing that's\nactually really niceis this continuous\nmapping theorem, whichessentially tells you that--so this is one of the\ntheorems that we like,because they tell\nus you can do whatyou feel like you want to do.So if I have Tn that goes to\nT, f of Tn goes to f of T,and this is true for\nany of those convergenceexcept for Lp.But they have to have f,\nwhich is continuous, otherwiseweird stuff can happen.So this is going to be\nconvenient, because here Idon't have X to n minus p.I have a continuous function.It's between a linear\nfunction of Xn minus p,but I could think of like\neven crazier stuff to do,and it would still be true.If I took the square, it would\nconverge to something thatlooks like its distribution.It's the same as\nthe distributionof a square Gaussian.So this is a mouthful,\nthese two slides--actually this particular\nslide is a mouthful.What I have in my head since\nI was pretty much where you'resitting, is this diagram.So what it tells me-- so it's\nactually voluntarily cropped,so you can start from\nany Lq you want large.And then as you\ndecrease the index,you are actually\nimplying, implying,implying until you imply\nconvergence in probability.Convergence almost surely\nimplies convergencein probability, and everything\ngoes to the [? sync, ?]that is convergence\nin distribution.So everything implies\nconvergence in distribution.So that's basically rather than\nremembering those formulas,this is really the diagram\nyou want to remember.", "start": 2280.0, "heat": 0.371}, {"text": "All right, so why do we bother\nlearning about those things.That's because of this\nlimits and operations.Operations and limits.If I have a sequence\nof real numbers,and I know that Xn converges\nto X and Yn converges to Y,then I can start doing all\nmy manipulations and thingsare happy.I can add stuff.I can multiply stuff.But it's not true always for\nconvergence in distribution.But it is, what's\nnice, it's actuallytrue for convergence\nalmost surely.Convergence almost surely\neverything is true.It's just impossible\nto make it fail.But convergence in probability\nis not always everything,but at least you can actually\nadd stuff and multiply stuff.And it will still give\nyou the sum of the n,and the product of the n.You can even take the ratio\nif V is not 0 of course.If the limit is not\n0, then actuallyyou need Vn to be not 0 as well.You can actually prove\nthis last statement, right?Because it's a combination\nof the first statementof the second one, and the\ncontinuous mapping theorem.Because the function\nthat maps x to 1over x on everything\nbut 0, is continuous.And so 1 over Vn\nconverges to 1 over V,and then I can multiply\nthose two things.So you actually knew that one.But really this is\nnot what matters,because this is something that\nyou will do whatever happens.If I don't tell you you cannot\ndo it, well, you will do it.But in general\nthose things don'tapply to convergence\nin distributionunless the pair itself is known\nto converge in distribution.Remember when I said that\nthese things apply to vectors,then you need to actually\nsay that the vector convergesin distributions to\nthe limiting factor.Now this tells\nyou in particular,since the cumulative\ndistribution function is notdefined for vectors,\nI would haveto actually use one of the\nother distributions, one", "start": 2400.0, "heat": 0.292}, {"text": "of the other criteria,\nwhich is convergenceof characteristic\nfunctions or convergenceof a function of bounded\ncontinuous functionof the random variable.0.2 or 0.3, but 0.1 is not\ngoing get you anywhere.But this is something\nthat's goingto be too hard for us to\ndeal with, so we're actuallygoing to rely on the\nfact that we havesomething that's even better.There's something\nthat is waiting for usat the end of his lecture, which\nis called Slutsky's that saysthat if V, in this case,\nconverges in probabilitybut U converge in distribution,\nI can actually still do that.I actually don't\nneed both of themto converge in probability.I actually need only one of\nthem to converge in probabilityto make this statement.But two sum.So let's go to another example.So I just want to make sure that\nwe keep on doing statistics.And every time we're going\nto just do a little bittoo much probability, I'm\ngoing to reset the pressure,and start doing\nstatistics again.All right, so assume\nyou observe the timesthe inter-arrival time\nof the T at Kendall.So this is not the arrival time.It's not like 7:56, 8:15.No, it's really the\ninter-arrival time, right?So say the next T is\narriving in six minutes.So let's say [INAUDIBLE] bound.And so you have this\ninter-arrival time.So those are numbers say,\n3, 4, 5, 4, 3, et cetera.So I have this\nsequence of numbers.So I'm going to\nobserve this, and I'mgoing to try to infer what\nis the rate of T's going outof the station from this.So I'm going to assume\nthat these things aremutually independent.That's probably not\ncompletely true.Again, it just means\nthat what it would meanis that two consecutive\ninter-arrival times areindependent.I mean, you can make it\nindependent if you want,but again, this\nindependent assumptionis for us to be happy and safe.Unless someone comes\nwith overwhelming proofthat it's not independent and\nfar from being independent,", "start": 2520.0, "heat": 0.361}, {"text": "then yes, you have a problem.But it might be the fact\nthat it's actually-- if youhave a T that's one hour late.If an inter-arrival time is\none hour, then the other T,either they fixed\nit, and it's goingto be just 30 seconds behind,\nor they haven't fixed it,then it's going to be\nanother hour behind.So they're not\nexactly independent,but they are when things\nwork well and approximate.And so now I need to model\na random variable that'spositive, maybe\nnot upper bounded.I mean, people complain\nenough that this thingcan be really large.And so one thing that people\nlike for inter-arrival timesis exponential distribution.So that's a positive\nrandom variable.Looks like an exponential\non the right-hand slide,on the positive line.And so it decays\nvery fast towards 0.The probability that\nyou have very largevalues exponentially small, and\nthere's a [INAUDIBLE] lambdathat controls how\nexponential is defined.It's exponential minus\nlambda times something.And so we're going\nto assume that theyhave the same distribution,\nthe same random variable.So they're IID, because\nthey are independent,and they're identically\ndistributed.They all have this exponential\nwith parameter lambda,and I'm going to try to\nlearn something about lambda.What is the estimated\nvalue of lambda,and can I build a confidence\ninterval for lambda.So we observe n arrival times.So as I said, the\nmutual independenceis plausible, but not\ncompletely justified.The fact that\nthey're exponentialis actually something that\npeople like in all this what'scalled queuing theory.So exponentials\narise a lot when youtalk about inter-arrival times.It's not about\nthe bus, but whereit's very important is call\ncenters, service, servers wheretasks come, and people\nwant to know how long it'sgoing to take to serve a task.So when I call at\na center, nobodyknows how long I'm going to stay\non the phone with this person.But it turns out that\nempirically exponentialdistributions have been\nvery good at modeling this.And what it means is\nthat they're actually--you have this\nmemoryless property.", "start": 2640.0, "heat": 0.327}, {"text": "It's kind of crazy if\nyou think about it.What does that thing say?Let's parse it.That's the probability.So this is condition on the\nfact that T1 is larger than T.So T1 is just say the\nfirst arrival time.That means that\nconditionally on the factthat I've been waiting\nfor the first T, well,the first [INAUDIBLE].Well, I should probably-- the\nfirst subway for more than Tconditionally-- so I've been\nthere T minutes already.Then the probability that\nI wait for s more minutes.So that's the probability\nthat T1 is learned,and the time that we've\nalready waited plus x.Given that I've been\nwaiting for T minutes,really I wait for\ns more minutes,is actually the probability\nthat I wait for s minutes total.It's completely memoryless.It doesn't remember how\nlong have you been waiting.The probability does not change.You can have waited for\ntwo hours, the probabilitythat it takes\nanother 10 minutes isgoing to be the\nsame as if you hadbeen waiting for zero minutes.And that's something\nthat's actuallypart of your problem set.Very easy to compute.This is just an\nanalytical property.And you just\nmanipulate functions,and you see that this thing\njust happen to be true,and that's something\nthat people like.Because that's also\nsomething that benefit.And also what we like is\nthat this thing is positivealmost surely, which is good\nwhen you model arrival times.To be fair, we're not\ngoing to be that careful.Because sometimes\nwe are just goingto assume that something\nfollows a normal distribution.And in particular,\nI mean, I don'tknow if we're going to\ngo into that details,but a good thing that you\ncan model with a Gaussiandistribution are\nheights of students.But technically with\npositive probability,you can have a negative\nGaussian random variable, right?And the probability being it's\nprobably 10 to the minus 25,but it's positive.But it's good enough\nfor us for our modeling.So this thing is nice, but this\nis not going to be required.When you're modeling\npositive random variables,you don't always have to use\npositive distributions that aresupported on positive numbers.", "start": 2760.0, "heat": 0.278}, {"text": "You can use distributions\nlike Gaussian.So now this exponential\ndistribution of T1, Tnthey have the same\nparameter, and thatmeans that in average they have\nthe same inter-arrival time.So this lambda is\nactually the expectation.And what I'm just saying\nis that they're identicallydistributed means\nthat I mean some sortof a stationary regime,\nand it's not always true.I have to look at a\nshorter period of time,because at rush\nhour and 11:00 PMclearly those average\ninter-arrival timesare going to be different\nSo it means that I am reallyfocusing maybe on rush hour.Sorry, I said it's lambda.It's actually 1 over lambda.I always mix the two.All right, so you have\nthe density of T1.So f of T is this.So it's on the\npositive real line.The fact that I have strictly\npositive or larger [INAUDIBLE]to 0 doesn't make\nany difference.So this is the density.So it's lambda E to the minus\nlambda T. The lambda in frontjust ensures that\nwhen I integratethis function between 0\nand infinity, I get 1.And you can see, it decays like\nexponential minus lambda T.So if I were to draw it, it\nwould just look like this.So at 0, what\nvalue does it take?Lambda.And then I decay like\nexponential minus lambda T.So this is 0, and\nthis is f of T.So very small probability\nof being very large.Of course, it depends on lambda.Now the expectation, you\ncan compute the expectationof this thing, right?So you integrate T\ntimes f of T. Thisis part of the little sheet\nthat I gave you last time.This is one of the\nthings you shouldbe able to do blindfolded.And then you get the expectation\nof T1 is 1 over lambda.That's what comes out.So as I actually tell many of\nmy students, 99% of statisticsis replacing\nexpectations by averages.", "start": 2880.0, "heat": 0.371}, {"text": "And so what you're tempted to do\nis say, well, if in average I'msupposed to see 1 over lambda,\nI have 15 observations.I'm just going to average\nthose observations,and I'm going to see something\nthat should be close to 1over lambda.So statistics is about\nreplacing averages,expectations with\naverages, and that's we do.So Tn bar here, which is\nthe average of the Ti's, isa pretty good estimator\nfor 1 over lambda.So if I want an\nestimate for lambda,then I need to\ntake 1 over Tn bar.So here is one estimator.I did it without much\nprinciple except that I justwant to replace\nexpectations by averages,and then I fixed the problem\nthat I was actually estimating1 over lambda by lambda.But you could come up with\nother estimators, right?But let's say this is my way\nof getting to that estimator.Just like I didn't give you\nany principled way of getting phat, which is Xn bar\nin the kiss example.But that's the\nnatural way to do it.Everybody is completely\nshocked by this approach?All right, so let's do this.So what can I say about the\nproperties of this estimatorlambda hat?Well, I know that Tn bar\nis going to 1 over lambdaby the law of large number.It's an average.It converges to the\nexpectation both almost surely,and in probability.So the first one is the\nstrong law of large number,the second one is the\nweak law of large number.I can apply the strong one.I have enough conditions.And hence, what do I apply\nso that 1 over Tn baractually goes to lambda?So I said hence.What is hence?What is it based on?AUDIENCE: [INAUDIBLE]PHILIPPE RIGOLLET Yeah,\ncontinuous mapping theorem,right?So I have this\nfunction 1 over x.I just apply this function.So if it was 1 over\nlambda squared,I would have the\nsame thing that wouldhappen just because\nthe function 1 over xis continuous away from 0.And now the central\nlimit theorem", "start": 3000.0, "heat": 0.147}, {"text": "is also telling me\nsomething about lambda.About Tn bar, right?It's telling me that if\nI look at my average,I remove the expectation here.So if I do Tn bar\nminus my expectation,rescale by this guy here,\nthen this thing is goingto converge to some\nGaussian random variable,but here I have this\nlambda to the negative 1--to the negative 2\nhere, and that'sbecause they did not\ntell you that if youcompute the variance--so from this, you\ncan probably extract.So if I have X that follows\nsome exponential distributionwith parameter lambda.Well, let's call it T.So we know that T in\nexpectation, the expectationof T is 1 over lambda.What is the variance of T?You should be able to read\nit from the thing here.1 over lambda squared.That's what you actually\nread in the variance,because the central limit\ntheorem is really telling youthe distribution\ngoes through this n.But this numbers and this\nnumber you can read, right?If you look at the expectation\nof this guy it's-- of this guycomes out.This is 1 over lambda\nminus 1 over lambda.That's why you read the 0.And if you look at the\nvariance of the dot,you get n times the\nvariance of this average.Variance of the average is\npicking up a factor 1 over n.So the n cancels.And then I'm left with only\none of the variances, whichis 1 over lambda squared.OK, so we're not going\nto do that in details,because, again, this is just\na pure calculus exercise.But this is if you compute\nintegral of lambda eto the minus t lambda\ntimes t squared.Actually t minus 1\nover lambda squared", "start": 3120.0, "heat": 0.364}, {"text": "dt between 0 and infinity.You will see that this thing\nis 1 over lambda squared.How would I do this?Configuration by\n[INAUDIBLE] or you know it.All right.So this is what the central\nlimit theorem tells me.So this gives me\nif I solve this,and I plug in so I can\nmultiply by lambda and solve,it would give me somewhat\na confidence interval for 1over lambda.If we just think\nof 1 over lambdaas being the p\nthat I had before,this would give me a\ncentral limit theorem for--sorry, a confidence\ninterval for 1 over lambda.So I'm hiding a little\nbit under the rugthe fact that I have\nto still define it.Let's just actually\ngo through this.I see some of you are\nuncomfortable with this,so let's just do it.So what we've just proved\nby the central limittheorem is that the\nprobability, that'ssquare root of n Tn minus 1 over\nlambda exceeds q alpha over 2is approximately\nequal to alpha, right?That's just the statement of\nthe central limit theorem,and by approximately equal I\nmean as n goes to infinity.Sorry I did not\nwrite it correctly.I still have to divide\nby square root of 1over lambda squared, which is\nthe standard deviation, right?And we said that\nthis is a bit ugly.So let's just do it\nthe way it should be.So multiply all these\nthings by lambda.So that means now that\nthe absolute value, sowith probability 1 minus\nalpha asymptotically,I have that square root of\nn times lambda Tn minus 1", "start": 3240.0, "heat": 0.5}, {"text": "is less than or equal\nto q alpha over 2.So what it means is that, oh,\nI have negative q alpha over 2less than square root of n.Let me divide by\nsquare root of n here.lambda Tn minus\n1 q alpha over 2.And so now what I have is that\nI get that lambda is between--that's Tn bar-- is between\n1 plus q alpha over 2divided by root n.And the whole thing\nis divided by Tn bar,and same thing on the other side\nexcept I have 1 minus q alphaover 2 divided by root\nn divided by Tn bar.So it's kind of a weird\nshape, but it's stillof the form 1 over Tn bar\nplus or minus something.But this something\ndepends on Tn bar itself.And that's actually normal,\nbecause Tn bar is not onlygiving me information\nabout the mean,but it's also giving me\ninformation about the variance.So it should definitely come\nin the size of my error bars.And that's the way it comes\nin this fairly natural way.Everybody agrees?So now I have actually\nbuilt a confidence interval.But what I want to show\nyou with this example is,can I translate this\nin a central limittheorem for something that\nconverges to lambda, right?I know that Tn bar\nconverges to 1 over lambda,", "start": 3360.0, "heat": 0.639}, {"text": "but I also know that 1 over\nTn bar converges to lambda.So do I have a central limit\ntheorem for 1 over Tn bar?Technically no, right?Central limit theorems are about\naverages, and 1 over an averageis not an average.But there's something that\nstatisticians like a lot,and it's called\nthe Delta method.The Delta method\nis really somethingthat's telling you\nthat you can actuallytake a function of\nan average, and letit go to the function\nof the limit,and you still have a\ncentral limit theorem.And the factor or the\nprice to pay for thisis something which depends on\nthe derivative of the function.And so let's just\ngo through this,and it's, again, just like\nthe proof of the central limittheorem.And actually in many of those\nasymptotic statistics results,this is actually just\na Taylor expansion,and here it's not\neven the second order,it's actually the\nfirst order, all right?So I'm just going to do linear\napproximation of this function.So let's do it.So I have that g of Tn bar--actually let's use the\nnotation of this slide,which is Zn and theta.So what I know is that Zn\nminus theta square root of ngoes to some Gaussian,\nthis standard Gaussian.No, not standard.OK, so that's the assumptions.And what I want to show is\nsome convergence of g of Znto g of theta.So I'm not going to\nmultiply by root n just yet.So I'm going to do a first\norder Taylor expansion.So what it is telling me is that\nthis is equal to Zn minus thetatimes g prime of,\nlet's call it theta bar", "start": 3480.0, "heat": 0.248}, {"text": "where theta bar is\nsomewhere between sayZn and theta, for sum.OK, so if theta is less than\nZn you just permute those two.So that's what the\nTaylor first order Taylorexpansion tells me.There exists a theta bar\nthat's between the twovalues at which I'm expanding\nso that those two things areequal.Is everybody shocked?No?So that's standard\nTaylor expansion.Now I'm going to\nmultiply by root n.And so that's going to be what?That's going to be\nroot n Zn minus theta.Ah-ha, that's something I like.Times g prime of theta bar.Now the central limit\ntheorem tells methat this goes to what?Well, this goes to sum n\n0 sigma squared, right?That was the first\nline over there.This guy here, well,\nit's not clear, right?Actually it is.Let's start with this guy.What does theta bar go to?Well, I know that Zn\nis going to theta.Just because, well, that's\nmy law of large numbers.Zn is going to\ntheta, which meansthat theta bar is sandwiched\nbetween two values thatconverge to theta.So that means that theta bar\nconverges to theta itselfas n goes to infinity.That's just the law\nof large numbers.Everybody agrees?Just because it's\nsandwiched, right?So I have Zn.", "start": 3600.0, "heat": 0.225}, {"text": "I have theta, and theta\nbar is somewhere here.The picture might be reversed.It might be that Zn end\nis larger than theta.But the law of large\nnumber tells methat this guy is not moving,\nbut this guy is moving that way.So you know when\nn is [INAUDIBLE],,there's very little\nwiggle room for theta bar,and it can only get to theta.And I call it the\nsandwich theorem,or just find your\nfavorite food in there.So this guy goes\nto theta, and now Ineed to make an extra\nassumption, whichis that g prime is continuous.And if g prime is continuous,\nthen g prime of theta bargoes to g prime of theta.So this thing goes\nto g prime of theta.But I have an issue here.Is that now I have\nsomething thatconverges in distribution\nand somethingthat converges in say--I mean, this converges almost\nsurely or saying probabilityjust to be safe.And this one converges\nin distribution.And I want to combine them.But I don't have a\nslide that tells meI'm allowed to take the product\nof something that convergesin distribution, and something\nthat converges in probability.This does not exist.Actually, if\nanything it told me,do not do anything with things\nthat converge in distribution.And so that gets us to our--OK, so I'll come back\nto this in a second.And that gets us to something\ncalled Slutsky's theorem.And Slutsky's theorem tells us\nthat in very specific cases,you can do just that.So you have two sequences\nof random variables, Xn bar,that's Xn that converges to\nX. And Yn that converges to Y,but Y is not anything.Y is not any random variable.So X converges in\nthis distribution.Sorry, I forgot to mention,\nthis is very important.", "start": 3720.0, "heat": 0.223}, {"text": "Xn converges in distribution,\nY converges in probability.And we know that in generality\nwe cannot combine those twothings, but Slutsky tells\nus that if the limit of Y isa constant, meaning it's\nnot a random variable,but it's a\ndeterministic number 2,just a fixed number that's\nnot a random variable,then you can combine them.Then you can sum them, and\nthen you can multiply them.I mean, actually you can do\nwhatever combination you want,because it actually implies\nthat X, the vector Xn, Ynconverges to the vector Xc.OK, so here I just\ntook two combinations.They are very convenient for\nus, the sum and the productso I could do other\nstuff like the ratioif c is not 0, things like that.So that's what\nSlutsky does for us.So what you're going to have to\nwrite a lot in your homework,in your mid-terms, by Slutsky.I know some people are very\ngenerous with their by Slutsky.They just do numerical\napplications,mu is equal to 6, and\ntherefore by Slutskymu square is equal to 36.All right, so don't do that.Just use, write Slutsky when\nyou're actually using Slutsky.But this is something that's\nvery important for us,and it turns out\nthat you're goingto feel like you can write\nby Slutsky all the time,because that's going to\nwork for us all the time.Everything we're going\nto see is actuallygoing to be where we're going\nto have to combine stuff.Since we only rely on\nconvergence from distributionarising from the\ncentral limit theorem,we're actually going to have\nto rely on something thatallows us to combine them,\nand the only thing we knowis Slutsky.So we better hope\nthat this thing works.So why Slutsky works for us.Can somebody tell\nme why Slutsky worksto combine those two guys?So this one is converging\nin distribution.This one is converging\nin probability,but to a deterministic number.g prime of theta is a\ndeterministic number.I don't know what theta is, but\nit's certainly deterministic.", "start": 3840.0, "heat": 0.143}, {"text": "All right, so I can combine\nthem, multiply them.So that's just the second\nline of that in particular.All right, everybody is with me?So now I'm allowed to do this.You can actually--\nyou will see somethinglike counterexample\nquestions in your problemset just so that you\ncan convince yourself.It's always a good thing.I don't like to\ngive them, because Ithink it's much better\nfor you to actually cometo the counterexample yourself.Like what can go wrong\nif Y is not a random--sorry, if Y is not a--sorry, if c is not the constant,\nbut it's a random variable.You can figure that out.All right, so let's go back.So we have now this Delta\nmethod that tells usthat now I have a\ncentral limit theoremfor functions of averages,\nand not just for averages.So the only price to pay\nis this derivative there.So, for example, if g is\njust a linear function,then I'm going to have a\nconstant multiplication.If g is a quadratic\nfunction, then I'mgoing to have theta squared\nthat shows up there.Things like that.So just think of what\nkind of applicationsyou could have for this.Here are the functions\nthat we're interested in,is x maps to 1 over x.What is the derivative\nof this guy?What is the derivative\nof 1 over x?Negative 1 over\nx squared, right?That's the thing we're going\nto have to put in there.And so this is what we get.So now when I'm actually\ngoing to write this,so if I want to show square root\nof n lambda hat minus lambda.That's my application, right?This is actually 1 over Tn, and\nthis is 1 over 1 over lambda.So the function g of x\nis 1 over x in this case.", "start": 3960.0, "heat": 0.327}, {"text": "So now I have this thing.So I know that by\nthe Delta method--oh, and I knew\nthat Tn, remember,square root of Tn\nminus 1 over lambdawas going to sum\nnormal with mean 0and variance 1 over\nlambda squared, right?So the sigma square over there\nis 1 over lambda squared.So now this thing goes to what?Sum normal.What is going to be the mean?0.And what is the variance?So the variance is going--I'm going to pick up\nthis guy, 1 over lambdasquared, and then I'm going to\nhave to take g prime of what?Of 1 over lambda, right?That's my theta.So I have g of theta,\nwhich is 1 over theta.So I'm going to have g\nprime of 1 over lambda.And what is g prime\nof 1 over lambda?So we said that g prime is 1\nover negative 1 over x squared.So it's negative 1 over\n1 over lambda squared--sorry, squared.Which is nice, because\ng can be decreasing.So that would be annoying\nto have a negative variance.And so g prime is\nnegative 1 over, and sowhat I get eventually is\nlambda squared up here,but then I square it again.So this whole thing\nhere becomes what?Can somebody tell me\nwhat the final result is?Lambda squared right?So it's lambda 4\ndivided by lambda 2.So that's what's written there.And now I can just do my\ngood old computation for a--", "start": 4080.0, "heat": 0.237}, {"text": "I can do a good computation\nfor a confidence interval.All right, so let's just\ngo from the second line.So we know that lambda\nhat minus lambdais less than, we've done\nthat several times already.So it's q alpha over 2--sorry, I should put alpha\nover 2 over this thing, right?So that's really the quintile\nof what our alpha over 2 timeslambda divided by\nsquare root of n.All right, and so that means\nthat my confidence intervalshould be this, lambda hat.Lambda belongs to lambda\nplus or minus q alphaover 2 lambda divided\nby root n, right?So that's my\nconfidence interval.But again, it's not\nvery suitable, because--sorry, that's lambda hat.Because they don't\nknow how to compute it.So now I'm going to\nrequest from the audiencesome remedies for this.What do you suggest we do?What is the laziest\nthing I can do?Anybody?Yeah.AUDIENCE: [INAUDIBLE]PHILIPPE RIGOLLET Replace\nlambda by lambda hat.What justifies\nfor me to do this?AUDIENCE: [INAUDIBLE]PHILIPPE RIGOLLET\nYeah, and Slutskytells me I can actually do\nit, because Slutsky tells me,where does this lambda\ncome from, right?This lambda comes from here.That's the one that's here.So actually I could\nrewrite this entire thingas square root of n lambda hat\nminus lambda divided by lambdaconverges to sum n 0, 1.Now if I replace this by\nlambda hat, what I have isthat this is actually really\nthe original one times", "start": 4200.0, "heat": 0.45}, {"text": "lambda divided by lambda hat.And this converges\nto n 0, 1, right?And now what you're telling\nme is, well, this guyI know it converges to n 0, 1,\nand this guy is converging to 1by the law of large number.But this one is converging to 1,\nwhich happens to be a constant.It converges in probability,\nso by Slutsky I can actuallytake the product and still\nmaintain my conversionto distribution to\na standard Gaussian.So you can always do this.Every time you replace\nsome p by p hat,as long as their\nratio goes to 1,which is going to be guaranteed\nby the law of large number,you're actually\ngoing to be fine.And that's where we're\ngoing to use Slutsky a lot.When we do plug in, Slutsky\nis going to be our friend.OK, so we can do this.And that's one way.And then other\nways to just solvefor lambda like we did before.So the first one we\ngot is actually--I don't know if I still\nhave it somewhere.Yeah, that was the one, right?So we had 1 over Tn q, and\nthat's exactly the samethat we have here.So your solution is actually\ngiving us exactly this guy whenwe actually solve for lambda.So this is what we get.Lambda hat.We replace lambda by\nlambda hat, and wehave our asymptotic\nconvergence theorem.And that's exactly what we\ndid in Slutsky's theorem.Now we're getting to it at\nthis point is just telling usthat we can actually do this.Are there any questions\nabout what we did here?So this derivation right\nhere is exactly what Idid on the board I showed you.So let me just show you\nwith a little more spacejust so that we all\nunderstand, right?So we know that square root of n\nlambda hat minus lambda dividedby lambda, the\ntrue lambda defined", "start": 4320.0, "heat": 0.607}, {"text": "converges to sum n 0, 1.So that was CLT\nplus Delta method.Applying those two,\nwe got to here.And we know that\nlambda hat convergesto lambda in probability and\nalmost surely, and that's what?That was law of large number\nplus continued mapping theorem,right?Because we only knew that\none of our lambda hatconverges to 1 over lambda.So we had to flip\nthose things around.And now what I said is\nthat I apply Slutsky,so I write square root of n\nlambda hat minus lambda dividedby lambda hat, which is the\nsuggestion that was made to me.They said, I want\nthis, but I wouldwant to show that it\nconverges to sum n 0,1 so I can legitimately use\nq alpha over 2 in this onethough.And the way we said is like,\nwell, this thing is actuallyreally q divided by lambda times\nlambda divided by lambda hat.So this thing that\nwas proposed to me,I can decompose\nit in the productof those two random variables.The first one here converges\nthrough the Gaussianfrom the central limit theorem.And the second one converges\nto 1 from this guy,but in probability this time.That was the ratio of two\nthings in probability,we can actually get it.And so now I apply Slutsky.And Slutsky tells me that\nI can actually do that.But when I take the product\nof this thing that convergesto some standard Gaussian,\nand this thing that convergesin probability to 1, then\ntheir product actuallyconverges to still this\nstandard Gaussian [INAUDIBLE]Well, that's exactly\nwhat's done here,and I think I'm getting there.", "start": 4440.0, "heat": 0.653}, {"text": "So in our case, OK, so just a\nremark for Slutsky's theorem.So that's the last line.So in the first example we used\nthe problem dependent trick,which was to say,\nwell, turns outthat we knew that p\nis between 0 and 1.So we have this p 1 minus\np that was annoying to us.We just said, let's\njust bound it by 1/4,because that's going to be\ntrue for any value of p.But here, lambda takes any\nvalue between 0 and infinity,so we didn't have such a trick.It's something like we could\nsee that lambda was lessthan something.Maybe we know it, in which\ncase we could use that.But then in this case,\nwe could actually alsohave used Slutsky's theorem\nby doing plug in, right?So here this is my p 1 minus\np that's replaced by p hat 1minus p hat.And Slutsky justify,\nso we did thatwithout really\nthinking last time.But Slutsky actually\njustifies the factthat this is valid, and\nstill allows me to usethis q alpha over 2 here.All right, so that's\nthe end of this lecture.Tonight I will post the next\nset of slides, chapter two.And, well, hopefully the video.I'm not sure when it's\ngoing to come out.", "start": 4560.0, "heat": 0.539}]