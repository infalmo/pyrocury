[{"text": "The following\ncontent is providedunder a Creative\nCommons license.Your support will help MIT\nOpenCourseWare continueto offer high quality\neducational resources for free.To make a donation or\nview additional materialsfrom hundreds of MIT courses,\nvisit MIT OpenCourseWareat ocw.mit.edu.PROFESSOR: One more\nexacting lecture on hashing.And a couple reminders.I don't want to start out\nsaying unpopular things,but we do have a quiz coming\nup next week on Tuesday.There will not be a\nlecture next Tuesday,but there will be a quiz.7:30 to 9:30 Tuesday evening.I will send announcement.There's going to\nbe a couple rooms.Some of you will\nbe in this room.Some of you will have to\ngo to a different room,since this room\nreally can't hold180 students taking a quiz.All right?So hashing.I'm pretty excited\nabout this lecture,because I think as I was\ntalking with Victor justbefore this, if there's one\nthing you want to rememberabout hashing and you want\nto go implement a hash table,it's open addressing.It's the simplest way\nthat you can possiblyimplement a hash table.You can implement a hash\ntable using an array.We've obviously talked\nabout link listsand chaining to implement hash\ntables in previous lectures,but we're going to actually get\nrid of pointers and link lists,and implement a hash table using\na single array data structure,and that's the notion\nof open addressing.Now in order to get\nopen addressing to work,there's no free lunch, right?So you have a simple\nimplementation.It turns out that in order to\nmake open addressing efficient,you have to be a little\nmore careful than if you'reusing the hash\ntables with chaining.", "start": 0.0, "heat": 0.1}, {"text": "And we're going to have\nto make an assumptionabout uniform hashing.I'll say a little\nbit more about that.But it's a different assumption\nfrom simple uniform hashingthat Eric talked about.And we'll state this\nuniform hashing assumption.And we look at what the\nperformance is of openaddressing under\nthis assumption.And this is assumption\nis going to give usa sense of what good\nhash functions arefor open addressing applications\nor for open addressinghash tables.And finally we'll talk\nabout cryptographic hashing.This is not really\n6006 material,but it's kind of cool material.It has a lot of applications\nin computer securityand cryptography.And so as we'll describe the\nnotion of a cryptographic hash,and we'll talk about a couple\nof real simple and pervasiveapplications like\npassword storageand file corruption detectors\nthat you can implementusing cryptographic\nhash functions, whichare quite different from\nthe regular hash functionsthat we're using in hash tables.Be it chaining hash tables or\nopen addressing hash tables.All right?So let's get started and\ntalk about open addressing.This is another approach\nto dealing with collisions.If you didn't have\ncollisions, obviously an arraywould work, right?If you could somehow guarantee\nthat there were no collisions.When you have\ncollisions, you haveto worry about the\nchaining and ensuringthat you can still find\nthe keys even though youhad two keys that collided\ninto the same slot.And we don't want\nto use chaining.The simplest data structure that\nwe can possibly use are arrays.Back when I was a grad student,\nI went through and got a PhD", "start": 120.0, "heat": 0.1}, {"text": "writing programs in C, never\nusing any other structurethan arrays, because I\ndidn't like pointers.And so open addressing\nis a way that youcan implement hash tables\ndoing exactly this.And in particular,\nwhat we're going to dois assume an array\nstructure with items.And we're going to assume\nthat this one item-- at mostone item per slot.So m has to be greater\nthan or equal to n, right?So this is important because\nwe don't have link lists.We can't arbitrarily\nincrease the storageof a slot using\na chain, and haven, which is the\nnumber of elements,be greater than m, right?Which you could in the link\nlist table with chaining.But here you only have\nthese area locations,these indices that you\ncan put items into.So it's pretty much guaranteed\nthat if you want a working openaddressing hash table that m,\nwhich is the number of slotsin the table, should be greater\nthan or equal to the numberof elements, all right?That's important.Now how does this work.Well, we're going to have\nthis notion of probing.And the notion of\nprobing is that we'regoing to try to see if\nwe can insert somethinginto this hash table,\nand if you failwe're actually\ngoing to recomputea slightly different\nhash for the key", "start": 240.0, "heat": 0.242}, {"text": "that we're trying to\ninsert, the key valuepair that we're\ntrying to insert.All right?So this is an iterative\nprocess, and we'regoing to continually probe\nuntil we find an empty slotinto which we can insert\nthis key value pair.The key should index into it.So you do have\ndifferent hashes thatare going to be computed\nbased on this probingnotion for a given key.All right?And so what we need\nnow is a hash functionthat's different from the\nstandard hash functionsthat we've talked about\nso far, which specifiesthe order of slots to\nprobe, which is basicallyto try for a key.And this is going to be true\nfor insert, search, and delete,which are three\nbasic operations.And they're a little bit\ndifferent, all right?Just like they were different\nfor the chaining hash table,they're different here, but\nthey're kind of more differenthere.And you'll see what I mean\nwhen we go through this.And this is not\njust for one slot.It's going to specify\nan order of slots.And so our hash\nfunction h is goingto take the universe\nof keys and also takewhat we're going to\ncall the trial count.So if you're lucky-- well, you\nget lucky in your first trial.And if you're not, you hope to\nget lucky in your second trial,", "start": 360.0, "heat": 0.361}, {"text": "and so on and so forth.But the hash function is\ngoing to take two arguments.It's going to take the\nkey as an argument,and it's going to take a trial,\nwhich is an integer between 0to n minus 1, all right?And it's going to produce-- just\nlike the chaining hash functionit's going to produce a number\nbetween 0 and m minus 1, right?Where m is the number\nof slots in the table.All right.So that's the story.In order to ensure that you\nare using the hash tablecorresponding to open addressing\nproperly, what you wantis-- and this is an important\nproperty-- that h k 1,so that's a key\nthat you're given.And this could be an\narbitrary key, mind you.So arbitrary key k.And what you have in\nterms of the slots thatare being computed is\nthis, h k 1, h k 2,and so on and so forth\nto h k n minus 1.And what you want\nis for this vectorto be a permutation of 0\n1 and so on to n minus 1.And the reason for this\nhopefully is clear.It's because you want\nto be able to use", "start": 480.0, "heat": 0.15}, {"text": "the entirety of your hash table.You don't want particular\nslots to go unused.And when you get to the point\nwhere the number of elements nis pretty close to m, and maybe\nthere's just one slot left, OK?And you want to fill up this\nlast slot with this key kthat you want to put\nin there, and whatyou want to be able to say is\nthat for this arbitrary key kthat you want to put in there\nthat the one slot that's free--and it could be that first slot.It could be the 17th slot.Whatever-- That eventually\nthe sequence of probesis going to be able to allow\nyou to insert into that slot.All right?And we generalize\nthis notion intothe uniform hashing\nassumption in a few minutes,but hopefully this makes\nsense from a standpointof really load\nbalancing the tableand ensuring that all\nslots in the tableare sort of equal\nopportunity slots.That you're going to be able to\nput keys in them as long as youprobe long enough that you're\ngoing to be able to get there.Now of course the\nfact that you'reusing one particular slot\nfor one particular keydepends on the order\nof keys that you'reinserting into this table.Again, you'll see that as we go\nthrough an example, all right?So that's the set up.That's the open\naddressing notion.And that as you\ncan see, we're justgoing to go through\na sequence of probesand our hash function\nis going to tell uswhat the sequences is, and\nso we don't need any pointersor anything like that.So let's take a look at how\nthis might work in practice.So maybe the easiest thing to\ndo is to run through an example,and then I'll show\nyou some pseudocode.But let's say that\nI have a table here,", "start": 600.0, "heat": 0.128}, {"text": "and I'm going to concentrate\non the insert operation.And I'm going to start inserting\nthings into this table.And right here I have\nseven slots up there.So let's say that I want to\ninsert 586 into the table,and I compute h of 586 comma\n1, and that gives me 1.OK?This is the first insert.So I'm going to go ahead and\nstick 586 in here, all right?And then I insert, for\nargument's sake, 133.I insert 204 out here.And these are all things\nbecause the hash table is empty.481 out here and so on.And because the\nhash table is empty,my very first trial is\nsuccessful, all right?So h of 481-- I'm not going to\nwrite this all out, but h 481 1happens to be 6 and so on.All right?Now I get to the point\nwhere I want to insert 496.And when I try to insert\n496, I have h 496 1.It happens to be 4.OK?So the first thing that\nhappens is I go in here,and I say oops.This slot is occupied,\nbecause this-- I'mgoing to have a special flag\nassociated with an empty slot,", "start": 720.0, "heat": 0.207}, {"text": "and we can say it's none.And if it's not none,\nthen it's occupied.And 204 is not equal to none.So I look at this, and I say\nthe first probe actually failed.OK?And so h 496 1 equals 4 fails,\nso I need to go do h 496 2.And h 496 2 may also fail.You might be in a situation\nwhere h 496 2 gives you 586.So this was h 496 1 h\n496 2 might give you 586.And finally it may be that h 496\n3, which is your third attempt,equals 3.So you go in, and you say great.I can insert 496.And let me write\nthat in bold here.Out there.All right?So pretty straightforward.In this case, you've gone\nthrough three trials in orderto find an empty slot.And so the big\nquestion really here isother than taking care of\nsearch and delete, how long isthis process going to take?All right?And I'm talking about\nthat in a few minutes,but let me explain,\nnow that you'veseen insert, how search\nwould work, right?Or maybe I get one of\nyou guys to explain to meonce you have insert,\nhow would search work?Someone?Someone from the back?", "start": 840.0, "heat": 0.437}, {"text": "No one.You guys are always\nanswering questions.Yeah, all the way in the back.AUDIENCE: Would you\njust do the same kindof probing [INAUDIBLE] where you\nfind it or you don't find it?PROFESSOR: Right.So you do exactly.It's very similar to insert.You have a situation\nwhere you'regoing to none would\nindicate an empty slot.And you can think of\nthis as being a flag.And in the case of insert,\nwhat you did was you--insert k v would\nsay keep probing.I'm not going to write\nthe pseudocode for it.Keep probing until an\nempty slot is found.And then when it's\nfound, insert item.And as long as you have\nthe permutation propertythat we have up there, and\ngiven that m is greater thanor equal to n, you're\nguaranteed that insertis going to find a slot.OK?That's the good news.Now it might take\nawhile, and so wehave a talk about performance\na bit later, but it'll work.OK?Now search is a\nlittle bit different.You're searching for a\nkey k, and you essentiallysay you're going\nto keep probing.And you say as long as\nthe slots encountered", "start": 960.0, "heat": 0.446}, {"text": "are occupied by\nkeys not equal to k.So every time you\nprobe, you go in thereand you say I got a key.I found a hash for it.I go to this particular slot.I look inside of it,\nand I check to seewhether the key that's\nstored inside of itis the same as the\nkey I'm searching for.If not, I go to the next trial.If it is, then I return it.Right?So that's pretty much it.And we keep probing until you\neither encounter k or findan empty slot.And this is the key.No pun intended.A notion which is that when\nyou find an empty slot,it means that you have\nfailed to discover this key.You fail to-- yeah,\nquestion back there?AUDIENCE: What happens if you\nwere to delete a key though?PROFESSOR: I'll make you answer\nthat question for a cushion.So we'll get to\ndelete in a minute.But I want to make\nsure you're allon board with insert and search.OK?So these are actually fairly\nstraightforward in comparisonto delete.It's not like delete is\nmuch more complicated,but there is a subtlety there.And so that's kind\nof neat, right?I mean this actually works.So if you had a situation where\nyou were just accumulatingkeys, and you're looking for\nthe number of distinct elements", "start": 1080.0, "heat": 0.526}, {"text": "in the stream of data\nthat was coming in,and that was pretty much it\nwith respect to your program,you'd never have to delete\nkeys, and this would be allthat you'd have to implement.Right?But let's talk about delete.Every once in awhile we'd\nwant to delete a key?Yeah, you had a question?AUDIENCE: I have a\nquestion about search.Why do you stop searching\nonce you find an empty slot?PROFESSOR: Because\nyou're searching.So what that means\nis that you'relooking to see if this key\nwere already in the table.And if key were\nalready in the table,you want to return the value\nassociated with that key.If you find an empty\nslot, since you'reusing the same deterministic\nsequence of probesthat you would have if\nyou had inserted it,then-- that make sense?Good.All right.So so far so good?That's what works for\ninsert and search.Let's talk delete.So back there.How does delete work?AUDIENCE: Well\n[INAUDIBLE] if yousearch until you find\nthe none and assumethat the key you're searching\nfor was not put in there.But let's say you had one\nthat was in that slot beforeand it got put back\nin, but then youdelete the one that\nwas in the slot before.PROFESSOR: Great, great.You haven't told me\nhow to fix it yet,but do you have\nthe guts for this?No.OK, I think this\nveers to the right.I always wanted to do this\nto somebody in the back.All right.Whoa.All right, good catch.All right.OK.So you pointed out\nthe problem, and I'mgoing to ask somebody\nelse for a solution.All right?But here's the problem.Here's the problem,\nand we can lookat it from a standpoint of\nthat example right there.", "start": 1200.0, "heat": 0.558}, {"text": "Let's say for argument's\nsake that I'm searching-- nowI've done all of the inserts\nthat I have up there, OK?So I've inserted 496.All right?Then I delete 586\nfrom the table, OK?I delete 586 from the table.So let's just say\nthat what I end updoing-- I have 586,\n133, 496, and thenI have 204, and then a 481.And this is 0, 1, 2, et cetera.So I'm deleting 586, and let's\nsay I replace it with none.OK?Let's just say I\nreplace it with none.Now what happens is that when\nI search for 496, accordingto this search algorithm\nwhat am I going to get?AUDIENCE: None.PROFESSOR: Well the first slot\nI'm going to look at is 1,and according to this\nsearch algorithm,I find an empty slot, right?And when I find\nan empty slot, I'mgoing to say I\nfailed in the search.If you encounter k, you succeed\nand return the key value pair,right?Success means you\nreturn the value.And if you encounter\nan empty slot,it means that you've\ndecided that this key is notin the table.And you say couldn't\nfind it, right?That make sense?So this is obviously\nwrong, right?Because I just inserted\n496 into the table.So this would fail incorrectly.", "start": 1320.0, "heat": 0.889}, {"text": "So failed to find\nthe key, which is OK.I mean failure is OK\nif the key isn't there.But you don't want\nto fail incorrectly.Right?Everyone buy that?Everyone buy that?Good.All right.So how do I fix it.Someone else?How do I fix this?Someone who doesn't\nhave a cushion.All right, you.AUDIENCE: [INAUDIBLE] you can\nmark that spot by a, and whensearch comes across a,\nyou just [INAUDIBLE].PROFESSOR: Right, great answer.We're now going to have to do\na couple of different thingsfor insert and search, OK?It's going to be\nsubtly different,but the first thing\nwe're going to dois we're going to\nhave this flag,and I'll just call\nit delete me flag.OK?And we're going to say that\nwhen I delete something,replace deleted item\nwith not the non flag,but a different flag that\nwe'll call delete me.Is different from none.And that's going\nto be important,because now that you\nhave a different flag,and you replace\n586 with delete me,you can now do different things\nin insert versus search, right?So in particular,\nwhat you would dois you'd have to\nmodify this slightly,because the notion\nof an empty slotmeans that you're\nlooking for none, right?And all it means is that--\nwell actually in some sense,", "start": 1440.0, "heat": 0.639}, {"text": "the pseudo code\ndoesn't really changebecause if you say\nyou either encounter kor you would-- even if\nyou encounter a delete me,you keep going.All right?That's the important thing.So I guess it does\nchange, because I assumethat you have only\ntwo cases here,but what you really have\nnow are three cases.The three cases are\nwhen you're doingthe search is that you\nencounter the key, whichis the easy case.You return it.You return the value.Or you can encounter a\ndelete me flag, in which caseyou keep going.OK?And if you encounter\nan empty slot, whichcorresponds to none,\nat that point you knowyou failed and the key\ndoesn't exist in the table.All right?So let me just write that out.Insert treats delete\nme the same as none.But search keeps going\nand treats it differently.And that's pretty much it.So what would happen\nin our example?Well, going through\nexactly the same example,we started from here, and\nthen we decided to delete 586.And so if we replaced 586 not\nwith none, but with delete me,and the next time around\nwhen you search for 496,you're searching for 496.And what would\nhappen is that youwould go look at 586-- the\nslot that contained 586,", "start": 1560.0, "heat": 0.449}, {"text": "and you see that there's\na delete me flag in there.And so you go to the next trial.And then in the next trial, you\ndiscover that, in this case,you have-- I'm sorry.I had 204 first as\nthe first trial,and then in the second\ntrial I had 586.And I would continue\nbeyond the second trialand get to third trial, and in\nfact return 496 in this case.I would get to returning\n496 in my third trial, whichis exactly what I want.The interesting thing here is\nthat you can reuse storage.I mean the whole\npoint of deletingis that you can take the storage\nand insert other keys in there.Once you've freed\nup the storage.And you can do that by\nmaking insert treat delete methe same as the none.So the next time you\nwant to insert youcould-- if you happen to index\ninto the index correspondingto 586, you can override that.The delete me flag goes\naway, and some other key--call it 999 or something--\nwould get in there.And you're all set with that.OK?Any questions?This all makes sense?So you could imagine coding\nthis up with an array structureis fairly straightforward.What remains here\nto be discussedis how well does\nthis work, right?You have this extra requirement\non the hash functioncorresponding to creating\nan extra argumentas an input to it, which\nis this trial count.And you'd like to have this\nnice property of correspondingto a permutation.Can we actually design\nhash functions like this?", "start": 1680.0, "heat": 0.643}, {"text": "And we'll take a look\nat a bad hash function,and then at a better one.So let's talk about\nprobing strategies, whichis essentially the same\nas taking a hash functionand changing it\nso it is actuallyapplicable to open addressing.So the notion of\nlinear probing isthat you do h k i\nequals h prime k, whichis some hash function\nthat you've chosen,plus i mod m, where this is\nan ordinary hash function.OK?So that looks pretty\nstraightforward.What happens here?Does this satisfy the\npermutation argument?Before I forget.Does it satisfy the\npermutation propertythat I want h k 1, h k 2, h k\nm minus 1 to be a permutation?That make sense?Yep, yep.Because I then I start adding.The mod is precisely kind\nof this round robin cycle,so it's going to\nsatisfy the permutation.That's good.What's wrong with this?What's wrong with this?Someone?AUDIENCE: The fact that\n[INAUDIBLE] keys, which they'reall filled, then if you hit\nanywhere in here [INAUDIBLE]list of consecutive keys.AUDIENCE: Right.That's excellent.Excellent, excellent answer.So this notion of\nclustering is basicallywhat's wrong with\nthis probing strategy.", "start": 1800.0, "heat": 0.655}, {"text": "And in fact, I'm not going to\ndo this particular analysis,but I'll give you a sense of why\nthe statement I'm going to makeis true.But the notion of\nclustering is that youstart getting consecutive\ngroups of occupied slots, OK?Which keep growing.And so these clusters\nget longer and longer.And if you have a\nbig cluster, it'smore likely to\ngrow bigger, right?Which is bad.This is exactly the wrong thing\nfor load balancing, right?And clustering is the reverse\nof load balancing, right?If you have a bunch\nof clumps and youhave a bunch of empty space\nin your table, that's bad.Right?The problem with\nlinear probing isthat once you start getting a\ncluster, given the, let's say,the randomness in the hash\nfunction, and h prime kis a pretty good hash function\nand can randomly go anywhere.Well, if you have 100 slots and\nyou have a cluster of size 4,well there's a for 4/100\nchance, which is obviouslyfour times greater than\n1/100, even I can do that,to go into those four slots.And if you going\ninto those four slotsyou're going to keep\ngoing down to the bottom,and you're going to make that\na cluster of size five, right?So that's the problem\nthe linear probing,and you can essentially\nargue through makingsome probabilistic assumptions\nthat if, in fact, youuse linear probing that you\nlose your average constant timelook up in your hash table\nfor most load factors.So what's happening out\nhere pictorially reallyis that you have a table and\nlet's say you have a cluster.", "start": 1920.0, "heat": 0.67}, {"text": "And this is your cluster.So if your h k 1--\nit doesn't reallymatter what it is-- but h\nk i maps to this cluster,then you're going\nto-- linear probingsays that the next thing\nyou're going to tryis if you map to\n42 in the cluster,the next thing\nyou're going to tryis 43, 44, until you get maybe\nto this slot here, which is 57,for argument's sake.Right?So you're going to\nkeep going, and you'regoing to try 15 times in\nthis relatively dumb fashionto go down to get to the\nopen slot, which is 57.And oh, by the way,\nat the end of this youjust increased your\ncluster length by one.All right?So it doesn't really work.And in fact, under reasonable\nprobabilistic assumptionsin terms of what your\nhash functions are,you can say that when you have\nalpha, which is essentiallyyour load factor, which is\nn over m less than 0.99,you see clusters\nof size log n, OK?Right.So this is a\nprobabilistic argument,and you're assuming that you\nhave a hash function that'sa pretty good hash function.So h prime k can be this perfect\nhash function, all right?So there's a problem here\nbeyond the choice of hprime k, which is this hash\nfunction that worked reallywell for chaining.All right?And the problem here is the\nlinear probing aspect of it.So what does that mean?If you have clusters\nof theta log n,then your search and\nyour insert are notgoing to be constant\ntime anymore.Right?Which is bad in a\nprobabilistic sense.", "start": 2040.0, "heat": 0.691}, {"text": "OK?So how do we fix that?Well, one strategy that\nworks reasonably wellis called double hashing.And it literally\nmeans what it says.You have to run a\ncouple of hashes.And so the notion of double\nhashing is that you have h k iequals h1 k plus i h2 k mod m.And h1 and h2 are just\nordinary hash functions.OK?Now the first thing\nthat we need to dois figure out how we can\nguarantee a permutation, right?Because we still have\nthat requirement,and it was OK for the\nlinear probing part,but you still have\nthis requirementthat you need a permutation.And so those of you who\nare into number theory,can you tell me what property,\nwhat neat property of h2 and mcan we ask for to\nguarantee a permutation?Do you have a question?You already do.Do you have a question?AUDIENCE: [INAUDIBLE].PROFESSOR: [INAUDIBLE]\nrelatively prime.OK, good.So I figured some of\nyou knew the answer,but I've seen you before.Right.Exactly right.Relatively prime.Just hand it to Victor.So h2 k and m being\nrelatively prime,if that implies a permutation.", "start": 2160.0, "heat": 0.566}, {"text": "It's similar to\nwhat we had before.You're multiplying this\nby i. i keeps increasing,and you're going to roll around.All right?I mean you could\ndo a proof of it,but I'm not going to bother.The important thing\nhere is that you can nowdo something as simple as\nm equals 2 raised to r,and h2 k for all k is odd,\nand now you're in great shape.You can have your\narray to be 2 raisedto something, which is\nwhat you really want.And you just use h2 k.You could even take a\nregular hash functionand truncate it to\nmake sure it's odd.You can do a bunch of things.There's hash functions\nthat produce odd values,and you can use that.All right?And so double hashing works\nfairly well in practice.It's a good way of getting\nopen addressing to work.And in order to prove that\nopen addressing actuallyworks to the level at\nwhich chaining works,we have to make an\nassumption correspondingto uniform hashing.And I'm not going to\nactually do a proof,but it'll be in the notes.But I do want to talk about\nthe theorem and the resultthat the theorem\nimplies, assumingyou have the uniform\nhashing assumption.And let me first\nsay that this is notthe same as simple\nuniform happening, whichtalks about the independence of\nkeys in terms of their mappingto slots.The uniform hashing\nassumption saysthat each key is\nequally likely to have", "start": 2280.0, "heat": 0.629}, {"text": "any one of the m\nfactorial permutations--so we're talking about\nrandom permutationshere-- as its probe sequence.All right?This is very hard\nto get in practice.You can get pretty close\nusing double hashing.But nobody's discovered\na perfect hash function,deterministic hash function\nthat satisfies this property.At least not that I know off.So what does this imply?Assuming that you have\nthis and double hatchinggives you this property, to a\nlarge extent what this means isthat if alpha is\nn over m, you canshow that the cost of operations\nsuch as search, insert, delete,et cetera.And in particular\nwe talk about insertis less than or equal to 1\ndivided by 1 minus alpha.OK?So obviously this goes\nas alpha tends to 1.As alpha tends to 1, the load\nfactor in the table gets large,and the number of\nexpected probesthat you need to do when\nyou get an insert grows.And if alpha is 0.99,\nyou're going, on average,require 100 probes.It's a constant number, but\nit's a pretty bad constant.Right?So you really want alpha\nto be fairly small.", "start": 2400.0, "heat": 0.511}, {"text": "And in practice it\nturns out that youhave to re-size you're\nopen addressing tablewhen alpha gets beyond\nabout 0.5, 0.6 or so,because by then you're\nreally in trouble.Remember this is an average\ncase we're talking about.All of this is using a\nprobabilistic assumption.But as you get to\nhigh alphas, suddenlyby the time you get to\n0.7, open addressingdoesn't work well in relation\nto an equivalent tablewith the overall\nnumber of slots thatcorrespond to a\nchanging table, OK?So open addressing\nis easy to implement.It uses less memory because\nyou don't need pointers.But you better be careful that\nyour alpha stays around 0.5and no more.So all that means is\nyou can still use it.You just have to\nre-size your table.You have slightly\ndifferent strategiesfor resizing your\ntable when you use openaddressing as opposed\nto chaining hash tables.All right?So that's a summary\nof open addressing.I want to spend some time\non cryptographic hashesin the time that I have left.I guess I have a\nfew minutes left.But any questions\nabout open addressing?Yep?AUDIENCE: On this\ndelete part, what'sgoing to happen if, say, you\nfill the table up and thendelete everything, and\nthen you start searching.Isn't that going to\nbe bad because it'sgoing to search\nthrough everything?PROFESSOR: So that's right.The bad thing about\nopen addressingis that delete isn't\ninstantaneous, right?In the sense that if you deleted\nsomething from the link listin your chaining\ntable, then evenif you went to that same\nthing, the chain got smaller,and that helps you, because\nyour table now has lower load.But there's a delay\nassociated with loadwhen you have the\ndelete me flag.OK?So in some sense the alpha\nthat you want to think about,you should be careful as\nto how you define alpha.And that's one of\nthe reasons why", "start": 2520.0, "heat": 0.516}, {"text": "when you get alpha\nbeing 0.5, 0.6you get into trouble, because\nif you have all these deleteme flags, they're\nstill hurting you.AUDIENCE: And when\nyou resize do thosedelete me flags get deleted?PROFESSOR: When you\ncompletely resizeand you redo the\nwhole thing, then youcan clean up the delete me's\nand turn them into nonesbecause you're rehashing it.All right.So yeah, back there.Question?AUDIENCE: Yes, can you explain\nhow you got the equationthat the cost of operation\ninsert is less thanor equal to 1 over [INAUDIBLE].PROFESSOR: That's\na longish proof,but let me explain to\nyou how that comes out.Basically the intuition\nbehind the proofis that we're going to\nassume some probability p.And initially you're\ngoing to say somethinglike if the table, your p--\nI'll just write this out here--is m minus n divided by m.So what is that?Right now I have n\nelements in the table,and I have m slots, OK?So the probability that my very\nfirst trial is going to succeedis going to be m minus n\ndivided by m, because theseare the number of empty slots.And assuming my\npermutation argument,I could go into one of them.And so that's what I have here.And if you look at what this\nis, this is 1 minus alpha, OK?And so then you run\noff and you remember6041 or the high school\nprobability coursethat you take, and you\nsay generally speaking,you're going to be no worse\nthan p for every trial.And so if you assume\nthe worst and sayevery trial has a\nprobability of success of p,the expected number\nof trials is 1/p, OK?And that's how you got\nthe 1 over 1 minus alpha.", "start": 2640.0, "heat": 0.479}, {"text": "So you'll see that written\nin gory detail in the notes.All right?OK.Expected to have\na little more timein terms of talking about\ncryptographic hashes,but cryptographic hashes are\nnot going to be on the quiz.This is purely material FYI.For your interest only.And again I have\nsome notes on it,but I want to give you a sense\nof the other kinds of hashesthat exist in the\nworld, I guess.And hashes that are used for\nmany different applications.So maybe the best way\nof motivating thisis through an example.So let's talk about\nan example thatis near and dear to every\nsecurity person's heartand probably to people who\naren't interested in securityas well, which is\npassword storage.So think about how,\nlet's say, Unix systemswork when you type\nin your password.You're typing in your\npassword [INAUDIBLE],and this is true for\nother systems as well,but you have a password.And my password is a permutation\nof my first daughtersfirst name.[LAUGHTER]Yeah, but haven't\ngiven it away, right?Haven't given it away.And so this password\nis somethingthat I'm typing in\nevery day, right?Now the sum check\nthat needs to happento ensure that I'm typing\nin the right password.So what is a dumb\nway of doing things.What's a dumb way\nof building systems?AUDIENCE: Storing [INAUDIBLE].PROFESSOR: This is\nkind of a freebie.AUDIENCE: [INAUDIBLE].PROFESSOR: In situ hashing.That's better.So you'd store it.", "start": 2760.0, "heat": 0.183}, {"text": "I offered the dumb way.So there's a perfectly\nvalid answer.So you could clearly store\nthis in plain text in some fileand you could call it\nslash etc slaw password.And you could make it\nread for the work, right?And that'd be great, and\npeople do that, right?But what you would\nrather do is youwant to make sure that even\nthe sysadmin doesn't knowmy password or your\npassword, right?So how do you do that?Well you do that using a\ncryptographic hash thathas this interesting\nproperty that is one way, OK?And what that means is\nthat given h of x-- OK,this is the value\nof the hash-- itis very hard to find the\nx such that x basicallyhashes to this value.So if h of x equals\nlet's call it q,then you're only given h of x.And so what do you do now?Well, it's beautiful.Assuming you have this one way\nhash, this cryptographic hash,in your etc slash\npassword file, youhave something like\nlogin name, [INAUDIBLE],which happens to be the hash\nof my daughter's first name,or something.But this is what's stored\nin there and the same thingfor a bunch of\ndifferent users, right?So when I log in and I type\nin the actual password,what does the system do?What does the system do?It hashes it.It takes x prime, which is\nthe typed in password, which", "start": 2880.0, "heat": 0.274}, {"text": "may or may not be\nequal to my password,because somebody else might\nbe trying to break in,or I just mistyped, or forgot\nmy daughter's first name,which would be bad.And it will just check to see--\nit doesn't need x, because it'sstored h of x in the system,\nso it doesn't need x.So if we just compare\nagainst what I typed in,it would compute the hash again.And then would let me in\nassuming that these thingsmatched and would not\nlet me in if it didn't.So now we can talk about-- and\nI don't have time for this,but you can certainly\nread up on it on Wikipediaand a bunch in the notes.You can talk about\nwhat propertiesshould this hash function\nhave, namely one way collisionresistance, in order\nto solve these problemsand other problems.I'm happy to stick around\nand answer questions.", "start": 3000.0, "heat": 0.231}]