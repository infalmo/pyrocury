[{"text": "The following content is\nprovided under a CreativeCommons license.Your support will help\nMIT OpenCourseWarecontinue to offer high quality\neducational resources for free.To make a donation or\nview additional materialsfrom hundreds of MIT courses,\nvisit MIT OpenCourseWareat ocw.mit.edu.PROFESSOR: Let's begin.Today we're going to continue\nthe discussion on Ito calculus.I briefly introduced you\nto Ito's lemma last time,but let's begin by\nreviewing it and stating itin a slightly more general form.Last time what we did was we\ndid the quadratic variationof Brownian motion,\nBrownian process.We defined the Brownian\nprocess, Brownian motion,and then showed that it has\nquadratic variation, whichcan be written in this form--\ndB square is equal to dt.And then we used that to show\nthe simple form of Ito's lemma,which says that if f is a\nfunction on the Brownianmotion, then d of f is\nequal to f prime of dB_tplus f double prime of dt.This additional term was a\ncharacteristic of Ito calculus.", "start": 0.0, "heat": 0.1}, {"text": "In classical calculus\nwe only have this term,but we have this\nadditional term.And if you remember,\nthis happened exactlybecause of this\nquadratic variation.Let's review it, and let's do\nit in a slightly more generalform.As you know, we\nhave a function fdepending on two\nvariables, t and x.Now we're interested\nin-- we want to evaluateour information on the\nfunction f(t, B_t).The second coordinate,\nwe're planningto put in the\nBrownian motion there.Then again, let's do\nthe same analysis.Can we describe d of f in terms\nof these differentiations?To do that, deflect this, let\nme start from Taylor expansion.f at a point t plus delta\nt, x plus delta x by Taylorexpansion for two variables is\nf of t of x plus partial of fover partial of t at t\ncomma x of delta t plus...x.That's the first-order terms.Then we have the\nsecond-order terms.", "start": 120.0, "heat": 0.152}, {"text": "Then the third-order\nterms, and so on.That's just Taylor expansion.If you look at it,\nwe have a function f.We want to look at the\ndifference of f when we changethe first variable a little\nbit and the second variablea little bit.We start from f of t of x.In the first-order terms, you\ntake the partial derivative,so take del f over del\nt, and then multiplyby the t difference.Second term, you take\nthe partial derivativewith respect to the second\nvariable-- partial fover partial x-- and\nthen multiply by del x.That much is enough\nfor classical calculus.But then, as we\nhave seen before,we ought to look at\nthe second-order term.So let's first write\ndown what it is.That's exactly what happened\nin Taylor expansion,if you remember.If you don't remember,\njust believe me.This 1 over 2 times, take the\nsecond derivatives, partial.Let's write it in\nterms of-- yes?AUDIENCE: [INAUDIBLE]PROFESSOR: Oh,\nyeah, you're right.Thank you.Is it good now?Let's write it as\ndt, all these deltas.I'll just write like that.I'll just not\nwrite down t and x.", "start": 240.0, "heat": 0.445}, {"text": "And what we have is f plus\ndel f over del t dt plus delf over del x dx plus\nthe second-order terms.The only important terms--\nfirst of all, these termsare important.But then, if you want\nto use x equals B oft-- so if you're now\ninterested in f t comma B of t.Or more generally, if you're\ninterested in f t plus dt,f B_t plus d of B_t, then\nthese terms are important.If you subtract f of\nt of B_t, what you getis these two terms.Del f over del t dt\nplus del f over delx-- I'm just writing\nthis as a second variabledifferentiation-- at dB_t.And then the second-order terms.Instead of writing it all down,\ndt square is insignificant,and dt comma-- dt times\ndB_t also is insignificant.But the only thing that\nmatters will be this one.This is dB_t square, which\nyou saw is equal to dt.From the second-order term,\nwe'll have this term surviving.1 over 2 partial f over partial\nx second derivative, of dt.", "start": 360.0, "heat": 0.431}, {"text": "That's it.If you rearrange\nit, what we get ispartial f over partial\nt plus 1/2 this plus--and that's the additional term.If you ask me why these\nterms are not importantand this term is important, I\ncan't really say it rigorously.But if you think about dB_t\nsquare equals dt, then d timesB_t is kind of like\nsquare root of dt.It's not a good\nnotation, but if youdo that-- these two terms are\nsignificantly smaller than dtbecause you're\ntaking a power of it.dt square becomes a lot\nsmaller than dt, dt to the 3/2is a lot smaller than dt.But this one survives because\nit's equal to dt here.That's just the\nhigh-level description.That's a slightly more\nsophisticated formof Ito's lemma.Let me write it down here.And let's just fix it now.If f of t of B_t-- that's d of\nf is equal to-- Any questions?Just remember, from the\nclassical calculus term,", "start": 480.0, "heat": 0.214}, {"text": "we're only adding\nthis one term there.Yes?AUDIENCE: Why do\nwe have x there?PROFESSOR: Because the second\nvariable is supposed to be x.I don't want to write down\npartial derivative with respectto a Brownian motion here\nbecause it doesn't look good.It just means, take the\npartial derivative with respectto the second term.So just view this as a\nfunction f of t of x,evaluate it, and then plug\nin x equal B_t in the end,because I don't want to\nwrite down partial B_t here.Other questions?Consider a stochastic process\nX of t such that d of Xis equal to mu times d of t\nplus sigma times d of B_t.This is almost like\na Brownian motion,but you have this\nadditional term.This is called a drift term.Basically, this happens if X_t\nis equal to mu*t plus sigmaof B_t.Mu and sigma are constants.", "start": 600.0, "heat": 0.166}, {"text": "From now on, what\nwe're going to studyis stochastic process of\nthis type, whose differencecan be written in terms of drift\nterm and the Brownian motionterm.We want to do a slightly\nmore general formof Ito's lemma, where we\nwant f of t of X_t here.That will be the\nmain object of study.I'll finally state the\nstrongest Ito's lemmathat we're going to use.f is some smooth function and\nX_t is a stochastic processlike that.X_t satisfies...where B_t is a Brownian motion.Then df of t, X_t\ncan be expressedas-- it's just getting\nmore and more complicated.But it's based on this one\nsimple principle, really.It all happened because\nof quadratic variation.Now I'll show you why this form\ndeviates from this form whenwe replace B to an X.Remember here all other\nterms didn't matter,", "start": 720.0, "heat": 0.207}, {"text": "that the only term that mattered\nwas partial square of f...of dx square.To prove this, note that df\nis partial f over partial tdt plus partial f over\npartial x d of X_tplus 1/2 of d of x squared.Just exactly the same, but I've\nreplaced the dB-- previously,what we had dB, I'm\nreplacing to dX.Now what changes is dX_t\ncan be written like that.If you just plug it\nin, what you get hereis partial f over partial\nx mu dt plus sigma of dB_t.Then what you get here\nis 1/2 of partialsand then mu plus\nsigma dB_t square.Out of those three terms here\nwe get mu square dt squareplus 2 times mu sigma d mu dB\nplus sigma square dB square.Only this was survives,\njust as before.These ones disappear.And then you just\ncollect the terms.So dt-- there's one dt here.There's mu times that here,\nand that one will become a dt.It's 1/2 of sigma\nsquare partial square...", "start": 840.0, "heat": 0.704}, {"text": "of dt.And there's only\none dB_t term here.Sigma-- I made a mistake, sigma.This will be a form that\nyou'll use the most,because you want to evaluate\nsome stochastic process--some function that\ndepends on timeand that stochastic process.You want to understand\nthe difference, df.The X would have\nbeen written in termsof a Brownian motion\nand a drift term,and then that's the\nIto lemma for you.But if you want to\njust-- if you justsee this for the first time,\nit just looks too complicated.You don't understand where\nall the terms are coming from.But in reality, what\nit's really doingis just take this\nTaylor expansion.Remember these two\nclassical terms,and remember that there's\none more term here.You can derive it\nif you want to.Really try to know\nwhere it all comes from.It all started from this one\nfact, quadratic variation,because that made some of the\nsecond derivative survive,and because of those,\nyou get these kindof complicated terms.Questions?Let's do some examples.That's too much.", "start": 960.0, "heat": 0.783}, {"text": "Sorry, I'm going to use it\na lot, so let me record it.Example number one.Let f of x be equal to\nx square, and then youwant to compute d of f at B_t.I'll give you three minutes\njust to try a practice.Did you manage to do this?It's a very simple example.Assume it's just the\nfunction of two variables,but it doesn't depend on t.You don't have to do that,\nbut let me just do that.Partial f over partial t is 0.Partial f over partial\nx is equal to 2x,and the second derivative\nequal to 2 at t, x.", "start": 1080.0, "heat": 0.648}, {"text": "Now we just plug in\nt comma B_t, and whatyou have is mu equals\n0, sigma equals 1,if you want to write\nit in this formula.What you're going to have\nis 2 times B_t of dB_tplus 1 over 2 times 2dt.If you write it down.You can either use\nthese parametersand just plug in each of\nthem to figure it out.Or a different way\nto do it is reallywrite down, remember the proof.This is partial f\nover partial t dtplus partial f over partial x\ndx plus 1/2-- remember this one.And x is dB_t here.That one is 0, that one\nwas 2x, so 2B_t dB_t.Use it one more\ntime, so you get dt.Make sense?Let's do a few more examples.", "start": 1200.0, "heat": 0.527}, {"text": "And you want to compute\nd of f at t comma B of t.Let's do it this time.Again, partial f over\npartial t dt plus partial fover partial x dB_t.That's the first-order terms.The second-order term\nis 1/2 partial square fover partial x square of dB_t\nsquare, which is equal to dt.Let's do it.Partial f over partial\nt, you get mu times f.This one is just\nequal to mu times f.Maybe I'm going too quick.Mu times e to the\nmu t plus dx, dt.Partial f over partial\nx is sigma times eto the mu t plus\ndx, and then dB_tplus-- if you take\nthe second derivative,you do that again,\nwhat you get is1/2, and then sigma square\ntimes e to the mu t plus dx, dt.Yes?AUDIENCE: In the original\nequation that you just wrote,isn't it 1/2 times\nsigma squared,and then the second derivative?Up there.PROFESSOR: Here?AUDIENCE: Yes.PROFESSOR: 1/2?AUDIENCE: Times sigma squared.PROFESSOR: Oh, sigma-- OK,\nthat's a good question.But that sigma is different.That's if you plug in X_t here.If you plug in X_t\nwhere X_t is equal to muprime dt plus sigma\nprime d of B_t,then that sigma prime will\nbecome a sigma prime squarehere.", "start": 1320.0, "heat": 0.46}, {"text": "But here the function\nis mu and sigma,so maybe it's not\na good notation.Let me use a and b here instead.The sigma here is\ndifferent from here.AUDIENCE: Yeah, that\nmakes a lot more sense.PROFESSOR: If you\nreplace a and b,but I already wrote down\nall mu's and sigma's.That's a good point, actually.But that's when you\nwant to considera general stochastic\nprocess hereother than Brownian motion.But here it's just\na Brownian motion,so it's the most simple form.And that's what you get.Mu plus 1/2 sigma square-- and\nthese are just all f itself.That's the good thing\nabout exponential.f times dt plus\nsigma times d of B_t.Make sense?And there's a reason I\nwas covering this example.It's because-- let's come\nback to this question.You want to model stock price\nusing Brownian motion, Brownianprocess, S of t.But you don't want S_t\nto be a Brownian motion.What you want is a\npercentile differenceto be a Brownian motion, so you\nwant this percentile differenceto behave like a Brownian\nmotion with some variance.", "start": 1440.0, "heat": 0.254}, {"text": "The question was, is S_t equal\nto e to the sigma times B of tin this case?And I already told you last\ntime that no, it's not true.We can now see\nwhy it's not true.Take this function, S_t\nequals e to the sigmaB_t, that's exactly where\nmu is equal to 0 here.What we got here was d of S_t,\nin this case, is equal to-- muis 0, so we get 1/2 of sigma\nsquare times dt plus sigmatimes d of B_t.We originally were\ntargeting sigma times dB_t,but we got this\nadditional term which wedidn't want in the first hand.In other words, we\nhave this drift.I wasn't really clear\nin the beginning,but our goal was to\nmodel stock pricewhere the expected\nvalue is 0 at all times.Our guess was to take\ne to the sigma B_t,but it turns out\nthat in this casewe have a drift,\nif you just takenatural e to the sigma of B_t.To remove that drift,\nwhat you can dois subtract that term somehow.If you can get rid of that\nterm then you can see,if you add this mu to be\nminus 1 over 2 sigma square,you can remove that term.That's why it doesn't work.So instead use S of t equals\ne to the minus 1 over 2 sigmasquare t plus sigma of B_t.That's the geometric Brownian\nmotion without drift.", "start": 1560.0, "heat": 0.27}, {"text": "And the reason it has no\ndrift is because of that.If you actually do\nthe computation,the dt term disappears.Question?So far we have been\ndiscussing differentiation.Now let's talk\nabout integration.Yes?AUDIENCE: Could you we do get\nthis solution as [INAUDIBLE].Could you also\ndescribe what it means?What does it mean,\nthis solution of B_t?Does that mean if we\nhave a sample path B_t,then we could get a\nsample path for S_t?PROFESSOR: Oh, what\nthis means, yes.Whenever you have the B_t\nvalue, just at each timetake the exponential value.Because-- why we want to express\nthis in terms of a Brownianmotion is, for\nBrownian motion wehave a pretty good\nunderstanding.It's a really good process\nyou understand fairly well,and you have good control on it.But the problem is you want to\nhave a process whose percentiledifference behaves\nlike a Brownian motion.And this gives you a\nway of describing itin terms of Brownian motion, as\nan exponential function of it.Does that answer your question?AUDIENCE: Right,\ndistribution meansthat if we have a\nsample path B_t,that would be the corresponding\nsample path for S of t?Is it a pointwise evaluation?PROFESSOR: That's a\ngood question, actually.", "start": 1680.0, "heat": 0.383}, {"text": "Think of it as a\npointwise evaluation.That is not always\ncorrect, but for mostof the things that\nwe will cover,it's safe to think\nabout it that way.But if you think about it\npath-wise all the time,eventually it fails.But that's a very\nadvanced topic.So what this question\nis, basicallyB_t is a probability space,\nit's a probability distributionover paths.For this equation, if you just\nlook at it, it looks right,but it doesn't\nreally make sense,because B_t-- if it's a\nprobability distribution, whatis e to the B_t?Basically, what\nit's saying is B_tis a probability\ndistribution over paths.If you take omega according\nto-- a path accordingto the Brownian motion sample\nprobability distribution,and for this path it's well\ndefined, this function.So the probability density\nfunction of this pathis equal to the probability\ndensity function of eto the whatever that is\nin this distribution.Maybe it confused you more.Just consider this as some path,\nsome well-defined function,and you have a\nwell-defined function.Integral definition.I will first give you a\nvery, very stupid definitionof integration.We say that we define\nF as the integration...", "start": 1800.0, "heat": 0.565}, {"text": "if d of F is equal\nto f dB_t plus-- wedefine it as an inverse\nof differentiation.Because differentiation\nis now well-defined--we just defined integration\nas the inverse of it,just as in classical calculus.So far, it doesn't\nhave that good meaning,other than being\nan inverse of it,but at least it's well-defined.The question is, does it exist?Given f and g, does it exist,\ndoes integration always exist,and so on.There's lots of\nquestions to ask,but at least this\nis some definition.And the natural question is,\ndoes there exist a Riemanniansum type description?That means-- if you remember\nhow we defined integralin calculus, you have a\nfunction f, integrationof f from a to b according to\nthe Riemannian sum descriptionwas, you just chop the\ninterval into very fine pieces,", "start": 1920.0, "heat": 0.362}, {"text": "a_0, a_1, a_2, a_3,\ndot, dot, dot--and then sum the area of these\nboxes, and take the limit.And this is the limit\nof Riemannian sums.Slightly more, if you want, it's\nthe limit as n goes to infinityof the function 1 over n times\nthe sum of i equal zero to t--I'll just call it 0 to b-- f of\nt*b over n minus f of t minus 1over n.Does this ring a bell?Question?AUDIENCE: [INAUDIBLE]PROFESSOR: No, you're right.Good point, no we don't.Thanks.Does integral\ndefined in this wayhave this Riemannian sum type\ndescription, is the question.So keep that in mind.I will come back to\nthis point later.In fact, it turns out to\nbe a very deep questionand very important\nquestion, this question,because if you remember\nlike I hope you remember,in the Riemannian sum, it\ndidn't matter which point youtook in this interval.That was the whole point.You have the function.In the interval a_i to\na_(i+1), you take any point", "start": 2040.0, "heat": 0.665}, {"text": "in the middle and make a\nrectangle according to thatpoint.And then, no matter\nwhich point you take,when you go to the limit,\nyou had exactly the same sumall the time.That's how you define the limit.But what's really\ninteresting hereis that it's no longer true.If you take the left\npoint all the time,and you take the right\npoint all the time,the two limits are different.And again, that's due to\nthe quadratic variation,because that much of variance\ncan accumulate over time.That's the reason we didn't\nstart with Riemannian sum typedefinition of integral.But I'll just make one remark.Ito integral is the\nlimit of Riemannian sumswhen always take the leftmost\npoint of each interval.So you chop down this curve\nat-- the time intervalinto pieces, and\nfor each rectangle,pick the leftmost point,\nand use it as a rectangle.And you take the limit.That will be your\nIto integral defined.It will be exactly equal to this\nthing, the inverse of our Itodifferentiation.I won't be able\nto go into detail.What's more\ninteresting is instead,what happens if you take the\nrightmost point all the time,you get an equivalent\ntheory of calculus.It's just like Ito's calculus.It looks really, really similar\nand it's coherent itself,so there is no\nlogical flaw in it.It all makes sense,\nbut the only difference", "start": 2160.0, "heat": 0.484}, {"text": "is instead of a plus in\nthe second-order term,you get minuses.Let me just make this\nremark, because it's justa theoretical part, this thing,\nbut I think it's really cool.Remark-- there's this\nand equivalent version.Maybe equivalent is\nnot the right word,but a very similar\nversion of Itocalculus such that\nbasically, whatit says is d B_t square\nis equal to minus dt.Then that changed\na lot of things.But this part, it's\nnot that important.Just cool stuff.Let's think about this a\nlittle bit more, this fact.Taking the leftmost\npoint all the timemeans if you want to make\na decision for your timeinterval-- so at time t of\ni and time t of i plus 1,let's say it's the stock price.You want to say that you had\nso many stocks in this timeinterval.Let's say you had so many\nstocks in this time intervalaccording to the values\nbetween this and this.In real world, your only\nchoice you have is youhave to make the\ndecision at time t of i.Your choice cannot depend\non the future time.You can't suddenly say, OK,\nin this interval the stockprice increased a\nlot, so I'll assumethat I had a lot of\nstocks in this interval.In this interval, I knew\nit was going to drop,so I'll just take the\nrightmost interval.I'll assume that I only\nhad this many stock.You can't do that.Your decision has to be\nbased on the leftmost point,because the time.You can't see the future.", "start": 2280.0, "heat": 0.463}, {"text": "And the reason Ito's calculus\nworks well in our setting isbecause of this fact, because it\nhas inside it the fact that youcannot see the future.Every decision is made\nbased on the leftmost time.If you want to make a decision\nfor your time interval,you have to do it\nin the beginning.That intuition is hidden\ninside of the theory,and that's why it works so well.Let me reiterate this\npart a little bit more.It's the definition\nof these thingswhere you're only\nallowed to-- at time t,you're only allowed to use\nthe information up to time t.Definition: delta t is an\nadapted process-- sorry,adapted to another\nstochastic process X_t--if for all values\nof time variablesdelta t depends only\non X_0 up to X_t.There's a lot of vague\nstatements inside here,but what I'm trying\nto say is justassume X is the Brownian\nmotion underlying stock price.Your stock is changing.", "start": 2400.0, "heat": 0.647}, {"text": "You want to come\nup with a strategy,and you want to say\nthat mathematicallythis strategy makes sense.And what it's saying\nis if your strategymakes your decision\nat time t is onlybased on the past values\nof your stock price,then that's an adapted process.This defines the processes\nthat are reasonable,that cannot see future.And these are all--\nin terms of strategy,if delta_t is a\nportfolio strategy,these are the only meaningful\nstrategies that you can use.And because of what I said\nbefore, because we're alwaystaking the leftmost\npoint, adaptiveprocesses just also fit very\nwell with Ito's calculus.They'll come into\nplay altogether.Just a few examples.First, a very stupid example.X_t is adapted to X_t.Of course, because\nat time, X_t reallydepends on only\nX_t, nothing else.Two, X_(t+1) is\nnot adapted to X_t.This is maybe a\nlittle bit vague,so we'll call it\nY_t equals X_(t+1).Y_t is the value at t\nplus 1, and it's not basedon the values up to time t.Just a very artificial example.Another example, delta\nt equals minimum...", "start": 2520.0, "heat": 0.395}, {"text": "is adapted.And I'll let you think about it.The fourth is quite interesting.Suppose T is fixed,\nsome large integer,or some large real number.Then you let delta t to be the\nmaximum where X of s, where...It's not adapted.What is this?This means at time T,\nI'm going to take at itthis value, the\nmaximum of all valueinside this part, the future.This refers to the future.It's not an adapted process.Any questions?Now we're ready to talk\nabout the propertiesof Ito's integral.Let's quickly\nreview what we have.First, I defined Ito's lemma--\nthat means differentiationin Ito calculus.Then I defined integration using\ndifferentiation-- integrationwas an inverse operation\nof the differentiation.But this integration also had\nan alternative descriptionin terms of\nRiemannian sums, whereyou're taking just the\nleftmost point as the referencepoint for each interval.", "start": 2640.0, "heat": 0.242}, {"text": "And then, as you\nsee, this naturallyhad this concept of\nusing the leftmost point.And to abstract\nthat concept, we'vecome up with this adapted\nprocess, very natural process,which is like the\nreal-life procedures,real-life strategies\nwe can think of.Now let's see what\nhappens when youtake the integral of\nadapted processes.Ito integral has\nreally cool properties.The first thing is about\nnormal distribution.B_t has normal\ndistribution of 0 up to t.So your Brownian\nmotion at time thas normal\ndistribution with 0, t.That means if your stochastic\nprocess is some constant timesB of t, of course, then\nyou have 0 and c square t.It's still a normal variable.That means if you\nintegrate, that'sthe integration of some sigma.That's the integration\nof sigma of dB_t.If sigma is a fixed\nconstant, whenyou take the Ito\nintegral of sigma timesdB_t, this constant,\nat each timeyou get a normal distribution.And this is like saying the\nsum of normal distribution", "start": 2760.0, "heat": 0.327}, {"text": "is also normal distribution.It has this hidden\nfact, because integralis like sum in the limit.And this can be generalized.If delta t is a process\ndepending only on the timevariable-- so it does not depend\non the Brownian motion-- thenthe process X of t equals the\nintegration of delta t dB_thas normal distribution at\nall time, just like this.We don't know the\nexact variance yet;the variance will\ndepend on the sigmas.But still, it's like a\nsum of normal variables,so we'll have\nnormal distribution.In fact, it just gets\nbetter and better.The second fact is\ncalled Ito isometry.That was cool.Can we compute the variance?Yes?AUDIENCE: Can you\nput that board up?PROFESSOR: Sure.AUDIENCE: Does it go up?PROFESSOR: This\none doesn't go up.That's bad.I wish it did go up.This has a name\ncalled Ito isometry.Can be used to\ncompute the variance.B_t is a Brownian\nmotion, delta t", "start": 2880.0, "heat": 0.466}, {"text": "is adapted to a Brownian motion.Then the expectation\nof your Ito integral--that's the Ito integral\nof your adapted process.That's the variance-- we\ntake the square of it--is equal to something cool.The square just comes in.Quite nice, isn't it?I won't prove it, but\nlet me tell you why.We already saw this\nphenomenon before.This is basically\nquadratic variation.And the proof also uses it.If you take delta s\nequals to 1-- sorry,I was using Korean-- 1 at all\ntime, then what we have ishere you get a\nBrownian motion, B_t.So on the left you get like\nexpectation of B_t square,and on the right,\nwhat you get is t.Because when delta\ns is equal to 1at all time, when you have\nto get from 0 to t you get t,and you have t on\nthe right hand side.That's what it's saying.And that was the content\nof quadratic variation,if you remember.We're summing the squares--\nmaybe not exactly this,but you're summing the\nsquares over small intervals.", "start": 3000.0, "heat": 0.854}, {"text": "So that's a really\ngood fact that you canuse to compute the variance.You have an Ito integral,\nyou know the square,can be computed this simple way.That's really cool.And one more property.This one will be\nreally important.You'll see it a lot\nin future lectures.It's that when is Ito\nintegral a martingale?What's a martingale?Martingale meant if you\nhave a stochastic process,at any time t, whatever happens\nafter that, the expected valueat time t is equal to 0.It doesn't have any natural\ntendency to go up or go down.No matter which point\nyou stop your processand you see your future, it\ndoesn't have a natural tendencyto go up or go down.In formal language, it can\nbe defined as where F_tis the events X_0 up to X_t.So if you take the\nconditional expectationbased on whatever\nhappened up to time t,that expectation will\njust be whatever valueyou have at that time.Intuitively, that just means you\ndon't have any natural tendencyto go up or go down.Question is, when is an\nIto integral a martingale?", "start": 3120.0, "heat": 0.712}, {"text": "Adapted to B of t, then...is a martingale.As long as g is not\nsome crazy function,as long as g is reasonable--\none way can be reasonable if itsL^2-norm is bounded.If you don't know what it\nmeans, you can safely ignore it.Basically, if g doesn't-- it's\nnot a crazy function if itdoesn't grow too fast, then\nin most cases this integral isalways a martingale.If you flip it--\nremember, integralwas defined as the inverse\nof differentiation.So if dX_t is equal to\nsome function mu, thatdepends on both t and\nB_t, times dt, plus sigmaof dB_t, what this means\nis X_t is a martingaleif that is 0 at\nall time, always.", "start": 3240.0, "heat": 0.691}, {"text": "And if it's not 0,\nyou have a drift,so it's not a martingale.That gives you some\nclassification.Now, if you look at a\ndifferential equationof this stochastic--\nthis is calleda stochastic differential\nequation-- if you knowstochastic process, if you look\nat a stochastic differentialequation, if it doesn't have a\ndrift term, it's a martingale.If it has a drift term,\nit's not a martingale.That'll be really useful\nlater, so try to remember it.The whole point is\nwhen you write downa stochastic process in\nterms of something times dt,something times dB_t,\nreally this termcontributes towards the\ntendency, the slope of whateveris going to happen\nin the future.And this is like\nthe variance term.It adds some variance to\nyour stochastic process.But still, it doesn't add\nor subtract value over time,it fairly adds variation.Remember that.That's very important fact.You're going to use it a lot.For example, you're going to\nuse it for pricing theory.In pricing theory, you come up\nwith this stochastic processor some strategy.You look at its value.Let's say X_t is your value\nof your portfolio over time.If that portfolio has-- then you\nmatch it with your financial--let me go over it slowly again.First you have a financial\nderivative, like optionof a stock.Then you have your\nportfolio strategy.Assume that you have\nsome strategy that,at the expiration\ntime, gives youthe exact value of the option.", "start": 3360.0, "heat": 0.272}, {"text": "Now you look at the\ndifference between these twostochastic processes.Basically what the thing is,\nwhen your variance goes to 0,your drift also has to go to 0.So when you look\nat the difference,if you can somehow get rid\nof this variance term, thatmeans no matter\nwhat you do, thatwill govern the value\nof your portfolio.If it's positive, that means\nyou can always make money,because there's no variance.Without variance,\nyou make money.That's called arbitrage,\nand you cannot have that.But I won't go\ninto further detailbecause Vasily will\ncover it next time.But just remember that flavor.So when you write something down\nin a stochastic differentialequation form, that\nterm is a drift term,that term is a variance term.And if you don't have\ndrift, it's a martingale.That is very important.Any questions?That's kind of the\nbasics of Ito calculus.I will give you some\nexercises on it,mostly just basic computation\nexercises, so that you'llget familiar with it.Try to practice it.And let me cover one more\nthing called Girsanov theorem.It's related, but\nthese are reallybasics of the Ito\ncalculus, so if youhave any questions on\nthis, please ask meright now before I move\non to the next topic.The last thing I want\nto talk about today.", "start": 3480.0, "heat": 0.481}, {"text": "Here is an underlying question.Suppose you have two\nBrownian motions.This is without drift.And you have another B tilde,\nBrownian motion with drift.These are two probability\ndistributions over paths.According to B_t, you're\nmore likely to havesome Brownian motion\nthat has no drift.That's a sample path.According to B tilde,\nyou have some drift.Your Brownian motion will--A typical path will follow this\nline and will follow that line.The question is\nthis-- can we switchfrom this distribution\nto this distributionby a change of measure?", "start": 3600.0, "heat": 0.352}, {"text": "Can we switch between\nthe two measuresto probability distributions\nby a change of measure?Let me go a little bit\nmore what it really means.Assume that you're just\nlooking at a Brownian motionfrom time 0 up to time t,\nsome fixed time interval.Then according to B_t, let's\nsay this is a sample path omega.You have some probability\nof omega-- this is a p.d.f.given by this Brownian\nmotion B. And then youhave another p.d.f., P tilde\nof omega, which is a p.d.f.given by B of t.The question is,\ndoes there exist a Zdepending on omega\nsuch that P of omegais equal to Z times P tilde?Do you understand the question?Clearly, if you just look at\nit, they're quite different.The path that you get\naccording to the distributionsare quite different.It's not clear why we\nshould expect it at all.", "start": 3720.0, "heat": 0.409}, {"text": "You'll see the answer soon.But let me discuss all this\nin a different context.Just forget about all the\nBrownian motion and everythingjust for a moment.In this concept, changing from\none probability distributionto another distribution,\nit's a very important conceptin analysis and probability\njust in general, theoretically.And there's a name for this\nZ, for this changing measure.If Z exists, it's called the\nRadon-Nikodym derivative.Before doing that, let me\ntalk a little bit more.Suppose P is a probability\ndistribution over omega.It's a probability distribution.So this is some set, and P\ndescribes the probabilitythat you have each\nelement in the set.And you have another probability\ndistribution, P tilde.We define P and P tilde to be\nequivalent if the probabilitythat A is greater than\nzero if and only if...For all...These probability distributions\ndescribe the probability", "start": 3840.0, "heat": 0.634}, {"text": "of the subsets.Think about a very simple case.Sigma is equal to 1, 2, and 3.P gives 1/3 probability\nto 1, 1/3 probabilityto 2, 1/3 probability to 3.P tilde gives 2/3 probability\nto 3, 1 over 6 probabilityto 2, 1 over 6 probability to 3.We have two probability\ndistribution over some space.They are equivalent\nif, whenever youtake a subset of your\nbackground set-- let's say 1, 2.When A is equal\nto 1, 2, accordingto probability distribution\nP, the probabilityyou fall into this\nset A is equal to 2/3.According to P\ntilde, you have 5/6.They're not the same.The probability itself\nis not the same,but this condition is\nsatisfied when it's 0.And when it's not 0, it's not 0.And you can just check that it's\nalways true, because they'reall positive probabilities.On the other hand, if\nyou take instead, say,1/3 and 0, now you\ntake your A to be 3.Then you have 1/3 equal to 0.This means, according to\nprobability distribution P,there is some probability\nthat you'll get 3.But according to probability\ndistribution P tilde,you don't have any\nprobability of getting 3.So they're not\nequivalent in this case.If you think about it,\nthen it's really clear.The theorem says-- this is\na very important theoremin analysis, actually.The theorem-- there exists a Z\nsuch that P of omega is equal", "start": 3960.0, "heat": 0.741}, {"text": "to...If and only if P and P\ntilde are equivalent.You can change from\none probability measureto another probability\nmeasure justin terms of multiplication, if\nand only if they're equivalent.And you can see that it's\nnot the case for thiswhen they're not equivalent.You can't make a zero\nprobability to 1/3 probabilityby multiplication.So in the finite world this is\nvery just intuitive theorem,but what this is saying is\nit's true for all probabilityspaces.And these are called the\nRadon-Nikodym derivative.Our question is, are these two\nBrownian motions equivalent?The paths that this Brownian\nmotion without drifttakes and the Brownian\nmotion with drifttakes, are they kind of\nthe same but just skewedin distribution, or are they\nreally fundamentally different?That's the question.And what Girsanov's theorem says\nis that they are equivalent.To me, it came as a\nlittle bit non-intuitive.I would imagine that it's\nnot equivalent, these two.These paths have a\nvery natural tendency.As it goes to infinity,\nthese paths and these pathswill really look\na lot different,because when you go\nreally, really far,the paths which have\ndrift will be just reallyclose to your line mu of\nt, while the paths whichdon't have drift will be\nreally close to the x-axis.", "start": 4080.0, "heat": 0.698}, {"text": "But still, they are equivalent.You can change from\none to another.I'll just state that\ntheorem without proof.And this will also be\nused in pricing theory.I'm not an expert\nenough to tell why,but basically what\nit's saying is,you switch some\nstochastic processinto a stochastic\nprocess without drift,thus making it\ninto a martingale.And martingale has a lot of\nmeaning in pricing theory,as you'll see.This also has application.That's why I'm trying to\ncover it, although it'squite a technical theorem.Try to remember at least\na statement and the spiritof what it means.It just means these\ntwo are equivalent,you can change\nfrom one to anotherby a multiplicative function.Let me just state\nit in a simple form.GUEST SPEAKER: If I could\njust interject a comment.PROFESSOR: Sure.GUEST SPEAKER: With\nthese changes of measure,it turns out that all of these\ntheories with continuous timeprocesses should have an\ninterpretation if you'vediscretized time,\nand should considersort of a finer and finer\ndiscretization of the process.And with this change of measure,\nif you consider problemsin discrete stochastic\nprocesses like random walks,basically how-- say if you're\ngambling against a casinoor against another\nplayer, and youlook at how your winnings\nevolve as a random walk,depending on your\nodds, your oddscould be that you\nwill tend to lose.", "start": 4200.0, "heat": 0.871}, {"text": "So there's basically\na drift in your wealthas this random process evolves.You can transform that process,\nbasically by taking outyour expected losses,\nto a process whichhas zero change in expectation.And so you can convert\nthese gambling problemswhere there's drift to a version\nwhere the process, essentially,has no drift and\nis a martingale.And the martingale theory in\nstochastic process coursesis very, very powerful.There's martingale\nconvergence theorems.So you know that the\nlimit of the martingaleis-- there's a convergence\nof the process,and that applies here as well.PROFESSOR: You will see some\nsurprising applications.GUEST SPEAKER: Yeah.PROFESSOR: And try to at\nleast digest the statement.When the guest speaker comes\nand says by Girsanov theorem,they actually know what it is.There's a spirit.This is a very simple version.There's a lot of\ncomplicated versions,but let me just do it.So P is a probability\ndistribution over pathsfrom [0, T] to the infinity.What this means is just paths\nfrom that-- stochastic processdefined from time\n0 to time T. Theseare paths defined by a\nBrownian motion with drift mu.", "start": 4320.0, "heat": 0.619}, {"text": "And then P tilde is a\nprobability distributiondefined by Brownian\nmotion without drift.Then P and P tilde\nare equivalent.Not only are they\nequivalent, we can actuallycompute their\nRadon-Nikodym derivative.And the Radon-Nikodym\nderivative Zwhich is defined as T of--\nwhich we denote like thishas this nice form.That's a nice closed form.Let me just tell you a\nfew implications of this.Now, assume you have\nsome, let's say, valueof your portfolio over time.That's the stochastic process.And you measure it according to\nthis probability distribution.Let's say it depends\non some stock priceas the stock price is\nmodeled using a Brownianmotion with drift.What this is saying\nis, now, insteadof computing this expectation\nin your probability space--so this is defined over\nthe probability space P,", "start": 4440.0, "heat": 0.225}, {"text": "our sigma-- (omega, P)\ndefined by this probabilitydistribution.You can instead\ncompute it in-- youcan compute as expectation in\na different probability space.You transform the problems\nabout Brownian motion with driftinto a problem about Brownian\nmotion without a drift.And the reason I have\nZ tilde instead of Zhere is because I flipped.What you really should have is Z\ntilde here as expectation of Z.If you want to use this Z.I don't expect you to really\nbe able to do computationsand do that just by looking\nat this theorem once.Just really trying to\ndigest what it meansand understand the flavor of\nit, that you can transformproblems in one\nprobability spaceto another probability space.And you can actually do that\nwhen the two distributions aredefined by Brownian motions\nwhen one has drift and onedoesn't have a drift.How we're going\nto use it is we'regoing to transform a\nnon-martingale processinto a martingale process.When you change\ninto martingale ithas very good physical\nmeanings to it.That's it for today.And you only have one more\nmath lecture remainingand maybe one or two\nhomeworks but if you have two,the second one\nwon't be that long.And you'll have a lot of\nguest lectures, exciting guestlectures, so try\nnot to miss them.", "start": 4560.0, "heat": 0.385}]