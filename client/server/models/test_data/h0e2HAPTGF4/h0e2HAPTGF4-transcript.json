[{"text": "The following content is\nprovided under a Creative", "start": 0.79, "duration": 2.34}, {"text": "Commons license.", "start": 3.13, "duration": 1.42}, {"text": "Your support will help\nMIT OpenCourseWare", "start": 4.55, "duration": 2.21}, {"text": "continue to offer high quality\neducational resources for free.", "start": 6.76, "duration": 4.09}, {"text": "To make a donation or to\nview additional materials", "start": 10.85, "duration": 2.54}, {"text": "from hundreds of MIT courses,\nvisit MIT OpenCourseWare", "start": 13.39, "duration": 3.93}, {"text": "at ocw.mit.edu.", "start": 17.32, "duration": 1.25}, {"text": "ERIC GRIMSON: OK.", "start": 30.932, "duration": 0.708}, {"text": "Welcome back.", "start": 31.64, "duration": 2.84}, {"text": "You know, it's that\ntime a term when", "start": 34.48, "duration": 1.56}, {"text": "we're all kind of doing this.", "start": 36.04, "duration": 2.91}, {"text": "So let me see if I can get a few\nsmiles by simply noting to you", "start": 38.95, "duration": 3.03}, {"text": "that two weeks from\ntoday is the last class.", "start": 41.98, "duration": 3.737}, {"text": "Should be worth at least a\nlittle bit of a smile, right?", "start": 45.717, "duration": 2.333}, {"text": "Professor Guttag is smiling.", "start": 48.05, "duration": 1.45}, {"text": "He likes that idea.", "start": 49.5, "duration": 1.53}, {"text": "You're almost there.", "start": 51.03, "duration": 2.8}, {"text": "What are we doing for the\nlast couple of lectures?", "start": 53.83, "duration": 2.84}, {"text": "We're talking about\nlinear regression.", "start": 56.67, "duration": 1.782}, {"text": "And I just want to\nremind you, this", "start": 58.452, "duration": 1.458}, {"text": "was the idea of I have\nsome experimental data.", "start": 59.91, "duration": 3.78}, {"text": "Case of a spring where I put\ndifferent weights on measure", "start": 63.69, "duration": 2.67}, {"text": "displacements.", "start": 66.36, "duration": 1.26}, {"text": "And regression was giving\nus a way of deducing a model", "start": 67.62, "duration": 4.02}, {"text": "to fit that data.", "start": 71.64, "duration": 1.855}, {"text": "And In some cases it was easy.", "start": 73.495, "duration": 1.452}, {"text": "We knew, for example, it was\ngoing to be a linear model.", "start": 74.947, "duration": 2.333}, {"text": "We found the best line\nthat would fit that data.", "start": 77.28, "duration": 2.04}, {"text": "In some cases, we said\nwe could use validation", "start": 79.32, "duration": 2.79}, {"text": "to actually let us explore\nto find the best model that", "start": 82.11, "duration": 2.85}, {"text": "would fit it, whether a\nlinear, a quadratic, a cubic,", "start": 84.96, "duration": 4.62}, {"text": "some higher order thing.", "start": 89.58, "duration": 1.92}, {"text": "So we'll be using that to\ndeduce something about a model.", "start": 91.5, "duration": 4.84}, {"text": "That's a nice segue into\nthe topic for the next three", "start": 96.34, "duration": 3.46}, {"text": "lectures, the last big\ntopic of the class,", "start": 99.8, "duration": 2.88}, {"text": "which is machine learning.", "start": 102.68, "duration": 1.217}, {"text": "And I'm going to argue, you can\ndebate whether that's actually", "start": 103.897, "duration": 2.583}, {"text": "an example of learning.", "start": 106.48, "duration": 1.03}, {"text": "But it has many of\nthe elements that we", "start": 107.51, "duration": 1.625}, {"text": "want to talk about when we\ntalk about machine learning.", "start": 109.135, "duration": 3.565}, {"text": "So as always, there's\na reading assignment.", "start": 112.7, "duration": 2.51}, {"text": "Chapter 22 of the book gives\nyou a good start on this,", "start": 115.21, "duration": 2.29}, {"text": "and it will follow\nup with other pieces.", "start": 117.5, "duration": 2.66}, {"text": "And I want to start\nby basically outlining", "start": 120.16, "duration": 2.912}, {"text": "what we're going to do.", "start": 123.072, "duration": 0.958}, {"text": "And I'm going to\nbegin by saying,", "start": 124.03, "duration": 1.374}, {"text": "as I'm sure you're aware,\nthis is a huge topic.", "start": 125.404, "duration": 3.726}, {"text": "I've listed just five\nsubjects in course six", "start": 129.13, "duration": 3.63}, {"text": "that all focus on\nmachine learning.", "start": 132.76, "duration": 2.01}, {"text": "And that doesn't\ninclude other subjects", "start": 134.77, "duration": 2.13}, {"text": "where learning is\na central part.", "start": 136.9, "duration": 2.13}, {"text": "So natural language processing,\ncomputational biology,", "start": 139.03, "duration": 3.33}, {"text": "computer vision\nrobotics all rely today,", "start": 142.36, "duration": 3.03}, {"text": "heavily on machine learning.", "start": 145.39, "duration": 1.68}, {"text": "And you'll see those in\nthose subjects as well.", "start": 147.07, "duration": 2.98}, {"text": "So we're not going to\ncompress five subjects", "start": 150.05, "duration": 2.51}, {"text": "into three lectures.", "start": 152.56, "duration": 1.93}, {"text": "But what we are going to do\nis give you the introduction.", "start": 154.49, "duration": 2.43}, {"text": "We're going to start by talking\nabout the basic concepts", "start": 156.92, "duration": 2.66}, {"text": "of machine learning.", "start": 159.58, "duration": 1.23}, {"text": "The idea of having examples, and\nhow do you talk about features", "start": 160.81, "duration": 2.97}, {"text": "representing those\nexamples, how do", "start": 163.78, "duration": 1.83}, {"text": "you measure distances\nbetween them,", "start": 165.61, "duration": 2.04}, {"text": "and use the notion\nof distance to try", "start": 167.65, "duration": 2.43}, {"text": "and group similar\nthings together as a way", "start": 170.08, "duration": 2.13}, {"text": "of doing machine learning.", "start": 172.21, "duration": 1.24}, {"text": "And we're going to\nlook, as a consequence,", "start": 173.45, "duration": 1.88}, {"text": "of two different standard\nways of doing learning.", "start": 175.33, "duration": 4.2}, {"text": "One, we call\nclassification methods.", "start": 179.53, "duration": 2.025}, {"text": "Example we're\ngoing to see, there", "start": 181.555, "duration": 1.375}, {"text": "is something called\n\"k nearest neighbor\"", "start": 182.93, "duration": 2.18}, {"text": "and the second class,\ncalled clustering methods.", "start": 185.11, "duration": 3.28}, {"text": "Classification works\nwell when I have what", "start": 188.39, "duration": 2.36}, {"text": "we would call labeled data.", "start": 190.75, "duration": 1.34}, {"text": "I know labels on my\nexamples, and I'm", "start": 192.09, "duration": 2.98}, {"text": "going to use that to\ntry and define classes", "start": 195.07, "duration": 2.13}, {"text": "that I can learn, and\nclustering working well,", "start": 197.2, "duration": 2.31}, {"text": "when I don't have labeled data.", "start": 199.51, "duration": 1.42}, {"text": "And we'll see what that\nmeans in a couple of minutes.", "start": 200.93, "duration": 2.208}, {"text": "But we're going to give\nyou an early view of this.", "start": 203.138, "duration": 4.362}, {"text": "Unless Professor Guttag\nchanges his mind,", "start": 207.5, "duration": 1.86}, {"text": "we're probably not going to\nshow you the current really", "start": 209.36, "duration": 2.4}, {"text": "sophisticated machine\nlearning methods", "start": 211.76, "duration": 1.74}, {"text": "like convolutional neural\nnets or deep learning,", "start": 213.5, "duration": 2.37}, {"text": "things you'll read\nabout in the news.", "start": 215.87, "duration": 1.17}, {"text": "But you're going to\nget a sense of what's", "start": 217.04, "duration": 1.68}, {"text": "behind those, by looking\nat what we do when we", "start": 218.72, "duration": 1.92}, {"text": "talk about learning algorithms.", "start": 220.64, "duration": 3.25}, {"text": "Before I do it, I want\nto point out to you", "start": 223.89, "duration": 1.75}, {"text": "just how prevalent this is.", "start": 225.64, "duration": 1.56}, {"text": "And I'm going to admit\nwith my gray hair,", "start": 227.2, "duration": 2.67}, {"text": "I started working in AI in\n1975 when machine learning was", "start": 229.87, "duration": 3.66}, {"text": "a pretty simple thing to do.", "start": 233.53, "duration": 1.5}, {"text": "And it's been\nfascinating to watch", "start": 235.03, "duration": 1.44}, {"text": "over 40 years, the change.", "start": 236.47, "duration": 1.68}, {"text": "And if you think about it, just\nthink about where you see it.", "start": 238.15, "duration": 3.4}, {"text": "AlphaGo, machine learning based\nsystem from Google that beat", "start": 241.55, "duration": 5.18}, {"text": "a world-class level Go player.", "start": 246.73, "duration": 2.31}, {"text": "Chess has already been conquered\nby computers for a while.", "start": 249.04, "duration": 2.94}, {"text": "Go now belongs to computers.", "start": 251.98, "duration": 2.04}, {"text": "Best Go players in the\nworld are computers.", "start": 254.02, "duration": 2.91}, {"text": "I'm sure many of\nyou use Netflix.", "start": 256.93, "duration": 1.589}, {"text": "Any recommendation\nsystem, Netflix,", "start": 258.519, "duration": 2.141}, {"text": "Amazon, pick your favorite, uses\na machine learning algorithm", "start": 260.66, "duration": 3.11}, {"text": "to suggest things for you.", "start": 263.77, "duration": 1.711}, {"text": "And in fact, you've probably\nseen it on Google, right?", "start": 265.481, "duration": 2.249}, {"text": "The ads that pop\nup on Google are", "start": 267.73, "duration": 1.83}, {"text": "coming from a machine\nlearning algorithm that's", "start": 269.56, "duration": 2.13}, {"text": "looking at your preferences.", "start": 271.69, "duration": 1.53}, {"text": "Scary thought.", "start": 273.22, "duration": 1.68}, {"text": "Drug discovery, character\nrecognition-- the post office", "start": 274.9, "duration": 4.08}, {"text": "does character recognition of\nhandwritten characters using", "start": 278.98, "duration": 2.995}, {"text": "a machine learning algorithm\nand a computer vision system", "start": 281.975, "duration": 2.375}, {"text": "behind it.", "start": 284.35, "duration": 1.98}, {"text": "You probably don't\nknow this company.", "start": 286.33, "duration": 1.86}, {"text": "It's actually an MIT\nspin-off called Two Sigma,", "start": 288.19, "duration": 2.07}, {"text": "it's a hedge fund in New York.", "start": 290.26, "duration": 1.8}, {"text": "They heavily use AI and\nmachine learning techniques.", "start": 292.06, "duration": 2.91}, {"text": "And two years ago, their\nfund returned a 56% return.", "start": 294.97, "duration": 6.977}, {"text": "I wish I'd invested in the fund.", "start": 301.947, "duration": 1.333}, {"text": "I don't have the kinds\nof millions you need,", "start": 303.28, "duration": 1.57}, {"text": "but that's an impressive return.", "start": 304.85, "duration": 1.52}, {"text": "56% return on your\nmoney in one year.", "start": 306.37, "duration": 3.176}, {"text": "Last year they didn't\ndo quite as well,", "start": 309.546, "duration": 1.624}, {"text": "but they do extremely well using\nmachine learning techniques.", "start": 311.17, "duration": 2.97}, {"text": "Siri.", "start": 314.14, "duration": 2.41}, {"text": "Another great MIT\ncompany called Mobileye", "start": 316.55, "duration": 2.13}, {"text": "that does computer vision\nsystems with a heavy machine", "start": 318.68, "duration": 2.43}, {"text": "learning component that is\nused in assistive driving", "start": 321.11, "duration": 2.97}, {"text": "and will be used in\ncompletely autonomous driving.", "start": 324.08, "duration": 2.37}, {"text": "It will do things like\nkick in your brakes", "start": 326.45, "duration": 2.07}, {"text": "if you're closing too fast\non the car in front of you,", "start": 328.52, "duration": 3.547}, {"text": "which is going to\nbe really bad for me", "start": 332.067, "duration": 1.583}, {"text": "because I drive\nlike a Bostonian.", "start": 333.65, "duration": 1.95}, {"text": "And it would be\nkicking in constantly.", "start": 335.6, "duration": 2.43}, {"text": "Face recognition.", "start": 338.03, "duration": 1.5}, {"text": "Facebook uses this,\nmany other systems", "start": 339.53, "duration": 3.0}, {"text": "do to both detect\nand recognize faces.", "start": 342.53, "duration": 3.54}, {"text": "IBM Watson-- cancer diagnosis.", "start": 346.07, "duration": 2.65}, {"text": "These are all just\nexamples of machine", "start": 348.72, "duration": 1.67}, {"text": "learning being used everywhere.", "start": 350.39, "duration": 2.43}, {"text": "And it really is.", "start": 352.82, "duration": 1.05}, {"text": "I've only picked nine.", "start": 353.87, "duration": 2.85}, {"text": "So what is it?", "start": 356.72, "duration": 3.56}, {"text": "I'm going to make an\nobnoxious statement.", "start": 360.28, "duration": 1.86}, {"text": "You're now used to that.", "start": 362.14, "duration": 1.555}, {"text": "I'm going to claim\nthat you could", "start": 363.695, "duration": 1.375}, {"text": "argue that almost every computer\nprogram learns something.", "start": 365.07, "duration": 4.35}, {"text": "But the level of learning\nreally varies a lot.", "start": 369.42, "duration": 2.22}, {"text": "So if you think back to\nthe first lecture in 60001,", "start": 371.64, "duration": 3.51}, {"text": "we showed you Newton's method\nfor computing square roots.", "start": 375.15, "duration": 3.48}, {"text": "And you could argue,\nyou'd have to stretch it,", "start": 378.63, "duration": 2.28}, {"text": "but you could argue\nthat that method learns", "start": 380.91, "duration": 2.37}, {"text": "something about how to\ncompute square roots.", "start": 383.28, "duration": 1.98}, {"text": "In fact, you could generalize\nit to roots of any order power.", "start": 385.26, "duration": 4.726}, {"text": "But it really didn't learn.", "start": 389.986, "duration": 1.124}, {"text": "I really had to program it.", "start": 391.11, "duration": 2.33}, {"text": "All right.", "start": 393.44, "duration": 0.52}, {"text": "Think about last week when we\ntalked about linear regression.", "start": 393.96, "duration": 3.54}, {"text": "Now it starts to feel\na little bit more", "start": 397.5, "duration": 2.31}, {"text": "like a learning algorithm.", "start": 399.81, "duration": 1.23}, {"text": "Because what did we do?", "start": 401.04, "duration": 0.958}, {"text": "We gave you a set\nof data points,", "start": 401.998, "duration": 2.552}, {"text": "mass displacement data points.", "start": 404.55, "duration": 2.65}, {"text": "And then we showed you how\nthe computer could essentially", "start": 407.2, "duration": 2.45}, {"text": "fit a curve to that data point.", "start": 409.65, "duration": 2.64}, {"text": "And it was, in some sense,\nlearning a model for that data", "start": 412.29, "duration": 3.81}, {"text": "that it could then use\nto predict behavior.", "start": 416.1, "duration": 2.86}, {"text": "In other situations.", "start": 418.96, "duration": 1.465}, {"text": "And that's getting\ncloser to what", "start": 420.425, "duration": 1.375}, {"text": "we would like when we\nthink about a machine", "start": 421.8, "duration": 1.71}, {"text": "learning algorithm.", "start": 423.51, "duration": 0.791}, {"text": "We'd like to have program that\ncan learn from experience,", "start": 424.301, "duration": 6.159}, {"text": "something that it can then\nuse to deduce new facts.", "start": 430.46, "duration": 3.82}, {"text": "Now it's been a problem in\nAI for a very long time.", "start": 434.28, "duration": 2.7}, {"text": "And I love this quote.", "start": 436.98, "duration": 1.1}, {"text": "It's from a gentleman\nnamed Art Samuel.", "start": 438.08, "duration": 3.45}, {"text": "1959 is the quote\nin which he says,", "start": 441.53, "duration": 3.264}, {"text": "his definition of\nmachine learning", "start": 444.794, "duration": 1.416}, {"text": "is the field of study\nthat gives computers", "start": 446.21, "duration": 1.92}, {"text": "the ability to learn without\nbeing explicitly programmed.", "start": 448.13, "duration": 4.261}, {"text": "And I think many\npeople would argue,", "start": 452.391, "duration": 1.499}, {"text": "he wrote the first such program.", "start": 453.89, "duration": 2.19}, {"text": "It learned from experience.", "start": 456.08, "duration": 2.63}, {"text": "In his case, it played checkers.", "start": 458.71, "duration": 1.582}, {"text": "Kind of shows you how\nthe field has progressed.", "start": 460.292, "duration": 1.958}, {"text": "But we started with checkers,\nwe got to chess, we now do Go.", "start": 462.25, "duration": 3.36}, {"text": "But it played checkers.", "start": 465.61, "duration": 0.96}, {"text": "It beat national level\nplayers, most importantly,", "start": 466.57, "duration": 2.67}, {"text": "it learned to\nimprove its methods", "start": 469.24, "duration": 3.33}, {"text": "by watching how it did in games\nand then inferring something", "start": 472.57, "duration": 3.06}, {"text": "to change what it thought\nabout as it did that.", "start": 475.63, "duration": 2.862}, {"text": "Samuel did a bunch\nof other things.", "start": 478.492, "duration": 1.458}, {"text": "I just highlighted one.", "start": 479.95, "duration": 0.99}, {"text": "You may see in a\nfollow on course,", "start": 480.94, "duration": 1.23}, {"text": "he invented what's called\nAlpha-Beta Pruning, which", "start": 482.17, "duration": 2.125}, {"text": "is a really useful\ntechnique for doing search.", "start": 484.295, "duration": 2.601}, {"text": "But the idea is, how can\nwe have the computer learn", "start": 486.896, "duration": 3.494}, {"text": "without being\nexplicitly programmed?", "start": 490.39, "duration": 3.054}, {"text": "And one way to\nthink about this is", "start": 493.444, "duration": 1.416}, {"text": "to think about the difference\nbetween how we would normally", "start": 494.86, "duration": 2.58}, {"text": "program and what we would\nlike from a machine learning", "start": 497.44, "duration": 2.43}, {"text": "algorithm.", "start": 499.87, "duration": 1.822}, {"text": "Normal programming, I\nknow you're not convinced", "start": 501.692, "duration": 1.958}, {"text": "there's such a thing\nas normal programming,", "start": 503.65, "duration": 1.791}, {"text": "but if you think of\ntraditional programming,", "start": 505.441, "duration": 2.379}, {"text": "what's the process?", "start": 507.82, "duration": 2.28}, {"text": "I write a program that\nI input to the computer", "start": 510.1, "duration": 3.51}, {"text": "so that it can then\ntake data and produce", "start": 513.61, "duration": 2.73}, {"text": "some appropriate output.", "start": 516.34, "duration": 2.069}, {"text": "And the square root finder\nreally sits there, right?", "start": 518.409, "duration": 2.341}, {"text": "I wrote code for using Newton\nmethod to find a square root,", "start": 520.75, "duration": 2.73}, {"text": "and then it gave me the\nprocess of given any number,", "start": 523.48, "duration": 3.52}, {"text": "I'll give you the square root.", "start": 527.0, "duration": 1.25}, {"text": "But if you think about\nwhat we did last time,", "start": 530.8, "duration": 1.98}, {"text": "it was a little different.", "start": 532.78, "duration": 1.083}, {"text": "And in fact, in a machine\nlearning approach,", "start": 533.863, "duration": 3.037}, {"text": "the idea is that I'm going\nto give the computer output.", "start": 536.9, "duration": 4.7}, {"text": "I'm going to give it examples of\nwhat I want the program to do,", "start": 541.6, "duration": 4.32}, {"text": "labels on data,\ncharacterizations", "start": 545.92, "duration": 2.46}, {"text": "of different classes of things.", "start": 548.38, "duration": 2.0}, {"text": "And what I want\nthe computer to do", "start": 550.38, "duration": 1.48}, {"text": "is, given that characterization\nof output and data,", "start": 551.86, "duration": 3.72}, {"text": "I wanted that machine\nlearning algorithm", "start": 555.58, "duration": 1.92}, {"text": "to actually produce\nfor me a program,", "start": 557.5, "duration": 2.98}, {"text": "a program that I can\nthen use to infer", "start": 560.48, "duration": 2.85}, {"text": "new information about things.", "start": 563.33, "duration": 2.04}, {"text": "And that creates, if you\nlike, a really nice loop", "start": 565.37, "duration": 4.072}, {"text": "where I can have the\nmachine learning algorithm", "start": 569.442, "duration": 1.958}, {"text": "learn the program\nwhich I can then use", "start": 571.4, "duration": 2.79}, {"text": "to solve some other problem.", "start": 574.19, "duration": 2.0}, {"text": "That would be really\ngreat if we could do it.", "start": 576.19, "duration": 2.07}, {"text": "And as I suggested, that\ncurve-fitting algorithm", "start": 578.26, "duration": 2.08}, {"text": "is a simple version of that.", "start": 580.34, "duration": 1.53}, {"text": "It learned a model for the\ndata, which I could then", "start": 581.87, "duration": 2.82}, {"text": "use to label any other\ninstances of the data", "start": 584.69, "duration": 2.13}, {"text": "or predict what I would see in\nterms of spring displacement", "start": 586.82, "duration": 2.85}, {"text": "as I changed the masses.", "start": 589.67, "duration": 2.43}, {"text": "So that's the kind of idea\nwe're going to explore.", "start": 592.1, "duration": 2.75}, {"text": "If we want to learn\nthings, we could also", "start": 594.85, "duration": 2.2}, {"text": "ask, so how do you learn?", "start": 597.05, "duration": 2.15}, {"text": "And how should a computer learn?", "start": 599.2, "duration": 3.337}, {"text": "Well, for you as a human, there\nare a couple of possibilities.", "start": 602.537, "duration": 2.583}, {"text": "This is the boring one.", "start": 605.12, "duration": 1.02}, {"text": "This is the old style\nway of doing it, right?", "start": 606.14, "duration": 2.76}, {"text": "Memorize facts.", "start": 608.9, "duration": 2.01}, {"text": "Memorize as many facts as you\ncan and hope that we ask you", "start": 610.91, "duration": 2.72}, {"text": "on the final exam\ninstances of those facts,", "start": 613.63, "duration": 2.56}, {"text": "as opposed to some other\nfacts you haven't memorized.", "start": 616.19, "duration": 2.91}, {"text": "This is, if you think way\nback to the first lecture,", "start": 619.1, "duration": 3.48}, {"text": "an example of declarative\nknowledge, statements of truth.", "start": 622.58, "duration": 4.26}, {"text": "Memorize as many as you can.", "start": 626.84, "duration": 1.53}, {"text": "Have Wikipedia in\nyour back pocket.", "start": 628.37, "duration": 3.25}, {"text": "Better way to learn is to\nbe able to infer, to deduce", "start": 631.62, "duration": 3.66}, {"text": "new information from old.", "start": 635.28, "duration": 2.7}, {"text": "And if you think\nabout this, this", "start": 637.98, "duration": 1.65}, {"text": "gets closer to what we\ncalled imperative knowledge--", "start": 639.63, "duration": 3.24}, {"text": "ways to deduce new things.", "start": 642.87, "duration": 3.5}, {"text": "Now, in the first\ncases, we built", "start": 646.37, "duration": 1.73}, {"text": "that in when we wrote that\nprogram to do square roots.", "start": 648.1, "duration": 3.41}, {"text": "But what we'd like in\na learning algorithm", "start": 651.51, "duration": 1.92}, {"text": "is to have much more like\nthat generalization idea.", "start": 653.43, "duration": 3.33}, {"text": "We're interested in\nextending our capabilities", "start": 656.76, "duration": 3.12}, {"text": "to write programs that can\ninfer useful information", "start": 659.88, "duration": 3.96}, {"text": "from implicit\npatterns in the data.", "start": 663.84, "duration": 2.19}, {"text": "So not something\nexplicitly built", "start": 666.03, "duration": 2.28}, {"text": "like that comparison of\nweights and displacements,", "start": 668.31, "duration": 2.79}, {"text": "but actually implicit\npatterns in the data,", "start": 671.1, "duration": 2.25}, {"text": "and have the algorithm figure\nout what those patterns are,", "start": 673.35, "duration": 3.39}, {"text": "and use those to\ngenerate a program you", "start": 676.74, "duration": 2.04}, {"text": "can use to infer new\ndata about objects,", "start": 678.78, "duration": 3.39}, {"text": "about string\ndisplacements, whatever", "start": 682.17, "duration": 2.13}, {"text": "it is you're trying to do.", "start": 684.3, "duration": 3.101}, {"text": "OK.", "start": 687.401, "duration": 0.499}, {"text": "So the idea then,\nthe basic paradigm", "start": 687.9, "duration": 2.3}, {"text": "that we're going\nto see, is we're", "start": 690.2, "duration": 2.28}, {"text": "going to give the\nsystem some training", "start": 692.48, "duration": 2.61}, {"text": "data, some observations.", "start": 695.09, "duration": 2.04}, {"text": "We did that last time with\njust the spring displacements.", "start": 697.13, "duration": 4.17}, {"text": "We're going to then\ntry and have a way", "start": 701.3, "duration": 1.744}, {"text": "to figure out, how do\nwe write code, how do we", "start": 703.044, "duration": 1.916}, {"text": "write a program, a system\nthat will infer something", "start": 704.96, "duration": 2.55}, {"text": "about the process that\ngenerated the data?", "start": 707.51, "duration": 3.78}, {"text": "And then from\nthat, we want to be", "start": 711.29, "duration": 1.979}, {"text": "able to use that to make\npredictions about things", "start": 713.269, "duration": 2.041}, {"text": "we haven't seen before.", "start": 715.31, "duration": 2.55}, {"text": "So again, I want to\ndrive home this point.", "start": 717.86, "duration": 1.75}, {"text": "If you think about it, the\nspring example fit that model.", "start": 719.61, "duration": 5.22}, {"text": "I gave you a set of\ndata, spatial deviations", "start": 724.83, "duration": 3.51}, {"text": "relative to mass displacements.", "start": 728.34, "duration": 1.38}, {"text": "For different masses, how\nfar did the spring move?", "start": 729.72, "duration": 2.32}, {"text": "I then inferred something\nabout the underlying process.", "start": 732.04, "duration": 4.51}, {"text": "In the first case, I\nsaid I know it's linear,", "start": 736.55, "duration": 2.11}, {"text": "but let me figure out what\nthe actual linear equation is.", "start": 738.66, "duration": 2.82}, {"text": "What's the spring constant\nassociated with it?", "start": 741.48, "duration": 2.67}, {"text": "And based on that result,\nI got a piece of code", "start": 744.15, "duration": 2.67}, {"text": "I could use to predict\nnew displacements.", "start": 746.82, "duration": 3.3}, {"text": "So it's got all of those\nelements, training data,", "start": 750.12, "duration": 2.74}, {"text": "an inference engine,\nand then the ability", "start": 752.86, "duration": 2.33}, {"text": "to use that to make\nnew predictions.", "start": 755.19, "duration": 2.95}, {"text": "But that's a very simple\nkind of learning setting.", "start": 758.14, "duration": 2.19}, {"text": "So the more common\none is one I'm", "start": 760.33, "duration": 1.59}, {"text": "going to use as\nan example, which", "start": 761.92, "duration": 1.53}, {"text": "is, when I give you\na set of examples,", "start": 763.45, "duration": 3.76}, {"text": "those examples have some\ndata associated with them,", "start": 767.21, "duration": 2.15}, {"text": "some features and some labels.", "start": 769.36, "duration": 2.97}, {"text": "For each example,\nI might say this", "start": 772.33, "duration": 1.65}, {"text": "is a particular kind of thing.", "start": 773.98, "duration": 1.98}, {"text": "This other one is\nanother kind of thing.", "start": 775.96, "duration": 2.142}, {"text": "And what I want to\ndo is figure out", "start": 778.102, "duration": 1.458}, {"text": "how to do inference on\nlabeling new things.", "start": 779.56, "duration": 2.37}, {"text": "So it's not just, what's the\ndisplacement of the mass,", "start": 781.93, "duration": 2.594}, {"text": "it's actually a label.", "start": 784.524, "duration": 0.916}, {"text": "And I'm going to use one\nof my favorite examples.", "start": 785.44, "duration": 2.1}, {"text": "I'm a big New\nEngland Patriots fan,", "start": 787.54, "duration": 2.43}, {"text": "if you're not, my apologies.", "start": 789.97, "duration": 1.537}, {"text": "But I'm going to use\nfootball players.", "start": 791.507, "duration": 1.583}, {"text": "So I'm going to show\nyou in a second,", "start": 793.09, "duration": 1.95}, {"text": "I'm going to give you a set of\nexamples of football players.", "start": 795.04, "duration": 2.79}, {"text": "The label is the\nposition they play.", "start": 797.83, "duration": 2.392}, {"text": "And the data, well, it\ncould be lots of things.", "start": 800.222, "duration": 1.958}, {"text": "We're going to use\nheight and weight.", "start": 802.18, "duration": 1.74}, {"text": "But what we want\nto do is then see", "start": 803.92, "duration": 1.74}, {"text": "how would we come up with\na way of characterizing", "start": 805.66, "duration": 3.42}, {"text": "the implicit pattern of how\ndoes weight and height predict", "start": 809.08, "duration": 3.09}, {"text": "the kind of position\nthis player could play.", "start": 812.17, "duration": 2.46}, {"text": "And then come up\nwith an algorithm", "start": 814.63, "duration": 1.66}, {"text": "that will predict the\nposition of new players.", "start": 816.29, "duration": 2.225}, {"text": "We'll do the draft\nfor next year.", "start": 818.515, "duration": 1.425}, {"text": "Where do we want them to play?", "start": 819.94, "duration": 2.73}, {"text": "That's the paradigm.", "start": 822.67, "duration": 1.83}, {"text": "Set of observations, potentially\nlabeled, potentially not.", "start": 824.5, "duration": 4.41}, {"text": "Think about how do we do\ninference to find a model.", "start": 828.91, "duration": 2.61}, {"text": "And then how do we use that\nmodel to make predictions.", "start": 831.52, "duration": 3.48}, {"text": "What we're going\nto see, and we're", "start": 835.0, "duration": 1.429}, {"text": "going to see multiple\nexamples today,", "start": 836.429, "duration": 1.541}, {"text": "is that that\nlearning can be done", "start": 837.97, "duration": 1.53}, {"text": "in one of two very broad ways.", "start": 839.5, "duration": 3.37}, {"text": "The first one is called\nsupervised learning.", "start": 842.87, "duration": 2.59}, {"text": "And in that case,\nfor every new example", "start": 845.46, "duration": 2.68}, {"text": "I give you as part\nof the training data,", "start": 848.14, "duration": 1.71}, {"text": "I have a label on it.", "start": 849.85, "duration": 1.62}, {"text": "I know the kind of thing it is.", "start": 851.47, "duration": 2.084}, {"text": "And what I'm going\nto do is look for how", "start": 853.554, "duration": 1.666}, {"text": "do I find a rule that would\npredict the label associated", "start": 855.22, "duration": 3.18}, {"text": "with unseen input based\non those examples.", "start": 858.4, "duration": 3.21}, {"text": "It's supervised because I\nknow what the labeling is.", "start": 861.61, "duration": 3.4}, {"text": "Second kind, if\nthis is supervised,", "start": 865.01, "duration": 1.74}, {"text": "the obvious other one\nis called unsupervised.", "start": 866.75, "duration": 2.07}, {"text": "In that case, I'm just going to\ngive you a bunch of examples.", "start": 868.82, "duration": 3.39}, {"text": "But I don't know the labels\nassociated with them.", "start": 872.21, "duration": 2.34}, {"text": "I'm going to just\ntry and find what", "start": 874.55, "duration": 1.59}, {"text": "are the natural ways\nto group those examples", "start": 876.14, "duration": 2.88}, {"text": "together into different models.", "start": 879.02, "duration": 2.66}, {"text": "And in some cases, I may know\nhow many models are there.", "start": 881.68, "duration": 2.41}, {"text": "In some cases, I may\nwant to just say what's", "start": 884.09, "duration": 1.833}, {"text": "the best grouping I can find.", "start": 885.923, "duration": 2.847}, {"text": "OK.", "start": 888.77, "duration": 1.99}, {"text": "What I'm going to do today\nis not a lot of code.", "start": 890.76, "duration": 2.169}, {"text": "I was expecting cheers for that,\nJohn, but I didn't get them.", "start": 892.929, "duration": 2.541}, {"text": "Not a lot of code.", "start": 895.47, "duration": 1.77}, {"text": "What I'm going to do\nis show you basically,", "start": 897.24, "duration": 2.01}, {"text": "the intuitions behind\ndoing this learning.", "start": 899.25, "duration": 1.81}, {"text": "And I\"m going to start with my\nNew England Patriots example.", "start": 901.06, "duration": 2.5}, {"text": "So here are some data points\nabout current Patriots players.", "start": 903.56, "duration": 3.32}, {"text": "And I've got two\nkinds of positions.", "start": 906.88, "duration": 2.24}, {"text": "I've got receivers,\nand I have linemen.", "start": 909.12, "duration": 3.12}, {"text": "And each one is just labeled by\nthe name, the height in inches,", "start": 912.24, "duration": 2.85}, {"text": "and the weight in pounds.", "start": 915.09, "duration": 1.56}, {"text": "OK?", "start": 916.65, "duration": 1.05}, {"text": "Five of each.", "start": 917.7, "duration": 2.89}, {"text": "If I plot those on a\ntwo dimensional plot,", "start": 920.59, "duration": 3.78}, {"text": "this is what I get.", "start": 924.37, "duration": 1.89}, {"text": "OK?", "start": 926.26, "duration": 0.6}, {"text": "No big deal.", "start": 926.86, "duration": 2.46}, {"text": "What am I trying to do?", "start": 929.32, "duration": 1.17}, {"text": "I'm trying to learn, are\ntheir characteristics", "start": 930.49, "duration": 2.88}, {"text": "that distinguish the two\nclasses from one another?", "start": 933.37, "duration": 2.85}, {"text": "And in the unlabeled\ncase, all I have", "start": 936.22, "duration": 1.98}, {"text": "are just a set of examples.", "start": 938.2, "duration": 2.04}, {"text": "So what I want to\ndo is decide what", "start": 940.24, "duration": 1.98}, {"text": "makes two players similar\nwith the goal of seeing,", "start": 942.22, "duration": 4.02}, {"text": "can I separate this\ndistribution into two or more", "start": 946.24, "duration": 4.02}, {"text": "natural groups.", "start": 950.26, "duration": 2.17}, {"text": "Similar is a distance measure.", "start": 952.43, "duration": 1.69}, {"text": "It says how do I take\ntwo examples with values", "start": 954.12, "duration": 1.998}, {"text": "or features\nassociated, and we're", "start": 956.118, "duration": 1.375}, {"text": "going to decide how\nfar apart are they?", "start": 957.493, "duration": 2.007}, {"text": "And in the unlabeled case, the\nsimple way to do it is to say,", "start": 959.5, "duration": 4.27}, {"text": "if I know that there are\nat least k groups there--", "start": 963.77, "duration": 2.446}, {"text": "in this case, I'm going\nto tell you there are", "start": 966.216, "duration": 1.874}, {"text": "two different groups there--", "start": 968.09, "duration": 1.71}, {"text": "how could I decide how\nbest to cluster things", "start": 969.8, "duration": 3.03}, {"text": "together so that all the\nexamples in one group", "start": 972.83, "duration": 2.64}, {"text": "are close to each other, all\nthe examples in the other group", "start": 975.47, "duration": 2.94}, {"text": "are close to each other, and\nthey're reasonably far apart.", "start": 978.41, "duration": 3.78}, {"text": "There are many ways to do it.", "start": 982.19, "duration": 1.59}, {"text": "I'm going to show you one.", "start": 983.78, "duration": 1.48}, {"text": "It's a very standard way, and\nit works, basically, as follows.", "start": 985.26, "duration": 4.66}, {"text": "If all I know is that\nthere are two groups there,", "start": 989.92, "duration": 2.42}, {"text": "I'm going to start\nby just picking", "start": 992.34, "duration": 1.74}, {"text": "two examples as my exemplars.", "start": 994.08, "duration": 3.417}, {"text": "Pick them at random.", "start": 997.497, "duration": 0.833}, {"text": "Actually at random is not great.", "start": 998.33, "duration": 1.08}, {"text": "I don't want to pick too\nclosely to each other.", "start": 999.41, "duration": 1.41}, {"text": "I'm going to try and\npick them far apart.", "start": 1000.82, "duration": 1.708}, {"text": "But I pick two examples\nas my exemplars.", "start": 1002.528, "duration": 2.392}, {"text": "And for all the other\nexamples in the training data,", "start": 1004.92, "duration": 2.62}, {"text": "I say which one\nis it closest to.", "start": 1007.54, "duration": 3.322}, {"text": "What I'm going to try\nand do is create clusters", "start": 1010.862, "duration": 1.958}, {"text": "with the property\nthat the distances", "start": 1012.82, "duration": 1.77}, {"text": "between all of the examples\nof that cluster are small.", "start": 1014.59, "duration": 3.27}, {"text": "The average distance is small.", "start": 1017.86, "duration": 2.072}, {"text": "And see if I can\nfind clusters that", "start": 1019.932, "duration": 1.458}, {"text": "gets the average distance\nfor both clusters", "start": 1021.39, "duration": 1.86}, {"text": "as small as possible.", "start": 1023.25, "duration": 2.13}, {"text": "This algorithm works by\npicking two examples,", "start": 1025.38, "duration": 2.719}, {"text": "clustering all the other\nexamples by simply saying", "start": 1028.099, "duration": 2.191}, {"text": "put it in the group to which\nit's closest to that example.", "start": 1030.29, "duration": 5.19}, {"text": "Once I've got\nthose clusters, I'm", "start": 1035.48, "duration": 1.889}, {"text": "going to find the median\nelement of that group.", "start": 1037.369, "duration": 2.791}, {"text": "Not mean, but median, what's\nthe one closest to the center?", "start": 1040.16, "duration": 3.9}, {"text": "And treat those as exemplars\nand repeat the process.", "start": 1044.06, "duration": 3.997}, {"text": "And I'll just do it either\nsome number of times", "start": 1048.057, "duration": 1.958}, {"text": "or until I don't get any\nchange in the process.", "start": 1050.015, "duration": 3.555}, {"text": "So it's clustering\nbased on distance.", "start": 1053.57, "duration": 1.92}, {"text": "And we'll come back to\ndistance in a second.", "start": 1055.49, "duration": 3.244}, {"text": "So here's what would\nhave my football players.", "start": 1058.734, "duration": 1.916}, {"text": "If I just did this\nbased on weight,", "start": 1060.65, "duration": 3.12}, {"text": "there's the natural\ndividing line.", "start": 1063.77, "duration": 1.63}, {"text": "And it kind of makes sense.", "start": 1065.4, "duration": 1.465}, {"text": "All right?", "start": 1066.865, "duration": 0.635}, {"text": "These three are\nobviously clustered,", "start": 1067.5, "duration": 1.694}, {"text": "and again, it's\njust on this axis.", "start": 1069.194, "duration": 1.416}, {"text": "They're all down here.", "start": 1070.61, "duration": 1.38}, {"text": "These seven are at\na different place.", "start": 1071.99, "duration": 1.59}, {"text": "There's a natural\ndividing line there.", "start": 1073.58, "duration": 2.95}, {"text": "If I were to do it based\non height, not as clean.", "start": 1076.53, "duration": 5.26}, {"text": "This is what my\nalgorithm came up", "start": 1081.79, "duration": 1.62}, {"text": "with as the best\ndividing line here,", "start": 1083.41, "duration": 1.95}, {"text": "meaning that these four,\nagain, just based on this axis", "start": 1085.36, "duration": 3.78}, {"text": "are close together.", "start": 1089.14, "duration": 1.41}, {"text": "These six are close together.", "start": 1090.55, "duration": 1.62}, {"text": "But it's not nearly as clean.", "start": 1092.17, "duration": 1.73}, {"text": "And that's part of the\nissue we'll look at", "start": 1093.9, "duration": 1.75}, {"text": "is how do I find\nthe best clusters.", "start": 1095.65, "duration": 2.7}, {"text": "If I use both\nheight and weight, I", "start": 1098.35, "duration": 4.09}, {"text": "get that, which was actually\nkind of nice, right?", "start": 1102.44, "duration": 3.13}, {"text": "Those three cluster together.\nthey're near each other,", "start": 1105.57, "duration": 3.21}, {"text": "in terms of just\ndistance in the plane.", "start": 1108.78, "duration": 2.13}, {"text": "Those seven are near each other.", "start": 1110.91, "duration": 1.92}, {"text": "There's a nice, natural\ndividing line through here.", "start": 1112.83, "duration": 3.72}, {"text": "And in fact, that\ngives me a classifier.", "start": 1116.55, "duration": 3.69}, {"text": "This line is the\nequidistant line", "start": 1120.24, "duration": 3.12}, {"text": "between the centers\nof those two clusters.", "start": 1123.36, "duration": 2.1}, {"text": "Meaning, any point\nalong this line", "start": 1125.46, "duration": 2.19}, {"text": "is the same distance to\nthe center of that group", "start": 1127.65, "duration": 2.1}, {"text": "as it is to that group.", "start": 1129.75, "duration": 1.82}, {"text": "And so any new example,\nif it's above the line,", "start": 1131.57, "duration": 2.05}, {"text": "I would say gets that label,\nif it's below the line,", "start": 1133.62, "duration": 2.46}, {"text": "gets that label.", "start": 1136.08, "duration": 2.131}, {"text": "In a second, we'll\ncome back to look", "start": 1138.211, "duration": 1.499}, {"text": "at how do we measure\nthe distances,", "start": 1139.71, "duration": 1.458}, {"text": "but the idea here\nis pretty simple.", "start": 1141.168, "duration": 1.662}, {"text": "I want to find groupings\nnear each other", "start": 1142.83, "duration": 2.7}, {"text": "and far apart from\nthe other group.", "start": 1145.53, "duration": 3.58}, {"text": "Now suppose I actually knew\nthe labels on these players.", "start": 1149.11, "duration": 4.78}, {"text": "These are the receivers.", "start": 1156.79, "duration": 2.19}, {"text": "Those are the linemen.", "start": 1158.98, "duration": 2.08}, {"text": "And for those of you\nwho are football fans,", "start": 1161.06, "duration": 1.82}, {"text": "you can figure it out, right?", "start": 1162.88, "duration": 0.83}, {"text": "Those are the two tight ends.", "start": 1163.71, "duration": 1.208}, {"text": "They are much bigger.", "start": 1164.918, "duration": 1.209}, {"text": "I think that's Bennett and\nthat's Gronk if you're really", "start": 1166.127, "duration": 2.333}, {"text": "a big Patriots fan.", "start": 1168.46, "duration": 0.846}, {"text": "But those are tight ends,\nthose are wide receivers,", "start": 1169.306, "duration": 2.124}, {"text": "and it's going to\ncome back in a second,", "start": 1171.43, "duration": 1.666}, {"text": "but there are the labels.", "start": 1173.096, "duration": 1.304}, {"text": "Now what I want to do is say,\nif I could take advantage", "start": 1174.4, "duration": 2.43}, {"text": "of knowing the labels, how\nwould I divide these groups up?", "start": 1176.83, "duration": 3.45}, {"text": "And that's kind of easy to see.", "start": 1180.28, "duration": 2.49}, {"text": "Basic idea, in this\ncase, is if I've", "start": 1182.77, "duration": 2.1}, {"text": "got labeled groups\nin that feature", "start": 1184.87, "duration": 1.77}, {"text": "space, what I want to do is\nfind a subsurface that naturally", "start": 1186.64, "duration": 4.44}, {"text": "divides that space.", "start": 1191.08, "duration": 1.14}, {"text": "Now subsurface is a fancy word.", "start": 1192.22, "duration": 1.59}, {"text": "It says, in the\ntwo-dimensional case,", "start": 1193.81, "duration": 1.65}, {"text": "I want to know\nwhat's the best line,", "start": 1195.46, "duration": 2.82}, {"text": "if I can find a single line,\nthat separates all the examples", "start": 1198.28, "duration": 2.79}, {"text": "with one label from all the\nexamples of the second label.", "start": 1201.07, "duration": 3.75}, {"text": "We'll see that, if the\nexamples are well separated,", "start": 1204.82, "duration": 2.74}, {"text": "this is easy to\ndo, and it's great.", "start": 1207.56, "duration": 2.33}, {"text": "But in some cases,\nit's going to be", "start": 1209.89, "duration": 1.71}, {"text": "more complicated because\nsome of the examples", "start": 1211.6, "duration": 2.19}, {"text": "may be very close\nto one another.", "start": 1213.79, "duration": 2.082}, {"text": "And that's going\nto raise a problem", "start": 1215.872, "duration": 1.458}, {"text": "that you saw last lecture.", "start": 1217.33, "duration": 1.71}, {"text": "I want to avoid overfitting.", "start": 1219.04, "duration": 1.86}, {"text": "I don't want to create a\nreally complicated surface", "start": 1220.9, "duration": 2.61}, {"text": "to separate things.", "start": 1223.51, "duration": 1.36}, {"text": "And so we may have to\ntolerate a few incorrectly", "start": 1224.87, "duration": 2.69}, {"text": "labeled things, if\nwe can't pull it out.", "start": 1227.56, "duration": 3.156}, {"text": "And as you already\nfigured out, in this case,", "start": 1230.716, "duration": 1.874}, {"text": "with the labeled data,\nthere's the best fitting line", "start": 1232.59, "duration": 2.43}, {"text": "right there.", "start": 1235.02, "duration": 1.44}, {"text": "Anybody over 280 pounds is\ngoing to be a great lineman.", "start": 1236.46, "duration": 3.63}, {"text": "Anybody under 280 pounds is\nmore likely to be a receiver.", "start": 1240.09, "duration": 5.16}, {"text": "OK.", "start": 1245.25, "duration": 0.539}, {"text": "So I've got two different\nways of trying to think", "start": 1245.789, "duration": 2.041}, {"text": "about doing this labeling.", "start": 1247.83, "duration": 1.083}, {"text": "I'm going to come back to\nboth of them in a second.", "start": 1248.913, "duration": 3.247}, {"text": "Now suppose I add\nin some new data.", "start": 1252.16, "duration": 3.33}, {"text": "I want to label new instances.", "start": 1255.49, "duration": 2.389}, {"text": "Now these are actually players\nof a different position.", "start": 1257.879, "duration": 2.291}, {"text": "These are running backs.", "start": 1260.17, "duration": 1.06}, {"text": "But I say, all I know about\nis receivers and linemen.", "start": 1261.23, "duration": 3.3}, {"text": "I get these two new data points.", "start": 1264.53, "duration": 1.98}, {"text": "I'd like to know, are\nthey more likely to be", "start": 1266.51, "duration": 2.1}, {"text": "a receiver or a linemen?", "start": 1268.61, "duration": 2.82}, {"text": "And there's the data\nfor these two gentlemen.", "start": 1271.43, "duration": 2.7}, {"text": "So if I go back to\nnow plotting them,", "start": 1274.13, "duration": 3.51}, {"text": "oh you notice one of the issues.", "start": 1277.64, "duration": 1.57}, {"text": "So there are my linemen, the\nred ones are my receivers,", "start": 1279.21, "duration": 2.9}, {"text": "the two black dots are\nthe two running backs.", "start": 1282.11, "duration": 3.75}, {"text": "And notice right here.", "start": 1285.86, "duration": 2.64}, {"text": "It's going to be really\nhard to separate those two", "start": 1288.5, "duration": 3.05}, {"text": "examples from one another.", "start": 1291.55, "duration": 1.157}, {"text": "They are so close to each other.", "start": 1292.707, "duration": 1.333}, {"text": "And that's going to\nbe one of the things", "start": 1294.04, "duration": 1.666}, {"text": "we have to trade off.", "start": 1295.706, "duration": 1.334}, {"text": "But if I think about using\nwhat I learned as a classifier", "start": 1297.04, "duration": 4.2}, {"text": "with unlabeled data, there\nwere my two clusters.", "start": 1301.24, "duration": 4.79}, {"text": "Now you see, oh, I've got\nan interesting example.", "start": 1306.03, "duration": 2.39}, {"text": "This new example I would\nsay is clearly more", "start": 1308.42, "duration": 3.27}, {"text": "like a receiver than a lineman.", "start": 1311.69, "duration": 2.55}, {"text": "But that one there, unclear.", "start": 1314.24, "duration": 3.42}, {"text": "Almost exactly lies\nalong that dividing line", "start": 1317.66, "duration": 2.52}, {"text": "between those two clusters.", "start": 1320.18, "duration": 2.13}, {"text": "And I would either say, I\nwant to rethink the clustering", "start": 1322.31, "duration": 2.55}, {"text": "or I want to say, you know what?", "start": 1324.86, "duration": 1.75}, {"text": "As I know, maybe there\naren't two clusters here.", "start": 1326.61, "duration": 2.66}, {"text": "Maybe there are three.", "start": 1329.27, "duration": 1.29}, {"text": "And I want to classify\nthem a little differently.", "start": 1330.56, "duration": 2.71}, {"text": "So I'll come back to that.", "start": 1333.27, "duration": 2.3}, {"text": "On the other hand, if I\nhad used the labeled data,", "start": 1335.57, "duration": 2.97}, {"text": "there was my dividing line.", "start": 1338.54, "duration": 1.8}, {"text": "This is really easy.", "start": 1340.34, "duration": 1.62}, {"text": "Both of those new\nexamples are clearly", "start": 1341.96, "duration": 2.19}, {"text": "below the dividing line.", "start": 1344.15, "duration": 1.17}, {"text": "They are clearly\nexamples that I would", "start": 1345.32, "duration": 1.92}, {"text": "categorize as being\nmore like receivers", "start": 1347.24, "duration": 2.67}, {"text": "than they are like linemen.", "start": 1349.91, "duration": 2.47}, {"text": "And I know it's a\nfootball example.", "start": 1352.38, "duration": 1.5}, {"text": "If you don't like football,\npick another example.", "start": 1353.88, "duration": 2.25}, {"text": "But you get the\nsense of why I can", "start": 1356.13, "duration": 1.95}, {"text": "use the data in a labeled\ncase and the unlabeled case", "start": 1358.08, "duration": 3.42}, {"text": "to come up with different\nways of building the clusters.", "start": 1361.5, "duration": 4.272}, {"text": "So what we're going\nto do over the next 2", "start": 1365.772, "duration": 1.708}, {"text": "and 1/2 lectures is\nlook at how can we", "start": 1367.48, "duration": 2.71}, {"text": "write code to learn that way\nof separating things out?", "start": 1370.19, "duration": 4.36}, {"text": "We're going to learn models\nbased on unlabeled data.", "start": 1374.55, "duration": 2.509}, {"text": "That's the case where I don't\nknow what the labels are,", "start": 1377.059, "duration": 2.291}, {"text": "by simply trying to find ways\nto cluster things together", "start": 1379.35, "duration": 3.54}, {"text": "nearby, and then use the\nclusters to assign labels", "start": 1382.89, "duration": 2.94}, {"text": "to new data.", "start": 1385.83, "duration": 1.19}, {"text": "And we're going to learn models\nby looking at labeled data", "start": 1387.02, "duration": 2.8}, {"text": "and seeing how do we best come\nup with a way of separating", "start": 1389.82, "duration": 3.69}, {"text": "with a line or a plane or a\ncollection of lines, examples", "start": 1393.51, "duration": 3.72}, {"text": "from one group, from\nexamples of the other group.", "start": 1397.23, "duration": 3.09}, {"text": "With the acknowledgment that\nwe want to avoid overfitting,", "start": 1400.32, "duration": 3.144}, {"text": "we don't want to create a\nreally complicated system.", "start": 1403.464, "duration": 2.166}, {"text": "And as a consequence,\nwe're going", "start": 1405.63, "duration": 1.497}, {"text": "to have to make some\ntrade-offs between what", "start": 1407.127, "duration": 1.833}, {"text": "we call false positives\nand false negatives.", "start": 1408.96, "duration": 3.24}, {"text": "But the resulting classifier\ncan then label any new data", "start": 1412.2, "duration": 2.58}, {"text": "by just deciding where\nyou are with respect", "start": 1414.78, "duration": 1.95}, {"text": "to that separating line.", "start": 1416.73, "duration": 1.0}, {"text": "So here's what you're going\nto see over the next 2", "start": 1420.36, "duration": 2.66}, {"text": "and 1/2 lectures.", "start": 1423.02, "duration": 1.91}, {"text": "Every machine learning method\nhas five essential components.", "start": 1424.93, "duration": 4.58}, {"text": "We need to decide what's\nthe training data,", "start": 1429.51, "duration": 1.8}, {"text": "and how are we going to evaluate\nthe success of that system.", "start": 1431.31, "duration": 3.06}, {"text": "We've already seen\nsome examples of that.", "start": 1434.37, "duration": 2.53}, {"text": "We need to decide\nhow are we going", "start": 1436.9, "duration": 1.7}, {"text": "to represent each instance\nthat we're giving it.", "start": 1438.6, "duration": 3.96}, {"text": "I happened to choose height and\nweight for football players.", "start": 1442.56, "duration": 2.63}, {"text": "But I might have been better\noff to pick average speed", "start": 1445.19, "duration": 3.01}, {"text": "or, I don't know, arm\nlength, something else.", "start": 1448.2, "duration": 2.01}, {"text": "How do I figure out what\nare the right features.", "start": 1450.21, "duration": 2.46}, {"text": "And associated with that,\nhow do I measure distances", "start": 1452.67, "duration": 3.15}, {"text": "between those features?", "start": 1455.82, "duration": 1.5}, {"text": "How do I decide what's\nclose and what's not close?", "start": 1457.32, "duration": 2.776}, {"text": "Maybe it should be different, in\nterms of weight versus height,", "start": 1460.096, "duration": 2.624}, {"text": "for example.", "start": 1462.72, "duration": 0.57}, {"text": "I need to make that decision.", "start": 1463.29, "duration": 1.444}, {"text": "And those are the\ntwo things we're", "start": 1464.734, "duration": 1.416}, {"text": "going to show you examples of\ntoday, how to go through that.", "start": 1466.15, "duration": 3.88}, {"text": "Starting next week,\nProfessor Guttag", "start": 1470.03, "duration": 1.5}, {"text": "is going to show you how you\ntake those and actually start", "start": 1471.53, "duration": 2.9}, {"text": "building more detailed versions\nof measuring clustering,", "start": 1474.43, "duration": 3.83}, {"text": "measuring similarities to find\nan objective function that you", "start": 1478.26, "duration": 3.3}, {"text": "want to minimize to decide what\nis the best cluster to use.", "start": 1481.56, "duration": 3.27}, {"text": "And then what is the best\noptimization method you want", "start": 1484.83, "duration": 2.4}, {"text": "to use to learn that model.", "start": 1487.23, "duration": 3.12}, {"text": "So let's start talking\nabout features.", "start": 1490.35, "duration": 3.73}, {"text": "I've got a set of\nexamples, labeled or not.", "start": 1494.08, "duration": 2.88}, {"text": "I need to decide what is it\nabout those examples that's", "start": 1496.96, "duration": 2.49}, {"text": "useful to use when I\nwant to decide what's", "start": 1499.45, "duration": 3.21}, {"text": "close to another thing or not.", "start": 1502.66, "duration": 2.69}, {"text": "And one of the problems\nis, if it was really easy,", "start": 1505.35, "duration": 2.12}, {"text": "it would be really easy.", "start": 1507.47, "duration": 2.13}, {"text": "Features don't always\ncapture what you want.", "start": 1509.6, "duration": 2.91}, {"text": "I'm going to belabor\nthat football analogy,", "start": 1512.51, "duration": 1.98}, {"text": "but why did I pick\nheight and weight.", "start": 1514.49, "duration": 1.56}, {"text": "Because it was easy to find.", "start": 1516.05, "duration": 2.257}, {"text": "You know, if you work for the\nNew England Patriots, what", "start": 1518.307, "duration": 2.333}, {"text": "is the thing that you really\nlook for when you're asking,", "start": 1520.64, "duration": 2.26}, {"text": "what's the right feature?", "start": 1522.9, "duration": 0.76}, {"text": "It's probably some other\ncombination of things.", "start": 1523.66, "duration": 2.0}, {"text": "So you, as a designer,\nhave to say what", "start": 1525.66, "duration": 2.15}, {"text": "are the features I want to use.", "start": 1527.81, "duration": 2.142}, {"text": "That quote, by the\nway, is from one", "start": 1529.952, "duration": 1.458}, {"text": "of the great statisticians\nof the 20th century, which", "start": 1531.41, "duration": 2.208}, {"text": "I think captures it well.", "start": 1533.618, "duration": 2.022}, {"text": "So feature engineering,\nas you, as a programmer,", "start": 1535.64, "duration": 3.99}, {"text": "comes down to deciding\nboth what are the features", "start": 1539.63, "duration": 2.4}, {"text": "I want to measure in that vector\nthat I'm going to put together,", "start": 1542.03, "duration": 3.45}, {"text": "and how do I decide\nrelative ways to weight it?", "start": 1545.48, "duration": 3.86}, {"text": "So John, and Ana, and I\ncould have made our job", "start": 1549.34, "duration": 6.18}, {"text": "this term really easy\nif we had sat down", "start": 1555.52, "duration": 2.38}, {"text": "at the beginning of the\nterm and said, you know,", "start": 1557.9, "duration": 2.0}, {"text": "we've taught this\ncourse many times.", "start": 1559.9, "duration": 1.37}, {"text": "We've got data\nfrom, I don't know,", "start": 1561.27, "duration": 1.416}, {"text": "John, thousands of students,\nprobably over this time.", "start": 1562.686, "duration": 2.964}, {"text": "Let's just build a\nlittle learning algorithm", "start": 1565.65, "duration": 1.99}, {"text": "that takes a set of data and\npredicts your final grade.", "start": 1567.64, "duration": 3.487}, {"text": "You don't have to\ncome to class, don't", "start": 1571.127, "duration": 1.583}, {"text": "have to go through\nall the problems,", "start": 1572.71, "duration": 0.96}, {"text": "because we'll just\npredict your final grade.", "start": 1573.67, "duration": 1.77}, {"text": "Wouldn't that be nice?", "start": 1575.44, "duration": 0.916}, {"text": "Make our job a little easier,\nand you may or may not", "start": 1576.356, "duration": 2.594}, {"text": "like that idea.", "start": 1578.95, "duration": 1.98}, {"text": "But I could think about\npredicting that grade?", "start": 1580.93, "duration": 2.274}, {"text": "Now why am I telling\nthis example.", "start": 1583.204, "duration": 1.416}, {"text": "I was trying to see if I\ncould get a few smiles.", "start": 1584.62, "duration": 2.0}, {"text": "I saw a couple of them there.", "start": 1586.62, "duration": 2.13}, {"text": "But think about the features.", "start": 1588.75, "duration": 2.03}, {"text": "What I measure?", "start": 1590.78, "duration": 1.181}, {"text": "Actually, I'll put this on\nJohn because it's his idea.", "start": 1591.961, "duration": 2.249}, {"text": "What would he measure?", "start": 1594.21, "duration": 1.72}, {"text": "Well, GPA is probably not a\nbad predictor of performance.", "start": 1595.93, "duration": 5.16}, {"text": "You do well in other\nclasses, you're", "start": 1601.09, "duration": 1.56}, {"text": "likely to do well in this class.", "start": 1602.65, "duration": 2.49}, {"text": "I'm going to use this\none very carefully.", "start": 1605.14, "duration": 1.86}, {"text": "Prior programming experience\nis at least a predictor,", "start": 1607.0, "duration": 3.84}, {"text": "but it is not a\nperfect predictor.", "start": 1610.84, "duration": 2.709}, {"text": "Those of you who haven't\nprogrammed before,", "start": 1613.549, "duration": 1.791}, {"text": "in this class, you can still\ndo really well in this class.", "start": 1615.34, "duration": 1.98}, {"text": "But it's an indication that\nyou've seen other programming", "start": 1617.32, "duration": 2.375}, {"text": "languages.", "start": 1619.695, "duration": 1.885}, {"text": "On the other hand, I don't\nbelieve in astrology.", "start": 1621.58, "duration": 2.67}, {"text": "So I don't think the month\nin which you're born,", "start": 1624.25, "duration": 2.64}, {"text": "the astrological sign\nunder which you were born", "start": 1626.89, "duration": 2.58}, {"text": "has probably anything to do\nwith how well you'd program.", "start": 1629.47, "duration": 3.03}, {"text": "I doubt that eye color\nhas anything to do", "start": 1632.5, "duration": 1.804}, {"text": "with how well you'd program.", "start": 1634.304, "duration": 1.166}, {"text": "You get the idea.", "start": 1635.47, "duration": 0.708}, {"text": "Some features\nmatter, others don't.", "start": 1636.178, "duration": 3.552}, {"text": "Now I could just throw all\nthe features in and hope that", "start": 1639.73, "duration": 3.3}, {"text": "the machine learning algorithm\nsorts out those it wants", "start": 1643.03, "duration": 2.58}, {"text": "to keep from those it doesn't.", "start": 1645.61, "duration": 2.31}, {"text": "But I remind you of that\nidea of overfitting.", "start": 1647.92, "duration": 2.64}, {"text": "If I do that,\nthere is the danger", "start": 1650.56, "duration": 2.01}, {"text": "that it will find some\ncorrelation between birth", "start": 1652.57, "duration": 3.33}, {"text": "month, eye color, and GPA.", "start": 1655.9, "duration": 3.3}, {"text": "And that's going to\nlead to a conclusion", "start": 1659.2, "duration": 1.83}, {"text": "that we really don't like.", "start": 1661.03, "duration": 2.132}, {"text": "By the way, in case\nyou're worried,", "start": 1663.162, "duration": 1.458}, {"text": "I can assure you\nthat Stu Schmill", "start": 1664.62, "duration": 1.44}, {"text": "in the dean of\nadmissions department", "start": 1666.06, "duration": 1.8}, {"text": "does not use machine\nlearning to pick you.", "start": 1667.86, "duration": 2.577}, {"text": "He actually looks at a\nwhole bunch of things", "start": 1670.437, "duration": 1.833}, {"text": "because it's not easy to\nreplace him with a machine--", "start": 1672.27, "duration": 2.91}, {"text": "yet.", "start": 1675.18, "duration": 1.585}, {"text": "All right.", "start": 1676.765, "duration": 0.605}, {"text": "So what this says is\nwe need to think about", "start": 1677.37, "duration": 2.644}, {"text": "how do we pick the features.", "start": 1680.014, "duration": 1.166}, {"text": "And mostly, what\nwe're trying to do", "start": 1681.18, "duration": 1.458}, {"text": "is to maximize something called\nthe signal to noise ratio.", "start": 1682.638, "duration": 3.192}, {"text": "Maximize those features that\ncarry the most information,", "start": 1685.83, "duration": 3.84}, {"text": "and remove the ones that don't.", "start": 1689.67, "duration": 2.91}, {"text": "So I want to show\nyou an example of how", "start": 1692.58, "duration": 1.83}, {"text": "you might think about this.", "start": 1694.41, "duration": 3.12}, {"text": "I want to label reptiles.", "start": 1697.53, "duration": 2.435}, {"text": "I want to come up with a\nway of labeling animals as,", "start": 1699.965, "duration": 2.895}, {"text": "are they a reptile or not.", "start": 1702.86, "duration": 2.207}, {"text": "And I give you a single example.", "start": 1705.067, "duration": 1.333}, {"text": "With a single example,\nyou can't really do much.", "start": 1706.4, "duration": 2.16}, {"text": "But from this example, I know\nthat a cobra, it lays eggs,", "start": 1708.56, "duration": 4.2}, {"text": "it has scales, it's\npoisonous, it's cold blooded,", "start": 1712.76, "duration": 2.37}, {"text": "it has no legs,\nand it's a reptile.", "start": 1715.13, "duration": 2.07}, {"text": "So I could say my model\nof a reptile is well,", "start": 1717.2, "duration": 2.634}, {"text": "I'm not certain.", "start": 1719.834, "duration": 0.666}, {"text": "I don't have enough data yet.", "start": 1720.5, "duration": 2.49}, {"text": "But if I give you\na second example,", "start": 1722.99, "duration": 2.34}, {"text": "and it also happens\nto be egg-laying,", "start": 1725.33, "duration": 1.74}, {"text": "have scales, poisonous,\ncold blooded, no legs.", "start": 1727.07, "duration": 2.67}, {"text": "There is my model, right?", "start": 1729.74, "duration": 1.98}, {"text": "Perfectly reasonable\nmodel, whether I design it", "start": 1731.72, "duration": 2.239}, {"text": "or a machine learning\nalgorithm would", "start": 1733.959, "duration": 1.541}, {"text": "do it says, if all of these are\ntrue, label it as a reptile.", "start": 1735.5, "duration": 4.71}, {"text": "OK?", "start": 1740.21, "duration": 1.9}, {"text": "And now I give you\na boa constrictor.", "start": 1742.11, "duration": 3.256}, {"text": "Ah.", "start": 1745.366, "duration": 1.894}, {"text": "It's a reptile.", "start": 1747.26, "duration": 1.53}, {"text": "But it doesn't fit the model.", "start": 1748.79, "duration": 2.33}, {"text": "And in particular,\nit's not egg-laying,", "start": 1751.12, "duration": 3.64}, {"text": "and it's not poisonous.", "start": 1754.76, "duration": 2.147}, {"text": "So I've got to refine the model.", "start": 1756.907, "duration": 1.333}, {"text": "Or the algorithm has\ngot to refine the model.", "start": 1758.24, "duration": 1.75}, {"text": "And this, I want to remind you,\nis looking at the features.", "start": 1759.99, "duration": 1.97}, {"text": "So I started out\nwith five features.", "start": 1761.96, "duration": 1.95}, {"text": "This doesn't fit.", "start": 1763.91, "duration": 1.96}, {"text": "So probably what I\nshould do is reduce it.", "start": 1765.87, "duration": 2.86}, {"text": "I'm going to look at scales.", "start": 1768.73, "duration": 1.24}, {"text": "I'm going to look\nat cold blooded.", "start": 1769.97, "duration": 1.416}, {"text": "I'm going to look at legs.", "start": 1771.386, "duration": 1.404}, {"text": "That captures all\nthree examples.", "start": 1772.79, "duration": 1.621}, {"text": "Again, if you think about\nthis in terms of clustering,", "start": 1774.411, "duration": 2.249}, {"text": "all three of them\nwould fit with that.", "start": 1776.66, "duration": 2.961}, {"text": "OK.", "start": 1779.621, "duration": 0.499}, {"text": "Now I give you another example--", "start": 1780.12, "duration": 2.56}, {"text": "chicken.", "start": 1782.68, "duration": 1.39}, {"text": "I don't think it's a reptile.", "start": 1784.07, "duration": 1.465}, {"text": "In fact, I'm pretty\nsure it's not a reptile.", "start": 1785.535, "duration": 3.065}, {"text": "And it nicely still\nfits this model, right?", "start": 1788.6, "duration": 4.75}, {"text": "Because, while it has scales,\nwhich you may or not realize,", "start": 1793.35, "duration": 2.96}, {"text": "it's not cold blooded,\nand it has legs.", "start": 1796.31, "duration": 2.19}, {"text": "So it is a negative example\nthat reinforces the model.", "start": 1798.5, "duration": 3.88}, {"text": "Sounds good.", "start": 1802.38, "duration": 2.264}, {"text": "And now I'll give\nyou an alligator.", "start": 1804.644, "duration": 3.096}, {"text": "It's a reptile.", "start": 1807.74, "duration": 1.98}, {"text": "And oh fudge, right?", "start": 1809.72, "duration": 1.74}, {"text": "It doesn't satisfy the model.", "start": 1811.46, "duration": 2.91}, {"text": "Because while it does have\nscales and it is cold blooded,", "start": 1814.37, "duration": 4.8}, {"text": "it has legs.", "start": 1819.17, "duration": 1.985}, {"text": "I'm almost done\nwith the example.", "start": 1821.155, "duration": 1.375}, {"text": "But you see the point.", "start": 1822.53, "duration": 0.916}, {"text": "Again, I've got to think\nabout how do I refine this.", "start": 1823.446, "duration": 2.204}, {"text": "And I could by\nsaying, all right.", "start": 1825.65, "duration": 2.85}, {"text": "Let's make it a little more\ncomplicated-- has scales,", "start": 1828.5, "duration": 2.43}, {"text": "cold blooded, 0 or four legs--", "start": 1830.93, "duration": 1.857}, {"text": "I'm going to say it's a reptile.", "start": 1832.787, "duration": 1.333}, {"text": "I'll give you the dart frog.", "start": 1836.67, "duration": 2.19}, {"text": "Not a reptile,\nit's an amphibian.", "start": 1838.86, "duration": 1.92}, {"text": "And that's nice because\nit still satisfies this.", "start": 1840.78, "duration": 2.22}, {"text": "So it's an example outside\nof the cluster that", "start": 1843.0, "duration": 2.73}, {"text": "says no scales,\nnot cold blooded,", "start": 1845.73, "duration": 4.481}, {"text": "but happens to have four legs.", "start": 1850.211, "duration": 1.249}, {"text": "It's not a reptile.", "start": 1851.46, "duration": 0.791}, {"text": "That's good.", "start": 1852.251, "duration": 1.529}, {"text": "And then I give you--", "start": 1853.78, "duration": 1.332}, {"text": "I have to give you\na python, right?", "start": 1855.112, "duration": 1.458}, {"text": "I mean, there has to\nbe a python in here.", "start": 1856.57, "duration": 2.361}, {"text": "Oh come on.", "start": 1858.931, "duration": 0.499}, {"text": "At least grown at\nme when I say that.", "start": 1859.43, "duration": 1.7}, {"text": "There has to be a python here.", "start": 1861.13, "duration": 1.86}, {"text": "And I give you\nthat and a salmon.", "start": 1862.99, "duration": 2.48}, {"text": "And now I am in trouble.", "start": 1865.47, "duration": 3.15}, {"text": "Because look at scales, look\nat cold blooded, look at legs.", "start": 1868.62, "duration": 6.19}, {"text": "I can't separate them.", "start": 1874.81, "duration": 1.8}, {"text": "On those features,\nthere's no way", "start": 1876.61, "duration": 1.62}, {"text": "to come up with a way\nthat will correctly", "start": 1878.23, "duration": 2.28}, {"text": "say that the python is a\nreptile and the salmon is not.", "start": 1880.51, "duration": 4.066}, {"text": "And so there's no easy\nway to add in that rule.", "start": 1884.576, "duration": 3.794}, {"text": "And probably my best\nthing is to simply go back", "start": 1888.37, "duration": 2.19}, {"text": "to just two features,\nscales and cold blooded.", "start": 1890.56, "duration": 3.93}, {"text": "And basically say,\nif something has", "start": 1894.49, "duration": 1.47}, {"text": "scales and it's cold blooded,\nI'm going to call it a reptile.", "start": 1895.96, "duration": 2.826}, {"text": "If it doesn't have\nboth of those,", "start": 1898.786, "duration": 1.374}, {"text": "I'm going to say\nit's not a reptile.", "start": 1900.16, "duration": 2.01}, {"text": "It won't be perfect.", "start": 1902.17, "duration": 1.839}, {"text": "It's going to incorrectly\nlabel the salmon.", "start": 1904.009, "duration": 1.791}, {"text": "But I've made a design\nchoice here that's important.", "start": 1905.8, "duration": 3.51}, {"text": "And the design choice is that\nI will have no false negatives.", "start": 1909.31, "duration": 4.92}, {"text": "What that means is\nthere's not going", "start": 1914.23, "duration": 1.5}, {"text": "to be any instance of something\nthat's not a reptile that I'm", "start": 1915.73, "duration": 3.51}, {"text": "going to call a reptile.", "start": 1919.24, "duration": 2.14}, {"text": "I may have some false positives.", "start": 1921.38, "duration": 2.734}, {"text": "So I did that the wrong way.", "start": 1924.114, "duration": 1.166}, {"text": "A false negative\nsays, everything", "start": 1925.28, "duration": 1.44}, {"text": "that's not a reptile I'm going\nto categorize that direction.", "start": 1926.72, "duration": 3.3}, {"text": "I may have some false\npositives, in that,", "start": 1930.02, "duration": 1.74}, {"text": "I may have a few things\nthat I will incorrectly", "start": 1931.76, "duration": 2.16}, {"text": "label as a reptile.", "start": 1933.92, "duration": 1.77}, {"text": "And in particular,\nsalmon is going", "start": 1935.69, "duration": 2.01}, {"text": "to be an instance of that.", "start": 1937.7, "duration": 1.92}, {"text": "This trade off of false\npositives and false negatives", "start": 1939.62, "duration": 2.479}, {"text": "is something that we worry\nabout, as we think about it.", "start": 1942.099, "duration": 2.291}, {"text": "Because there's no perfect\nway, in many cases,", "start": 1944.39, "duration": 2.3}, {"text": "to separate out the data.", "start": 1946.69, "duration": 1.701}, {"text": "And if you think back to my\nexample of the New England", "start": 1948.391, "duration": 2.249}, {"text": "Patriots, that running back\nand that wide receiver were", "start": 1950.64, "duration": 3.236}, {"text": "so close together in\nheight and weight,", "start": 1953.876, "duration": 1.624}, {"text": "there was no way I'm going to\nbe able to separate them apart.", "start": 1955.5, "duration": 2.756}, {"text": "And I just have to\nbe willing to decide", "start": 1958.256, "duration": 1.624}, {"text": "how many false positives\nor false negatives", "start": 1959.88, "duration": 2.44}, {"text": "do I want to tolerate.", "start": 1962.32, "duration": 3.05}, {"text": "Once I've figured out what\nfeatures to use, which is good,", "start": 1965.37, "duration": 4.61}, {"text": "then I have to decide\nabout distance.", "start": 1969.98, "duration": 2.23}, {"text": "How do I compare\ntwo feature vectors?", "start": 1972.21, "duration": 1.75}, {"text": "I'm going to say vector\nbecause there could", "start": 1973.96, "duration": 1.0}, {"text": "be multiple dimensions to it.", "start": 1974.96, "duration": 1.68}, {"text": "How do I decide how\nto compare them?", "start": 1976.64, "duration": 1.62}, {"text": "Because I want to use the\ndistances to figure out either", "start": 1978.26, "duration": 3.09}, {"text": "how to group things together\nor how to find a dividing line", "start": 1981.35, "duration": 2.61}, {"text": "that separates things apart.", "start": 1983.96, "duration": 1.98}, {"text": "So one of the things I have\nto decide is which features.", "start": 1985.94, "duration": 3.53}, {"text": "I also have to\ndecide the distance.", "start": 1989.47, "duration": 1.5}, {"text": "And finally, I\nmay want to decide", "start": 1990.97, "duration": 1.74}, {"text": "how to weigh relative importance\nof different dimensions", "start": 1992.71, "duration": 3.95}, {"text": "in the feature vector.", "start": 1996.66, "duration": 1.33}, {"text": "Some may be more valuable than\nothers in making that decision.", "start": 1997.99, "duration": 3.41}, {"text": "And I want to show you\nan example of that.", "start": 2001.4, "duration": 3.17}, {"text": "So let's go back to my animals.", "start": 2004.57, "duration": 3.339}, {"text": "I started off with a\nfeature vector that actually", "start": 2007.909, "duration": 2.041}, {"text": "had five dimensions to it.", "start": 2009.95, "duration": 1.44}, {"text": "It was egg-laying, cold\nblooded, has scales,", "start": 2011.39, "duration": 4.915}, {"text": "I forget what the other one\nwas, and number of legs.", "start": 2016.305, "duration": 3.395}, {"text": "So one of the ways I\ncould think about this", "start": 2019.7, "duration": 1.86}, {"text": "is saying I've got four binary\nfeatures and one integer", "start": 2021.56, "duration": 4.62}, {"text": "feature associated\nwith each animal.", "start": 2026.18, "duration": 2.73}, {"text": "And one way to learn to separate\nout reptiles from non reptiles", "start": 2028.91, "duration": 3.09}, {"text": "is to measure the distance\nbetween pairs of examples", "start": 2032.0, "duration": 4.591}, {"text": "and use that distance to\ndecide what's near each other", "start": 2036.591, "duration": 2.249}, {"text": "and what's not.", "start": 2038.84, "duration": 0.824}, {"text": "And as we've said\nbefore, it will either", "start": 2039.664, "duration": 1.666}, {"text": "be used to cluster things or to\nfind a classifier surface that", "start": 2041.33, "duration": 2.88}, {"text": "separates them.", "start": 2044.21, "duration": 2.41}, {"text": "So here's a simple way to do it.", "start": 2046.62, "duration": 2.45}, {"text": "For each of these examples,\nI'm going to just let true", "start": 2049.07, "duration": 2.4}, {"text": "be 1, false be 0.", "start": 2051.47, "duration": 1.59}, {"text": "So the first four\nare either 0s or 1s.", "start": 2053.06, "duration": 2.25}, {"text": "And the last one is\nthe number of legs.", "start": 2055.31, "duration": 2.399}, {"text": "And now I could say, all right.", "start": 2057.709, "duration": 1.291}, {"text": "How do I measure\ndistances between animals", "start": 2059.0, "duration": 3.54}, {"text": "or anything else, but these\nkinds of feature vectors?", "start": 2062.54, "duration": 3.344}, {"text": "Here, we're going\nto use something", "start": 2065.884, "duration": 1.416}, {"text": "called the Minkowski Metric\nor the Minkowski difference.", "start": 2067.3, "duration": 3.45}, {"text": "Given two vectors\nand a power, p,", "start": 2070.75, "duration": 3.33}, {"text": "we basically take\nthe absolute value", "start": 2074.08, "duration": 2.22}, {"text": "of the difference between\neach of the components", "start": 2076.3, "duration": 2.129}, {"text": "of the vector, raise it to\nthe p-th power, take the sum,", "start": 2078.429, "duration": 5.54}, {"text": "and take the p-th route of that.", "start": 2083.969, "duration": 2.871}, {"text": "So let's do the two\nobvious examples.", "start": 2086.84, "duration": 1.62}, {"text": "If p is equal to 1, I just\nmeasure the absolute distance", "start": 2088.46, "duration": 3.239}, {"text": "between each component, add\nthem up, and that's my distance.", "start": 2091.699, "duration": 4.77}, {"text": "It's called the\nManhattan metric.", "start": 2096.469, "duration": 2.246}, {"text": "The one you've seen more,\nthe one we saw last time,", "start": 2098.715, "duration": 2.125}, {"text": "if p is equal to 2, this is\nEuclidean distance, right?", "start": 2100.84, "duration": 3.06}, {"text": "It's the sum of the\nsquares of the differences", "start": 2103.9, "duration": 2.09}, {"text": "of the components.", "start": 2105.99, "duration": 1.06}, {"text": "Take the square root.", "start": 2107.05, "duration": 1.099}, {"text": "Take the square root\nbecause it makes", "start": 2108.149, "duration": 1.541}, {"text": "it have certain\nproperties of a distance.", "start": 2109.69, "duration": 2.73}, {"text": "That's the Euclidean distance.", "start": 2112.42, "duration": 4.12}, {"text": "So now if I want to measure\ndifference between these two,", "start": 2116.54, "duration": 3.7}, {"text": "here's the question.", "start": 2120.24, "duration": 2.51}, {"text": "Is this circle closer to the\nstar or closer to the cross?", "start": 2122.75, "duration": 5.03}, {"text": "Unfortunately, I put\nthe answer up here.", "start": 2127.78, "duration": 2.53}, {"text": "But it differs, depending\non the metric I use.", "start": 2130.31, "duration": 2.95}, {"text": "Right?", "start": 2133.26, "duration": 0.5}, {"text": "Euclidean distance, well,\nthat's square root of 2 times 2,", "start": 2133.76, "duration": 3.24}, {"text": "so it's about 2.8.", "start": 2137.0, "duration": 1.692}, {"text": "And that's three.", "start": 2138.692, "duration": 0.708}, {"text": "So in terms of just standard\ndistance in the plane,", "start": 2139.4, "duration": 3.18}, {"text": "we would say that these two\nare closer than those two are.", "start": 2142.58, "duration": 4.1}, {"text": "Manhattan distance,\nwhy is it called that?", "start": 2146.68, "duration": 1.75}, {"text": "Because you can only walk along\nthe avenues and the streets.", "start": 2148.43, "duration": 3.61}, {"text": "Manhattan distance\nwould basically", "start": 2152.04, "duration": 1.46}, {"text": "say this is one, two,\nthree, four units away.", "start": 2153.5, "duration": 3.0}, {"text": "This is one, two,\nthree units away.", "start": 2156.5, "duration": 2.67}, {"text": "And under Manhattan\ndistance, this is closer,", "start": 2159.17, "duration": 2.85}, {"text": "this pairing is closer\nthan that pairing is.", "start": 2162.02, "duration": 3.827}, {"text": "Now you're used to\nthinking Euclidean.", "start": 2165.847, "duration": 1.583}, {"text": "We're going to use that.", "start": 2167.43, "duration": 0.79}, {"text": "But this is going\nto be important", "start": 2168.22, "duration": 1.375}, {"text": "when we think about how\nare we comparing distances", "start": 2169.595, "duration": 2.485}, {"text": "between these different pieces.", "start": 2172.08, "duration": 3.28}, {"text": "So typically, we'll\nuse Euclidean.", "start": 2175.36, "duration": 1.552}, {"text": "We're going to see Manhattan\nactually has some value.", "start": 2176.912, "duration": 2.208}, {"text": "So if I go back to my three\nexamples-- boy, that's", "start": 2179.12, "duration": 1.84}, {"text": "a gross slide, isn't it?", "start": 2180.96, "duration": 1.0}, {"text": "But there we go--", "start": 2181.96, "duration": 0.83}, {"text": "rattlesnake, boa\nconstrictor, and dart frog.", "start": 2182.79, "duration": 2.78}, {"text": "There is the representation.", "start": 2185.57, "duration": 1.3}, {"text": "I can ask, what's the\ndistance between them?", "start": 2186.87, "duration": 2.587}, {"text": "In the handout for today,\nwe've given you a little piece", "start": 2189.457, "duration": 2.333}, {"text": "of code that would do that.", "start": 2191.79, "duration": 1.124}, {"text": "And if I actually run\nthrough it, I get,", "start": 2192.914, "duration": 3.136}, {"text": "actually, a nice\nlittle result. Here", "start": 2196.05, "duration": 2.46}, {"text": "are the distances between those\nvectors using Euclidean metric.", "start": 2198.51, "duration": 4.689}, {"text": "I'm going to come back to them.", "start": 2203.199, "duration": 1.291}, {"text": "But you can see the\ntwo snakes, nicely, are", "start": 2204.49, "duration": 3.86}, {"text": "reasonably close to each other.", "start": 2208.35, "duration": 1.68}, {"text": "Whereas, the dart frog is a\nfair distance away from that.", "start": 2210.03, "duration": 4.19}, {"text": "Nice, right?", "start": 2214.22, "duration": 0.69}, {"text": "That's a nice separation\nthat says there's", "start": 2214.91, "duration": 1.83}, {"text": "a difference between these two.", "start": 2216.74, "duration": 1.74}, {"text": "OK.", "start": 2218.48, "duration": 1.74}, {"text": "Now I throw in the alligator.", "start": 2220.22, "duration": 2.94}, {"text": "Sounds like a Dungeons\n& Dragons game.", "start": 2223.16, "duration": 1.65}, {"text": "I throw in the alligator, and I\nwant to do the same comparison.", "start": 2224.81, "duration": 4.67}, {"text": "And I don't get nearly as nice\na result. Because now it says,", "start": 2229.48, "duration": 5.24}, {"text": "as before, the two snakes\nare close to each other.", "start": 2234.72, "duration": 4.6}, {"text": "But it says that the dart\nfrog and the alligator", "start": 2239.32, "duration": 2.38}, {"text": "are much closer, under\nthis measurement,", "start": 2241.7, "duration": 2.94}, {"text": "than either of them\nis to the other.", "start": 2244.64, "duration": 2.545}, {"text": "And to remind you, right,\nthe alligator and the two", "start": 2247.185, "duration": 3.035}, {"text": "snakes I would like to be close\nto one another and a distance", "start": 2250.22, "duration": 3.03}, {"text": "away from the frog.", "start": 2253.25, "duration": 1.39}, {"text": "Because I'm trying to\nclassify reptiles versus not.", "start": 2254.64, "duration": 3.83}, {"text": "So what happened here?", "start": 2258.47, "duration": 2.545}, {"text": "Well, this is a place where\nthe feature engineering", "start": 2261.015, "duration": 2.125}, {"text": "is going to be important.", "start": 2263.14, "duration": 1.5}, {"text": "Because in fact, the alligator\ndiffers from the frog", "start": 2264.64, "duration": 3.18}, {"text": "in three features.", "start": 2267.82, "duration": 1.3}, {"text": "And only in two features from,\nsay, the boa constrictor.", "start": 2271.81, "duration": 3.49}, {"text": "But one of those features\nis the number of legs.", "start": 2275.3, "duration": 2.29}, {"text": "And there, while\non the binary axes,", "start": 2277.59, "duration": 2.06}, {"text": "the difference is\nbetween a 0 and 1,", "start": 2279.65, "duration": 1.89}, {"text": "here it can be between 0 and 4.", "start": 2281.54, "duration": 4.08}, {"text": "So that is weighing the distance\na lot more than we would like.", "start": 2285.62, "duration": 3.48}, {"text": "The legs dimension is\ntoo large, if you like.", "start": 2289.1, "duration": 4.42}, {"text": "How would I fix this?", "start": 2293.52, "duration": 1.896}, {"text": "This is actually, I would\nargue, a natural place", "start": 2295.416, "duration": 2.604}, {"text": "to use Manhattan distance.", "start": 2298.02, "duration": 2.67}, {"text": "Why should I think\nthat the difference", "start": 2300.69, "duration": 1.83}, {"text": "in the number of legs or the\nnumber of legs difference", "start": 2302.52, "duration": 3.64}, {"text": "is more important than\nwhether it has scales or not?", "start": 2306.16, "duration": 4.24}, {"text": "Why should I think that\nmeasuring that distance", "start": 2310.4, "duration": 2.22}, {"text": "Euclidean-wise makes sense?", "start": 2312.62, "duration": 1.68}, {"text": "They are really completely\ndifferent measurements.", "start": 2314.3, "duration": 2.29}, {"text": "And in fact, I'm\nnot going to do it,", "start": 2316.59, "duration": 1.5}, {"text": "but if I ran Manhattan\nmetric on this,", "start": 2318.09, "duration": 1.79}, {"text": "it would get the alligator\nmuch closer to the snakes,", "start": 2319.88, "duration": 3.28}, {"text": "exactly because it differs only\nin two features, not three.", "start": 2323.16, "duration": 5.0}, {"text": "The other way I\ncould fix it would", "start": 2328.16, "duration": 1.74}, {"text": "be to say I'm letting too\nmuch weight be associated", "start": 2329.9, "duration": 2.61}, {"text": "with the difference\nin the number of legs.", "start": 2332.51, "duration": 1.92}, {"text": "So let's just make\nit a binary feature.", "start": 2334.43, "duration": 2.37}, {"text": "Either it doesn't have\nlegs or it does have legs.", "start": 2336.8, "duration": 3.51}, {"text": "Run the same classification.", "start": 2340.31, "duration": 2.73}, {"text": "And now you see the\nsnakes and the alligator", "start": 2343.04, "duration": 4.41}, {"text": "are all close to each other.", "start": 2347.45, "duration": 2.06}, {"text": "Whereas the dart frog, not\nas far away as it was before,", "start": 2349.51, "duration": 3.78}, {"text": "but there's a pretty natural\nseparation, especially", "start": 2353.29, "duration": 2.19}, {"text": "using that number between them.", "start": 2355.48, "duration": 2.97}, {"text": "What's my point?", "start": 2358.45, "duration": 1.73}, {"text": "Choice of features matters.", "start": 2360.18, "duration": 2.43}, {"text": "Throwing too many\nfeatures in may, in fact,", "start": 2362.61, "duration": 2.1}, {"text": "give us some overfitting.", "start": 2364.71, "duration": 2.74}, {"text": "And in particular,\ndeciding the weights", "start": 2367.45, "duration": 1.85}, {"text": "that I want on those\nfeatures has a real impact.", "start": 2369.3, "duration": 2.79}, {"text": "And you, as a designer\nor a programmer,", "start": 2372.09, "duration": 1.74}, {"text": "have a lot of influence in how\nyou think about using those.", "start": 2373.83, "duration": 3.51}, {"text": "So feature engineering\nreally matters.", "start": 2377.34, "duration": 1.59}, {"text": "How you pick the\nfeatures, what you use", "start": 2378.93, "duration": 1.68}, {"text": "is going to be important.", "start": 2380.61, "duration": 2.97}, {"text": "OK.", "start": 2383.58, "duration": 1.3}, {"text": "The last piece of\nthis then is we're", "start": 2384.88, "duration": 2.86}, {"text": "going to look at some examples\nwhere we give you data, got", "start": 2387.74, "duration": 3.63}, {"text": "features associated with them.", "start": 2391.37, "duration": 1.81}, {"text": "We're going to, in some\ncases have them labeled,", "start": 2393.18, "duration": 2.0}, {"text": "in other cases not.", "start": 2395.18, "duration": 0.94}, {"text": "And we know how now to\nthink about how do we", "start": 2396.12, "duration": 1.85}, {"text": "measure distances between them.", "start": 2397.97, "duration": 1.291}, {"text": "John.", "start": 2399.261, "duration": 1.164}, {"text": "JOHN GUTTAG: You\nprobably didn't intend", "start": 2400.425, "duration": 1.625}, {"text": "to say weights of features.", "start": 2402.05, "duration": 1.41}, {"text": "You intended to say\nhow they're scaled.", "start": 2403.46, "duration": 1.32}, {"text": "ERIC GRIMSON: Sorry.", "start": 2404.78, "duration": 0.21}, {"text": "The scales and not\nthe-- thank you, John.", "start": 2404.99, "duration": 1.54}, {"text": "No, I did.", "start": 2406.53, "duration": 0.499}, {"text": "I take that back.", "start": 2407.029, "duration": 0.821}, {"text": "I did not mean to say\nweights of features.", "start": 2407.85, "duration": 1.75}, {"text": "I meant to say the\nscale of the dimension", "start": 2409.6, "duration": 2.05}, {"text": "is going to be important here.", "start": 2411.65, "duration": 1.25}, {"text": "Thank you, for the\namplification and correction.", "start": 2412.9, "duration": 2.31}, {"text": "You're absolutely right.", "start": 2415.21, "duration": 1.0}, {"text": "JOHN GUTTAG: Weights, we\nuse in a different way,", "start": 2416.21, "duration": 1.872}, {"text": "as we'll see next time.", "start": 2418.082, "duration": 0.938}, {"text": "ERIC GRIMSON: And\nwe're going to see", "start": 2419.02, "duration": 0.57}, {"text": "next time why we're going to\nuse weights in different ways.", "start": 2419.59, "duration": 1.86}, {"text": "So rephrase it.", "start": 2421.45, "duration": 0.954}, {"text": "Block that out of your mind.", "start": 2422.404, "duration": 1.166}, {"text": "We're going to talk about\nscales and the scale on the axes", "start": 2423.57, "duration": 2.5}, {"text": "as being important here.", "start": 2426.07, "duration": 1.466}, {"text": "And we already said\nwe're going to look", "start": 2427.536, "duration": 1.624}, {"text": "at two different\nkinds of learning,", "start": 2429.16, "duration": 2.58}, {"text": "labeled and unlabeled,\nclustering and classifying.", "start": 2431.74, "duration": 3.18}, {"text": "And I want to just\nfinish up by showing you", "start": 2434.92, "duration": 2.61}, {"text": "two examples of that.", "start": 2437.53, "duration": 1.41}, {"text": "How we would think about\nthem algorithmically,", "start": 2438.94, "duration": 2.37}, {"text": "and we'll look at them\nin more detail next time.", "start": 2441.31, "duration": 2.694}, {"text": "As we look at it,\nI want to remind", "start": 2444.004, "duration": 1.416}, {"text": "you the things that are\ngoing to be important to you.", "start": 2445.42, "duration": 3.11}, {"text": "How do I measure distance\nbetween examples?", "start": 2448.53, "duration": 2.4}, {"text": "What's the right\nway to design that?", "start": 2450.93, "duration": 2.13}, {"text": "What is the right set of\nfeatures to use in that vector?", "start": 2453.06, "duration": 4.0}, {"text": "And then, what constraints do\nI want to put on the model?", "start": 2457.06, "duration": 4.46}, {"text": "In the case of\nunlabelled data, how", "start": 2461.52, "duration": 1.5}, {"text": "do I decide how many\nclusters I want to have?", "start": 2463.02, "duration": 3.404}, {"text": "Because I can give you a really\neasy way to do clustering.", "start": 2466.424, "duration": 2.416}, {"text": "If I give you 100 examples,\nI say build 100 clusters.", "start": 2468.84, "duration": 3.27}, {"text": "Every example is\nits own cluster.", "start": 2472.11, "duration": 2.14}, {"text": "Distance is really good.", "start": 2474.25, "duration": 1.22}, {"text": "It's really close to itself,\nbut it does a lousy job", "start": 2475.47, "duration": 2.64}, {"text": "of labeling things on it.", "start": 2478.11, "duration": 1.13}, {"text": "So I have to think\nabout, how do I", "start": 2479.24, "duration": 1.416}, {"text": "decide how many clusters,\nwhat's the complexity", "start": 2480.656, "duration": 2.87}, {"text": "of that separating service?", "start": 2483.526, "duration": 1.124}, {"text": "How do I basically avoid\nthe overfitting problem,", "start": 2484.65, "duration": 3.06}, {"text": "which I don't want to have?", "start": 2487.71, "duration": 3.13}, {"text": "So just to remind\nyou, we've already", "start": 2490.84, "duration": 2.01}, {"text": "seen a little version of\nthis, the clustering method.", "start": 2492.85, "duration": 3.39}, {"text": "This is a standard way to\ndo it, simply repeating what", "start": 2496.24, "duration": 3.036}, {"text": "we had on an earlier slide.", "start": 2499.276, "duration": 1.124}, {"text": "If I want to cluster\nit into groups,", "start": 2500.4, "duration": 2.02}, {"text": "I start by saying how many\nclusters am I looking for?", "start": 2502.42, "duration": 2.99}, {"text": "Pick an example I take as\nmy early representation.", "start": 2505.41, "duration": 3.18}, {"text": "For every other example\nin the training data,", "start": 2508.59, "duration": 2.05}, {"text": "put it to the closest cluster.", "start": 2510.64, "duration": 2.57}, {"text": "Once I've got those, find the\nmedian, repeat the process.", "start": 2513.21, "duration": 3.87}, {"text": "And that led to that separation.", "start": 2517.08, "duration": 4.74}, {"text": "Now once I've got it,\nI like to validate it.", "start": 2521.82, "duration": 2.11}, {"text": "And in fact, I should\nhave said this better.", "start": 2523.93, "duration": 1.85}, {"text": "Those two clusters came without\nlooking at the two black dots.", "start": 2525.78, "duration": 4.2}, {"text": "Once I put the\nblack dots in, I'd", "start": 2529.98, "duration": 1.65}, {"text": "like to validate, how well\ndoes this really work?", "start": 2531.63, "duration": 2.88}, {"text": "And that example there is\nreally not very encouraging.", "start": 2534.51, "duration": 3.27}, {"text": "It's too close.", "start": 2537.78, "duration": 1.81}, {"text": "So that's a natural place to\nsay, OK, what if I did this", "start": 2539.59, "duration": 2.43}, {"text": "with three clusters?", "start": 2542.02, "duration": 3.34}, {"text": "That's what I get.", "start": 2545.36, "duration": 2.61}, {"text": "I like the that.", "start": 2547.97, "duration": 1.27}, {"text": "All right?", "start": 2549.24, "duration": 0.62}, {"text": "That has a really\nnice cluster up here.", "start": 2549.86, "duration": 3.6}, {"text": "The fact that the algorithm\ndidn't know the labeling", "start": 2553.46, "duration": 2.17}, {"text": "is irrelevant.", "start": 2555.63, "duration": 0.583}, {"text": "There's a nice grouping of five.", "start": 2556.213, "duration": 1.507}, {"text": "There's a nice grouping of four.", "start": 2557.72, "duration": 1.99}, {"text": "And there's a nice grouping\nof three in between.", "start": 2559.71, "duration": 2.91}, {"text": "And in fact, if I looked\nat the average distance", "start": 2562.62, "duration": 3.36}, {"text": "between examples in\neach of these clusters,", "start": 2565.98, "duration": 2.22}, {"text": "it is much tighter\nthan in that example.", "start": 2568.2, "duration": 4.24}, {"text": "And so that leads to, then,\nthe question of should I", "start": 2572.44, "duration": 4.11}, {"text": "look for four clusters?", "start": 2576.55, "duration": 1.092}, {"text": "Question, please.", "start": 2577.642, "duration": 0.708}, {"text": "AUDIENCE: Is that overlap\nbetween the two clusters", "start": 2578.35, "duration": 2.67}, {"text": "not an issue?", "start": 2581.02, "duration": 0.67}, {"text": "ERIC GRIMSON: Yes.", "start": 2581.69, "duration": 0.75}, {"text": "The question is, is the overlap\nbetween the two clusters", "start": 2582.44, "duration": 2.16}, {"text": "a problem?", "start": 2584.6, "duration": 0.499}, {"text": "No.", "start": 2585.099, "duration": 0.725}, {"text": "I just drew it\nhere so I could let", "start": 2585.824, "duration": 1.416}, {"text": "you see where those pieces are.", "start": 2587.24, "duration": 1.77}, {"text": "But in fact, if you like,\nthe center is there.", "start": 2589.01, "duration": 4.08}, {"text": "Those three points are\nall closer to that center", "start": 2593.09, "duration": 2.46}, {"text": "than they are to that center.", "start": 2595.55, "duration": 1.23}, {"text": "So the fact that they\noverlap is a good question.", "start": 2596.78, "duration": 1.48}, {"text": "It's just the way I\nhappened to draw them.", "start": 2598.26, "duration": 1.76}, {"text": "I should really\ndraw these, not as", "start": 2600.02, "duration": 1.47}, {"text": "circles, but as some little\nbit more convoluted surface.", "start": 2601.49, "duration": 3.614}, {"text": "OK?", "start": 2605.104, "duration": 0.946}, {"text": "Having done three, I could\nsay should I look for four?", "start": 2606.05, "duration": 2.85}, {"text": "Well, those points down\nthere, as I've already said,", "start": 2608.9, "duration": 3.019}, {"text": "are an example where\nit's going to be", "start": 2611.919, "duration": 1.541}, {"text": "hard to separate them out.", "start": 2613.46, "duration": 1.29}, {"text": "And I don't want to overfit.", "start": 2614.75, "duration": 1.17}, {"text": "Because the only way\nto separate those out", "start": 2615.92, "duration": 1.8}, {"text": "is going to be to come up with\na really convoluted cluster,", "start": 2617.72, "duration": 3.18}, {"text": "which I don't like.", "start": 2620.9, "duration": 1.05}, {"text": "All right?", "start": 2621.95, "duration": 1.63}, {"text": "Let me finish with showing\nyou one other example", "start": 2623.58, "duration": 2.9}, {"text": "from the other direction.", "start": 2626.48, "duration": 1.17}, {"text": "Which is, suppose I give\nyou labeled examples.", "start": 2627.65, "duration": 4.36}, {"text": "So again, the goal\nis I've got features", "start": 2632.01, "duration": 2.19}, {"text": "associated with each example.", "start": 2634.2, "duration": 1.27}, {"text": "They're going to have\nmultiple dimensions on it.", "start": 2635.47, "duration": 2.0}, {"text": "But I also know the label\nassociated with them.", "start": 2637.47, "duration": 1.98}, {"text": "And I want to learn\nwhat is the best", "start": 2639.45, "duration": 2.43}, {"text": "way to come up with a rule that\nwill let me take new examples", "start": 2641.88, "duration": 2.88}, {"text": "and assign them to\nthe right group.", "start": 2644.76, "duration": 2.541}, {"text": "A number of ways to do this.", "start": 2647.301, "duration": 1.609}, {"text": "You can simply say I'm looking\nfor the simplest surface that", "start": 2648.91, "duration": 3.11}, {"text": "will separate those examples.", "start": 2652.02, "duration": 1.907}, {"text": "In my football case that\nwere in the plane, what's", "start": 2653.927, "duration": 2.083}, {"text": "the best line that\nseparates them,", "start": 2656.01, "duration": 1.65}, {"text": "which turns out to be easy.", "start": 2657.66, "duration": 1.95}, {"text": "I might look for a more\ncomplicated surface.", "start": 2659.61, "duration": 2.115}, {"text": "And we're going to see\nan example in a second", "start": 2661.725, "duration": 1.875}, {"text": "where maybe it's a\nsequence of line segments", "start": 2663.6, "duration": 2.661}, {"text": "that separates them out.", "start": 2666.261, "duration": 0.999}, {"text": "Because there's not just one\nline that does the separation.", "start": 2667.26, "duration": 3.66}, {"text": "As before, I want to be careful.", "start": 2670.92, "duration": 1.87}, {"text": "If I make it too\ncomplicated, I may", "start": 2672.79, "duration": 1.58}, {"text": "get a really good separator,\nbut I overfit to the data.", "start": 2674.37, "duration": 3.684}, {"text": "And you're going\nto see next time.", "start": 2678.054, "duration": 1.416}, {"text": "I'm going to just\nhighlight it here.", "start": 2679.47, "duration": 1.05}, {"text": "There's a third\nway, which will lead", "start": 2680.52, "duration": 1.499}, {"text": "to almost the same\nkind of result", "start": 2682.019, "duration": 1.891}, {"text": "called k nearest neighbors.", "start": 2683.91, "duration": 2.25}, {"text": "And the idea here is I've\ngot a set of labeled data.", "start": 2686.16, "duration": 3.39}, {"text": "And what I'm going to do\nis, for every new example,", "start": 2689.55, "duration": 2.55}, {"text": "say find the k, say the five\nclosest labeled examples.", "start": 2692.1, "duration": 5.15}, {"text": "And take a vote.", "start": 2697.25, "duration": 1.35}, {"text": "If 3 out of 5 or 4 out of 5\nor 5 out of 5 of those labels", "start": 2698.6, "duration": 3.27}, {"text": "are the same, I'm going to\nsay it's part of that group.", "start": 2701.87, "duration": 2.735}, {"text": "And if I have less\nthan that, I'm", "start": 2704.605, "duration": 1.375}, {"text": "going to leave it\nas unclassified.", "start": 2705.98, "duration": 1.53}, {"text": "And that's a nice way\nof actually thinking", "start": 2707.51, "duration": 1.749}, {"text": "about how to learn them.", "start": 2709.259, "duration": 1.611}, {"text": "And let me just finish by\nshowing you an example.", "start": 2710.87, "duration": 2.07}, {"text": "Now I won't use football\nplayers on this one.", "start": 2712.94, "duration": 1.874}, {"text": "I'll use a different example.", "start": 2714.814, "duration": 2.566}, {"text": "I'm going to give\nyou some voting data.", "start": 2717.38, "duration": 2.64}, {"text": "I think this is\nactually simulated data.", "start": 2720.02, "duration": 1.78}, {"text": "But these are a set of\nvoters in the United States", "start": 2721.8, "duration": 4.174}, {"text": "with their preference.", "start": 2725.974, "duration": 0.916}, {"text": "They tend to vote Republican.", "start": 2726.89, "duration": 1.246}, {"text": "They tend to vote Democrat.", "start": 2728.136, "duration": 1.124}, {"text": "And the two categories are\ntheir age and how far away", "start": 2729.26, "duration": 3.54}, {"text": "they live from Boston.", "start": 2732.8, "duration": 1.641}, {"text": "Whether those are relevant\nor not, I don't know,", "start": 2734.441, "duration": 1.999}, {"text": "but they are just two things I'm\ngoing to use to classify them.", "start": 2736.44, "duration": 2.624}, {"text": "And I'd like to say,\nhow would I fit a curve", "start": 2739.064, "duration": 2.686}, {"text": "to separate those two classes?", "start": 2741.75, "duration": 4.36}, {"text": "I'm going to keep\nhalf the data to test.", "start": 2746.11, "duration": 2.58}, {"text": "I'm going to use half\nthe data to train.", "start": 2748.69, "duration": 2.22}, {"text": "So if this is my\ntraining data, I", "start": 2750.91, "duration": 1.68}, {"text": "can say what's the best\nline that separates these?", "start": 2752.59, "duration": 4.45}, {"text": "I don't know about best,\nbut here are two examples.", "start": 2757.04, "duration": 3.16}, {"text": "This solid line has the\nproperty that all the Democrats", "start": 2760.2, "duration": 3.68}, {"text": "are on one side.", "start": 2763.88, "duration": 1.74}, {"text": "Everything on the other\nside is a Republican,", "start": 2765.62, "duration": 1.92}, {"text": "but there are some Republicans\non this side of the line.", "start": 2767.54, "duration": 2.46}, {"text": "I can't find a line that\ncompletely separates these,", "start": 2770.0, "duration": 2.31}, {"text": "as I did with the\nfootball players.", "start": 2772.31, "duration": 1.95}, {"text": "But there is a decent\nline to separate them.", "start": 2774.26, "duration": 3.399}, {"text": "Here's another candidate.", "start": 2777.659, "duration": 1.041}, {"text": "That dash line has the\nproperty that on the right side", "start": 2778.7, "duration": 3.995}, {"text": "you've got-- boy, I don't\nthink this is deliberate,", "start": 2782.695, "duration": 2.125}, {"text": "John, right-- but\non the right side,", "start": 2784.82, "duration": 1.66}, {"text": "you've got almost\nall Republicans.", "start": 2786.48, "duration": 1.715}, {"text": "It seems perfectly appropriate.", "start": 2788.195, "duration": 2.535}, {"text": "One Democrat, but there's a\npretty good separation there.", "start": 2790.73, "duration": 3.27}, {"text": "And on the left side,\nyou've got a mix of things.", "start": 2794.0, "duration": 2.13}, {"text": "But most of the Democrats are\non the left side of that line.", "start": 2796.13, "duration": 3.85}, {"text": "All right?", "start": 2799.98, "duration": 0.5}, {"text": "The fact that left\nand right correlates", "start": 2800.48, "duration": 1.624}, {"text": "with distance from Boston is\ncompletely irrelevant here.", "start": 2802.104, "duration": 2.366}, {"text": "But it has a nice punch to it.", "start": 2804.47, "duration": 2.15}, {"text": "JOHN GUTTAG: Relevant,\nbut not accidental.", "start": 2806.62, "duration": 1.75}, {"text": "ERIC GRIMSON: But\nnot accidental.", "start": 2808.37, "duration": 1.375}, {"text": "Thank you.", "start": 2809.745, "duration": 0.825}, {"text": "All right.", "start": 2810.57, "duration": 0.5}, {"text": "So now the question is,\nhow would I evaluate these?", "start": 2811.07, "duration": 2.124}, {"text": "How do I decide\nwhich one is better?", "start": 2813.194, "duration": 2.112}, {"text": "And I'm simply\ngoing to show you,", "start": 2815.306, "duration": 1.374}, {"text": "very quickly, some examples.", "start": 2816.68, "duration": 2.2}, {"text": "First one is to look at what's\ncalled the confusion matrix.", "start": 2818.88, "duration": 3.867}, {"text": "What does that mean?", "start": 2822.747, "duration": 0.833}, {"text": "It says for this, one of\nthese classifiers for example,", "start": 2823.58, "duration": 3.51}, {"text": "the solid line.", "start": 2827.09, "duration": 0.67}, {"text": "Here are the predictions,\nbased on the solid line", "start": 2827.76, "duration": 2.5}, {"text": "of whether they would\nbe more likely to be", "start": 2830.26, "duration": 1.75}, {"text": "Democrat or Republican.", "start": 2832.01, "duration": 1.53}, {"text": "And here is the actual label.", "start": 2833.54, "duration": 2.55}, {"text": "Same thing for the dashed line.", "start": 2836.09, "duration": 1.32}, {"text": "And that diagonal is\nimportant because those are", "start": 2837.41, "duration": 3.87}, {"text": "the correctly labeled results.", "start": 2841.28, "duration": 2.46}, {"text": "Right?", "start": 2843.74, "duration": 0.8}, {"text": "It correctly, in\nthe solid line case,", "start": 2844.54, "duration": 2.92}, {"text": "gets all of the correct\nlabelings of the Democrats.", "start": 2847.46, "duration": 2.94}, {"text": "It gets half of the\nRepublicans right.", "start": 2850.4, "duration": 1.68}, {"text": "But it has some where\nit's actually Republican,", "start": 2852.08, "duration": 3.0}, {"text": "but it labels it as a Democrat.", "start": 2855.08, "duration": 2.62}, {"text": "That, we'd like to\nbe really large.", "start": 2857.7, "duration": 2.88}, {"text": "And in fact, it leads\nto a natural measure", "start": 2860.58, "duration": 2.49}, {"text": "called the accuracy.", "start": 2863.07, "duration": 1.81}, {"text": "Which is, just to\ngo back to that,", "start": 2864.88, "duration": 1.64}, {"text": "we say that these\nare true positives.", "start": 2866.52, "duration": 2.13}, {"text": "Meaning, I labeled it as being\nan instance, and it really is.", "start": 2868.65, "duration": 3.42}, {"text": "These are true negatives.", "start": 2872.07, "duration": 1.26}, {"text": "I label it as not being an\ninstance, and it really isn't.", "start": 2873.33, "duration": 3.0}, {"text": "And then these are\nthe false positives.", "start": 2876.33, "duration": 3.12}, {"text": "I labeled it as being an\ninstance and it's not,", "start": 2879.45, "duration": 1.974}, {"text": "and these are the\nfalse negatives.", "start": 2881.424, "duration": 1.416}, {"text": "I labeled it as not being\nan instance, and it is.", "start": 2882.84, "duration": 2.84}, {"text": "And an easy way to measure it\nis to look at the correct labels", "start": 2885.68, "duration": 3.94}, {"text": "over all of the labels.", "start": 2889.62, "duration": 1.67}, {"text": "The true positives and\nthe true negatives,", "start": 2891.29, "duration": 1.75}, {"text": "the ones I got right.", "start": 2893.04, "duration": 1.78}, {"text": "And in that case, both models\ncome up with a value of 0.7.", "start": 2894.82, "duration": 5.042}, {"text": "So which one is better?", "start": 2899.862, "duration": 0.958}, {"text": "Well, I should validate that.", "start": 2900.82, "duration": 1.08}, {"text": "And I'm going to\ndo that in a second", "start": 2901.9, "duration": 1.499}, {"text": "by looking at other data.", "start": 2903.399, "duration": 2.112}, {"text": "We could also ask,\ncould we find something", "start": 2905.511, "duration": 1.749}, {"text": "with less training error?", "start": 2907.26, "duration": 1.4}, {"text": "This is only getting 70% right.", "start": 2908.66, "duration": 2.65}, {"text": "Not great.", "start": 2911.31, "duration": 1.94}, {"text": "Well, here is a more\ncomplicated model.", "start": 2913.25, "duration": 2.442}, {"text": "And this is where\nyou start getting", "start": 2915.692, "duration": 1.458}, {"text": "worried about overfitting.", "start": 2917.15, "duration": 0.99}, {"text": "Now what I've done,\nis I've come up", "start": 2918.14, "duration": 1.458}, {"text": "with a sequence of lines\nthat separate them.", "start": 2919.598, "duration": 2.832}, {"text": "So everything above this\nline, I'm going to say", "start": 2922.43, "duration": 2.83}, {"text": "is a Republican.", "start": 2925.26, "duration": 0.82}, {"text": "Everything below this line,\nI'm going to say is a Democrat.", "start": 2926.08, "duration": 2.83}, {"text": "So I'm avoiding that one.", "start": 2928.91, "duration": 1.44}, {"text": "I'm avoiding that one.", "start": 2930.35, "duration": 0.96}, {"text": "I'm still capturing\nmany of the same things.", "start": 2931.31, "duration": 3.03}, {"text": "And in this case, I get 12 true\npositives, 13 true negatives,", "start": 2934.34, "duration": 4.8}, {"text": "and only 5 false positives.", "start": 2939.14, "duration": 2.861}, {"text": "And that's kind of nice.", "start": 2942.001, "duration": 0.999}, {"text": "You can see the 5.", "start": 2943.0, "duration": 0.79}, {"text": "It's those five red\nones down there.", "start": 2943.79, "duration": 2.25}, {"text": "It's accuracy is 0.833.", "start": 2946.04, "duration": 3.32}, {"text": "And now, if I apply that to the\ntest data, I get an OK result.", "start": 2949.36, "duration": 6.236}, {"text": "It has an accuracy of about 0.6.", "start": 2955.596, "duration": 3.844}, {"text": "I could use this idea to try\nand generalize to say could I", "start": 2959.44, "duration": 2.49}, {"text": "come up with a better model.", "start": 2961.93, "duration": 1.17}, {"text": "And you're going to\nsee that next time.", "start": 2963.1, "duration": 2.76}, {"text": "There could be other ways\nin which I measure this.", "start": 2965.86, "duration": 2.19}, {"text": "And I want to use this\nas the last example.", "start": 2968.05, "duration": 1.81}, {"text": "Another good measure we use is\ncalled PPV, Positive Predictive", "start": 2969.86, "duration": 4.88}, {"text": "Value which is how many true\npositives do I come up with out", "start": 2974.74, "duration": 4.55}, {"text": "of all the things I\nlabeled positively.", "start": 2979.29, "duration": 3.29}, {"text": "And in this solid model,\nin the dashed line,", "start": 2982.58, "duration": 3.05}, {"text": "I can get values about 0.57.", "start": 2985.63, "duration": 2.49}, {"text": "The complex model on the\ntraining data is better.", "start": 2988.12, "duration": 2.38}, {"text": "And then the testing\ndata is even stronger.", "start": 2990.5, "duration": 3.46}, {"text": "And finally, two other\nexamples are called", "start": 2993.96, "duration": 1.86}, {"text": "sensitivity and specificity.", "start": 2995.82, "duration": 3.03}, {"text": "Sensitivity basically\ntells you what percentage", "start": 2998.85, "duration": 2.64}, {"text": "did I correctly find.", "start": 3001.49, "duration": 2.12}, {"text": "And specificity\nsaid what percentage", "start": 3003.61, "duration": 1.9}, {"text": "did I correctly reject.", "start": 3005.51, "duration": 2.19}, {"text": "And I show you this\nbecause this is", "start": 3007.7, "duration": 1.59}, {"text": "where the trade-off comes in.", "start": 3009.29, "duration": 2.95}, {"text": "If sensitivity is how\nmany did I correctly", "start": 3012.24, "duration": 1.97}, {"text": "label out of those\nthat I both correctly", "start": 3014.21, "duration": 2.19}, {"text": "labeled and incorrectly\nlabeled as being negative,", "start": 3016.4, "duration": 3.982}, {"text": "how many them did\nI correctly label", "start": 3020.382, "duration": 1.458}, {"text": "as being the kind that I want?", "start": 3021.84, "duration": 2.14}, {"text": "I can make sensitivity 1.", "start": 3023.98, "duration": 3.33}, {"text": "Label everything is the\nthing I'm looking for.", "start": 3027.31, "duration": 2.78}, {"text": "Great.", "start": 3030.09, "duration": 0.62}, {"text": "Everything is correct.", "start": 3030.71, "duration": 1.43}, {"text": "But the specificity will be 0.", "start": 3032.14, "duration": 3.6}, {"text": "Because I'll have a bunch of\nthings incorrectly labeled.", "start": 3035.74, "duration": 3.28}, {"text": "I could make the specificity\n1, reject everything.", "start": 3039.02, "duration": 4.44}, {"text": "Say nothing as an instance.", "start": 3043.46, "duration": 1.95}, {"text": "True negatives goes to 1, and\nI'm in a great place there,", "start": 3045.41, "duration": 6.66}, {"text": "but my sensitivity goes to 0.", "start": 3052.07, "duration": 3.1}, {"text": "I've got a trade-off.", "start": 3055.17, "duration": 0.96}, {"text": "As I think about the machine\nlearning algorithm I'm using", "start": 3056.13, "duration": 2.55}, {"text": "and my choice of\nthat classifier,", "start": 3058.68, "duration": 2.484}, {"text": "I'm going to see\na trade off where", "start": 3061.164, "duration": 1.416}, {"text": "I can increase specificity at\nthe cost of sensitivity or vice", "start": 3062.58, "duration": 4.68}, {"text": "versa.", "start": 3067.26, "duration": 1.05}, {"text": "And you'll see a nice technique\ncalled ROC or Receiver Operator", "start": 3068.31, "duration": 3.12}, {"text": "Curve that gives you a sense of\nhow you want to deal with that.", "start": 3071.43, "duration": 3.146}, {"text": "And with that, we'll\nsee you next time.", "start": 3074.576, "duration": 1.624}, {"text": "We'll take your\nquestion off line", "start": 3076.2, "duration": 0.98}, {"text": "if you don't mind, because\nI've run over time.", "start": 3077.18, "duration": 1.5}, {"text": "But we'll see you next\ntime where Professor Guttag", "start": 3078.68, "duration": 2.083}, {"text": "will show you examples of this.", "start": 3080.763, "duration": 2.167}]