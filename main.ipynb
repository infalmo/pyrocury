{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt\n",
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import symbl\n",
    "\n",
    "def symbl_get_topics(text: str, video_id: str | None):\n",
    "    \"\"\"Gets (abstract) topics keywords\"\"\"\n",
    "\n",
    "    conversation_object = symbl.Text.process({\n",
    "        \"name\": video_id,\n",
    "        \"messages\": [{\"payload\": {\"content\": text}}] \n",
    "    }, wait=True)\n",
    "\n",
    "    data = conversation_object.get_topics()\n",
    "    return [x[\"text\"] for x in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import textacy\n",
    "from textacy.extract import keyterms\n",
    "from textacy import text_stats\n",
    "\n",
    "\n",
    "def add_topics(data: dict):\n",
    "    \"\"\"Parses and adds topics to the video data\"\"\"\n",
    "\n",
    "    # Ignore the first segment, usually introduction.\n",
    "    txt = \" \".join([x[\"text\"] for x in data[\"transcript\"][1:]]).lower()\n",
    "\n",
    "    try:\n",
    "        # TODO: The secret is that this always panics, so it's never used.\n",
    "        # topics = symbl_get_topics(txt, data[\"video_id\"])\n",
    "        raise RuntimeError()\n",
    "\n",
    "    except:\n",
    "        doc = textacy.make_spacy_doc(txt, lang=\"en_core_web_sm\")\n",
    "        topics = keyterms.textrank(doc, normalize=\"lemma\", topn=20)\n",
    "\n",
    "    if \"metadata\" not in data:\n",
    "        data[\"metadata\"] = {}\n",
    "    data[\"metadata\"][\"topics\"] = topics\n",
    "\n",
    "def add_misc_readability(data: dict):\n",
    "    \n",
    "    readability = []\n",
    "\n",
    "    for ts in data[\"transcript\"]:\n",
    "        doc = textacy.make_spacy_doc(ts[\"text\"], lang=\"en_core_web_sm\")\n",
    "        readability.append(text_stats.flesch_kincaid_grade_level(doc))\n",
    "\n",
    "    if \"metadata\" not in data:\n",
    "        data[\"metadata\"] = {}\n",
    "    data[\"metadata\"][\"readability\"] = readability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "\n",
    "def main():\n",
    "    data = json.load(open(\"testdata.json\"))\n",
    "    for subdata in data:\n",
    "        del subdata[\"metadata\"][\"entropy\"]\n",
    "    json.dump(data, open(\"new_testdata.json\", \"w+\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f946df053fbf2b937619d3c5458e7af74262f9a954d8797ba0b27400bcafe06"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
